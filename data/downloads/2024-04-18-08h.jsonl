{"created":"2024-04-17 17:59:59","title":"Factorized Diffusion: Perceptual Illusions by Noise Decomposition","abstract":"Given a factorization of an image into a sum of linear components, we present a zero-shot method to control each individual component through diffusion model sampling. For example, we can decompose an image into low and high spatial frequencies and condition these components on different text prompts. This produces hybrid images, which change appearance depending on viewing distance. By decomposing an image into three frequency subbands, we can generate hybrid images with three prompts. We also use a decomposition into grayscale and color components to produce images whose appearance changes when they are viewed in grayscale, a phenomena that naturally occurs under dim lighting. And we explore a decomposition by a motion blur kernel, which produces images that change appearance under motion blurring. Our method works by denoising with a composite noise estimate, built from the components of noise estimates conditioned on different prompts. We also show that for certain decompositions, our method recovers prior approaches to compositional generation and spatial control. Finally, we show that we can extend our approach to generate hybrid images from real images. We do this by holding one component fixed and generating the remaining components, effectively solving an inverse problem.","sentences":["Given a factorization of an image into a sum of linear components, we present a zero-shot method to control each individual component through diffusion model sampling.","For example, we can decompose an image into low and high spatial frequencies and condition these components on different text prompts.","This produces hybrid images, which change appearance depending on viewing distance.","By decomposing an image into three frequency subbands, we can generate hybrid images with three prompts.","We also use a decomposition into grayscale and color components to produce images whose appearance changes when they are viewed in grayscale, a phenomena that naturally occurs under dim lighting.","And we explore a decomposition by a motion blur kernel, which produces images that change appearance under motion blurring.","Our method works by denoising with a composite noise estimate, built from the components of noise estimates conditioned on different prompts.","We also show that for certain decompositions, our method recovers prior approaches to compositional generation and spatial control.","Finally, we show that we can extend our approach to generate hybrid images from real images.","We do this by holding one component fixed and generating the remaining components, effectively solving an inverse problem."],"url":"http://arxiv.org/abs/2404.11615v1"}
{"created":"2024-04-17 17:59:55","title":"Dynamic Typography: Bringing Words to Life","abstract":"Text animation serves as an expressive medium, transforming static communication into dynamic experiences by infusing words with motion to evoke emotions, emphasize meanings, and construct compelling narratives. Crafting animations that are semantically aware poses significant challenges, demanding expertise in graphic design and animation. We present an automated text animation scheme, termed \"Dynamic Typography\", which combines two challenging tasks. It deforms letters to convey semantic meaning and infuses them with vibrant movements based on user prompts. Our technique harnesses vector graphics representations and an end-to-end optimization-based framework. This framework employs neural displacement fields to convert letters into base shapes and applies per-frame motion, encouraging coherence with the intended textual concept. Shape preservation techniques and perceptual loss regularization are employed to maintain legibility and structural integrity throughout the animation process. We demonstrate the generalizability of our approach across various text-to-video models and highlight the superiority of our end-to-end methodology over baseline methods, which might comprise separate tasks. Through quantitative and qualitative evaluations, we demonstrate the effectiveness of our framework in generating coherent text animations that faithfully interpret user prompts while maintaining readability. Our code is available at: https://animate-your-word.github.io/demo/.","sentences":["Text animation serves as an expressive medium, transforming static communication into dynamic experiences by infusing words with motion to evoke emotions, emphasize meanings, and construct compelling narratives.","Crafting animations that are semantically aware poses significant challenges, demanding expertise in graphic design and animation.","We present an automated text animation scheme, termed \"Dynamic Typography\", which combines two challenging tasks.","It deforms letters to convey semantic meaning and infuses them with vibrant movements based on user prompts.","Our technique harnesses vector graphics representations and an end-to-end optimization-based framework.","This framework employs neural displacement fields to convert letters into base shapes and applies per-frame motion, encouraging coherence with the intended textual concept.","Shape preservation techniques and perceptual loss regularization are employed to maintain legibility and structural integrity throughout the animation process.","We demonstrate the generalizability of our approach across various text-to-video models and highlight the superiority of our end-to-end methodology over baseline methods, which might comprise separate tasks.","Through quantitative and qualitative evaluations, we demonstrate the effectiveness of our framework in generating coherent text animations that faithfully interpret user prompts while maintaining readability.","Our code is available at: https://animate-your-word.github.io/demo/."],"url":"http://arxiv.org/abs/2404.11614v1"}
{"created":"2024-04-17 17:59:53","title":"InFusion: Inpainting 3D Gaussians via Learning Depth Completion from Diffusion Prior","abstract":"3D Gaussians have recently emerged as an efficient representation for novel view synthesis. This work studies its editability with a particular focus on the inpainting task, which aims to supplement an incomplete set of 3D Gaussians with additional points for visually harmonious rendering. Compared to 2D inpainting, the crux of inpainting 3D Gaussians is to figure out the rendering-relevant properties of the introduced points, whose optimization largely benefits from their initial 3D positions. To this end, we propose to guide the point initialization with an image-conditioned depth completion model, which learns to directly restore the depth map based on the observed image. Such a design allows our model to fill in depth values at an aligned scale with the original depth, and also to harness strong generalizability from largescale diffusion prior. Thanks to the more accurate depth completion, our approach, dubbed InFusion, surpasses existing alternatives with sufficiently better fidelity and efficiency under various complex scenarios. We further demonstrate the effectiveness of InFusion with several practical applications, such as inpainting with user-specific texture or with novel object insertion.","sentences":["3D Gaussians have recently emerged as an efficient representation for novel view synthesis.","This work studies its editability with a particular focus on the inpainting task, which aims to supplement an incomplete set of 3D Gaussians with additional points for visually harmonious rendering.","Compared to 2D inpainting, the crux of inpainting 3D Gaussians is to figure out the rendering-relevant properties of the introduced points, whose optimization largely benefits from their initial 3D positions.","To this end, we propose to guide the point initialization with an image-conditioned depth completion model, which learns to directly restore the depth map based on the observed image.","Such a design allows our model to fill in depth values at an aligned scale with the original depth, and also to harness strong generalizability from largescale diffusion prior.","Thanks to the more accurate depth completion, our approach, dubbed InFusion, surpasses existing alternatives with sufficiently better fidelity and efficiency under various complex scenarios.","We further demonstrate the effectiveness of InFusion with several practical applications, such as inpainting with user-specific texture or with novel object insertion."],"url":"http://arxiv.org/abs/2404.11613v1"}
{"created":"2024-04-17 17:55:27","title":"Private federated discovery of out-of-vocabulary words for Gboard","abstract":"The vocabulary of language models in Gboard, Google's keyboard application, plays a crucial role for improving user experience. One way to improve the vocabulary is to discover frequently typed out-of-vocabulary (OOV) words on user devices. This task requires strong privacy protection due to the sensitive nature of user input data. In this report, we present a private OOV discovery algorithm for Gboard, which builds on recent advances in private federated analytics. The system offers local differential privacy (LDP) guarantees for user contributed words. With anonymous aggregation, the final released words satisfy central differential privacy guarantees with $\\epsilon = 0.315, \\delta = 10^{-10}$ for OOV discovery in en-US (English in United States).","sentences":["The vocabulary of language models in Gboard, Google's keyboard application, plays a crucial role for improving user experience.","One way to improve the vocabulary is to discover frequently typed out-of-vocabulary (OOV) words on user devices.","This task requires strong privacy protection due to the sensitive nature of user input data.","In this report, we present a private OOV discovery algorithm for Gboard, which builds on recent advances in private federated analytics.","The system offers local differential privacy (LDP) guarantees for user contributed words.","With anonymous aggregation, the final released words satisfy central differential privacy guarantees with $\\epsilon = 0.315, \\delta = 10^{-10}$ for OOV discovery in en-US (English in United States)."],"url":"http://arxiv.org/abs/2404.11607v1"}
{"created":"2024-04-17 17:55:17","title":"Learning to Solve the Constrained Most Probable Explanation Task in Probabilistic Graphical Models","abstract":"We propose a self-supervised learning approach for solving the following constrained optimization task in log-linear models or Markov networks. Let $f$ and $g$ be two log-linear models defined over the sets $\\mathbf{X}$ and $\\mathbf{Y}$ of random variables respectively. Given an assignment $\\mathbf{x}$ to all variables in $\\mathbf{X}$ (evidence) and a real number $q$, the constrained most-probable explanation (CMPE) task seeks to find an assignment $\\mathbf{y}$ to all variables in $\\mathbf{Y}$ such that $f(\\mathbf{x}, \\mathbf{y})$ is maximized and $g(\\mathbf{x}, \\mathbf{y})\\leq q$. In our proposed self-supervised approach, given assignments $\\mathbf{x}$ to $\\mathbf{X}$ (data), we train a deep neural network that learns to output near-optimal solutions to the CMPE problem without requiring access to any pre-computed solutions. The key idea in our approach is to use first principles and approximate inference methods for CMPE to derive novel loss functions that seek to push infeasible solutions towards feasible ones and feasible solutions towards optimal ones. We analyze the properties of our proposed method and experimentally demonstrate its efficacy on several benchmark problems.","sentences":["We propose a self-supervised learning approach for solving the following constrained optimization task in log-linear models or Markov networks.","Let $f$ and $g$ be two log-linear models defined over the sets $\\mathbf{X}$ and $\\mathbf{Y}$ of random variables respectively.","Given an assignment $\\mathbf{x}$ to all variables in $\\mathbf{X}$ (evidence) and a real number $q$, the constrained most-probable explanation (CMPE) task seeks to find an assignment $\\mathbf{y}$ to all variables in $\\mathbf{Y}$ such that $f(\\mathbf{x}, \\mathbf{y})$ is maximized and $g(\\mathbf{x}, \\mathbf{y})\\leq q$. In our proposed self-supervised approach, given assignments $\\mathbf{x}$ to $\\mathbf{X}$ (data), we train a deep neural network that learns to output near-optimal solutions to the CMPE problem without requiring access to any pre-computed solutions.","The key idea in our approach is to use first principles and approximate inference methods for CMPE to derive novel loss functions that seek to push infeasible solutions towards feasible ones and feasible solutions towards optimal ones.","We analyze the properties of our proposed method and experimentally demonstrate its efficacy on several benchmark problems."],"url":"http://arxiv.org/abs/2404.11606v1"}
{"created":"2024-04-17 17:54:49","title":"VG4D: Vision-Language Model Goes 4D Video Recognition","abstract":"Understanding the real world through point cloud video is a crucial aspect of robotics and autonomous driving systems. However, prevailing methods for 4D point cloud recognition have limitations due to sensor resolution, which leads to a lack of detailed information. Recent advances have shown that Vision-Language Models (VLM) pre-trained on web-scale text-image datasets can learn fine-grained visual concepts that can be transferred to various downstream tasks. However, effectively integrating VLM into the domain of 4D point clouds remains an unresolved problem. In this work, we propose the Vision-Language Models Goes 4D (VG4D) framework to transfer VLM knowledge from visual-text pre-trained models to a 4D point cloud network. Our approach involves aligning the 4D encoder's representation with a VLM to learn a shared visual and text space from training on large-scale image-text pairs. By transferring the knowledge of the VLM to the 4D encoder and combining the VLM, our VG4D achieves improved recognition performance. To enhance the 4D encoder, we modernize the classic dynamic point cloud backbone and propose an improved version of PSTNet, im-PSTNet, which can efficiently model point cloud videos. Experiments demonstrate that our method achieves state-of-the-art performance for action recognition on both the NTU RGB+D 60 dataset and the NTU RGB+D 120 dataset. Code is available at \\url{https://github.com/Shark0-0/VG4D}.","sentences":["Understanding the real world through point cloud video is a crucial aspect of robotics and autonomous driving systems.","However, prevailing methods for 4D point cloud recognition have limitations due to sensor resolution, which leads to a lack of detailed information.","Recent advances have shown that Vision-Language Models (VLM) pre-trained on web-scale text-image datasets can learn fine-grained visual concepts that can be transferred to various downstream tasks.","However, effectively integrating VLM into the domain of 4D point clouds remains an unresolved problem.","In this work, we propose the Vision-Language Models Goes 4D (VG4D) framework to transfer VLM knowledge from visual-text pre-trained models to a 4D point cloud network.","Our approach involves aligning the 4D encoder's representation with a VLM to learn a shared visual and text space from training on large-scale image-text pairs.","By transferring the knowledge of the VLM to the 4D encoder and combining the VLM, our VG4D achieves improved recognition performance.","To enhance the 4D encoder, we modernize the classic dynamic point cloud backbone and propose an improved version of PSTNet, im-PSTNet, which can efficiently model point cloud videos.","Experiments demonstrate that our method achieves state-of-the-art performance for action recognition on both the NTU RGB+D 60 dataset and the NTU RGB+D 120 dataset.","Code is available at \\url{https://github.com/Shark0-0/VG4D}."],"url":"http://arxiv.org/abs/2404.11605v1"}
{"created":"2024-04-17 17:51:15","title":"Interaction Techniques for Exploratory Data Visualization on Mobile Devices","abstract":"The ubiquity and on-the-go availability of mobile devices makes them central to many tasks such as interpersonal communication and media consumption. However, despite the potential of mobile devices for on-demand exploratory data visualization, existing mobile interactions are difficult, often using highly custom interactions, complex gestures, or multi-modal input. We synthesize limitations from the literature and outline four motivating principles for improved mobile interaction: leverage ubiquitous modalities, prioritize discoverability, enable rapid in-context data exploration, and promote graceful recovery. We then contribute thirteen interaction candidates and conduct a formative study with twelve participants who experienced our interactions in a testbed prototype. Based on these interviews, we discuss design considerations and tradeoffs from four main themes: precise and rapid inspection, focused navigation, single-touch and fixed orientation interaction, and judicious use of motion.","sentences":["The ubiquity and on-the-go availability of mobile devices makes them central to many tasks such as interpersonal communication and media consumption.","However, despite the potential of mobile devices for on-demand exploratory data visualization, existing mobile interactions are difficult, often using highly custom interactions, complex gestures, or multi-modal input.","We synthesize limitations from the literature and outline four motivating principles for improved mobile interaction: leverage ubiquitous modalities, prioritize discoverability, enable rapid in-context data exploration, and promote graceful recovery.","We then contribute thirteen interaction candidates and conduct a formative study with twelve participants who experienced our interactions in a testbed prototype.","Based on these interviews, we discuss design considerations and tradeoffs from four main themes: precise and rapid inspection, focused navigation, single-touch and fixed orientation interaction, and judicious use of motion."],"url":"http://arxiv.org/abs/2404.11602v1"}
{"created":"2024-04-17 17:50:24","title":"Variational Bayesian Last Layers","abstract":"We introduce a deterministic variational formulation for training Bayesian last layer neural networks. This yields a sampling-free, single-pass model and loss that effectively improves uncertainty estimation. Our variational Bayesian last layer (VBLL) can be trained and evaluated with only quadratic complexity in last layer width, and is thus (nearly) computationally free to add to standard architectures. We experimentally investigate VBLLs, and show that they improve predictive accuracy, calibration, and out of distribution detection over baselines across both regression and classification. Finally, we investigate combining VBLL layers with variational Bayesian feature learning, yielding a lower variance collapsed variational inference method for Bayesian neural networks.","sentences":["We introduce a deterministic variational formulation for training Bayesian last layer neural networks.","This yields a sampling-free, single-pass model and loss that effectively improves uncertainty estimation.","Our variational Bayesian last layer (VBLL) can be trained and evaluated with only quadratic complexity in last layer width, and is thus (nearly) computationally free to add to standard architectures.","We experimentally investigate VBLLs, and show that they improve predictive accuracy, calibration, and out of distribution detection over baselines across both regression and classification.","Finally, we investigate combining VBLL layers with variational Bayesian feature learning, yielding a lower variance collapsed variational inference method for Bayesian neural networks."],"url":"http://arxiv.org/abs/2404.11599v1"}
{"created":"2024-04-17 17:49:38","title":"Explainable Artificial Intelligence Techniques for Accurate Fault Detection and Diagnosis: A Review","abstract":"As the manufacturing industry advances with sensor integration and automation, the opaque nature of deep learning models in machine learning poses a significant challenge for fault detection and diagnosis. And despite the related predictive insights Artificial Intelligence (AI) can deliver, advanced machine learning engines often remain a black box. This paper reviews the eXplainable AI (XAI) tools and techniques in this context. We explore various XAI methodologies, focusing on their role in making AI decision-making transparent, particularly in critical scenarios where humans are involved. We also discuss current limitations and potential future research that aims to balance explainability with model performance while improving trustworthiness in the context of AI applications for critical industrial use cases.","sentences":["As the manufacturing industry advances with sensor integration and automation, the opaque nature of deep learning models in machine learning poses a significant challenge for fault detection and diagnosis.","And despite the related predictive insights Artificial Intelligence (AI) can deliver, advanced machine learning engines often remain a black box.","This paper reviews the eXplainable AI (XAI) tools and techniques in this context.","We explore various XAI methodologies, focusing on their role in making AI decision-making transparent, particularly in critical scenarios where humans are involved.","We also discuss current limitations and potential future research that aims to balance explainability with model performance while improving trustworthiness in the context of AI applications for critical industrial use cases."],"url":"http://arxiv.org/abs/2404.11597v1"}
{"created":"2024-04-17 17:48:18","title":"A Deep Dive into Large Language Models for Automated Bug Localization and Repair","abstract":"Large language models (LLMs) have shown impressive effectiveness in various software engineering tasks, including automated program repair (APR). In this study, we take a deep dive into automated bug fixing utilizing LLMs. In contrast to many deep learning-based APR methods that assume known bug locations, rely on line-level localization tools, or address bug prediction and fixing in one step, our approach uniquely employs LLMs to predict bug location at the token level and subsequently utilizes them for bug fixing. This methodological separation of bug localization and fixing using different LLMs enables effective integration of diverse contextual information and improved incorporation of inductive biases. We introduce Toggle: Token-Granulated Bug Localization and Repair, a comprehensive program repair framework that integrates a bug localization model, an adjustment unit, and a bug-fixing model. Toggle takes a buggy function as input and generates a complete corrected function. We investigate various styles of prompting to the bug fixing model to identify the most effective prompts that better utilize the inductive bias and significantly outperform others. Toggle achieves the new state-of-the-art (SOTA) performance on the CodeXGLUE code refinement benchmark, and exhibits better and comparable performance on several other widely-used APR datasets, including Defects4J.","sentences":["Large language models (LLMs) have shown impressive effectiveness in various software engineering tasks, including automated program repair (APR).","In this study, we take a deep dive into automated bug fixing utilizing LLMs.","In contrast to many deep learning-based APR methods that assume known bug locations, rely on line-level localization tools, or address bug prediction and fixing in one step, our approach uniquely employs LLMs to predict bug location at the token level and subsequently utilizes them for bug fixing.","This methodological separation of bug localization and fixing using different LLMs enables effective integration of diverse contextual information and improved incorporation of inductive biases.","We introduce Toggle: Token-Granulated Bug Localization and Repair, a comprehensive program repair framework that integrates a bug localization model, an adjustment unit, and a bug-fixing model.","Toggle takes a buggy function as input and generates a complete corrected function.","We investigate various styles of prompting to the bug fixing model to identify the most effective prompts that better utilize the inductive bias and significantly outperform others.","Toggle achieves the new state-of-the-art (SOTA) performance on the CodeXGLUE code refinement benchmark, and exhibits better and comparable performance on several other widely-used APR datasets, including Defects4J."],"url":"http://arxiv.org/abs/2404.11595v1"}
{"created":"2024-04-17 17:45:08","title":"IntrinsicAnything: Learning Diffusion Priors for Inverse Rendering Under Unknown Illumination","abstract":"This paper aims to recover object materials from posed images captured under an unknown static lighting condition. Recent methods solve this task by optimizing material parameters through differentiable physically based rendering. However, due to the coupling between object geometry, materials, and environment lighting, there is inherent ambiguity during the inverse rendering process, preventing previous methods from obtaining accurate results. To overcome this ill-posed problem, our key idea is to learn the material prior with a generative model for regularizing the optimization process. We observe that the general rendering equation can be split into diffuse and specular shading terms, and thus formulate the material prior as diffusion models of albedo and specular. Thanks to this design, our model can be trained using the existing abundant 3D object data, and naturally acts as a versatile tool to resolve the ambiguity when recovering material representations from RGB images. In addition, we develop a coarse-to-fine training strategy that leverages estimated materials to guide diffusion models to satisfy multi-view consistent constraints, leading to more stable and accurate results. Extensive experiments on real-world and synthetic datasets demonstrate that our approach achieves state-of-the-art performance on material recovery. The code will be available at https://zju3dv.github.io/IntrinsicAnything.","sentences":["This paper aims to recover object materials from posed images captured under an unknown static lighting condition.","Recent methods solve this task by optimizing material parameters through differentiable physically based rendering.","However, due to the coupling between object geometry, materials, and environment lighting, there is inherent ambiguity during the inverse rendering process, preventing previous methods from obtaining accurate results.","To overcome this ill-posed problem, our key idea is to learn the material prior with a generative model for regularizing the optimization process.","We observe that the general rendering equation can be split into diffuse and specular shading terms, and thus formulate the material prior as diffusion models of albedo and specular.","Thanks to this design, our model can be trained using the existing abundant 3D object data, and naturally acts as a versatile tool to resolve the ambiguity when recovering material representations from RGB images.","In addition, we develop a coarse-to-fine training strategy that leverages estimated materials to guide diffusion models to satisfy multi-view consistent constraints, leading to more stable and accurate results.","Extensive experiments on real-world and synthetic datasets demonstrate that our approach achieves state-of-the-art performance on material recovery.","The code will be available at https://zju3dv.github.io/IntrinsicAnything."],"url":"http://arxiv.org/abs/2404.11593v1"}
{"created":"2024-04-17 17:43:23","title":"Real Time Evolvable Hardware for Optimal Reconfiguration of Cusp-Like Pulse Shapers","abstract":"The design of a cusp-like digital pulse shaper for particle energy measurements requires the definition of four parameters whose values are defined based on the nature of the shaper input signal (timing, noise, ...) provided by a sensor. However, after high doses of radiation, sensors degenerate and their output signals do not meet the original characteristics, which may lead to erroneous measurements of the particle energies. We present in this paper an evolvable cusp-like digital shaper, which is able to auto-recalibrate the original hardware implementation into a new design that match the original specifications under the new sensor features.","sentences":["The design of a cusp-like digital pulse shaper for particle energy measurements requires the definition of four parameters whose values are defined based on the nature of the shaper input signal (timing, noise, ...) provided by a sensor.","However, after high doses of radiation, sensors degenerate and their output signals do not meet the original characteristics, which may lead to erroneous measurements of the particle energies.","We present in this paper an evolvable cusp-like digital shaper, which is able to auto-recalibrate the original hardware implementation into a new design that match the original specifications under the new sensor features."],"url":"http://arxiv.org/abs/2404.11592v1"}
{"created":"2024-04-17 17:42:48","title":"The EDGE Language: Extended General Einsums for Graph Algorithms","abstract":"In this work, we propose a unified abstraction for graph algorithms: the Extended General Einsums language, or EDGE. The EDGE language expresses graph algorithms in the language of tensor algebra, providing a rigorous, succinct, and expressive mathematical framework. EDGE leverages two ideas: (1) the well-known foundations provided by the graph-matrix duality, where a graph is simply a 2D tensor, and (2) the power and expressivity of Einsum notation in the tensor algebra world. In this work, we describe our design goals for EDGE and walk through the extensions we add to Einsums to support more complex operations common in graph algorithms. Additionally, we provide a few examples of how to express graph algorithms in our proposed notation. We hope that a single, mathematical notation for graph algorithms will (1) allow researchers to more easily compare different algorithms and different implementations of a graph algorithm; (2) enable developers to factor complexity by separating the concerns of what to compute (described with the extended Einsum notation) from the lower level details of how to compute; and (3) enable the discovery of different algorithmic variants of a problem through algebraic manipulations and transformations on a given EDGE expression.","sentences":["In this work, we propose a unified abstraction for graph algorithms: the Extended General Einsums language, or EDGE.","The EDGE language expresses graph algorithms in the language of tensor algebra, providing a rigorous, succinct, and expressive mathematical framework.","EDGE leverages two ideas: (1) the well-known foundations provided by the graph-matrix duality, where a graph is simply a 2D tensor, and (2) the power and expressivity of Einsum notation in the tensor algebra world.","In this work, we describe our design goals for EDGE and walk through the extensions we add to Einsums to support more complex operations common in graph algorithms.","Additionally, we provide a few examples of how to express graph algorithms in our proposed notation.","We hope that a single, mathematical notation for graph algorithms will (1) allow researchers to more easily compare different algorithms and different implementations of a graph algorithm; (2) enable developers to factor complexity by separating the concerns of what to compute (described with the extended Einsum notation) from the lower level details of how to compute; and (3) enable the discovery of different algorithmic variants of a problem through algebraic manipulations and transformations on a given EDGE expression."],"url":"http://arxiv.org/abs/2404.11591v1"}
{"created":"2024-04-17 17:39:59","title":"A Subspace-Constrained Tyler's Estimator and its Applications to Structure from Motion","abstract":"We present the subspace-constrained Tyler's estimator (STE) designed for recovering a low-dimensional subspace within a dataset that may be highly corrupted with outliers. STE is a fusion of the Tyler's M-estimator (TME) and a variant of the fast median subspace. Our theoretical analysis suggests that, under a common inlier-outlier model, STE can effectively recover the underlying subspace, even when it contains a smaller fraction of inliers relative to other methods in the field of robust subspace recovery. We apply STE in the context of Structure from Motion (SfM) in two ways: for robust estimation of the fundamental matrix and for the removal of outlying cameras, enhancing the robustness of the SfM pipeline. Numerical experiments confirm the state-of-the-art performance of our method in these applications. This research makes significant contributions to the field of robust subspace recovery, particularly in the context of computer vision and 3D reconstruction.","sentences":["We present the subspace-constrained Tyler's estimator (STE) designed for recovering a low-dimensional subspace within a dataset that may be highly corrupted with outliers.","STE is a fusion of the Tyler's M-estimator (TME) and a variant of the fast median subspace.","Our theoretical analysis suggests that, under a common inlier-outlier model, STE can effectively recover the underlying subspace, even when it contains a smaller fraction of inliers relative to other methods in the field of robust subspace recovery.","We apply STE in the context of Structure from Motion (SfM) in two ways: for robust estimation of the fundamental matrix and for the removal of outlying cameras, enhancing the robustness of the SfM pipeline.","Numerical experiments confirm the state-of-the-art performance of our method in these applications.","This research makes significant contributions to the field of robust subspace recovery, particularly in the context of computer vision and 3D reconstruction."],"url":"http://arxiv.org/abs/2404.11590v1"}
{"created":"2024-04-17 17:38:56","title":"Prompt Optimizer of Text-to-Image Diffusion Models for Abstract Concept Understanding","abstract":"The rapid evolution of text-to-image diffusion models has opened the door of generative AI, enabling the translation of textual descriptions into visually compelling images with remarkable quality. However, a persistent challenge within this domain is the optimization of prompts to effectively convey abstract concepts into concrete objects. For example, text encoders can hardly express \"peace\", while can easily illustrate olive branches and white doves. This paper introduces a novel approach named Prompt Optimizer for Abstract Concepts (POAC) specifically designed to enhance the performance of text-to-image diffusion models in interpreting and generating images from abstract concepts. We propose a Prompt Language Model (PLM), which is initialized from a pre-trained language model, and then fine-tuned with a curated dataset of abstract concept prompts. The dataset is created with GPT-4 to extend the abstract concept to a scene and concrete objects. Our framework employs a Reinforcement Learning (RL)-based optimization strategy, focusing on the alignment between the generated images by a stable diffusion model and optimized prompts. Through extensive experiments, we demonstrate that our proposed POAC significantly improves the accuracy and aesthetic quality of generated images, particularly in the description of abstract concepts and alignment with optimized prompts. We also present a comprehensive analysis of our model's performance across diffusion models under different settings, showcasing its versatility and effectiveness in enhancing abstract concept representation.","sentences":["The rapid evolution of text-to-image diffusion models has opened the door of generative AI, enabling the translation of textual descriptions into visually compelling images with remarkable quality.","However, a persistent challenge within this domain is the optimization of prompts to effectively convey abstract concepts into concrete objects.","For example, text encoders can hardly express \"peace\", while can easily illustrate olive branches and white doves.","This paper introduces a novel approach named Prompt Optimizer for Abstract Concepts (POAC) specifically designed to enhance the performance of text-to-image diffusion models in interpreting and generating images from abstract concepts.","We propose a Prompt Language Model (PLM), which is initialized from a pre-trained language model, and then fine-tuned with a curated dataset of abstract concept prompts.","The dataset is created with GPT-4 to extend the abstract concept to a scene and concrete objects.","Our framework employs a Reinforcement Learning (RL)-based optimization strategy, focusing on the alignment between the generated images by a stable diffusion model and optimized prompts.","Through extensive experiments, we demonstrate that our proposed POAC significantly improves the accuracy and aesthetic quality of generated images, particularly in the description of abstract concepts and alignment with optimized prompts.","We also present a comprehensive analysis of our model's performance across diffusion models under different settings, showcasing its versatility and effectiveness in enhancing abstract concept representation."],"url":"http://arxiv.org/abs/2404.11589v1"}
{"created":"2024-04-17 17:37:30","title":"Related Work and Citation Text Generation: A Survey","abstract":"To convince readers of the novelty of their research paper, authors must perform a literature review and compose a coherent story that connects and relates prior works to the current work. This challenging nature of literature review writing makes automatic related work generation (RWG) academically and computationally interesting, and also makes it an excellent test bed for examining the capability of SOTA natural language processing (NLP) models. Since the initial proposal of the RWG task, its popularity has waxed and waned, following the capabilities of mainstream NLP approaches. In this work, we survey the zoo of RWG historical works, summarizing the key approaches and task definitions and discussing the ongoing challenges of RWG.","sentences":["To convince readers of the novelty of their research paper, authors must perform a literature review and compose a coherent story that connects and relates prior works to the current work.","This challenging nature of literature review writing makes automatic related work generation (RWG) academically and computationally interesting, and also makes it an excellent test bed for examining the capability of SOTA natural language processing (NLP) models.","Since the initial proposal of the RWG task, its popularity has waxed and waned, following the capabilities of mainstream NLP approaches.","In this work, we survey the zoo of RWG historical works, summarizing the key approaches and task definitions and discussing the ongoing challenges of RWG."],"url":"http://arxiv.org/abs/2404.11588v1"}
{"created":"2024-04-17 17:33:32","title":"Spatial Context-based Self-Supervised Learning for Handwritten Text Recognition","abstract":"Handwritten Text Recognition (HTR) is a relevant problem in computer vision, and implies unique challenges owing to its inherent variability and the rich contextualization required for its interpretation. Despite the success of Self-Supervised Learning (SSL) in computer vision, its application to HTR has been rather scattered, leaving key SSL methodologies unexplored. This work focuses on one of them, namely Spatial Context-based SSL. We investigate how this family of approaches can be adapted and optimized for HTR and propose new workflows that leverage the unique features of handwritten text. Our experiments demonstrate that the methods considered lead to advancements in the state-of-the-art of SSL for HTR in a number of benchmark cases.","sentences":["Handwritten Text Recognition (HTR) is a relevant problem in computer vision, and implies unique challenges owing to its inherent variability and the rich contextualization required for its interpretation.","Despite the success of Self-Supervised Learning (SSL) in computer vision, its application to HTR has been rather scattered, leaving key SSL methodologies unexplored.","This work focuses on one of them, namely Spatial Context-based SSL.","We investigate how this family of approaches can be adapted and optimized for HTR and propose new workflows that leverage the unique features of handwritten text.","Our experiments demonstrate that the methods considered lead to advancements in the state-of-the-art of SSL for HTR in a number of benchmark cases."],"url":"http://arxiv.org/abs/2404.11585v1"}
{"created":"2024-04-17 17:32:41","title":"The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey","abstract":"This survey paper examines the recent advancements in AI agent implementations, with a focus on their ability to achieve complex goals that require enhanced reasoning, planning, and tool execution capabilities. The primary objectives of this work are to a) communicate the current capabilities and limitations of existing AI agent implementations, b) share insights gained from our observations of these systems in action, and c) suggest important considerations for future developments in AI agent design. We achieve this by providing overviews of single-agent and multi-agent architectures, identifying key patterns and divergences in design choices, and evaluating their overall impact on accomplishing a provided goal. Our contribution outlines key themes when selecting an agentic architecture, the impact of leadership on agent systems, agent communication styles, and key phases for planning, execution, and reflection that enable robust AI agent systems.","sentences":["This survey paper examines the recent advancements in AI agent implementations, with a focus on their ability to achieve complex goals that require enhanced reasoning, planning, and tool execution capabilities.","The primary objectives of this work are to a) communicate the current capabilities and limitations of existing AI agent implementations, b) share insights gained from our observations of these systems in action, and c) suggest important considerations for future developments in AI agent design.","We achieve this by providing overviews of single-agent and multi-agent architectures, identifying key patterns and divergences in design choices, and evaluating their overall impact on accomplishing a provided goal.","Our contribution outlines key themes when selecting an agentic architecture, the impact of leadership on agent systems, agent communication styles, and key phases for planning, execution, and reflection that enable robust AI agent systems."],"url":"http://arxiv.org/abs/2404.11584v1"}
{"created":"2024-04-17 17:28:30","title":"Maximin Shares in Hereditary Set Systems","abstract":"We consider the problem of fairly allocating a set of indivisible items under the criteria of the maximin share guarantee. Specifically, we study approximation of maximin share allocations under hereditary set system valuations, in which each valuation function is based on the independent sets of an underlying hereditary set systems. Using a lone divider approach, we show the existence of $1/2$-approximate MMS allocations, improving on the $11/30$ guarantee of Li and Vetta. Moreover, we prove that ($2/3 + \\epsilon$)-approximate MMS allocations do not always exist in this model for every $\\epsilon > 0$, an improvement from the recent $3/4 + \\epsilon$ result of Li and Deng. Our existence proof is constructive, but does not directly yield a polynomial-time approximation algorithm. However, we show that a $2/5$-approximate MMS allocation can be found in polynomial time, given valuation oracles. Finally, we show that our existence and approximation results transfer to a variety of problems within constrained fair allocation, improving on existing results in some of these settings.","sentences":["We consider the problem of fairly allocating a set of indivisible items under the criteria of the maximin share guarantee.","Specifically, we study approximation of maximin share allocations under hereditary set system valuations, in which each valuation function is based on the independent sets of an underlying hereditary set systems.","Using a lone divider approach, we show the existence of $1/2$-approximate MMS allocations, improving on the $11/30$ guarantee of Li and Vetta.","Moreover, we prove that ($2/3 + \\epsilon$)-approximate MMS allocations do not always exist in this model for every $\\epsilon > 0$, an improvement from the recent $3/4 + \\epsilon$ result of Li and Deng.","Our existence proof is constructive, but does not directly yield a polynomial-time approximation algorithm.","However, we show that a $2/5$-approximate MMS allocation can be found in polynomial time, given valuation oracles.","Finally, we show that our existence and approximation results transfer to a variety of problems within constrained fair allocation, improving on existing results in some of these settings."],"url":"http://arxiv.org/abs/2404.11582v1"}
{"created":"2024-04-17 17:28:05","title":"LLMTune: Accelerate Database Knob Tuning with Large Language Models","abstract":"Database knob tuning is a critical challenge in the database community, aiming to optimize knob values to enhance database performance for specific workloads. DBMS often feature hundreds of tunable knobs, posing a significant challenge for DBAs to recommend optimal configurations. Consequently, many machine learning-based tuning methods have been developed to automate this process. Despite the introduction of various optimizers, practical applications have unveiled a new problem: they typically require numerous workload runs to achieve satisfactory performance, a process that is both time-consuming and resource-intensive. This inefficiency largely stems from the optimal configuration often being substantially different from the default setting, necessitating multiple iterations during tuning. Recognizing this, we argue that an effective starting point could significantly reduce redundant exploration in less efficient areas, thereby potentially speeding up the tuning process for the optimizers. Based on this assumption, we introduce LLMTune, a large language model-based configuration generator designed to produce an initial, high-quality configuration for new workloads. These generated configurations can then serve as starting points for various base optimizers, accelerating their tuning processes. To obtain training data for LLMTune's supervised fine-tuning, we have devised a new automatic data generation framework capable of efficiently creating a large number of <workload, configuration> pairs. We have conducted thorough experiments to evaluate LLMTune's effectiveness with different workloads, such as TPC-H and JOB. In comparison to leading methods, LLMTune demonstrates a quicker ability to identify superior configurations. For instance, with the challenging TPC-H workload, our LLMTune achieves a significant 15.6x speed-up ratio in finding the best-performing configurations.","sentences":["Database knob tuning is a critical challenge in the database community, aiming to optimize knob values to enhance database performance for specific workloads.","DBMS often feature hundreds of tunable knobs, posing a significant challenge for DBAs to recommend optimal configurations.","Consequently, many machine learning-based tuning methods have been developed to automate this process.","Despite the introduction of various optimizers, practical applications have unveiled a new problem: they typically require numerous workload runs to achieve satisfactory performance, a process that is both time-consuming and resource-intensive.","This inefficiency largely stems from the optimal configuration often being substantially different from the default setting, necessitating multiple iterations during tuning.","Recognizing this, we argue that an effective starting point could significantly reduce redundant exploration in less efficient areas, thereby potentially speeding up the tuning process for the optimizers.","Based on this assumption, we introduce LLMTune, a large language model-based configuration generator designed to produce an initial, high-quality configuration for new workloads.","These generated configurations can then serve as starting points for various base optimizers, accelerating their tuning processes.","To obtain training data for LLMTune's supervised fine-tuning, we have devised a new automatic data generation framework capable of efficiently creating a large number of <workload, configuration> pairs.","We have conducted thorough experiments to evaluate LLMTune's effectiveness with different workloads, such as TPC-H and JOB.","In comparison to leading methods, LLMTune demonstrates a quicker ability to identify superior configurations.","For instance, with the challenging TPC-H workload, our LLMTune achieves a significant 15.6x speed-up ratio in finding the best-performing configurations."],"url":"http://arxiv.org/abs/2404.11581v1"}
{"created":"2024-04-17 17:24:44","title":"Deep Policy Optimization with Temporal Logic Constraints","abstract":"Temporal logics, such as linear temporal logic (LTL), offer a precise means of specifying tasks for (deep) reinforcement learning (RL) agents. In our work, we consider the setting where the task is specified by an LTL objective and there is an additional scalar reward that we need to optimize. Previous works focus either on learning a LTL task-satisfying policy alone or are restricted to finite state spaces. We make two contributions: First, we introduce an RL-friendly approach to this setting by formulating this problem as a single optimization objective. Our formulation guarantees that an optimal policy will be reward-maximal from the set of policies that maximize the likelihood of satisfying the LTL specification. Second, we address a sparsity issue that often arises for LTL-guided Deep RL policies by introducing Cycle Experience Replay (CyclER), a technique that automatically guides RL agents towards the satisfaction of an LTL specification. Our experiments demonstrate the efficacy of CyclER in finding performant deep RL policies in both continuous and discrete experimental domains.","sentences":["Temporal logics, such as linear temporal logic (LTL), offer a precise means of specifying tasks for (deep) reinforcement learning (RL) agents.","In our work, we consider the setting where the task is specified by an LTL objective and there is an additional scalar reward that we need to optimize.","Previous works focus either on learning a LTL task-satisfying policy alone or are restricted to finite state spaces.","We make two contributions: First, we introduce an RL-friendly approach to this setting by formulating this problem as a single optimization objective.","Our formulation guarantees that an optimal policy will be reward-maximal from the set of policies that maximize the likelihood of satisfying the LTL specification.","Second, we address a sparsity issue that often arises for LTL-guided Deep RL policies by introducing Cycle Experience Replay (CyclER), a technique that automatically guides RL agents towards the satisfaction of an LTL specification.","Our experiments demonstrate the efficacy of CyclER in finding performant deep RL policies in both continuous and discrete experimental domains."],"url":"http://arxiv.org/abs/2404.11578v1"}
{"created":"2024-04-17 17:20:27","title":"Towards Reliable Empirical Machine Unlearning Evaluation: A Game-Theoretic View","abstract":"Machine unlearning is the process of updating machine learning models to remove the information of specific training data samples, in order to comply with data protection regulations that allow individuals to request the removal of their personal data. Despite the recent development of numerous unlearning algorithms, reliable evaluation of these algorithms remains an open research question. In this work, we focus on membership inference attack (MIA) based evaluation, one of the most common approaches for evaluating unlearning algorithms, and address various pitfalls of existing evaluation metrics that lack reliability. Specifically, we propose a game-theoretic framework that formalizes the evaluation process as a game between unlearning algorithms and MIA adversaries, measuring the data removal efficacy of unlearning algorithms by the capability of the MIA adversaries. Through careful design of the game, we demonstrate that the natural evaluation metric induced from the game enjoys provable guarantees that the existing evaluation metrics fail to satisfy. Furthermore, we propose a practical and efficient algorithm to estimate the evaluation metric induced from the game, and demonstrate its effectiveness through both theoretical analysis and empirical experiments. This work presents a novel and reliable approach to empirically evaluating unlearning algorithms, paving the way for the development of more effective unlearning techniques.","sentences":["Machine unlearning is the process of updating machine learning models to remove the information of specific training data samples, in order to comply with data protection regulations that allow individuals to request the removal of their personal data.","Despite the recent development of numerous unlearning algorithms, reliable evaluation of these algorithms remains an open research question.","In this work, we focus on membership inference attack (MIA) based evaluation, one of the most common approaches for evaluating unlearning algorithms, and address various pitfalls of existing evaluation metrics that lack reliability.","Specifically, we propose a game-theoretic framework that formalizes the evaluation process as a game between unlearning algorithms and MIA adversaries, measuring the data removal efficacy of unlearning algorithms by the capability of the MIA adversaries.","Through careful design of the game, we demonstrate that the natural evaluation metric induced from the game enjoys provable guarantees that the existing evaluation metrics fail to satisfy.","Furthermore, we propose a practical and efficient algorithm to estimate the evaluation metric induced from the game, and demonstrate its effectiveness through both theoretical analysis and empirical experiments.","This work presents a novel and reliable approach to empirically evaluating unlearning algorithms, paving the way for the development of more effective unlearning techniques."],"url":"http://arxiv.org/abs/2404.11577v1"}
{"created":"2024-04-17 17:19:48","title":"State-space Decomposition Model for Video Prediction Considering Long-term Motion Trend","abstract":"Stochastic video prediction enables the consideration of uncertainty in future motion, thereby providing a better reflection of the dynamic nature of the environment. Stochastic video prediction methods based on image auto-regressive recurrent models need to feed their predictions back into the latent space. Conversely, the state-space models, which decouple frame synthesis and temporal prediction, proves to be more efficient. However, inferring long-term temporal information about motion and generalizing to dynamic scenarios under non-stationary assumptions remains an unresolved challenge. In this paper, we propose a state-space decomposition stochastic video prediction model that decomposes the overall video frame generation into deterministic appearance prediction and stochastic motion prediction. Through adaptive decomposition, the model's generalization capability to dynamic scenarios is enhanced. In the context of motion prediction, obtaining a prior on the long-term trend of future motion is crucial. Thus, in the stochastic motion prediction branch, we infer the long-term motion trend from conditional frames to guide the generation of future frames that exhibit high consistency with the conditional frames. Experimental results demonstrate that our model outperforms baselines on multiple datasets.","sentences":["Stochastic video prediction enables the consideration of uncertainty in future motion, thereby providing a better reflection of the dynamic nature of the environment.","Stochastic video prediction methods based on image auto-regressive recurrent models need to feed their predictions back into the latent space.","Conversely, the state-space models, which decouple frame synthesis and temporal prediction, proves to be more efficient.","However, inferring long-term temporal information about motion and generalizing to dynamic scenarios under non-stationary assumptions remains an unresolved challenge.","In this paper, we propose a state-space decomposition stochastic video prediction model that decomposes the overall video frame generation into deterministic appearance prediction and stochastic motion prediction.","Through adaptive decomposition, the model's generalization capability to dynamic scenarios is enhanced.","In the context of motion prediction, obtaining a prior on the long-term trend of future motion is crucial.","Thus, in the stochastic motion prediction branch, we infer the long-term motion trend from conditional frames to guide the generation of future frames that exhibit high consistency with the conditional frames.","Experimental results demonstrate that our model outperforms baselines on multiple datasets."],"url":"http://arxiv.org/abs/2404.11576v1"}
{"created":"2024-04-17 17:11:47","title":"Simple Image Signal Processing using Global Context Guidance","abstract":"In modern smartphone cameras, the Image Signal Processor (ISP) is the core element that converts the RAW readings from the sensor into perceptually pleasant RGB images for the end users. The ISP is typically proprietary and handcrafted and consists of several blocks such as white balance, color correction, and tone mapping. Deep learning-based ISPs aim to transform RAW images into DSLR-like RGB images using deep neural networks. However, most learned ISPs are trained using patches (small regions) due to computational limitations. Such methods lack global context, which limits their efficacy on full-resolution images and harms their ability to capture global properties such as color constancy or illumination. First, we propose a novel module that can be integrated into any neural ISP to capture the global context information from the full RAW images. Second, we propose an efficient and simple neural ISP that utilizes our proposed module. Our model achieves state-of-the-art results on different benchmarks using diverse and real smartphone images.","sentences":["In modern smartphone cameras, the Image Signal Processor (ISP) is the core element that converts the RAW readings from the sensor into perceptually pleasant RGB images for the end users.","The ISP is typically proprietary and handcrafted and consists of several blocks such as white balance, color correction, and tone mapping.","Deep learning-based ISPs aim to transform RAW images into DSLR-like RGB images using deep neural networks.","However, most learned ISPs are trained using patches (small regions) due to computational limitations.","Such methods lack global context, which limits their efficacy on full-resolution images and harms their ability to capture global properties such as color constancy or illumination.","First, we propose a novel module that can be integrated into any neural ISP to capture the global context information from the full RAW images.","Second, we propose an efficient and simple neural ISP that utilizes our proposed module.","Our model achieves state-of-the-art results on different benchmarks using diverse and real smartphone images."],"url":"http://arxiv.org/abs/2404.11569v1"}
{"created":"2024-04-17 17:11:31","title":"On the Scalability of GNNs for Molecular Graphs","abstract":"Scaling deep learning models has been at the heart of recent revolutions in language modelling and image generation. Practitioners have observed a strong relationship between model size, dataset size, and performance. However, structure-based architectures such as Graph Neural Networks (GNNs) are yet to show the benefits of scale mainly due to the lower efficiency of sparse operations, large data requirements, and lack of clarity about the effectiveness of various architectures. We address this drawback of GNNs by studying their scaling behavior. Specifically, we analyze message-passing networks, graph Transformers, and hybrid architectures on the largest public collection of 2D molecular graphs. For the first time, we observe that GNNs benefit tremendously from the increasing scale of depth, width, number of molecules, number of labels, and the diversity in the pretraining datasets, resulting in a 30.25% improvement when scaling to 1 billion parameters and 28.98% improvement when increasing size of dataset to eightfold. We further demonstrate strong finetuning scaling behavior on 38 tasks, outclassing previous large models. We hope that our work paves the way for an era where foundational GNNs drive pharmaceutical drug discovery.","sentences":["Scaling deep learning models has been at the heart of recent revolutions in language modelling and image generation.","Practitioners have observed a strong relationship between model size, dataset size, and performance.","However, structure-based architectures such as Graph Neural Networks (GNNs) are yet to show the benefits of scale mainly due to the lower efficiency of sparse operations, large data requirements, and lack of clarity about the effectiveness of various architectures.","We address this drawback of GNNs by studying their scaling behavior.","Specifically, we analyze message-passing networks, graph Transformers, and hybrid architectures on the largest public collection of 2D molecular graphs.","For the first time, we observe that GNNs benefit tremendously from the increasing scale of depth, width, number of molecules, number of labels, and the diversity in the pretraining datasets, resulting in a 30.25% improvement when scaling to 1 billion parameters and 28.98% improvement when increasing size of dataset to eightfold.","We further demonstrate strong finetuning scaling behavior on 38 tasks, outclassing previous large models.","We hope that our work paves the way for an era where foundational GNNs drive pharmaceutical drug discovery."],"url":"http://arxiv.org/abs/2404.11568v1"}
{"created":"2024-04-17 17:08:05","title":"MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation","abstract":"We introduce a new architecture for personalization of text-to-image diffusion models, coined Mixture-of-Attention (MoA). Inspired by the Mixture-of-Experts mechanism utilized in large language models (LLMs), MoA distributes the generation workload between two attention pathways: a personalized branch and a non-personalized prior branch. MoA is designed to retain the original model's prior by fixing its attention layers in the prior branch, while minimally intervening in the generation process with the personalized branch that learns to embed subjects in the layout and context generated by the prior branch. A novel routing mechanism manages the distribution of pixels in each layer across these branches to optimize the blend of personalized and generic content creation. Once trained, MoA facilitates the creation of high-quality, personalized images featuring multiple subjects with compositions and interactions as diverse as those generated by the original model. Crucially, MoA enhances the distinction between the model's pre-existing capability and the newly augmented personalized intervention, thereby offering a more disentangled subject-context control that was previously unattainable. Project page: https://snap-research.github.io/mixture-of-attention","sentences":["We introduce a new architecture for personalization of text-to-image diffusion models, coined Mixture-of-Attention (MoA).","Inspired by the Mixture-of-Experts mechanism utilized in large language models (LLMs), MoA distributes the generation workload between two attention pathways: a personalized branch and a non-personalized prior branch.","MoA is designed to retain the original model's prior by fixing its attention layers in the prior branch, while minimally intervening in the generation process with the personalized branch that learns to embed subjects in the layout and context generated by the prior branch.","A novel routing mechanism manages the distribution of pixels in each layer across these branches to optimize the blend of personalized and generic content creation.","Once trained, MoA facilitates the creation of high-quality, personalized images featuring multiple subjects with compositions and interactions as diverse as those generated by the original model.","Crucially, MoA enhances the distinction between the model's pre-existing capability and the newly augmented personalized intervention, thereby offering a more disentangled subject-context control that was previously unattainable.","Project page: https://snap-research.github.io/mixture-of-attention"],"url":"http://arxiv.org/abs/2404.11565v1"}
{"created":"2024-04-17 17:00:26","title":"Spatio-Temporal Motion Retargeting for Quadruped Robots","abstract":"This work introduces a motion retargeting approach for legged robots, which aims to create motion controllers that imitate the fine behavior of animals. Our approach, namely spatio-temporal motion retargeting (STMR), guides imitation learning procedures by transferring motion from source to target, effectively bridging the morphological disparities by ensuring the feasibility of imitation on the target system. Our STMR method comprises two components: spatial motion retargeting (SMR) and temporal motion retargeting (TMR). On the one hand, SMR tackles motion retargeting at the kinematic level by generating kinematically feasible whole-body motions from keypoint trajectories. On the other hand, TMR aims to retarget motion at the dynamic level by optimizing motion in the temporal domain. We showcase the effectiveness of our method in facilitating Imitation Learning (IL) for complex animal movements through a series of simulation and hardware experiments. In these experiments, our STMR method successfully tailored complex animal motions from various media, including video captured by a hand-held camera, to fit the morphology and physical properties of the target robots. This enabled RL policy training for precise motion tracking, while baseline methods struggled with highly dynamic motion involving flying phases. Moreover, we validated that the control policy can successfully imitate six different motions in two quadruped robots with different dimensions and physical properties in real-world settings.","sentences":["This work introduces a motion retargeting approach for legged robots, which aims to create motion controllers that imitate the fine behavior of animals.","Our approach, namely spatio-temporal motion retargeting (STMR), guides imitation learning procedures by transferring motion from source to target, effectively bridging the morphological disparities by ensuring the feasibility of imitation on the target system.","Our STMR method comprises two components: spatial motion retargeting (SMR) and temporal motion retargeting (TMR).","On the one hand, SMR tackles motion retargeting at the kinematic level by generating kinematically feasible whole-body motions from keypoint trajectories.","On the other hand, TMR aims to retarget motion at the dynamic level by optimizing motion in the temporal domain.","We showcase the effectiveness of our method in facilitating Imitation Learning (IL) for complex animal movements through a series of simulation and hardware experiments.","In these experiments, our STMR method successfully tailored complex animal motions from various media, including video captured by a hand-held camera, to fit the morphology and physical properties of the target robots.","This enabled RL policy training for precise motion tracking, while baseline methods struggled with highly dynamic motion involving flying phases.","Moreover, we validated that the control policy can successfully imitate six different motions in two quadruped robots with different dimensions and physical properties in real-world settings."],"url":"http://arxiv.org/abs/2404.11557v1"}
{"created":"2024-04-17 17:00:12","title":"Hierarchical storage management in user space for neuroimaging applications","abstract":"Neuroimaging open-data initiatives have led to increased availability of large scientific datasets. While these datasets are shifting the processing bottleneck from compute-intensive to data-intensive, current standardized analysis tools have yet to adopt strategies that mitigate the costs associated with large data transfers. A major challenge in adapting neuroimaging applications for data-intensive processing is that they must be entirely rewritten. To facilitate data management for standardized neuroimaging tools, we developed Sea, a library that intercepts and redirects application read and write calls to minimize data transfer time. In this paper, we investigate the performance of Sea on three preprocessing pipelines implemented using standard toolboxes (FSL, SPM and AFNI), using three neuroimaging datasets of different sizes (OpenNeuro's ds001545, PREVENT-AD and the HCP dataset) on two high-performance computing clusters. Our results demonstrate that Sea provides large speedups (up to 32X) when the shared file system's (e.g. Lustre) performance is deteriorated. When the shared file system is not overburdened by other users, performance is unaffected by Sea, suggesting that Sea's overhead is minimal even in cases where its benefits are limited. Overall, Sea is beneficial, even when performance gain is minimal, as it can be used to limit the number of files created on parallel file systems.","sentences":["Neuroimaging open-data initiatives have led to increased availability of large scientific datasets.","While these datasets are shifting the processing bottleneck from compute-intensive to data-intensive, current standardized analysis tools have yet to adopt strategies that mitigate the costs associated with large data transfers.","A major challenge in adapting neuroimaging applications for data-intensive processing is that they must be entirely rewritten.","To facilitate data management for standardized neuroimaging tools, we developed Sea, a library that intercepts and redirects application read and write calls to minimize data transfer time.","In this paper, we investigate the performance of Sea on three preprocessing pipelines implemented using standard toolboxes (FSL, SPM and AFNI), using three neuroimaging datasets of different sizes (OpenNeuro's ds001545, PREVENT-AD and the HCP dataset) on two high-performance computing clusters.","Our results demonstrate that Sea provides large speedups (up to 32X) when the shared file system's (e.g. Lustre) performance is deteriorated.","When the shared file system is not overburdened by other users, performance is unaffected by Sea, suggesting that Sea's overhead is minimal even in cases where its benefits are limited.","Overall, Sea is beneficial, even when performance gain is minimal, as it can be used to limit the number of files created on parallel file systems."],"url":"http://arxiv.org/abs/2404.11556v1"}
{"created":"2024-04-17 16:56:31","title":"Predicting Long-horizon Futures by Conditioning on Geometry and Time","abstract":"Our work explores the task of generating future sensor observations conditioned on the past. We are motivated by `predictive coding' concepts from neuroscience as well as robotic applications such as self-driving vehicles. Predictive video modeling is challenging because the future may be multi-modal and learning at scale remains computationally expensive for video processing. To address both challenges, our key insight is to leverage the large-scale pretraining of image diffusion models which can handle multi-modality. We repurpose image models for video prediction by conditioning on new frame timestamps. Such models can be trained with videos of both static and dynamic scenes. To allow them to be trained with modestly-sized datasets, we introduce invariances by factoring out illumination and texture by forcing the model to predict (pseudo) depth, readily obtained for in-the-wild videos via off-the-shelf monocular depth networks. In fact, we show that simply modifying networks to predict grayscale pixels already improves the accuracy of video prediction. Given the extra controllability with timestamp conditioning, we propose sampling schedules that work better than the traditional autoregressive and hierarchical sampling strategies. Motivated by probabilistic metrics from the object forecasting literature, we create a benchmark for video prediction on a diverse set of videos spanning indoor and outdoor scenes and a large vocabulary of objects. Our experiments illustrate the effectiveness of learning to condition on timestamps, and show the importance of predicting the future with invariant modalities.","sentences":["Our work explores the task of generating future sensor observations conditioned on the past.","We are motivated by `predictive coding' concepts from neuroscience as well as robotic applications such as self-driving vehicles.","Predictive video modeling is challenging because the future may be multi-modal and learning at scale remains computationally expensive for video processing.","To address both challenges, our key insight is to leverage the large-scale pretraining of image diffusion models which can handle multi-modality.","We repurpose image models for video prediction by conditioning on new frame timestamps.","Such models can be trained with videos of both static and dynamic scenes.","To allow them to be trained with modestly-sized datasets, we introduce invariances by factoring out illumination and texture by forcing the model to predict (pseudo) depth, readily obtained for in-the-wild videos via off-the-shelf monocular depth networks.","In fact, we show that simply modifying networks to predict grayscale pixels already improves the accuracy of video prediction.","Given the extra controllability with timestamp conditioning, we propose sampling schedules that work better than the traditional autoregressive and hierarchical sampling strategies.","Motivated by probabilistic metrics from the object forecasting literature, we create a benchmark for video prediction on a diverse set of videos spanning indoor and outdoor scenes and a large vocabulary of objects.","Our experiments illustrate the effectiveness of learning to condition on timestamps, and show the importance of predicting the future with invariant modalities."],"url":"http://arxiv.org/abs/2404.11554v1"}
{"created":"2024-04-17 16:53:16","title":"Quantifying Multilingual Performance of Large Language Models Across Languages","abstract":"The training process of Large Language Models (LLMs) requires extensive text corpus. However, these data are often unevenly distributed in different languages. As a result, LLMs perform well on common languages, such as English, German, and French, but perform poorly on low-resource languages. However, currently there is no work to quantitatively measure the performance of LLMs in low-resource languages. To fill this gap, we proposed the Language Ranker that aims to benchmark and rank different languages according to the performance of LLMs on those languages. We employ the LLM's performance on the English corpus as a baseline to compare the performances of different languages and English. We have the following three findings: 1. The performance rankings of different LLMs in all languages are roughly the same. 2. LLMs with different sizes have the same partial order of performance. 3. There is a strong correlation between LlaMa2's performance in different languages and the proportion of the pre-training corpus. These findings illustrate that the Language Ranker can be used as an indicator to measure the language performance of LLMs.","sentences":["The training process of Large Language Models (LLMs) requires extensive text corpus.","However, these data are often unevenly distributed in different languages.","As a result, LLMs perform well on common languages, such as English, German, and French, but perform poorly on low-resource languages.","However, currently there is no work to quantitatively measure the performance of LLMs in low-resource languages.","To fill this gap, we proposed the Language Ranker that aims to benchmark and rank different languages according to the performance of LLMs on those languages.","We employ the LLM's performance on the English corpus as a baseline to compare the performances of different languages and English.","We have the following three findings: 1.","The performance rankings of different LLMs in all languages are roughly the same.","2. LLMs with different sizes have the same partial order of performance.","3.","There is a strong correlation between LlaMa2's performance in different languages and the proportion of the pre-training corpus.","These findings illustrate that the Language Ranker can be used as an indicator to measure the language performance of LLMs."],"url":"http://arxiv.org/abs/2404.11553v1"}
{"created":"2024-04-17 16:42:35","title":"Strategic Network Inspection with Location-Specific Detection Capabilities","abstract":"We consider a two-person network inspection game, in which a defender positions a limited number of detectors to detect multiple attacks caused by an attacker. We assume that detection is imperfect, and each detector location is associated with a probability of detecting attacks within its set of monitored network components. The objective of the defender (resp. attacker) is to minimize (resp. maximize) the expected number of undetected attacks. To compute Nash Equilibria (NE) for this large-scale zero-sum game, we formulate a linear program with a small number of constraints, which we solve via column generation. We provide an exact mixed-integer program for the pricing problem, which entails computing a defender's pure best response, and leverage its supermodular structure to derive two efficient approaches to obtain approximate NE with theoretical guarantees: A column generation and a multiplicative weights update (MWU) algorithm with approximate best responses. To address the computational challenges posed by combinatorial attacker strategies, each iteration of our MWU algorithm requires computing a projection under the unnormalized relative entropy. We provide a closed-form solution and a linear-time algorithm for the projection problem. Our computational results in real-world gas distribution networks illustrate the performance and scalability of our solution approaches.","sentences":["We consider a two-person network inspection game, in which a defender positions a limited number of detectors to detect multiple attacks caused by an attacker.","We assume that detection is imperfect, and each detector location is associated with a probability of detecting attacks within its set of monitored network components.","The objective of the defender (resp. attacker) is to minimize (resp.","maximize) the expected number of undetected attacks.","To compute Nash Equilibria (NE) for this large-scale zero-sum game, we formulate a linear program with a small number of constraints, which we solve via column generation.","We provide an exact mixed-integer program for the pricing problem, which entails computing a defender's pure best response, and leverage its supermodular structure to derive two efficient approaches to obtain approximate NE with theoretical guarantees: A column generation and a multiplicative weights update (MWU) algorithm with approximate best responses.","To address the computational challenges posed by combinatorial attacker strategies, each iteration of our MWU algorithm requires computing a projection under the unnormalized relative entropy.","We provide a closed-form solution and a linear-time algorithm for the projection problem.","Our computational results in real-world gas distribution networks illustrate the performance and scalability of our solution approaches."],"url":"http://arxiv.org/abs/2404.11545v1"}
{"created":"2024-04-17 16:37:33","title":"Ordinal Maximin Guarantees for Group Fair Division","abstract":"We investigate fairness in the allocation of indivisible items among groups of agents using the notion of maximin share (MMS). While previous work has shown that no nontrivial multiplicative MMS approximation can be guaranteed in this setting for general group sizes, we demonstrate that ordinal relaxations are much more useful. For example, we show that if $n$ agents are distributed equally across $g$ groups, there exists a $1$-out-of-$k$ MMS allocation for $k = O(g\\log(n/g))$, while if all but a constant number of agents are in the same group, we obtain $k = O(\\log n/\\log \\log n)$. We also establish the tightness of these bounds and provide non-asymptotic results for the case of two groups.","sentences":["We investigate fairness in the allocation of indivisible items among groups of agents using the notion of maximin share (MMS).","While previous work has shown that no nontrivial multiplicative MMS approximation can be guaranteed in this setting for general group sizes, we demonstrate that ordinal relaxations are much more useful.","For example, we show that if $n$ agents are distributed equally across $g$ groups, there exists a $1$-out-of-$k$ MMS allocation for $k = O(g\\log(n/g))$, while if all but a constant number of agents are in the same group, we obtain $k = O(\\log n/\\log \\log n)$. We also establish the tightness of these bounds and provide non-asymptotic results for the case of two groups."],"url":"http://arxiv.org/abs/2404.11543v1"}
{"created":"2024-04-17 16:36:55","title":"A Lean Simulation Framework for Stress Testing IoT Cloud Systems","abstract":"The Internet of Things connects a plethora of smart devices globally across various applications like smart cities, autonomous vehicles and health monitoring. Simulation plays a key role in the testing of IoT systems, noting that field testing of a complete IoT product may be infeasible or prohibitively expensive. This paper addresses a specific yet important need in simulation-based testing for IoT: Stress testing of cloud systems. Existing stress testing solutions for IoT demand significant computational resources, making them ill-suited and costly. We propose a lean simulation framework designed for IoT cloud stress testing which enables efficient simulation of a large array of IoT and edge devices that communicate with the cloud. To facilitate simulation construction for practitioners, we develop a domain-specific language (DSL), named IoTECS, for generating simulators from model-based specifications. We provide the syntax and semantics of IoTECS and implement IoTECS using Xtext and Xtend. We assess simulators generated from IoTECS specifications for stress testing two real-world systems: a cloud-based IoT monitoring system and an IoT-connected vehicle system. Our empirical results indicate that simulators created using IoTECS: (1)achieve best performance when configured with Docker containerization; (2)effectively assess the service capacity of our case-study systems, and (3)outperform industrial stress-testing baseline tools, JMeter and Locust, by a factor of 3.5 in terms of the number of IoT and edge devices they can simulate using identical hardware resources. To gain initial insights about the usefulness of IoTECS in practice, we interviewed two engineers from our industry partner who have firsthand experience with IoTECS. Feedback from these interviews suggests that IoTECS is effective in stress testing IoT cloud systems, saving significant time and effort.","sentences":["The Internet of Things connects a plethora of smart devices globally across various applications like smart cities, autonomous vehicles and health monitoring.","Simulation plays a key role in the testing of IoT systems, noting that field testing of a complete IoT product may be infeasible or prohibitively expensive.","This paper addresses a specific yet important need in simulation-based testing for IoT: Stress testing of cloud systems.","Existing stress testing solutions for IoT demand significant computational resources, making them ill-suited and costly.","We propose a lean simulation framework designed for IoT cloud stress testing which enables efficient simulation of a large array of IoT and edge devices that communicate with the cloud.","To facilitate simulation construction for practitioners, we develop a domain-specific language (DSL), named IoTECS, for generating simulators from model-based specifications.","We provide the syntax and semantics of IoTECS and implement IoTECS using Xtext and Xtend.","We assess simulators generated from IoTECS specifications for stress testing two real-world systems: a cloud-based IoT monitoring system and an IoT-connected vehicle system.","Our empirical results indicate that simulators created using IoTECS: (1)achieve best performance when configured with Docker containerization; (2)effectively assess the service capacity of our case-study systems, and (3)outperform industrial stress-testing baseline tools, JMeter and Locust, by a factor of 3.5 in terms of the number of IoT and edge devices they can simulate using identical hardware resources.","To gain initial insights about the usefulness of IoTECS in practice, we interviewed two engineers from our industry partner who have firsthand experience with IoTECS.","Feedback from these interviews suggests that IoTECS is effective in stress testing IoT cloud systems, saving significant time and effort."],"url":"http://arxiv.org/abs/2404.11542v1"}
{"created":"2024-04-17 16:33:22","title":"Evaluating Span Extraction in Generative Paradigm: A Reflection on Aspect-Based Sentiment Analysis","abstract":"In the era of rapid evolution of generative language models within the realm of natural language processing, there is an imperative call to revisit and reformulate evaluation methodologies, especially in the domain of aspect-based sentiment analysis (ABSA). This paper addresses the emerging challenges introduced by the generative paradigm, which has moderately blurred traditional boundaries between understanding and generation tasks. Building upon prevailing practices in the field, we analyze the advantages and shortcomings associated with the prevalent ABSA evaluation paradigms. Through an in-depth examination, supplemented by illustrative examples, we highlight the intricacies involved in aligning generative outputs with other evaluative metrics, specifically those derived from other tasks, including question answering. While we steer clear of advocating for a singular and definitive metric, our contribution lies in paving the path for a comprehensive guideline tailored for ABSA evaluations in this generative paradigm. In this position paper, we aim to provide practitioners with profound reflections, offering insights and directions that can aid in navigating this evolving landscape, ensuring evaluations that are both accurate and reflective of generative capabilities.","sentences":["In the era of rapid evolution of generative language models within the realm of natural language processing, there is an imperative call to revisit and reformulate evaluation methodologies, especially in the domain of aspect-based sentiment analysis (ABSA).","This paper addresses the emerging challenges introduced by the generative paradigm, which has moderately blurred traditional boundaries between understanding and generation tasks.","Building upon prevailing practices in the field, we analyze the advantages and shortcomings associated with the prevalent ABSA evaluation paradigms.","Through an in-depth examination, supplemented by illustrative examples, we highlight the intricacies involved in aligning generative outputs with other evaluative metrics, specifically those derived from other tasks, including question answering.","While we steer clear of advocating for a singular and definitive metric, our contribution lies in paving the path for a comprehensive guideline tailored for ABSA evaluations in this generative paradigm.","In this position paper, we aim to provide practitioners with profound reflections, offering insights and directions that can aid in navigating this evolving landscape, ensuring evaluations that are both accurate and reflective of generative capabilities."],"url":"http://arxiv.org/abs/2404.11539v1"}
{"created":"2024-04-17 16:32:13","title":"GenFighter: A Generative and Evolutive Textual Attack Removal","abstract":"Adversarial attacks pose significant challenges to deep neural networks (DNNs) such as Transformer models in natural language processing (NLP). This paper introduces a novel defense strategy, called GenFighter, which enhances adversarial robustness by learning and reasoning on the training classification distribution. GenFighter identifies potentially malicious instances deviating from the distribution, transforms them into semantically equivalent instances aligned with the training data, and employs ensemble techniques for a unified and robust response. By conducting extensive experiments, we show that GenFighter outperforms state-of-the-art defenses in accuracy under attack and attack success rate metrics. Additionally, it requires a high number of queries per attack, making the attack more challenging in real scenarios. The ablation study shows that our approach integrates transfer learning, a generative/evolutive procedure, and an ensemble method, providing an effective defense against NLP adversarial attacks.","sentences":["Adversarial attacks pose significant challenges to deep neural networks (DNNs) such as Transformer models in natural language processing (NLP).","This paper introduces a novel defense strategy, called GenFighter, which enhances adversarial robustness by learning and reasoning on the training classification distribution.","GenFighter identifies potentially malicious instances deviating from the distribution, transforms them into semantically equivalent instances aligned with the training data, and employs ensemble techniques for a unified and robust response.","By conducting extensive experiments, we show that GenFighter outperforms state-of-the-art defenses in accuracy under attack and attack success rate metrics.","Additionally, it requires a high number of queries per attack, making the attack more challenging in real scenarios.","The ablation study shows that our approach integrates transfer learning, a generative/evolutive procedure, and an ensemble method, providing an effective defense against NLP adversarial attacks."],"url":"http://arxiv.org/abs/2404.11538v1"}
{"created":"2024-04-17 16:30:56","title":"SSDiff: Spatial-spectral Integrated Diffusion Model for Remote Sensing Pansharpening","abstract":"Pansharpening is a significant image fusion technique that merges the spatial content and spectral characteristics of remote sensing images to generate high-resolution multispectral images. Recently, denoising diffusion probabilistic models have been gradually applied to visual tasks, enhancing controllable image generation through low-rank adaptation (LoRA). In this paper, we introduce a spatial-spectral integrated diffusion model for the remote sensing pansharpening task, called SSDiff, which considers the pansharpening process as the fusion process of spatial and spectral components from the perspective of subspace decomposition. Specifically, SSDiff utilizes spatial and spectral branches to learn spatial details and spectral features separately, then employs a designed alternating projection fusion module (APFM) to accomplish the fusion. Furthermore, we propose a frequency modulation inter-branch module (FMIM) to modulate the frequency distribution between branches. The two components of SSDiff can perform favorably against the APFM when utilizing a LoRA-like branch-wise alternative fine-tuning method. It refines SSDiff to capture component-discriminating features more sufficiently. Finally, extensive experiments on four commonly used datasets, i.e., WorldView-3, WorldView-2, GaoFen-2, and QuickBird, demonstrate the superiority of SSDiff both visually and quantitatively. The code will be made open source after possible acceptance.","sentences":["Pansharpening is a significant image fusion technique that merges the spatial content and spectral characteristics of remote sensing images to generate high-resolution multispectral images.","Recently, denoising diffusion probabilistic models have been gradually applied to visual tasks, enhancing controllable image generation through low-rank adaptation (LoRA).","In this paper, we introduce a spatial-spectral integrated diffusion model for the remote sensing pansharpening task, called SSDiff, which considers the pansharpening process as the fusion process of spatial and spectral components from the perspective of subspace decomposition.","Specifically, SSDiff utilizes spatial and spectral branches to learn spatial details and spectral features separately, then employs a designed alternating projection fusion module (APFM) to accomplish the fusion.","Furthermore, we propose a frequency modulation inter-branch module (FMIM) to modulate the frequency distribution between branches.","The two components of SSDiff can perform favorably against the APFM when utilizing a LoRA-like branch-wise alternative fine-tuning method.","It refines SSDiff to capture component-discriminating features more sufficiently.","Finally, extensive experiments on four commonly used datasets, i.e., WorldView-3, WorldView-2, GaoFen-2, and QuickBird, demonstrate the superiority of SSDiff both visually and quantitatively.","The code will be made open source after possible acceptance."],"url":"http://arxiv.org/abs/2404.11537v1"}
{"created":"2024-04-17 16:30:06","title":"FedPFT: Federated Proxy Fine-Tuning of Foundation Models","abstract":"Adapting Foundation Models (FMs) for downstream tasks through Federated Learning (FL) emerges a promising strategy for protecting data privacy and valuable FMs. Existing methods fine-tune FM by allocating sub-FM to clients in FL, however, leading to suboptimal performance due to insufficient tuning and inevitable error accumulations of gradients. In this paper, we propose Federated Proxy Fine-Tuning (FedPFT), a novel method enhancing FMs adaptation in downstream tasks through FL by two key modules. First, the sub-FM construction module employs a layer-wise compression approach, facilitating comprehensive FM fine-tuning across all layers by emphasizing those crucial neurons. Second, the sub-FM alignment module conducts a two-step distillations-layer-level and neuron-level-before and during FL fine-tuning respectively, to reduce error of gradient by accurately aligning sub-FM with FM under theoretical guarantees. Experimental results on seven commonly used datasets (i.e., four text and three vision) demonstrate the superiority of FedPFT.","sentences":["Adapting Foundation Models (FMs) for downstream tasks through Federated Learning (FL) emerges a promising strategy for protecting data privacy and valuable FMs.","Existing methods fine-tune FM by allocating sub-FM to clients in FL, however, leading to suboptimal performance due to insufficient tuning and inevitable error accumulations of gradients.","In this paper, we propose Federated Proxy Fine-Tuning (FedPFT), a novel method enhancing FMs adaptation in downstream tasks through FL by two key modules.","First, the sub-FM construction module employs a layer-wise compression approach, facilitating comprehensive FM fine-tuning across all layers by emphasizing those crucial neurons.","Second, the sub-FM alignment module conducts a two-step distillations-layer-level and neuron-level-before and during FL fine-tuning respectively, to reduce error of gradient by accurately aligning sub-FM with FM under theoretical guarantees.","Experimental results on seven commonly used datasets (i.e., four text and three vision) demonstrate the superiority of FedPFT."],"url":"http://arxiv.org/abs/2404.11536v1"}
{"created":"2024-04-17 16:28:08","title":"Decomposing and Editing Predictions by Modeling Model Computation","abstract":"How does the internal computation of a machine learning model transform inputs into predictions? In this paper, we introduce a task called component modeling that aims to address this question. The goal of component modeling is to decompose an ML model's prediction in terms of its components -- simple functions (e.g., convolution filters, attention heads) that are the \"building blocks\" of model computation. We focus on a special case of this task, component attribution, where the goal is to estimate the counterfactual impact of individual components on a given prediction. We then present COAR, a scalable algorithm for estimating component attributions; we demonstrate its effectiveness across models, datasets, and modalities. Finally, we show that component attributions estimated with COAR directly enable model editing across five tasks, namely: fixing model errors, ``forgetting'' specific classes, boosting subpopulation robustness, localizing backdoor attacks, and improving robustness to typographic attacks. We provide code for COAR at https://github.com/MadryLab/modelcomponents .","sentences":["How does the internal computation of a machine learning model transform inputs into predictions?","In this paper, we introduce a task called component modeling that aims to address this question.","The goal of component modeling is to decompose an ML model's prediction in terms of its components -- simple functions (e.g., convolution filters, attention heads) that are the \"building blocks\" of model computation.","We focus on a special case of this task, component attribution, where the goal is to estimate the counterfactual impact of individual components on a given prediction.","We then present COAR, a scalable algorithm for estimating component attributions; we demonstrate its effectiveness across models, datasets, and modalities.","Finally, we show that component attributions estimated with COAR directly enable model editing across five tasks, namely: fixing model errors, ``forgetting'' specific classes, boosting subpopulation robustness, localizing backdoor attacks, and improving robustness to typographic attacks.","We provide code for COAR at https://github.com/MadryLab/modelcomponents ."],"url":"http://arxiv.org/abs/2404.11534v1"}
{"created":"2024-04-17 16:25:19","title":"Select and Reorder: A Novel Approach for Neural Sign Language Production","abstract":"Sign languages, often categorised as low-resource languages, face significant challenges in achieving accurate translation due to the scarcity of parallel annotated datasets. This paper introduces Select and Reorder (S&R), a novel approach that addresses data scarcity by breaking down the translation process into two distinct steps: Gloss Selection (GS) and Gloss Reordering (GR). Our method leverages large spoken language models and the substantial lexical overlap between source spoken languages and target sign languages to establish an initial alignment. Both steps make use of Non-AutoRegressive (NAR) decoding for reduced computation and faster inference speeds. Through this disentanglement of tasks, we achieve state-of-the-art BLEU and Rouge scores on the Meine DGS Annotated (mDGS) dataset, demonstrating a substantial BLUE-1 improvement of 37.88% in Text to Gloss (T2G) Translation. This innovative approach paves the way for more effective translation models for sign languages, even in resource-constrained settings.","sentences":["Sign languages, often categorised as low-resource languages, face significant challenges in achieving accurate translation due to the scarcity of parallel annotated datasets.","This paper introduces Select and Reorder (S&R), a novel approach that addresses data scarcity by breaking down the translation process into two distinct steps: Gloss Selection (GS) and Gloss Reordering (GR).","Our method leverages large spoken language models and the substantial lexical overlap between source spoken languages and target sign languages to establish an initial alignment.","Both steps make use of Non-AutoRegressive (NAR) decoding for reduced computation and faster inference speeds.","Through this disentanglement of tasks, we achieve state-of-the-art BLEU and Rouge scores on the Meine DGS Annotated (mDGS) dataset, demonstrating a substantial BLUE-1 improvement of 37.88% in Text to Gloss (T2G) Translation.","This innovative approach paves the way for more effective translation models for sign languages, even in resource-constrained settings."],"url":"http://arxiv.org/abs/2404.11532v1"}
{"created":"2024-04-17 16:24:07","title":"Pack of LLMs: Model Fusion at Test-Time via Perplexity Optimization","abstract":"Fusing knowledge from multiple Large Language Models (LLMs) can combine their diverse strengths to achieve improved performance on a given task. However, current fusion approaches either rely on learning-based fusers that do not generalize to new LLMs, or do not take into account how well each LLM understands the input. In this work, we study LLM fusion at test-time, which enables leveraging knowledge from arbitrary user-specified LLMs during inference. We introduce Pack of LLMs (PackLLM), an effective method for test-time fusion that leverages each LLM's expertise, given an input prompt. PackLLM performs model fusion by solving an optimization problem for determining each LLM's importance, so that perplexity over the input prompt is minimized. First, our simple PackLLM-sim variant validates that perplexity is a good indicator for measuring each LLM's expertise. Second, our PackLLM-opt variant approximately solves the perplexity minimization problem via a greedy algorithm. The derived importance weights are used to combine the LLMs during inference. We conduct experiments with over 100 total LLMs on a diverse set of tasks. Experimental results show that (i) perplexity is a reliable measure for LLM fusion, (ii) PackLLM outperforms test-time fusion baselines by 1.89% accuracy points, and (iii) PackLLM can leverage new LLMs to improve performance over learning-based fusion approaches by 3.92-11.94% accuracy points.","sentences":["Fusing knowledge from multiple Large Language Models (LLMs) can combine their diverse strengths to achieve improved performance on a given task.","However, current fusion approaches either rely on learning-based fusers that do not generalize to new LLMs, or do not take into account how well each LLM understands the input.","In this work, we study LLM fusion at test-time, which enables leveraging knowledge from arbitrary user-specified LLMs during inference.","We introduce Pack of LLMs (PackLLM), an effective method for test-time fusion that leverages each LLM's expertise, given an input prompt.","PackLLM performs model fusion by solving an optimization problem for determining each LLM's importance, so that perplexity over the input prompt is minimized.","First, our simple PackLLM-sim variant validates that perplexity is a good indicator for measuring each LLM's expertise.","Second, our PackLLM-opt variant approximately solves the perplexity minimization problem via a greedy algorithm.","The derived importance weights are used to combine the LLMs during inference.","We conduct experiments with over 100 total LLMs on a diverse set of tasks.","Experimental results show that (i) perplexity is a reliable measure for LLM fusion, (ii) PackLLM outperforms test-time fusion baselines by 1.89% accuracy points, and (iii) PackLLM can leverage new LLMs to improve performance over learning-based fusion approaches by 3.92-11.94% accuracy points."],"url":"http://arxiv.org/abs/2404.11531v1"}
{"created":"2024-04-17 16:16:12","title":"JointViT: Modeling Oxygen Saturation Levels with Joint Supervision on Long-Tailed OCTA","abstract":"The oxygen saturation level in the blood (SaO2) is crucial for health, particularly in relation to sleep-related breathing disorders. However, continuous monitoring of SaO2 is time-consuming and highly variable depending on patients' conditions. Recently, optical coherence tomography angiography (OCTA) has shown promising development in rapidly and effectively screening eye-related lesions, offering the potential for diagnosing sleep-related disorders. To bridge this gap, our paper presents three key contributions. Firstly, we propose JointViT, a novel model based on the Vision Transformer architecture, incorporating a joint loss function for supervision. Secondly, we introduce a balancing augmentation technique during data preprocessing to improve the model's performance, particularly on the long-tail distribution within the OCTA dataset. Lastly, through comprehensive experiments on the OCTA dataset, our proposed method significantly outperforms other state-of-the-art methods, achieving improvements of up to 12.28% in overall accuracy. This advancement lays the groundwork for the future utilization of OCTA in diagnosing sleep-related disorders. See project website https://steve-zeyu-zhang.github.io/JointViT","sentences":["The oxygen saturation level in the blood (SaO2) is crucial for health, particularly in relation to sleep-related breathing disorders.","However, continuous monitoring of SaO2 is time-consuming and highly variable depending on patients' conditions.","Recently, optical coherence tomography angiography (OCTA) has shown promising development in rapidly and effectively screening eye-related lesions, offering the potential for diagnosing sleep-related disorders.","To bridge this gap, our paper presents three key contributions.","Firstly, we propose JointViT, a novel model based on the Vision Transformer architecture, incorporating a joint loss function for supervision.","Secondly, we introduce a balancing augmentation technique during data preprocessing to improve the model's performance, particularly on the long-tail distribution within the OCTA dataset.","Lastly, through comprehensive experiments on the OCTA dataset, our proposed method significantly outperforms other state-of-the-art methods, achieving improvements of up to 12.28% in overall accuracy.","This advancement lays the groundwork for the future utilization of OCTA in diagnosing sleep-related disorders.","See project website https://steve-zeyu-zhang.github.io/JointViT"],"url":"http://arxiv.org/abs/2404.11525v1"}
{"created":"2024-04-17 16:10:55","title":"Disentangled Cascaded Graph Convolution Networks for Multi-Behavior Recommendation","abstract":"Multi-behavioral recommender systems have emerged as a solution to address data sparsity and cold-start issues by incorporating auxiliary behaviors alongside target behaviors. However, existing models struggle to accurately capture varying user preferences across different behaviors and fail to account for diverse item preferences within behaviors. Various user preference factors (such as price or quality) entangled in the behavior may lead to sub-optimization problems. Furthermore, these models overlook the personalized nature of user behavioral preferences by employing uniform transformation networks for all users and items. To tackle these challenges, we propose the Disentangled Cascaded Graph Convolutional Network (Disen-CGCN), a novel multi-behavior recommendation model. Disen-CGCN employs disentangled representation techniques to effectively separate factors within user and item representations, ensuring their independence. In addition, it incorporates a multi-behavioral meta-network, enabling personalized feature transformation across user and item behaviors. Furthermore, an attention mechanism captures user preferences for different item factors within each behavior. By leveraging attention weights, we aggregate user and item embeddings separately for each behavior, computing preference scores that predict overall user preferences for items. Our evaluation on benchmark datasets demonstrates the superiority of Disen-CGCN over state-of-the-art models, showcasing an average performance improvement of 7.07% and 9.00% on respective datasets. These results highlight Disen-CGCN's ability to effectively leverage multi-behavioral data, leading to more accurate recommendations.","sentences":["Multi-behavioral recommender systems have emerged as a solution to address data sparsity and cold-start issues by incorporating auxiliary behaviors alongside target behaviors.","However, existing models struggle to accurately capture varying user preferences across different behaviors and fail to account for diverse item preferences within behaviors.","Various user preference factors (such as price or quality) entangled in the behavior may lead to sub-optimization problems.","Furthermore, these models overlook the personalized nature of user behavioral preferences by employing uniform transformation networks for all users and items.","To tackle these challenges, we propose the Disentangled Cascaded Graph Convolutional Network (Disen-CGCN), a novel multi-behavior recommendation model.","Disen-CGCN employs disentangled representation techniques to effectively separate factors within user and item representations, ensuring their independence.","In addition, it incorporates a multi-behavioral meta-network, enabling personalized feature transformation across user and item behaviors.","Furthermore, an attention mechanism captures user preferences for different item factors within each behavior.","By leveraging attention weights, we aggregate user and item embeddings separately for each behavior, computing preference scores that predict overall user preferences for items.","Our evaluation on benchmark datasets demonstrates the superiority of Disen-CGCN over state-of-the-art models, showcasing an average performance improvement of 7.07% and 9.00% on respective datasets.","These results highlight Disen-CGCN's ability to effectively leverage multi-behavioral data, leading to more accurate recommendations."],"url":"http://arxiv.org/abs/2404.11519v1"}
{"created":"2024-04-17 16:07:53","title":"Embedding Privacy in Computational Social Science and Artificial Intelligence Research","abstract":"Privacy is a human right. It ensures that individuals are free to engage in discussions, participate in groups, and form relationships online or offline without fear of their data being inappropriately harvested, analyzed, or otherwise used to harm them. Preserving privacy has emerged as a critical factor in research, particularly in the computational social science (CSS), artificial intelligence (AI) and data science domains, given their reliance on individuals' data for novel insights. The increasing use of advanced computational models stands to exacerbate privacy concerns because, if inappropriately used, they can quickly infringe privacy rights and lead to adverse effects for individuals - especially vulnerable groups - and society. We have already witnessed a host of privacy issues emerge with the advent of large language models (LLMs), such as ChatGPT, which further demonstrate the importance of embedding privacy from the start. This article contributes to the field by discussing the role of privacy and the primary issues that researchers working in CSS, AI, data science and related domains are likely to face. It then presents several key considerations for researchers to ensure participant privacy is best preserved in their research design, data collection and use, analysis, and dissemination of research results.","sentences":["Privacy is a human right.","It ensures that individuals are free to engage in discussions, participate in groups, and form relationships online or offline without fear of their data being inappropriately harvested, analyzed, or otherwise used to harm them.","Preserving privacy has emerged as a critical factor in research, particularly in the computational social science (CSS), artificial intelligence (AI) and data science domains, given their reliance on individuals' data for novel insights.","The increasing use of advanced computational models stands to exacerbate privacy concerns because, if inappropriately used, they can quickly infringe privacy rights and lead to adverse effects for individuals - especially vulnerable groups - and society.","We have already witnessed a host of privacy issues emerge with the advent of large language models (LLMs), such as ChatGPT, which further demonstrate the importance of embedding privacy from the start.","This article contributes to the field by discussing the role of privacy and the primary issues that researchers working in CSS, AI, data science and related domains are likely to face.","It then presents several key considerations for researchers to ensure participant privacy is best preserved in their research design, data collection and use, analysis, and dissemination of research results."],"url":"http://arxiv.org/abs/2404.11515v1"}
{"created":"2024-04-17 16:07:25","title":"Frameworking for a Community-led Feminist Ethics","abstract":"This paper introduces a relational perspective on ethics within the context of Feminist Digital Civics and community-led design. Ethics work in HCI has primarily focused on prescriptive machine ethics and bioethics principles rather than people. In response, we advocate for a community-led, processual approach to ethics, acknowledging power dynamics and local contexts. We thus propose a multidimensional adaptive model for ethics in HCI design, integrating an intersectional feminist ethical lens. This framework embraces feminist epistemologies, methods, and methodologies, fostering a reflexive practice. By weaving together situated knowledges, standpoint theory, intersectionality, participatory methods, and care ethics, our approach offers a holistic foundation for ethics in HCI, aiming to advance community-led practices and enrich the discourse surrounding ethics within this field.","sentences":["This paper introduces a relational perspective on ethics within the context of Feminist Digital Civics and community-led design.","Ethics work in HCI has primarily focused on prescriptive machine ethics and bioethics principles rather than people.","In response, we advocate for a community-led, processual approach to ethics, acknowledging power dynamics and local contexts.","We thus propose a multidimensional adaptive model for ethics in HCI design, integrating an intersectional feminist ethical lens.","This framework embraces feminist epistemologies, methods, and methodologies, fostering a reflexive practice.","By weaving together situated knowledges, standpoint theory, intersectionality, participatory methods, and care ethics, our approach offers a holistic foundation for ethics in HCI, aiming to advance community-led practices and enrich the discourse surrounding ethics within this field."],"url":"http://arxiv.org/abs/2404.11514v1"}
{"created":"2024-04-17 15:59:25","title":"Testing Intersectingness of Uniform Families","abstract":"A set family ${\\cal F}$ is called intersecting if every two members of ${\\cal F}$ intersect, and it is called uniform if all members of ${\\cal F}$ share a common size. A uniform family ${\\cal F} \\subseteq \\binom{[n]}{k}$ of $k$-subsets of $[n]$ is $\\varepsilon$-far from intersecting if one has to remove more than $\\varepsilon \\cdot \\binom{n}{k}$ of the sets of ${\\cal F}$ to make it intersecting. We study the property testing problem that given query access to a uniform family ${\\cal F} \\subseteq \\binom{[n]}{k}$, asks to distinguish between the case that ${\\cal F}$ is intersecting and the case that it is $\\varepsilon$-far from intersecting. We prove that for every fixed integer $r$, the problem admits a non-adaptive two-sided error tester with query complexity $O(\\frac{\\ln n}{\\varepsilon})$ for $\\varepsilon \\geq \\Omega( (\\frac{k}{n})^r)$ and a non-adaptive one-sided error tester with query complexity $O(\\frac{\\ln k}{\\varepsilon})$ for $\\varepsilon \\geq \\Omega( (\\frac{k^2}{n})^r)$. The query complexities are optimal up to the logarithmic terms. For $\\varepsilon \\geq \\Omega( (\\frac{k^2}{n})^2)$, we further provide a non-adaptive one-sided error tester with optimal query complexity of $O(\\frac{1}{\\varepsilon})$. Our findings show that the query complexity of the problem differs substantially from that of testing intersectingness of non-uniform families, studied recently by Chen, De, Li, Nadimpalli, and Servedio (ITCS, 2024).","sentences":["A set family ${\\cal F}$ is called intersecting if every two members of ${\\cal F}$ intersect, and it is called uniform if all members of ${\\cal F}$ share a common size.","A uniform family ${\\cal F} \\subseteq \\binom{[n]}{k}$ of $k$-subsets of $[n]$ is $\\varepsilon$-far from intersecting if one has to remove more than $\\varepsilon \\cdot \\binom{n}{k}$ of the sets of ${\\cal F}$ to make it intersecting.","We study the property testing problem that given query access to a uniform family ${\\cal F} \\subseteq \\binom{[n]}{k}$, asks to distinguish between the case that ${\\cal F}$ is intersecting and the case that it is $\\varepsilon$-far from intersecting.","We prove that for every fixed integer $r$, the problem admits a non-adaptive two-sided error tester with query complexity $O(\\frac{\\ln n}{\\varepsilon})$ for $\\varepsilon \\geq \\Omega( (\\frac{k}{n})^r)$ and a non-adaptive one-sided error tester with query complexity $O(\\frac{\\ln k}{\\varepsilon})$ for $\\varepsilon \\geq \\Omega( (\\frac{k^2}{n})^r)$. The query complexities are optimal up to the logarithmic terms.","For $\\varepsilon \\geq \\Omega( (\\frac{k^2}{n})^2)$, we further provide a non-adaptive one-sided error tester with optimal query complexity of $O(\\frac{1}{\\varepsilon})$. Our findings show that the query complexity of the problem differs substantially from that of testing intersectingness of non-uniform families, studied recently by Chen, De, Li, Nadimpalli, and Servedio (ITCS, 2024)."],"url":"http://arxiv.org/abs/2404.11504v1"}
{"created":"2024-04-17 15:57:50","title":"Towards Coarse-to-Fine Evaluation of Inference Efficiency for Large Language Models","abstract":"In real world, large language models (LLMs) can serve as the assistant to help users accomplish their jobs, and also support the development of advanced applications. For the wide application of LLMs, the inference efficiency is an essential concern, which has been widely studied in existing work, and numerous optimization algorithms and code libraries have been proposed to improve it. Nonetheless, users still find it challenging to compare the effectiveness of all the above methods and understand the underlying mechanisms. In this work, we perform a detailed coarse-to-fine analysis of the inference performance of various code libraries. To evaluate the overall effectiveness, we examine four usage scenarios within two practical applications. We further provide both theoretical and empirical fine-grained analyses of each module in the Transformer architecture. Our experiments yield comprehensive results that are invaluable for researchers to evaluate code libraries and improve inference strategies.","sentences":["In real world, large language models (LLMs) can serve as the assistant to help users accomplish their jobs, and also support the development of advanced applications.","For the wide application of LLMs, the inference efficiency is an essential concern, which has been widely studied in existing work, and numerous optimization algorithms and code libraries have been proposed to improve it.","Nonetheless, users still find it challenging to compare the effectiveness of all the above methods and understand the underlying mechanisms.","In this work, we perform a detailed coarse-to-fine analysis of the inference performance of various code libraries.","To evaluate the overall effectiveness, we examine four usage scenarios within two practical applications.","We further provide both theoretical and empirical fine-grained analyses of each module in the Transformer architecture.","Our experiments yield comprehensive results that are invaluable for researchers to evaluate code libraries and improve inference strategies."],"url":"http://arxiv.org/abs/2404.11502v1"}
{"created":"2024-04-17 15:53:49","title":"Paraphrase and Solve: Exploring and Exploiting the Impact of Surface Form on Mathematical Reasoning in Large Language Models","abstract":"This paper studies the relationship between the surface form of a mathematical problem and its solvability by large language models. We find that subtle alterations in the surface form can significantly impact the answer distribution and the solve rate, exposing the language model's lack of robustness and sensitivity to the surface form in reasoning through complex problems. To improve mathematical reasoning performance, we propose Self-Consistency-over-Paraphrases (SCoP), which diversifies reasoning paths from specific surface forms of the problem. We evaluate our approach on four mathematics reasoning benchmarks over three large language models and show that SCoP improves mathematical reasoning performance over vanilla self-consistency, particularly for problems initially deemed unsolvable. Finally, we provide additional experiments and discussion regarding problem difficulty and surface forms, including cross-model difficulty agreement and paraphrasing transferability, and Variance of Variations (VOV) for language model evaluation.","sentences":["This paper studies the relationship between the surface form of a mathematical problem and its solvability by large language models.","We find that subtle alterations in the surface form can significantly impact the answer distribution and the solve rate, exposing the language model's lack of robustness and sensitivity to the surface form in reasoning through complex problems.","To improve mathematical reasoning performance, we propose Self-Consistency-over-Paraphrases (SCoP), which diversifies reasoning paths from specific surface forms of the problem.","We evaluate our approach on four mathematics reasoning benchmarks over three large language models and show that SCoP improves mathematical reasoning performance over vanilla self-consistency, particularly for problems initially deemed unsolvable.","Finally, we provide additional experiments and discussion regarding problem difficulty and surface forms, including cross-model difficulty agreement and paraphrasing transferability, and Variance of Variations (VOV) for language model evaluation."],"url":"http://arxiv.org/abs/2404.11500v1"}
{"created":"2024-04-17 15:52:38","title":"A Data-Driven Representation for Sign Language Production","abstract":"Phonetic representations are used when recording spoken languages, but no equivalent exists for recording signed languages. As a result, linguists have proposed several annotation systems that operate on the gloss or sub-unit level; however, these resources are notably irregular and scarce.   Sign Language Production (SLP) aims to automatically translate spoken language sentences into continuous sequences of sign language. However, current state-of-the-art approaches rely on scarce linguistic resources to work. This has limited progress in the field. This paper introduces an innovative solution by transforming the continuous pose generation problem into a discrete sequence generation problem. Thus, overcoming the need for costly annotation. Although, if available, we leverage the additional information to enhance our approach.   By applying Vector Quantisation (VQ) to sign language data, we first learn a codebook of short motions that can be combined to create a natural sequence of sign. Where each token in the codebook can be thought of as the lexicon of our representation. Then using a transformer we perform a translation from spoken language text to a sequence of codebook tokens. Each token can be directly mapped to a sequence of poses allowing the translation to be performed by a single network. Furthermore, we present a sign stitching method to effectively join tokens together. We evaluate on the RWTH-PHOENIX-Weather-2014T (PHOENIX14T) and the more challenging Meine DGS Annotated (mDGS) datasets. An extensive evaluation shows our approach outperforms previous methods, increasing the BLEU-1 back translation score by up to 72%.","sentences":["Phonetic representations are used when recording spoken languages, but no equivalent exists for recording signed languages.","As a result, linguists have proposed several annotation systems that operate on the gloss or sub-unit level; however, these resources are notably irregular and scarce.   ","Sign Language Production (SLP) aims to automatically translate spoken language sentences into continuous sequences of sign language.","However, current state-of-the-art approaches rely on scarce linguistic resources to work.","This has limited progress in the field.","This paper introduces an innovative solution by transforming the continuous pose generation problem into a discrete sequence generation problem.","Thus, overcoming the need for costly annotation.","Although, if available, we leverage the additional information to enhance our approach.   ","By applying Vector Quantisation (VQ) to sign language data, we first learn a codebook of short motions that can be combined to create a natural sequence of sign.","Where each token in the codebook can be thought of as the lexicon of our representation.","Then using a transformer we perform a translation from spoken language text to a sequence of codebook tokens.","Each token can be directly mapped to a sequence of poses allowing the translation to be performed by a single network.","Furthermore, we present a sign stitching method to effectively join tokens together.","We evaluate on the RWTH-PHOENIX-Weather-2014T (PHOENIX14T) and the more challenging Meine DGS Annotated (mDGS) datasets.","An extensive evaluation shows our approach outperforms previous methods, increasing the BLEU-1 back translation score by up to 72%."],"url":"http://arxiv.org/abs/2404.11499v1"}
{"created":"2024-04-17 15:52:29","title":"Runtime Verification and Field Testing for ROS-Based Robotic Systems","abstract":"Robotic systems are becoming pervasive and adopted in increasingly many domains, such as manufacturing, healthcare, and space exploration. To this end, engineering software has emerged as a crucial discipline for building maintainable and reusable robotic systems. Robotics software engineering research has received increasing attention, fostering autonomy as a fundamental goal. However, robotics developers are still challenged trying to achieve this goal given that simulation is not able to deliver solutions to realistically emulate real-world phenomena. Robots also need to operate in unpredictable and uncontrollable environments, which require safe and trustworthy self-adaptation capabilities implemented in software. Typical techniques to address the challenges are runtime verification, field-based testing, and mitigation techniques that enable fail-safe solutions. However, there is no clear guidance to architect ROS-based systems to enable and facilitate runtime verification and field-based testing. This paper aims to fill in this gap by providing guidelines that can help developers and QA teams when developing, verifying or testing their robots in the field. These guidelines are carefully tailored to address the challenges and requirements of testing robotics systems in real-world scenarios. We conducted a literature review on studies addressing runtime verification and field-based testing for robotic systems, mined ROS-based application repositories, and validated the applicability, clarity, and usefulness via two questionnaires with 55 answers. We contribute 20 guidelines formulated for researchers and practitioners in robotic software engineering. Finally, we map our guidelines to open challenges thus far in runtime verification and field-based testing for ROS-based systems and, we outline promising research directions in the field.","sentences":["Robotic systems are becoming pervasive and adopted in increasingly many domains, such as manufacturing, healthcare, and space exploration.","To this end, engineering software has emerged as a crucial discipline for building maintainable and reusable robotic systems.","Robotics software engineering research has received increasing attention, fostering autonomy as a fundamental goal.","However, robotics developers are still challenged trying to achieve this goal given that simulation is not able to deliver solutions to realistically emulate real-world phenomena.","Robots also need to operate in unpredictable and uncontrollable environments, which require safe and trustworthy self-adaptation capabilities implemented in software.","Typical techniques to address the challenges are runtime verification, field-based testing, and mitigation techniques that enable fail-safe solutions.","However, there is no clear guidance to architect ROS-based systems to enable and facilitate runtime verification and field-based testing.","This paper aims to fill in this gap by providing guidelines that can help developers and QA teams when developing, verifying or testing their robots in the field.","These guidelines are carefully tailored to address the challenges and requirements of testing robotics systems in real-world scenarios.","We conducted a literature review on studies addressing runtime verification and field-based testing for robotic systems, mined ROS-based application repositories, and validated the applicability, clarity, and usefulness via two questionnaires with 55 answers.","We contribute 20 guidelines formulated for researchers and practitioners in robotic software engineering.","Finally, we map our guidelines to open challenges thus far in runtime verification and field-based testing for ROS-based systems and, we outline promising research directions in the field."],"url":"http://arxiv.org/abs/2404.11498v1"}
{"created":"2024-04-17 15:51:15","title":"Runtime Analysis of Evolutionary Diversity Optimization on the Multi-objective (LeadingOnes, TrailingZeros) Problem","abstract":"The diversity optimization is the class of optimization problems, in which we aim at finding a diverse set of good solutions. One of the frequently used approaches to solve such problems is to use evolutionary algorithms which evolve a desired diverse population. This approach is called evolutionary diversity optimization (EDO).   In this paper, we analyse EDO on a 3-objective function LOTZ$_k$, which is a modification of the 2-objective benchmark function (LeadingOnes, TrailingZeros). We prove that the GSEMO computes a set of all Pareto-optimal solutions in $O(kn^3)$ expected iterations. We also analyze the runtime of the GSEMO$_D$ (a modification of the GSEMO for diversity optimization) until it finds a population with the best possible diversity for two different diversity measures, the total imbalance and the sorted imbalances vector. For the first measure we show that the GSEMO$_D$ optimizes it asymptotically faster than it finds a Pareto-optimal population, in $O(kn^2\\log(n))$ expected iterations, and for the second measure we show an upper bound of $O(k^2n^3\\log(n))$ expected iterations. We complement our theoretical analysis with an empirical study, which shows a very similar behavior for both diversity measures that is close to the theory predictions.","sentences":["The diversity optimization is the class of optimization problems, in which we aim at finding a diverse set of good solutions.","One of the frequently used approaches to solve such problems is to use evolutionary algorithms which evolve a desired diverse population.","This approach is called evolutionary diversity optimization (EDO).   ","In this paper, we analyse EDO on a 3-objective function LOTZ$_k$, which is a modification of the 2-objective benchmark function (LeadingOnes, TrailingZeros).","We prove that the GSEMO computes a set of all Pareto-optimal solutions in $O(kn^3)$ expected iterations.","We also analyze the runtime of the GSEMO$_D$ (a modification of the GSEMO for diversity optimization) until it finds a population with the best possible diversity for two different diversity measures, the total imbalance and the sorted imbalances vector.","For the first measure we show that the GSEMO$_D$ optimizes it asymptotically faster than it finds a Pareto-optimal population, in $O(kn^2\\log(n))$ expected iterations, and for the second measure we show an upper bound of $O(k^2n^3\\log(n))$ expected iterations.","We complement our theoretical analysis with an empirical study, which shows a very similar behavior for both diversity measures that is close to the theory predictions."],"url":"http://arxiv.org/abs/2404.11496v1"}
{"created":"2024-04-17 15:47:26","title":"arcjetCV: an open-source software to analyze material ablation","abstract":"arcjetCV is an open-source Python software designed to automate time-resolved measurements of heatshield material recession and recession rates from arcjet test video footage. This new automated and accessible capability greatly exceeds previous manual extraction methods, enabling rapid and detailed characterization of material recession for any sample with a profile video. arcjetCV automates the video segmentation process using machine learning models, including a one-dimensional (1D) Convolutional Neural Network (CNN) to infer the time-window of interest, a two-dimensional (2D) CNN for image and edge segmentation, and a Local Outlier Factor (LOF) for outlier filtering. A graphical user interface (GUI) simplifies the user experience and an application programming interface (API) allows users to call the core functions from scripts, enabling video batch processing. arcjetCV's capability to measure time-resolved recession in turn enables characterization of non-linear processes (shrinkage, swelling, melt flows, etc.), contributing to higher fidelity validation and improved modeling of heatshield material performance. The source code associated with this article can be found at https://github.com/magnus-haw/arcjetCV.","sentences":["arcjetCV is an open-source Python software designed to automate time-resolved measurements of heatshield material recession and recession rates from arcjet test video footage.","This new automated and accessible capability greatly exceeds previous manual extraction methods, enabling rapid and detailed characterization of material recession for any sample with a profile video.","arcjetCV automates the video segmentation process using machine learning models, including a one-dimensional (1D) Convolutional Neural Network (CNN) to infer the time-window of interest, a two-dimensional (2D) CNN for image and edge segmentation, and a Local Outlier Factor (LOF) for outlier filtering.","A graphical user interface (GUI) simplifies the user experience and an application programming interface (API) allows users to call the core functions from scripts, enabling video batch processing.","arcjetCV's capability to measure time-resolved recession in turn enables characterization of non-linear processes (shrinkage, swelling, melt flows, etc.), contributing to higher fidelity validation and improved modeling of heatshield material performance.","The source code associated with this article can be found at https://github.com/magnus-haw/arcjetCV."],"url":"http://arxiv.org/abs/2404.11492v1"}
{"created":"2024-04-17 15:45:49","title":"Multi-resolution Rescored ByteTrack for Video Object Detection on Ultra-low-power Embedded Systems","abstract":"This paper introduces Multi-Resolution Rescored Byte-Track (MR2-ByteTrack), a novel video object detection framework for ultra-low-power embedded processors. This method reduces the average compute load of an off-the-shelf Deep Neural Network (DNN) based object detector by up to 2.25$\\times$ by alternating the processing of high-resolution images (320$\\times$320 pixels) with multiple down-sized frames (192$\\times$192 pixels). To tackle the accuracy degradation due to the reduced image input size, MR2-ByteTrack correlates the output detections over time using the ByteTrack tracker and corrects potential misclassification using a novel probabilistic Rescore algorithm. By interleaving two down-sized images for every high-resolution one as the input of different state-of-the-art DNN object detectors with our MR2-ByteTrack, we demonstrate an average accuracy increase of 2.16% and a latency reduction of 43% on the GAP9 microcontroller compared to a baseline frame-by-frame inference scheme using exclusively full-resolution images. Code available at: https://github.com/Bomps4/Multi_Resolution_Rescored_ByteTrack","sentences":["This paper introduces Multi-Resolution Rescored Byte-Track (MR2-ByteTrack), a novel video object detection framework for ultra-low-power embedded processors.","This method reduces the average compute load of an off-the-shelf Deep Neural Network (DNN) based object detector by up to 2.25$\\times$ by alternating the processing of high-resolution images (320$\\times$320 pixels) with multiple down-sized frames (192$\\times$192 pixels).","To tackle the accuracy degradation due to the reduced image input size, MR2-ByteTrack correlates the output detections over time using the ByteTrack tracker and corrects potential misclassification using a novel probabilistic Rescore algorithm.","By interleaving two down-sized images for every high-resolution one as the input of different state-of-the-art DNN object detectors with our MR2-ByteTrack, we demonstrate an average accuracy increase of 2.16% and a latency reduction of 43% on the GAP9 microcontroller compared to a baseline frame-by-frame inference scheme using exclusively full-resolution images.","Code available at: https://github.com/Bomps4/Multi_Resolution_Rescored_ByteTrack"],"url":"http://arxiv.org/abs/2404.11488v1"}
{"created":"2024-04-17 15:40:45","title":"AgentKit: Flow Engineering with Graphs, not Coding","abstract":"We propose an intuitive LLM prompting framework (AgentKit) for multifunctional agents. AgentKit offers a unified framework for explicitly constructing a complex \"thought process\" from simple natural language prompts. The basic building block in AgentKit is a node, containing a natural language prompt for a specific subtask. The user then puts together chains of nodes, like stacking LEGO pieces. The chains of nodes can be designed to explicitly enforce a naturally structured \"thought process\". For example, for the task of writing a paper, one may start with the thought process of 1) identify a core message, 2) identify prior research gaps, etc. The nodes in AgentKit can be designed and combined in different ways to implement multiple advanced capabilities including on-the-fly hierarchical planning, reflection, and learning from interactions. In addition, due to the modular nature and the intuitive design to simulate explicit human thought process, a basic agent could be implemented as simple as a list of prompts for the subtasks and therefore could be designed and tuned by someone without any programming experience. Quantitatively, we show that agents designed through AgentKit achieve SOTA performance on WebShop and Crafter. These advances underscore AgentKit's potential in making LLM agents effective and accessible for a wider range of applications. https://github.com/holmeswww/AgentKit","sentences":["We propose an intuitive LLM prompting framework (AgentKit) for multifunctional agents.","AgentKit offers a unified framework for explicitly constructing a complex \"thought process\" from simple natural language prompts.","The basic building block in AgentKit is a node, containing a natural language prompt for a specific subtask.","The user then puts together chains of nodes, like stacking LEGO pieces.","The chains of nodes can be designed to explicitly enforce a naturally structured \"thought process\".","For example, for the task of writing a paper, one may start with the thought process of 1) identify a core message, 2) identify prior research gaps, etc.","The nodes in AgentKit can be designed and combined in different ways to implement multiple advanced capabilities including on-the-fly hierarchical planning, reflection, and learning from interactions.","In addition, due to the modular nature and the intuitive design to simulate explicit human thought process, a basic agent could be implemented as simple as a list of prompts for the subtasks and therefore could be designed and tuned by someone without any programming experience.","Quantitatively, we show that agents designed through AgentKit achieve SOTA performance on WebShop and Crafter.","These advances underscore AgentKit's potential in making LLM agents effective and accessible for a wider range of applications.","https://github.com/holmeswww/AgentKit"],"url":"http://arxiv.org/abs/2404.11483v1"}
{"created":"2024-04-17 15:34:55","title":"IoTSim-Osmosis-RES: Towards autonomic renewable energy-aware osmotic computing","abstract":"Internet of Things systems exists in various areas of our everyday life. For example, sensors installed in smart cities and homes are processed in edge and cloud computing centres providing several benefits that improve our lives. The place of data processing is related to the required system response times -- processing data closer to its source results in a shorter system response time. The Osmotic Computing concept enables flexible deployment of data processing services and their possible movement, just like particles in the osmosis phenomenon move between regions of different densities. At the same time, the impact of complex computer architecture on the environment is increasingly being compensated by the use of renewable and low-carbon energy sources. However, the uncertainty of supplying green energy makes the management of Osmotic Computing demanding, and therefore their autonomy is desirable. In the paper, we present a framework enabling osmotic computing simulation based on renewable energy sources and autonomic osmotic agents, allowing the analysis of distributed management algorithms. We discuss the challenges posed to the framework and analyze various management algorithms for cooperating osmotic agents. In the evaluation we show that changing the adaptation logic of the osmotic agents, it is possible to increase the self-consumption of renewable energy sources or increase the usage of low emission ones.","sentences":["Internet of Things systems exists in various areas of our everyday life.","For example, sensors installed in smart cities and homes are processed in edge and cloud computing centres providing several benefits that improve our lives.","The place of data processing is related to the required system response times -- processing data closer to its source results in a shorter system response time.","The Osmotic Computing concept enables flexible deployment of data processing services and their possible movement, just like particles in the osmosis phenomenon move between regions of different densities.","At the same time, the impact of complex computer architecture on the environment is increasingly being compensated by the use of renewable and low-carbon energy sources.","However, the uncertainty of supplying green energy makes the management of Osmotic Computing demanding, and therefore their autonomy is desirable.","In the paper, we present a framework enabling osmotic computing simulation based on renewable energy sources and autonomic osmotic agents, allowing the analysis of distributed management algorithms.","We discuss the challenges posed to the framework and analyze various management algorithms for cooperating osmotic agents.","In the evaluation we show that changing the adaptation logic of the osmotic agents, it is possible to increase the self-consumption of renewable energy sources or increase the usage of low emission ones."],"url":"http://arxiv.org/abs/2404.11481v1"}
{"created":"2024-04-17 15:32:56","title":"Taxonomy to Regulation: A (Geo)Political Taxonomy for AI Risks and Regulatory Measures in the EU AI Act","abstract":"Technological innovations have shown remarkable capabilities to benefit and harm society alike. AI constitutes a democratized sophisticated technology accessible to large parts of society, including malicious actors. This work proposes a taxonomy focusing on on (geo)political risks associated with AI. It identifies 12 risks in total divided into four categories: (1) Geopolitical Pressures, (2) Malicious Usage, (3) Environmental, Social, and Ethical Risks, and (4) Privacy and Trust Violations. Incorporating a regulatory side, this paper conducts a policy assessment of the EU AI Act. Adopted in March 2023, the landmark regulation has the potential to have a positive top-down impact concerning AI risk reduction but needs regulatory adjustments to mitigate risks more comprehensively. Regulatory exceptions for open-source models, excessively high parameters for the classification of GPAI models as a systemic risk, and the exclusion of systems designed exclusively for military purposes from the regulation's obligations leave room for future action.","sentences":["Technological innovations have shown remarkable capabilities to benefit and harm society alike.","AI constitutes a democratized sophisticated technology accessible to large parts of society, including malicious actors.","This work proposes a taxonomy focusing on on (geo)political risks associated with AI.","It identifies 12 risks in total divided into four categories: (1) Geopolitical Pressures, (2) Malicious Usage, (3) Environmental, Social, and Ethical Risks, and (4) Privacy and Trust Violations.","Incorporating a regulatory side, this paper conducts a policy assessment of the EU AI Act.","Adopted in March 2023, the landmark regulation has the potential to have a positive top-down impact concerning AI risk reduction but needs regulatory adjustments to mitigate risks more comprehensively.","Regulatory exceptions for open-source models, excessively high parameters for the classification of GPAI models as a systemic risk, and the exclusion of systems designed exclusively for military purposes from the regulation's obligations leave room for future action."],"url":"http://arxiv.org/abs/2404.11476v1"}
{"created":"2024-04-17 15:31:06","title":"AdaIR: Exploiting Underlying Similarities of Image Restoration Tasks with Adapters","abstract":"Existing image restoration approaches typically employ extensive networks specifically trained for designated degradations. Despite being effective, such methods inevitably entail considerable storage costs and computational overheads due to the reliance on task-specific networks. In this work, we go beyond this well-established framework and exploit the inherent commonalities among image restoration tasks. The primary objective is to identify components that are shareable across restoration tasks and augment the shared components with modules specifically trained for individual tasks. Towards this goal, we propose AdaIR, a novel framework that enables low storage cost and efficient training without sacrificing performance. Specifically, a generic restoration network is first constructed through self-supervised pre-training using synthetic degradations. Subsequent to the pre-training phase, adapters are trained to adapt the pre-trained network to specific degradations. AdaIR requires solely the training of lightweight, task-specific modules, ensuring a more efficient storage and training regimen. We have conducted extensive experiments to validate the effectiveness of AdaIR and analyze the influence of the pre-training strategy on discovering shareable components. Extensive experimental results show that AdaIR achieves outstanding results on multi-task restoration while utilizing significantly fewer parameters (1.9 MB) and less training time (7 hours) for each restoration task. The source codes and trained models will be released.","sentences":["Existing image restoration approaches typically employ extensive networks specifically trained for designated degradations.","Despite being effective, such methods inevitably entail considerable storage costs and computational overheads due to the reliance on task-specific networks.","In this work, we go beyond this well-established framework and exploit the inherent commonalities among image restoration tasks.","The primary objective is to identify components that are shareable across restoration tasks and augment the shared components with modules specifically trained for individual tasks.","Towards this goal, we propose AdaIR, a novel framework that enables low storage cost and efficient training without sacrificing performance.","Specifically, a generic restoration network is first constructed through self-supervised pre-training using synthetic degradations.","Subsequent to the pre-training phase, adapters are trained to adapt the pre-trained network to specific degradations.","AdaIR requires solely the training of lightweight, task-specific modules, ensuring a more efficient storage and training regimen.","We have conducted extensive experiments to validate the effectiveness of AdaIR and analyze the influence of the pre-training strategy on discovering shareable components.","Extensive experimental results show that AdaIR achieves outstanding results on multi-task restoration while utilizing significantly fewer parameters (1.9 MB) and less training time (7 hours) for each restoration task.","The source codes and trained models will be released."],"url":"http://arxiv.org/abs/2404.11475v1"}
{"created":"2024-04-17 15:28:53","title":"Towards Highly Realistic Artistic Style Transfer via Stable Diffusion with Step-aware and Layer-aware Prompt","abstract":"Artistic style transfer aims to transfer the learned artistic style onto an arbitrary content image, generating artistic stylized images. Existing generative adversarial network-based methods fail to generate highly realistic stylized images and always introduce obvious artifacts and disharmonious patterns. Recently, large-scale pre-trained diffusion models opened up a new way for generating highly realistic artistic stylized images. However, diffusion model-based methods generally fail to preserve the content structure of input content images well, introducing some undesired content structure and style patterns. To address the above problems, we propose a novel pre-trained diffusion-based artistic style transfer method, called LSAST, which can generate highly realistic artistic stylized images while preserving the content structure of input content images well, without bringing obvious artifacts and disharmonious style patterns. Specifically, we introduce a Step-aware and Layer-aware Prompt Space, a set of learnable prompts, which can learn the style information from the collection of artworks and dynamically adjusts the input images' content structure and style pattern. To train our prompt space, we propose a novel inversion method, called Step-ware and Layer-aware Prompt Inversion, which allows the prompt space to learn the style information of the artworks collection. In addition, we inject a pre-trained conditional branch of ControlNet into our LSAST, which further improved our framework's ability to maintain content structure. Extensive experiments demonstrate that our proposed method can generate more highly realistic artistic stylized images than the state-of-the-art artistic style transfer methods.","sentences":["Artistic style transfer aims to transfer the learned artistic style onto an arbitrary content image, generating artistic stylized images.","Existing generative adversarial network-based methods fail to generate highly realistic stylized images and always introduce obvious artifacts and disharmonious patterns.","Recently, large-scale pre-trained diffusion models opened up a new way for generating highly realistic artistic stylized images.","However, diffusion model-based methods generally fail to preserve the content structure of input content images well, introducing some undesired content structure and style patterns.","To address the above problems, we propose a novel pre-trained diffusion-based artistic style transfer method, called LSAST, which can generate highly realistic artistic stylized images while preserving the content structure of input content images well, without bringing obvious artifacts and disharmonious style patterns.","Specifically, we introduce a Step-aware and Layer-aware Prompt Space, a set of learnable prompts, which can learn the style information from the collection of artworks and dynamically adjusts the input images' content structure and style pattern.","To train our prompt space, we propose a novel inversion method, called Step-ware and Layer-aware Prompt Inversion, which allows the prompt space to learn the style information of the artworks collection.","In addition, we inject a pre-trained conditional branch of ControlNet into our LSAST, which further improved our framework's ability to maintain content structure.","Extensive experiments demonstrate that our proposed method can generate more highly realistic artistic stylized images than the state-of-the-art artistic style transfer methods."],"url":"http://arxiv.org/abs/2404.11474v1"}
{"created":"2024-04-17 15:26:55","title":"Assessing The Effectiveness Of Current Cybersecurity Regulations And Policies In The US","abstract":"This article assesses the effectiveness of current cybersecurity regulations and policies in the United States amidst the escalating frequency and sophistication of cyber threats. The focus is on the comprehensive framework established by the U.S. government, with a spotlight on the National Institute of Standards and Technology (NIST) Cybersecurity Framework and key regulations such as HIPAA, GLBA, FISMA, CISA, CCPA, and the DOD Cybersecurity Maturity Model Certification. The study evaluates the impact of these regulations on different sectors and analyzes trends in cybercrime data from 2000 to 2022. The findings highlight the challenges, successes, and the need for continuous adaptation in the face of evolving cyber threats","sentences":["This article assesses the effectiveness of current cybersecurity regulations and policies in the United States amidst the escalating frequency and sophistication of cyber threats.","The focus is on the comprehensive framework established by the U.S. government, with a spotlight on the National Institute of Standards and Technology (NIST) Cybersecurity Framework and key regulations such as HIPAA, GLBA, FISMA, CISA, CCPA, and the DOD Cybersecurity Maturity Model Certification.","The study evaluates the impact of these regulations on different sectors and analyzes trends in cybercrime data from 2000 to 2022.","The findings highlight the challenges, successes, and the need for continuous adaptation in the face of evolving cyber threats"],"url":"http://arxiv.org/abs/2404.11473v1"}
{"created":"2024-04-17 15:23:12","title":"A Federated Learning Approach to Privacy Preserving Offensive Language Identification","abstract":"The spread of various forms of offensive speech online is an important concern in social media. While platforms have been investing heavily in ways of coping with this problem, the question of privacy remains largely unaddressed. Models trained to detect offensive language on social media are trained and/or fine-tuned using large amounts of data often stored in centralized servers. Since most social media data originates from end users, we propose a privacy preserving decentralized architecture for identifying offensive language online by introducing Federated Learning (FL) in the context of offensive language identification. FL is a decentralized architecture that allows multiple models to be trained locally without the need for data sharing hence preserving users' privacy. We propose a model fusion approach to perform FL. We trained multiple deep learning models on four publicly available English benchmark datasets (AHSD, HASOC, HateXplain, OLID) and evaluated their performance in detail. We also present initial cross-lingual experiments in English and Spanish. We show that the proposed model fusion approach outperforms baselines in all the datasets while preserving privacy.","sentences":["The spread of various forms of offensive speech online is an important concern in social media.","While platforms have been investing heavily in ways of coping with this problem, the question of privacy remains largely unaddressed.","Models trained to detect offensive language on social media are trained and/or fine-tuned using large amounts of data often stored in centralized servers.","Since most social media data originates from end users, we propose a privacy preserving decentralized architecture for identifying offensive language online by introducing Federated Learning (FL) in the context of offensive language identification.","FL is a decentralized architecture that allows multiple models to be trained locally without the need for data sharing hence preserving users' privacy.","We propose a model fusion approach to perform FL.","We trained multiple deep learning models on four publicly available English benchmark datasets (AHSD, HASOC, HateXplain, OLID) and evaluated their performance in detail.","We also present initial cross-lingual experiments in English and Spanish.","We show that the proposed model fusion approach outperforms baselines in all the datasets while preserving privacy."],"url":"http://arxiv.org/abs/2404.11470v1"}
{"created":"2024-04-17 15:17:57","title":"Designing Touchscreen Menu Interfaces for In-Vehicle Infotainment Systems: the Effect of Depth and Breadth Trade-off and Task Types on Visual-Manual Distraction","abstract":"Multitasking with a touch screen user-interface while driving is known to impact negatively driving performance and safety. Literature shows that list scrolling interfaces generate more visual-manual distraction than structured menus and sequential navigation. Depth and breadth trade-offs for structured navigation have been studied. However, little is known on how secondary task characteristics interact with those trade-offs. In this study, we make the hypothesis that both menu's depth and task complexity interact in generating visual-manual distraction. Using a driving simulation setup, we collected telemetry and eye-tracking data to evaluate driving performance. Participants were multitasking with a mobile app, presenting a range of eight depth and breadth trade-offs under three types of secondary tasks, involving different cognitive operations (Systematic reading, Search for an item, Memorize items' state). The results confirm our hypothesis. Systematic interaction with menu items generated a visual demand that increased with menu's depth, while visual demand reach an optimum for Search and Memory tasks. We discuss implications for design: In a multitasking context, display design effectiveness must be assessed while considering menu's layout but also cognitive processes involved.","sentences":["Multitasking with a touch screen user-interface while driving is known to impact negatively driving performance and safety.","Literature shows that list scrolling interfaces generate more visual-manual distraction than structured menus and sequential navigation.","Depth and breadth trade-offs for structured navigation have been studied.","However, little is known on how secondary task characteristics interact with those trade-offs.","In this study, we make the hypothesis that both menu's depth and task complexity interact in generating visual-manual distraction.","Using a driving simulation setup, we collected telemetry and eye-tracking data to evaluate driving performance.","Participants were multitasking with a mobile app, presenting a range of eight depth and breadth trade-offs under three types of secondary tasks, involving different cognitive operations (Systematic reading, Search for an item, Memorize items' state).","The results confirm our hypothesis.","Systematic interaction with menu items generated a visual demand that increased with menu's depth, while visual demand reach an optimum for Search and Memory tasks.","We discuss implications for design: In a multitasking context, display design effectiveness must be assessed while considering menu's layout but also cognitive processes involved."],"url":"http://arxiv.org/abs/2404.11469v1"}
{"created":"2024-04-17 15:16:01","title":"A Large-scale Fine-grained Analysis of Packages in Open-Source Software Ecosystems","abstract":"Package managers such as NPM, Maven, and PyPI play a pivotal role in open-source software (OSS) ecosystems, streamlining the distribution and management of various freely available packages. The fine-grained details within software packages can unveil potential risks within existing OSS ecosystems, offering valuable insights for detecting malicious packages. In this study, we undertake a large-scale empirical analysis focusing on fine-grained information (FGI): the metadata, static, and dynamic functions. Specifically, we investigate the FGI usage across a diverse set of 50,000+ legitimate and 1,000+ malicious packages. Based on this diverse data collection, we conducted a comparative analysis between legitimate and malicious packages. Our findings reveal that (1) malicious packages have less metadata content and utilize fewer static and dynamic functions than legitimate ones; (2) malicious packages demonstrate a higher tendency to invoke HTTP/URL functions as opposed to other application services, such as FTP or SMTP; (3) FGI serves as a distinguishable indicator between legitimate and malicious packages; and (4) one dimension in FGI has sufficient distinguishable capability to detect malicious packages, and combining all dimensions in FGI cannot significantly improve overall performance.","sentences":["Package managers such as NPM, Maven, and PyPI play a pivotal role in open-source software (OSS) ecosystems, streamlining the distribution and management of various freely available packages.","The fine-grained details within software packages can unveil potential risks within existing OSS ecosystems, offering valuable insights for detecting malicious packages.","In this study, we undertake a large-scale empirical analysis focusing on fine-grained information (FGI): the metadata, static, and dynamic functions.","Specifically, we investigate the FGI usage across a diverse set of 50,000+ legitimate and 1,000+ malicious packages.","Based on this diverse data collection, we conducted a comparative analysis between legitimate and malicious packages.","Our findings reveal that (1) malicious packages have less metadata content and utilize fewer static and dynamic functions than legitimate ones; (2) malicious packages demonstrate a higher tendency to invoke HTTP/URL functions as opposed to other application services, such as FTP or SMTP; (3) FGI serves as a distinguishable indicator between legitimate and malicious packages; and (4) one dimension in FGI has sufficient distinguishable capability to detect malicious packages, and combining all dimensions in FGI cannot significantly improve overall performance."],"url":"http://arxiv.org/abs/2404.11467v1"}
{"created":"2024-04-17 15:15:47","title":"X-posing Free Speech: Examining the Impact of Moderation Relaxation on Online Social Networks","abstract":"We investigate the impact of free speech and the relaxation of moderation on online social media platforms using Elon Musk's takeover of Twitter as a case study. By curating a dataset of over 10 million tweets, our study employs a novel framework combining content and network analysis. Our findings reveal a significant increase in the distribution of certain forms of hate content, particularly targeting the LGBTQ+ community and liberals. Network analysis reveals the formation of cohesive hate communities facilitated by influential bridge users, with substantial growth in interactions hinting at increased hate production and diffusion. By tracking the temporal evolution of PageRank, we identify key influencers, primarily self-identified far-right supporters disseminating hate against liberals and woke culture. Ironically, embracing free speech principles appears to have enabled hate speech against the very concept of freedom of expression and free speech itself. Our findings underscore the delicate balance platforms must strike between open expression and robust moderation to curb the proliferation of hate online.","sentences":["We investigate the impact of free speech and the relaxation of moderation on online social media platforms using Elon Musk's takeover of Twitter as a case study.","By curating a dataset of over 10 million tweets, our study employs a novel framework combining content and network analysis.","Our findings reveal a significant increase in the distribution of certain forms of hate content, particularly targeting the LGBTQ+ community and liberals.","Network analysis reveals the formation of cohesive hate communities facilitated by influential bridge users, with substantial growth in interactions hinting at increased hate production and diffusion.","By tracking the temporal evolution of PageRank, we identify key influencers, primarily self-identified far-right supporters disseminating hate against liberals and woke culture.","Ironically, embracing free speech principles appears to have enabled hate speech against the very concept of freedom of expression and free speech itself.","Our findings underscore the delicate balance platforms must strike between open expression and robust moderation to curb the proliferation of hate online."],"url":"http://arxiv.org/abs/2404.11465v1"}
{"created":"2024-04-17 15:14:45","title":"Low-Density Parity-Check Codes and Spatial Coupling for Quantitative Group Testing","abstract":"A non-adaptive quantitative group testing (GT) scheme based on sparse codes-on-graphs in combination with low-complexity peeling decoding was introduced and analyzed by Karimi et al.. In this work, we propose a variant of this scheme based on low-density parity-check codes where the BCH codes at the constraint nodes are replaced by simple single parity-check codes. Furthermore, we apply spatial coupling to both GT schemes, perform a density evolution analysis, and compare their performance with and without coupling. Our analysis shows that both schemes improve with increasing coupling memory, and for all considered cases, it is observed that the LDPC code-based scheme substantially outperforms the original scheme. Simulation results for finite block length confirm the asymptotic density evolution thresholds.","sentences":["A non-adaptive quantitative group testing (GT) scheme based on sparse codes-on-graphs in combination with low-complexity peeling decoding was introduced and analyzed by Karimi et al..","In this work, we propose a variant of this scheme based on low-density parity-check codes where the BCH codes at the constraint nodes are replaced by simple single parity-check codes.","Furthermore, we apply spatial coupling to both GT schemes, perform a density evolution analysis, and compare their performance with and without coupling.","Our analysis shows that both schemes improve with increasing coupling memory, and for all considered cases, it is observed that the LDPC code-based scheme substantially outperforms the original scheme.","Simulation results for finite block length confirm the asymptotic density evolution thresholds."],"url":"http://arxiv.org/abs/2404.11463v1"}
{"created":"2024-04-17 15:09:31","title":"Using Game Engines and Machine Learning to Create Synthetic Satellite Imagery for a Tabletop Verification Exercise","abstract":"Satellite imagery is regarded as a great opportunity for citizen-based monitoring of activities of interest. Relevant imagery may however not be available at sufficiently high resolution, quality, or cadence -- let alone be uniformly accessible to open-source analysts. This limits an assessment of the true long-term potential of citizen-based monitoring of nuclear activities using publicly available satellite imagery. In this article, we demonstrate how modern game engines combined with advanced machine-learning techniques can be used to generate synthetic imagery of sites of interest with the ability to choose relevant parameters upon request; these include time of day, cloud cover, season, or level of activity onsite. At the same time, resolution and off-nadir angle can be adjusted to simulate different characteristics of the satellite. While there are several possible use-cases for synthetic imagery, here we focus on its usefulness to support tabletop exercises in which simple monitoring scenarios can be examined to better understand verification capabilities enabled by new satellite constellations and very short revisit times.","sentences":["Satellite imagery is regarded as a great opportunity for citizen-based monitoring of activities of interest.","Relevant imagery may however not be available at sufficiently high resolution, quality, or cadence -- let alone be uniformly accessible to open-source analysts.","This limits an assessment of the true long-term potential of citizen-based monitoring of nuclear activities using publicly available satellite imagery.","In this article, we demonstrate how modern game engines combined with advanced machine-learning techniques can be used to generate synthetic imagery of sites of interest with the ability to choose relevant parameters upon request; these include time of day, cloud cover, season, or level of activity onsite.","At the same time, resolution and off-nadir angle can be adjusted to simulate different characteristics of the satellite.","While there are several possible use-cases for synthetic imagery, here we focus on its usefulness to support tabletop exercises in which simple monitoring scenarios can be examined to better understand verification capabilities enabled by new satellite constellations and very short revisit times."],"url":"http://arxiv.org/abs/2404.11461v1"}
{"created":"2024-04-17 15:07:06","title":"Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent","abstract":"A multimodal AI agent is characterized by its ability to process and learn from various types of data, including natural language, visual, and audio inputs, to inform its actions. Despite advancements in large language models that incorporate visual data, such as GPT-4V, effectively translating image-based data into actionable outcomes for AI agents continues to be challenging. In this paper, we introduce a multimodal model that incorporates the concept of functional token specifically designed for AI agent applications. To ensure compatibility with edge devices, our model is optimized to a compact size of less than 1B parameters. Like GPT-4, our model can process both English and Chinese. We demonstrate that this model is capable of operating efficiently on a wide range of edge devices, including as constrained as a Raspberry Pi.","sentences":["A multimodal AI agent is characterized by its ability to process and learn from various types of data, including natural language, visual, and audio inputs, to inform its actions.","Despite advancements in large language models that incorporate visual data, such as GPT-4V, effectively translating image-based data into actionable outcomes for AI agents continues to be challenging.","In this paper, we introduce a multimodal model that incorporates the concept of functional token specifically designed for AI agent applications.","To ensure compatibility with edge devices, our model is optimized to a compact size of less than 1B parameters.","Like GPT-4, our model can process both English and Chinese.","We demonstrate that this model is capable of operating efficiently on a wide range of edge devices, including as constrained as a Raspberry Pi."],"url":"http://arxiv.org/abs/2404.11459v1"}
{"created":"2024-04-17 15:05:51","title":"Learn to Tour: Operator Design For Solution Feasibility Mapping in Pickup-and-delivery Traveling Salesman Problem","abstract":"This paper aims to develop a learning method for a special class of traveling salesman problems (TSP), namely, the pickup-and-delivery TSP (PDTSP), which finds the shortest tour along a sequence of one-to-one pickup-and-delivery nodes. One-to-one here means that the transported people or goods are associated with designated pairs of pickup and delivery nodes, in contrast to that indistinguishable goods can be delivered to any nodes. In PDTSP, precedence constraints need to be satisfied that each pickup node must be visited before its corresponding delivery node. Classic operations research (OR) algorithms for PDTSP are difficult to scale to large-sized problems. Recently, reinforcement learning (RL) has been applied to TSPs. The basic idea is to explore and evaluate visiting sequences in a solution space. However, this approach could be less computationally efficient, as it has to potentially evaluate many infeasible solutions of which precedence constraints are violated. To restrict solution search within a feasible space, we utilize operators that always map one feasible solution to another, without spending time exploring the infeasible solution space. Such operators are evaluated and selected as policies to solve PDTSPs in an RL framework. We make a comparison of our method and baselines, including classic OR algorithms and existing learning methods. Results show that our approach can find tours shorter than baselines.","sentences":["This paper aims to develop a learning method for a special class of traveling salesman problems (TSP), namely, the pickup-and-delivery TSP (PDTSP), which finds the shortest tour along a sequence of one-to-one pickup-and-delivery nodes.","One-to-one here means that the transported people or goods are associated with designated pairs of pickup and delivery nodes, in contrast to that indistinguishable goods can be delivered to any nodes.","In PDTSP, precedence constraints need to be satisfied that each pickup node must be visited before its corresponding delivery node.","Classic operations research (OR) algorithms for PDTSP are difficult to scale to large-sized problems.","Recently, reinforcement learning (RL) has been applied to TSPs.","The basic idea is to explore and evaluate visiting sequences in a solution space.","However, this approach could be less computationally efficient, as it has to potentially evaluate many infeasible solutions of which precedence constraints are violated.","To restrict solution search within a feasible space, we utilize operators that always map one feasible solution to another, without spending time exploring the infeasible solution space.","Such operators are evaluated and selected as policies to solve PDTSPs in an RL framework.","We make a comparison of our method and baselines, including classic OR algorithms and existing learning methods.","Results show that our approach can find tours shorter than baselines."],"url":"http://arxiv.org/abs/2404.11458v1"}
{"created":"2024-04-17 15:05:03","title":"Unifying Bias and Unfairness in Information Retrieval: A Survey of Challenges and Opportunities with Large Language Models","abstract":"With the rapid advancement of large language models (LLMs), information retrieval (IR) systems, such as search engines and recommender systems, have undergone a significant paradigm shift. This evolution, while heralding new opportunities, introduces emerging challenges, particularly in terms of biases and unfairness, which may threaten the information ecosystem. In this paper, we present a comprehensive survey of existing works on emerging and pressing bias and unfairness issues in IR systems when the integration of LLMs. We first unify bias and unfairness issues as distribution mismatch problems, providing a groundwork for categorizing various mitigation strategies through distribution alignment. Subsequently, we systematically delve into the specific bias and unfairness issues arising from three critical stages of LLMs integration into IR systems: data collection, model development, and result evaluation. In doing so, we meticulously review and analyze recent literature, focusing on the definitions, characteristics, and corresponding mitigation strategies associated with these issues. Finally, we identify and highlight some open problems and challenges for future work, aiming to inspire researchers and stakeholders in the IR field and beyond to better understand and mitigate bias and unfairness issues of IR in this LLM era. We also consistently maintain a GitHub repository for the relevant papers and resources in this rising direction at https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey.","sentences":["With the rapid advancement of large language models (LLMs), information retrieval (IR) systems, such as search engines and recommender systems, have undergone a significant paradigm shift.","This evolution, while heralding new opportunities, introduces emerging challenges, particularly in terms of biases and unfairness, which may threaten the information ecosystem.","In this paper, we present a comprehensive survey of existing works on emerging and pressing bias and unfairness issues in IR systems when the integration of LLMs.","We first unify bias and unfairness issues as distribution mismatch problems, providing a groundwork for categorizing various mitigation strategies through distribution alignment.","Subsequently, we systematically delve into the specific bias and unfairness issues arising from three critical stages of LLMs integration into IR systems: data collection, model development, and result evaluation.","In doing so, we meticulously review and analyze recent literature, focusing on the definitions, characteristics, and corresponding mitigation strategies associated with these issues.","Finally, we identify and highlight some open problems and challenges for future work, aiming to inspire researchers and stakeholders in the IR field and beyond to better understand and mitigate bias and unfairness issues of IR in this LLM era.","We also consistently maintain a GitHub repository for the relevant papers and resources in this rising direction at https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey."],"url":"http://arxiv.org/abs/2404.11457v1"}
{"created":"2024-04-17 15:05:00","title":"Deep Pattern Network for Click-Through Rate Prediction","abstract":"Click-through rate (CTR) prediction tasks play a pivotal role in real-world applications, particularly in recommendation systems and online advertising. A significant research branch in this domain focuses on user behavior modeling. Current research predominantly centers on modeling co-occurrence relationships between the target item and items previously interacted with by users in their historical data. However, this focus neglects the intricate modeling of user behavior patterns. In reality, the abundance of user interaction records encompasses diverse behavior patterns, indicative of a spectrum of habitual paradigms. These patterns harbor substantial potential to significantly enhance CTR prediction performance. To harness the informational potential within user behavior patterns, we extend Target Attention (TA) to Target Pattern Attention (TPA) to model pattern-level dependencies. Furthermore, three critical challenges demand attention: the inclusion of unrelated items within behavior patterns, data sparsity in behavior patterns, and computational complexity arising from numerous patterns. To address these challenges, we introduce the Deep Pattern Network (DPN), designed to comprehensively leverage information from user behavior patterns. DPN efficiently retrieves target-related user behavior patterns using a target-aware attention mechanism. Additionally, it contributes to refining user behavior patterns through a pre-training paradigm based on self-supervised learning while promoting dependency learning within sparse patterns. Our comprehensive experiments, conducted across three public datasets, substantiate the superior performance and broad compatibility of DPN.","sentences":["Click-through rate (CTR) prediction tasks play a pivotal role in real-world applications, particularly in recommendation systems and online advertising.","A significant research branch in this domain focuses on user behavior modeling.","Current research predominantly centers on modeling co-occurrence relationships between the target item and items previously interacted with by users in their historical data.","However, this focus neglects the intricate modeling of user behavior patterns.","In reality, the abundance of user interaction records encompasses diverse behavior patterns, indicative of a spectrum of habitual paradigms.","These patterns harbor substantial potential to significantly enhance CTR prediction performance.","To harness the informational potential within user behavior patterns, we extend Target Attention (TA) to Target Pattern Attention (TPA) to model pattern-level dependencies.","Furthermore, three critical challenges demand attention: the inclusion of unrelated items within behavior patterns, data sparsity in behavior patterns, and computational complexity arising from numerous patterns.","To address these challenges, we introduce the Deep Pattern Network (DPN), designed to comprehensively leverage information from user behavior patterns.","DPN efficiently retrieves target-related user behavior patterns using a target-aware attention mechanism.","Additionally, it contributes to refining user behavior patterns through a pre-training paradigm based on self-supervised learning while promoting dependency learning within sparse patterns.","Our comprehensive experiments, conducted across three public datasets, substantiate the superior performance and broad compatibility of DPN."],"url":"http://arxiv.org/abs/2404.11456v1"}
{"created":"2024-04-17 14:55:49","title":"Real-Time Trajectory Synthesis with Local Differential Privacy","abstract":"Trajectory streams are being generated from location-aware devices, such as smartphones and in-vehicle navigation systems. Due to the sensitive nature of the location data, directly sharing user trajectories suffers from privacy leakage issues. Local differential privacy (LDP), which perturbs sensitive data on the user side before it is shared or analyzed, emerges as a promising solution for private trajectory stream collection and analysis. Unfortunately, existing stream release approaches often neglect the rich spatial-temporal context information within trajectory streams, resulting in suboptimal utility and limited types of downstream applications. To this end, we propose RetraSyn, a novel real-time trajectory synthesis framework, which is able to perform on-the-fly trajectory synthesis based on the mobility patterns privately extracted from users' trajectory streams. Thus, the downstream trajectory analysis can be performed on the high-utility synthesized data with privacy protection. We also take the genuine behaviors of real-world mobile travelers into consideration, ensuring authenticity and practicality. The key components of RetraSyn include the global mobility model, dynamic mobility update mechanism, real-time synthesis, and adaptive allocation strategy. We conduct extensive experiments on multiple real-world and synthetic trajectory datasets under various location-based utility metrics, encompassing both streaming and historical scenarios. The empirical results demonstrate the superiority and versatility of our proposed framework.","sentences":["Trajectory streams are being generated from location-aware devices, such as smartphones and in-vehicle navigation systems.","Due to the sensitive nature of the location data, directly sharing user trajectories suffers from privacy leakage issues.","Local differential privacy (LDP), which perturbs sensitive data on the user side before it is shared or analyzed, emerges as a promising solution for private trajectory stream collection and analysis.","Unfortunately, existing stream release approaches often neglect the rich spatial-temporal context information within trajectory streams, resulting in suboptimal utility and limited types of downstream applications.","To this end, we propose RetraSyn, a novel real-time trajectory synthesis framework, which is able to perform on-the-fly trajectory synthesis based on the mobility patterns privately extracted from users' trajectory streams.","Thus, the downstream trajectory analysis can be performed on the high-utility synthesized data with privacy protection.","We also take the genuine behaviors of real-world mobile travelers into consideration, ensuring authenticity and practicality.","The key components of RetraSyn include the global mobility model, dynamic mobility update mechanism, real-time synthesis, and adaptive allocation strategy.","We conduct extensive experiments on multiple real-world and synthetic trajectory datasets under various location-based utility metrics, encompassing both streaming and historical scenarios.","The empirical results demonstrate the superiority and versatility of our proposed framework."],"url":"http://arxiv.org/abs/2404.11450v1"}
{"created":"2024-04-17 14:55:27","title":"AI-Enhanced Cognitive Behavioral Therapy: Deep Learning and Large Language Models for Extracting Cognitive Pathways from Social Media Texts","abstract":"Cognitive Behavioral Therapy (CBT) is an effective technique for addressing the irrational thoughts stemming from mental illnesses, but it necessitates precise identification of cognitive pathways to be successfully implemented in patient care. In current society, individuals frequently express negative emotions on social media on specific topics, often exhibiting cognitive distortions, including suicidal behaviors in extreme cases. Yet, there is a notable absence of methodologies for analyzing cognitive pathways that could aid psychotherapists in conducting effective interventions online. In this study, we gathered data from social media and established the task of extracting cognitive pathways, annotating the data based on a cognitive theoretical framework. We initially categorized the task of extracting cognitive pathways as a hierarchical text classification with four main categories and nineteen subcategories. Following this, we structured a text summarization task to help psychotherapists quickly grasp the essential information. Our experiments evaluate the performance of deep learning and large language models (LLMs) on these tasks. The results demonstrate that our deep learning method achieved a micro-F1 score of 62.34% in the hierarchical text classification task. Meanwhile, in the text summarization task, GPT-4 attained a Rouge-1 score of 54.92 and a Rouge-2 score of 30.86, surpassing the experimental deep learning model's performance. However, it may suffer from an issue of hallucination. We have made all models and codes publicly available to support further research in this field.","sentences":["Cognitive Behavioral Therapy (CBT) is an effective technique for addressing the irrational thoughts stemming from mental illnesses, but it necessitates precise identification of cognitive pathways to be successfully implemented in patient care.","In current society, individuals frequently express negative emotions on social media on specific topics, often exhibiting cognitive distortions, including suicidal behaviors in extreme cases.","Yet, there is a notable absence of methodologies for analyzing cognitive pathways that could aid psychotherapists in conducting effective interventions online.","In this study, we gathered data from social media and established the task of extracting cognitive pathways, annotating the data based on a cognitive theoretical framework.","We initially categorized the task of extracting cognitive pathways as a hierarchical text classification with four main categories and nineteen subcategories.","Following this, we structured a text summarization task to help psychotherapists quickly grasp the essential information.","Our experiments evaluate the performance of deep learning and large language models (LLMs) on these tasks.","The results demonstrate that our deep learning method achieved a micro-F1 score of 62.34% in the hierarchical text classification task.","Meanwhile, in the text summarization task, GPT-4 attained a Rouge-1 score of 54.92 and a Rouge-2 score of 30.86, surpassing the experimental deep learning model's performance.","However, it may suffer from an issue of hallucination.","We have made all models and codes publicly available to support further research in this field."],"url":"http://arxiv.org/abs/2404.11449v1"}
{"created":"2024-04-17 14:55:03","title":"Research on emotionally intelligent dialogue generation based on automatic dialogue system","abstract":"Automated dialogue systems are important applications of artificial intelligence, and traditional systems struggle to understand user emotions and provide empathetic feedback. This study integrates emotional intelligence technology into automated dialogue systems and creates a dialogue generation model with emotional intelligence through deep learning and natural language processing techniques. The model can detect and understand a wide range of emotions and specific pain signals in real time, enabling the system to provide empathetic interaction. By integrating the results of the study \"Can artificial intelligence detect pain and express pain empathy?\", the model's ability to understand the subtle elements of pain empathy has been enhanced, setting higher standards for emotional intelligence dialogue systems. The project aims to provide theoretical understanding and practical suggestions to integrate advanced emotional intelligence capabilities into dialogue systems, thereby improving user experience and interaction quality.","sentences":["Automated dialogue systems are important applications of artificial intelligence, and traditional systems struggle to understand user emotions and provide empathetic feedback.","This study integrates emotional intelligence technology into automated dialogue systems and creates a dialogue generation model with emotional intelligence through deep learning and natural language processing techniques.","The model can detect and understand a wide range of emotions and specific pain signals in real time, enabling the system to provide empathetic interaction.","By integrating the results of the study \"Can artificial intelligence detect pain and express pain empathy?","\", the model's ability to understand the subtle elements of pain empathy has been enhanced, setting higher standards for emotional intelligence dialogue systems.","The project aims to provide theoretical understanding and practical suggestions to integrate advanced emotional intelligence capabilities into dialogue systems, thereby improving user experience and interaction quality."],"url":"http://arxiv.org/abs/2404.11447v1"}
{"created":"2024-04-17 14:54:58","title":"Open-Ended Wargames with Large Language Models","abstract":"Wargames are a powerful tool for understanding and rehearsing real-world decision making. Automated play of wargames using artificial intelligence (AI) enables possibilities beyond those of human-conducted games, such as playing the game many times over to see a range of possible outcomes. There are two categories of wargames: quantitative games, with discrete types of moves, and qualitative games, which revolve around open-ended responses. Historically, automation efforts have focused on quantitative games, but large language models (LLMs) make it possible to automate qualitative wargames. We introduce \"Snow Globe,\" an LLM-powered multi-agent system for playing qualitative wargames. With Snow Globe, every stage of a text-based qualitative wargame from scenario preparation to post-game analysis can be optionally carried out by AI, humans, or a combination thereof. We describe its software architecture conceptually and release an open-source implementation alongside this publication. As case studies, we simulate a tabletop exercise about an AI incident response and a political wargame about a geopolitical crisis. We discuss potential applications of the approach and how it fits into the broader wargaming ecosystem.","sentences":["Wargames are a powerful tool for understanding and rehearsing real-world decision making.","Automated play of wargames using artificial intelligence (AI) enables possibilities beyond those of human-conducted games, such as playing the game many times over to see a range of possible outcomes.","There are two categories of wargames: quantitative games, with discrete types of moves, and qualitative games, which revolve around open-ended responses.","Historically, automation efforts have focused on quantitative games, but large language models (LLMs) make it possible to automate qualitative wargames.","We introduce \"Snow Globe,\" an LLM-powered multi-agent system for playing qualitative wargames.","With Snow Globe, every stage of a text-based qualitative wargame from scenario preparation to post-game analysis can be optionally carried out by AI, humans, or a combination thereof.","We describe its software architecture conceptually and release an open-source implementation alongside this publication.","As case studies, we simulate a tabletop exercise about an AI incident response and a political wargame about a geopolitical crisis.","We discuss potential applications of the approach and how it fits into the broader wargaming ecosystem."],"url":"http://arxiv.org/abs/2404.11446v1"}
{"created":"2024-04-17 14:53:44","title":"Multi-modalities and non-commutativity/associativity in functorial linear logic: a case study","abstract":"Similar to modal connectives, the exponential ! in intuitionistic linear logic (ILL) is not canonical, in the sense that if $i\\not= j$ then $!^i F\\not\\equiv !^j F$. Intuitively, this means that we can mark the exponential with labels taken from a set I organized in a pre-order $\\preceq$, obtaining (possibly infinitely-many) exponentials ($!^i$ for $i\\in I$).   There are, however, two main differences between multi-modalities in normal modal logics and subexponentials in linear logic. i. substructural behaviour. Subexponentials carry the possibility of having different structural behaviors; ii. nature of modalities. Normal modal logics start from the weakest version, assuming only axiom K, then extensions are considered, by adding other axioms. Exponentials in linear logic \"take for granted\" the behaviors expressed by axioms T and 4.   Regarding (i), originally subexponentials could assume only weakening and contraction axioms, but later non-commutative/non-associative systems allowing commutative/ associative subexponentials were presented.   Concerning (ii), Guerrini et al unified the modal and LL approaches, with the exponentials assuming only the linear version of K, with the possibility of adding modal extensions to it. This discussion was brought to multi-modal case, where subexponentials consider not only the structural axioms for contraction and weakening, but also the subexponential version of axioms {K,4,D,T}.   In this work, we intend to join these two studies. This means that $!^{i}$ can behave classically or not, model associative and commutative systems or not, but also with exponential behaviors different from those in LL. Hence, by assigning different modal axioms one obtains, in a modular way, a class of different substructural modal logics.","sentences":["Similar to modal connectives, the exponential !","in intuitionistic linear logic (ILL) is not canonical, in the sense that if $i\\not= j$ then $!^i F\\not\\equiv !^j","F$. Intuitively, this means that we can mark the exponential with labels taken from a set I organized in a pre-order $\\preceq$, obtaining (possibly infinitely-many) exponentials ($!^i$ for $i\\in I$).   ","There are, however, two main differences between multi-modalities in normal modal logics and subexponentials in linear logic.","i. substructural behaviour.","Subexponentials carry the possibility of having different structural behaviors; ii. nature of modalities.","Normal modal logics start from the weakest version, assuming only axiom K, then extensions are considered, by adding other axioms.","Exponentials in linear logic \"take for granted\" the behaviors expressed by axioms T and 4.   ","Regarding (i), originally subexponentials could assume only weakening and contraction axioms, but later non-commutative/non-associative systems allowing commutative/ associative subexponentials were presented.   ","Concerning (ii), Guerrini et al unified the modal and LL approaches, with the exponentials assuming only the linear version of K, with the possibility of adding modal extensions to it.","This discussion was brought to multi-modal case, where subexponentials consider not only the structural axioms for contraction and weakening, but also the subexponential version of axioms {K,4,D,T}.   ","In this work, we intend to join these two studies.","This means that $!^{i}$ can behave classically or not, model associative and commutative systems or not, but also with exponential behaviors different from those in LL.","Hence, by assigning different modal axioms one obtains, in a modular way, a class of different substructural modal logics."],"url":"http://arxiv.org/abs/2404.11445v1"}
{"created":"2024-04-17 14:53:03","title":"Prediction of Unmanned Surface Vessel Motion Attitude Based on CEEMDAN-PSO-SVM","abstract":"Unmanned boats, while navigating at sea, utilize active compensation systems to mitigate wave disturbances experienced by onboard instruments and equipment. However, there exists a lag in the measurement of unmanned boat attitudes, thus introducing unmanned boat motion attitude prediction to compensate for the lag in the signal acquisition process. This paper, based on the basic principles of waves, derives the disturbance patterns of waves on unmanned boats from the wave energy spectrum. Through simulation analysis of unmanned boat motion attitudes, motion attitude data is obtained, providing experimental data for subsequent work. A combined prediction model based on Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN), Particle Swarm Optimization (PSO), and Support Vector Machine (SVM) is designed to predict the motion attitude of unmanned boats. Simulation results validate its superior prediction accuracy compared to traditional prediction models. For example, in terms of mean absolute error, it improves by 17% compared to the EMD-PSO-SVM model.","sentences":["Unmanned boats, while navigating at sea, utilize active compensation systems to mitigate wave disturbances experienced by onboard instruments and equipment.","However, there exists a lag in the measurement of unmanned boat attitudes, thus introducing unmanned boat motion attitude prediction to compensate for the lag in the signal acquisition process.","This paper, based on the basic principles of waves, derives the disturbance patterns of waves on unmanned boats from the wave energy spectrum.","Through simulation analysis of unmanned boat motion attitudes, motion attitude data is obtained, providing experimental data for subsequent work.","A combined prediction model based on Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN), Particle Swarm Optimization (PSO), and Support Vector Machine (SVM) is designed to predict the motion attitude of unmanned boats.","Simulation results validate its superior prediction accuracy compared to traditional prediction models.","For example, in terms of mean absolute error, it improves by 17% compared to the EMD-PSO-SVM model."],"url":"http://arxiv.org/abs/2404.11443v1"}
{"created":"2024-04-17 14:49:03","title":"A waypoint based approach to visibility in performance based fire safety design","abstract":"In performance-based fire safety design, ensuring safe egress, e.g. by visibility of safety signs, is a crucial safety goal. Compliance with the building requirements is often demonstrated by simulations of smoke spread. Numerical models like the Fire Dynamics Simulator generally compute visibility as a local quantity using the light extinction coefficient, without the consideration of the actual light path to a safety sign. Here, visibility maps are introduced, providing an approach for post-processing fire simulation data. They indicate safe areas along egress routes, with respect to visibility. At each location, the available visibility is calculated using Jin's law, as an integrated value of the extinction coefficient along the line of sight to the closest exit sign. The required visibility results from the distance between those points. Additional parameters like view angle or visual obstructions are considered. The presented method allows for temporal visibility assessment, e.g. in an ASET-RSET analysis.","sentences":["In performance-based fire safety design, ensuring safe egress, e.g. by visibility of safety signs, is a crucial safety goal.","Compliance with the building requirements is often demonstrated by simulations of smoke spread.","Numerical models like the Fire Dynamics Simulator generally compute visibility as a local quantity using the light extinction coefficient, without the consideration of the actual light path to a safety sign.","Here, visibility maps are introduced, providing an approach for post-processing fire simulation data.","They indicate safe areas along egress routes, with respect to visibility.","At each location, the available visibility is calculated using Jin's law, as an integrated value of the extinction coefficient along the line of sight to the closest exit sign.","The required visibility results from the distance between those points.","Additional parameters like view angle or visual obstructions are considered.","The presented method allows for temporal visibility assessment, e.g. in an ASET-RSET analysis."],"url":"http://arxiv.org/abs/2404.11439v1"}
{"created":"2024-04-17 14:39:14","title":"Runtime Analyses of NSGA-III on Many-Objective Problems","abstract":"NSGA-II and NSGA-III are two of the most popular evolutionary multi-objective algorithms used in practice. While NSGA-II is used for few objectives such as 2 and 3, NSGA-III is designed to deal with a larger number of objectives. In a recent breakthrough, Wietheger and Doerr (IJCAI 2023) gave the first runtime analysis for NSGA-III on the 3-objective OneMinMax problem, showing that this state-of-the-art algorithm can be analyzed rigorously. We advance this new line of research by presenting the first runtime analyses of NSGA-III on the popular many-objective benchmark problems mLOTZ, mOMM, and mCOCZ, for an arbitrary constant number $m$ of objectives. Our analysis provides ways to set the important parameters of the algorithm: the number of reference points and the population size, so that a good performance can be guaranteed. We show how these parameters should be scaled with the problem dimension, the number of objectives and the fitness range. To our knowledge, these are the first runtime analyses for NSGA-III for more than 3 objectives.","sentences":["NSGA-II and NSGA-III are two of the most popular evolutionary multi-objective algorithms used in practice.","While NSGA-II is used for few objectives such as 2 and 3, NSGA-III is designed to deal with a larger number of objectives.","In a recent breakthrough, Wietheger and Doerr (IJCAI 2023) gave the first runtime analysis for NSGA-III on the 3-objective OneMinMax problem, showing that this state-of-the-art algorithm can be analyzed rigorously.","We advance this new line of research by presenting the first runtime analyses of NSGA-III on the popular many-objective benchmark problems mLOTZ, mOMM, and mCOCZ, for an arbitrary constant number $m$ of objectives.","Our analysis provides ways to set the important parameters of the algorithm: the number of reference points and the population size, so that a good performance can be guaranteed.","We show how these parameters should be scaled with the problem dimension, the number of objectives and the fitness range.","To our knowledge, these are the first runtime analyses for NSGA-III for more than 3 objectives."],"url":"http://arxiv.org/abs/2404.11433v1"}
{"created":"2024-04-17 14:36:47","title":"Instantiations and Computational Aspects of Non-Flat Assumption-based Argumentation","abstract":"Most existing computational tools for assumption-based argumentation (ABA) focus on so-called flat frameworks, disregarding the more general case. In this paper, we study an instantiation-based approach for reasoning in possibly non-flat ABA. We make use of a semantics-preserving translation between ABA and bipolar argumentation frameworks (BAFs). By utilizing compilability theory, we establish that the constructed BAFs will in general be of exponential size. In order to keep the number of arguments and computational cost low, we present three ways of identifying redundant arguments. Moreover, we identify fragments of ABA which admit a poly-sized instantiation. We propose two algorithmic approaches for reasoning in possibly non-flat ABA. The first approach utilizes the BAF instantiation while the second works directly without constructing arguments. An empirical evaluation shows that the former outperforms the latter on many instances, reflecting the lower complexity of BAF reasoning. This result is in contrast to flat ABA, where direct approaches dominate instantiation-based approaches.","sentences":["Most existing computational tools for assumption-based argumentation (ABA) focus on so-called flat frameworks, disregarding the more general case.","In this paper, we study an instantiation-based approach for reasoning in possibly non-flat ABA.","We make use of a semantics-preserving translation between ABA and bipolar argumentation frameworks (BAFs).","By utilizing compilability theory, we establish that the constructed BAFs will in general be of exponential size.","In order to keep the number of arguments and computational cost low, we present three ways of identifying redundant arguments.","Moreover, we identify fragments of ABA which admit a poly-sized instantiation.","We propose two algorithmic approaches for reasoning in possibly non-flat ABA.","The first approach utilizes the BAF instantiation while the second works directly without constructing arguments.","An empirical evaluation shows that the former outperforms the latter on many instances, reflecting the lower complexity of BAF reasoning.","This result is in contrast to flat ABA, where direct approaches dominate instantiation-based approaches."],"url":"http://arxiv.org/abs/2404.11431v1"}
{"created":"2024-04-17 14:34:56","title":"CarcassFormer: An End-to-end Transformer-based Framework for Simultaneous Localization, Segmentation and Classification of Poultry Carcass Defect","abstract":"In the food industry, assessing the quality of poultry carcasses during processing is a crucial step. This study proposes an effective approach for automating the assessment of carcass quality without requiring skilled labor or inspector involvement. The proposed system is based on machine learning (ML) and computer vision (CV) techniques, enabling automated defect detection and carcass quality assessment. To this end, an end-to-end framework called CarcassFormer is introduced. It is built upon a Transformer-based architecture designed to effectively extract visual representations while simultaneously detecting, segmenting, and classifying poultry carcass defects. Our proposed framework is capable of analyzing imperfections resulting from production and transport welfare issues, as well as processing plant stunner, scalder, picker, and other equipment malfunctions. To benchmark the framework, a dataset of 7,321 images was initially acquired, which contained both single and multiple carcasses per image. In this study, the performance of the CarcassFormer system is compared with other state-of-the-art (SOTA) approaches for both classification, detection, and segmentation tasks. Through extensive quantitative experiments, our framework consistently outperforms existing methods, demonstrating remarkable improvements across various evaluation metrics such as AP, AP@50, and AP@75. Furthermore, the qualitative results highlight the strengths of CarcassFormer in capturing fine details, including feathers, and accurately localizing and segmenting carcasses with high precision. To facilitate further research and collaboration, the pre-trained model and source code of CarcassFormer is available for research purposes at: \\url{https://github.com/UARK-AICV/CarcassFormer}.","sentences":["In the food industry, assessing the quality of poultry carcasses during processing is a crucial step.","This study proposes an effective approach for automating the assessment of carcass quality without requiring skilled labor or inspector involvement.","The proposed system is based on machine learning (ML) and computer vision (CV) techniques, enabling automated defect detection and carcass quality assessment.","To this end, an end-to-end framework called CarcassFormer is introduced.","It is built upon a Transformer-based architecture designed to effectively extract visual representations while simultaneously detecting, segmenting, and classifying poultry carcass defects.","Our proposed framework is capable of analyzing imperfections resulting from production and transport welfare issues, as well as processing plant stunner, scalder, picker, and other equipment malfunctions.","To benchmark the framework, a dataset of 7,321 images was initially acquired, which contained both single and multiple carcasses per image.","In this study, the performance of the CarcassFormer system is compared with other state-of-the-art (SOTA) approaches for both classification, detection, and segmentation tasks.","Through extensive quantitative experiments, our framework consistently outperforms existing methods, demonstrating remarkable improvements across various evaluation metrics such as AP, AP@50, and AP@75.","Furthermore, the qualitative results highlight the strengths of CarcassFormer in capturing fine details, including feathers, and accurately localizing and segmenting carcasses with high precision.","To facilitate further research and collaboration, the pre-trained model and source code of CarcassFormer is available for research purposes at: \\url{https://github.com/UARK-AICV/CarcassFormer}."],"url":"http://arxiv.org/abs/2404.11429v1"}
{"created":"2024-04-17 14:33:41","title":"SPAMming Labels: Efficient Annotations for the Trackers of Tomorrow","abstract":"Increasing the annotation efficiency of trajectory annotations from videos has the potential to enable the next generation of data-hungry tracking algorithms to thrive on large-scale datasets. Despite the importance of this task, there are currently very few works exploring how to efficiently label tracking datasets comprehensively. In this work, we introduce SPAM, a tracking data engine that provides high-quality labels with minimal human intervention. SPAM is built around two key insights: i) most tracking scenarios can be easily resolved. To take advantage of this, we utilize a pre-trained model to generate high-quality pseudo-labels, reserving human involvement for a smaller subset of more difficult instances; ii) handling the spatiotemporal dependencies of track annotations across time can be elegantly and efficiently formulated through graphs. Therefore, we use a unified graph formulation to address the annotation of both detections and identity association for tracks across time. Based on these insights, SPAM produces high-quality annotations with a fraction of ground truth labeling cost. We demonstrate that trackers trained on SPAM labels achieve comparable performance to those trained on human annotations while requiring only 3-20% of the human labeling effort. Hence, SPAM paves the way towards highly efficient labeling of large-scale tracking datasets. Our code and models will be available upon acceptance.","sentences":["Increasing the annotation efficiency of trajectory annotations from videos has the potential to enable the next generation of data-hungry tracking algorithms to thrive on large-scale datasets.","Despite the importance of this task, there are currently very few works exploring how to efficiently label tracking datasets comprehensively.","In this work, we introduce SPAM, a tracking data engine that provides high-quality labels with minimal human intervention.","SPAM is built around two key insights: i) most tracking scenarios can be easily resolved.","To take advantage of this, we utilize a pre-trained model to generate high-quality pseudo-labels, reserving human involvement for a smaller subset of more difficult instances; ii) handling the spatiotemporal dependencies of track annotations across time can be elegantly and efficiently formulated through graphs.","Therefore, we use a unified graph formulation to address the annotation of both detections and identity association for tracks across time.","Based on these insights, SPAM produces high-quality annotations with a fraction of ground truth labeling cost.","We demonstrate that trackers trained on SPAM labels achieve comparable performance to those trained on human annotations while requiring only 3-20% of the human labeling effort.","Hence, SPAM paves the way towards highly efficient labeling of large-scale tracking datasets.","Our code and models will be available upon acceptance."],"url":"http://arxiv.org/abs/2404.11426v1"}
{"created":"2024-04-17 14:27:45","title":"Short-term wind speed forecasting model based on an attention-gated recurrent neural network and error correction strategy","abstract":"The accurate wind speed series forecast is very pivotal to security of grid dispatching and the application of wind power. Nevertheless, on account of their nonlinear and non-stationary nature, their short-term forecast is extremely challenging. Therefore, this dissertation raises one short-term wind speed forecast pattern on the foundation of attention with an improved gated recurrent neural network (AtGRU) and a tactic of error correction. That model uses the AtGRU model as the preliminary predictor and the GRU model as the error corrector. At the beginning, SSA (singular spectrum analysis) is employed in previous wind speed series for lessening the noise. Subsequently, historical wind speed series is going to be used for the predictor training. During this process, the prediction can have certain errors. The sequence of these errors processed by variational modal decomposition (VMD) is used to train the corrector of error. The eventual forecast consequence is just the sum of predictor forecast and error corrector. The proposed SSA-AtGRU-VMD-GRU model outperforms the compared models in three case studies on Woodburn, St. Thomas, and Santa Cruz. It is indicated that the model evidently enhances the correction of the wind speed forecast.","sentences":["The accurate wind speed series forecast is very pivotal to security of grid dispatching and the application of wind power.","Nevertheless, on account of their nonlinear and non-stationary nature, their short-term forecast is extremely challenging.","Therefore, this dissertation raises one short-term wind speed forecast pattern on the foundation of attention with an improved gated recurrent neural network (AtGRU) and a tactic of error correction.","That model uses the AtGRU model as the preliminary predictor and the GRU model as the error corrector.","At the beginning, SSA (singular spectrum analysis) is employed in previous wind speed series for lessening the noise.","Subsequently, historical wind speed series is going to be used for the predictor training.","During this process, the prediction can have certain errors.","The sequence of these errors processed by variational modal decomposition (VMD) is used to train the corrector of error.","The eventual forecast consequence is just the sum of predictor forecast and error corrector.","The proposed SSA-AtGRU-VMD-GRU model outperforms the compared models in three case studies on Woodburn, St. Thomas, and Santa Cruz.","It is indicated that the model evidently enhances the correction of the wind speed forecast."],"url":"http://arxiv.org/abs/2404.11422v1"}
{"created":"2024-04-17 14:24:39","title":"Quantum Cloud Computing: A Review, Open Problems, and Future Directions","abstract":"Quantum cloud computing is an emerging paradigm of computing that empowers quantum applications and their deployment on quantum computing resources without the need for a specialized environment to host and operate physical quantum computers. This paper reviews recent advances, identifies open problems, and proposes future directions in quantum cloud computing. It discusses the state-of-the-art quantum cloud advances, including the various cloud-based models, platforms, and recently developed technologies and software use cases. Furthermore, it discusses different aspects of the quantum cloud, including resource management, quantum serverless, security, and privacy problems. Finally, the paper examines open problems and proposes the future directions of quantum cloud computing, including potential opportunities and ongoing research in this emerging field.","sentences":["Quantum cloud computing is an emerging paradigm of computing that empowers quantum applications and their deployment on quantum computing resources without the need for a specialized environment to host and operate physical quantum computers.","This paper reviews recent advances, identifies open problems, and proposes future directions in quantum cloud computing.","It discusses the state-of-the-art quantum cloud advances, including the various cloud-based models, platforms, and recently developed technologies and software use cases.","Furthermore, it discusses different aspects of the quantum cloud, including resource management, quantum serverless, security, and privacy problems.","Finally, the paper examines open problems and proposes the future directions of quantum cloud computing, including potential opportunities and ongoing research in this emerging field."],"url":"http://arxiv.org/abs/2404.11420v1"}
{"created":"2024-04-17 14:23:28","title":"SLAIM: Robust Dense Neural SLAM for Online Tracking and Mapping","abstract":"We present SLAIM - Simultaneous Localization and Implicit Mapping. We propose a novel coarse-to-fine tracking model tailored for Neural Radiance Field SLAM (NeRF-SLAM) to achieve state-of-the-art tracking performance. Notably, existing NeRF-SLAM systems consistently exhibit inferior tracking performance compared to traditional SLAM algorithms. NeRF-SLAM methods solve camera tracking via image alignment and photometric bundle-adjustment. Such optimization processes are difficult to optimize due to the narrow basin of attraction of the optimization loss in image space (local minima) and the lack of initial correspondences. We mitigate these limitations by implementing a Gaussian pyramid filter on top of NeRF, facilitating a coarse-to-fine tracking optimization strategy. Furthermore, NeRF systems encounter challenges in converging to the right geometry with limited input views. While prior approaches use a Signed-Distance Function (SDF)-based NeRF and directly supervise SDF values by approximating ground truth SDF through depth measurements, this often results in suboptimal geometry. In contrast, our method employs a volume density representation and introduces a novel KL regularizer on the ray termination distribution, constraining scene geometry to consist of empty space and opaque surfaces. Our solution implements both local and global bundle-adjustment to produce a robust (coarse-to-fine) and accurate (KL regularizer) SLAM solution. We conduct experiments on multiple datasets (ScanNet, TUM, Replica) showing state-of-the-art results in tracking and in reconstruction accuracy.","sentences":["We present SLAIM - Simultaneous Localization and Implicit Mapping.","We propose a novel coarse-to-fine tracking model tailored for Neural Radiance Field SLAM (NeRF-SLAM) to achieve state-of-the-art tracking performance.","Notably, existing NeRF-SLAM systems consistently exhibit inferior tracking performance compared to traditional SLAM algorithms.","NeRF-SLAM methods solve camera tracking via image alignment and photometric bundle-adjustment.","Such optimization processes are difficult to optimize due to the narrow basin of attraction of the optimization loss in image space (local minima) and the lack of initial correspondences.","We mitigate these limitations by implementing a Gaussian pyramid filter on top of NeRF, facilitating a coarse-to-fine tracking optimization strategy.","Furthermore, NeRF systems encounter challenges in converging to the right geometry with limited input views.","While prior approaches use a Signed-Distance Function (SDF)-based NeRF and directly supervise SDF values by approximating ground truth SDF through depth measurements, this often results in suboptimal geometry.","In contrast, our method employs a volume density representation and introduces a novel KL regularizer on the ray termination distribution, constraining scene geometry to consist of empty space and opaque surfaces.","Our solution implements both local and global bundle-adjustment to produce a robust (coarse-to-fine) and accurate (KL regularizer) SLAM solution.","We conduct experiments on multiple datasets (ScanNet, TUM, Replica) showing state-of-the-art results in tracking and in reconstruction accuracy."],"url":"http://arxiv.org/abs/2404.11419v1"}
{"created":"2024-04-17 14:17:05","title":"Neural Shr\u00f6dinger Bridge Matching for Pansharpening","abstract":"Recent diffusion probabilistic models (DPM) in the field of pansharpening have been gradually gaining attention and have achieved state-of-the-art (SOTA) performance. In this paper, we identify shortcomings in directly applying DPMs to the task of pansharpening as an inverse problem: 1) initiating sampling directly from Gaussian noise neglects the low-resolution multispectral image (LRMS) as a prior; 2) low sampling efficiency often necessitates a higher number of sampling steps. We first reformulate pansharpening into the stochastic differential equation (SDE) form of an inverse problem. Building upon this, we propose a Schr\\\"odinger bridge matching method that addresses both issues.   We design an efficient deep neural network architecture tailored for the proposed SB matching.   In comparison to the well-established DL-regressive-based framework and the recent DPM framework, our method demonstrates SOTA performance with fewer sampling steps. Moreover, we discuss the relationship between SB matching and other methods based on SDEs and ordinary differential equations (ODEs), as well as its connection with optimal transport.   Code will be available.","sentences":["Recent diffusion probabilistic models (DPM) in the field of pansharpening have been gradually gaining attention and have achieved state-of-the-art (SOTA) performance.","In this paper, we identify shortcomings in directly applying DPMs to the task of pansharpening as an inverse problem: 1) initiating sampling directly from Gaussian noise neglects the low-resolution multispectral image (LRMS) as a prior; 2) low sampling efficiency often necessitates a higher number of sampling steps.","We first reformulate pansharpening into the stochastic differential equation (SDE) form of an inverse problem.","Building upon this, we propose a Schr\\\"odinger bridge matching method that addresses both issues.   ","We design an efficient deep neural network architecture tailored for the proposed SB matching.   ","In comparison to the well-established DL-regressive-based framework and the recent DPM framework, our method demonstrates SOTA performance with fewer sampling steps.","Moreover, we discuss the relationship between SB matching and other methods based on SDEs and ordinary differential equations (ODEs), as well as its connection with optimal transport.   ","Code will be available."],"url":"http://arxiv.org/abs/2404.11416v1"}
