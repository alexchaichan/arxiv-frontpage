{"created":"2024-02-29 18:59:58","title":"DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models","abstract":"Diffusion models have achieved great success in synthesizing high-quality images. However, generating high-resolution images with diffusion models is still challenging due to the enormous computational costs, resulting in a prohibitive latency for interactive applications. In this paper, we propose DistriFusion to tackle this problem by leveraging parallelism across multiple GPUs. Our method splits the model input into multiple patches and assigns each patch to a GPU. However, na\\\"{\\i}vely implementing such an algorithm breaks the interaction between patches and loses fidelity, while incorporating such an interaction will incur tremendous communication overhead. To overcome this dilemma, we observe the high similarity between the input from adjacent diffusion steps and propose displaced patch parallelism, which takes advantage of the sequential nature of the diffusion process by reusing the pre-computed feature maps from the previous timestep to provide context for the current step. Therefore, our method supports asynchronous communication, which can be pipelined by computation. Extensive experiments show that our method can be applied to recent Stable Diffusion XL with no quality degradation and achieve up to a 6.1$\\times$ speedup on eight NVIDIA A100s compared to one. Our code is publicly available at https://github.com/mit-han-lab/distrifuser.","sentences":["Diffusion models have achieved great success in synthesizing high-quality images.","However, generating high-resolution images with diffusion models is still challenging due to the enormous computational costs, resulting in a prohibitive latency for interactive applications.","In this paper, we propose DistriFusion to tackle this problem by leveraging parallelism across multiple GPUs.","Our method splits the model input into multiple patches and assigns each patch to a GPU.","However, na\\\"{\\i}vely implementing such an algorithm breaks the interaction between patches and loses fidelity, while incorporating such an interaction will incur tremendous communication overhead.","To overcome this dilemma, we observe the high similarity between the input from adjacent diffusion steps and propose displaced patch parallelism, which takes advantage of the sequential nature of the diffusion process by reusing the pre-computed feature maps from the previous timestep to provide context for the current step.","Therefore, our method supports asynchronous communication, which can be pipelined by computation.","Extensive experiments show that our method can be applied to recent Stable Diffusion XL with no quality degradation and achieve up to a 6.1$\\times$ speedup on eight NVIDIA A100s compared to one.","Our code is publicly available at https://github.com/mit-han-lab/distrifuser."],"url":"http://arxiv.org/abs/2402.19481v1"}
{"created":"2024-02-29 18:59:50","title":"Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers","abstract":"The quality of the data and annotation upper-bounds the quality of a downstream model. While there exist large text corpora and image-text pairs, high-quality video-text data is much harder to collect. First of all, manual labeling is more time-consuming, as it requires an annotator to watch an entire video. Second, videos have a temporal dimension, consisting of several scenes stacked together, and showing multiple actions. Accordingly, to establish a video dataset with high-quality captions, we propose an automatic approach leveraging multimodal inputs, such as textual video description, subtitles, and individual video frames. Specifically, we curate 3.8M high-resolution videos from the publicly available HD-VILA-100M dataset. We then split them into semantically consistent video clips, and apply multiple cross-modality teacher models to obtain captions for each video. Next, we finetune a retrieval model on a small subset where the best caption of each video is manually selected and then employ the model in the whole dataset to select the best caption as the annotation. In this way, we get 70M videos paired with high-quality text captions. We dub the dataset as Panda-70M. We show the value of the proposed dataset on three downstream tasks: video captioning, video and text retrieval, and text-driven video generation. The models trained on the proposed data score substantially better on the majority of metrics across all the tasks.","sentences":["The quality of the data and annotation upper-bounds the quality of a downstream model.","While there exist large text corpora and image-text pairs, high-quality video-text data is much harder to collect.","First of all, manual labeling is more time-consuming, as it requires an annotator to watch an entire video.","Second, videos have a temporal dimension, consisting of several scenes stacked together, and showing multiple actions.","Accordingly, to establish a video dataset with high-quality captions, we propose an automatic approach leveraging multimodal inputs, such as textual video description, subtitles, and individual video frames.","Specifically, we curate 3.8M high-resolution videos from the publicly available HD-VILA-100M dataset.","We then split them into semantically consistent video clips, and apply multiple cross-modality teacher models to obtain captions for each video.","Next, we finetune a retrieval model on a small subset where the best caption of each video is manually selected and then employ the model in the whole dataset to select the best caption as the annotation.","In this way, we get 70M videos paired with high-quality text captions.","We dub the dataset as Panda-70M. We show the value of the proposed dataset on three downstream tasks: video captioning, video and text retrieval, and text-driven video generation.","The models trained on the proposed data score substantially better on the majority of metrics across all the tasks."],"url":"http://arxiv.org/abs/2402.19479v1"}
{"created":"2024-02-29 18:59:31","title":"Learning a Generalized Physical Face Model From Data","abstract":"Physically-based simulation is a powerful approach for 3D facial animation as the resulting deformations are governed by physical constraints, allowing to easily resolve self-collisions, respond to external forces and perform realistic anatomy edits. Today's methods are data-driven, where the actuations for finite elements are inferred from captured skin geometry. Unfortunately, these approaches have not been widely adopted due to the complexity of initializing the material space and learning the deformation model for each character separately, which often requires a skilled artist followed by lengthy network training. In this work, we aim to make physics-based facial animation more accessible by proposing a generalized physical face model that we learn from a large 3D face dataset in a simulation-free manner. Once trained, our model can be quickly fit to any unseen identity and produce a ready-to-animate physical face model automatically. Fitting is as easy as providing a single 3D face scan, or even a single face image. After fitting, we offer intuitive animation controls, as well as the ability to retarget animations across characters. All the while, the resulting animations allow for physical effects like collision avoidance, gravity, paralysis, bone reshaping and more.","sentences":["Physically-based simulation is a powerful approach for 3D facial animation as the resulting deformations are governed by physical constraints, allowing to easily resolve self-collisions, respond to external forces and perform realistic anatomy edits.","Today's methods are data-driven, where the actuations for finite elements are inferred from captured skin geometry.","Unfortunately, these approaches have not been widely adopted due to the complexity of initializing the material space and learning the deformation model for each character separately, which often requires a skilled artist followed by lengthy network training.","In this work, we aim to make physics-based facial animation more accessible by proposing a generalized physical face model that we learn from a large 3D face dataset in a simulation-free manner.","Once trained, our model can be quickly fit to any unseen identity and produce a ready-to-animate physical face model automatically.","Fitting is as easy as providing a single 3D face scan, or even a single face image.","After fitting, we offer intuitive animation controls, as well as the ability to retarget animations across characters.","All the while, the resulting animations allow for physical effects like collision avoidance, gravity, paralysis, bone reshaping and more."],"url":"http://arxiv.org/abs/2402.19477v1"}
{"created":"2024-02-29 18:59:25","title":"The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?","abstract":"While language models are increasingly more proficient at code generation, they still frequently generate incorrect programs. Many of these programs are obviously wrong, but others are more subtle and pass weaker correctness checks such as being able to compile. In this work, we focus on these counterfeit samples: programs sampled from a language model that 1) have a high enough log-probability to be generated at a moderate temperature and 2) pass weak correctness checks. Overall, we discover that most models have a very shallow understanding of counterfeits through three clear failure modes. First, models mistakenly classify them as correct. Second, models are worse at reasoning about the execution behaviour of counterfeits and often predict their execution results as if they were correct. Third, when asking models to fix counterfeits, the likelihood of a model successfully repairing a counterfeit is often even lower than that of sampling a correct program from scratch. Counterfeits also have very unexpected properties: first, counterfeit programs for problems that are easier for a model to solve are not necessarily easier to detect and only slightly easier to execute and repair. Second, counterfeits from a given model are just as confusing to the model itself as they are to other models. Finally, both strong and weak models are able to generate counterfeit samples that equally challenge all models. In light of our findings, we recommend that care and caution be taken when relying on models to understand their own samples, especially when no external feedback is incorporated.","sentences":["While language models are increasingly more proficient at code generation, they still frequently generate incorrect programs.","Many of these programs are obviously wrong, but others are more subtle and pass weaker correctness checks such as being able to compile.","In this work, we focus on these counterfeit samples: programs sampled from a language model that 1) have a high enough log-probability to be generated at a moderate temperature and 2) pass weak correctness checks.","Overall, we discover that most models have a very shallow understanding of counterfeits through three clear failure modes.","First, models mistakenly classify them as correct.","Second, models are worse at reasoning about the execution behaviour of counterfeits and often predict their execution results as if they were correct.","Third, when asking models to fix counterfeits, the likelihood of a model successfully repairing a counterfeit is often even lower than that of sampling a correct program from scratch.","Counterfeits also have very unexpected properties: first, counterfeit programs for problems that are easier for a model to solve are not necessarily easier to detect and only slightly easier to execute and repair.","Second, counterfeits from a given model are just as confusing to the model itself as they are to other models.","Finally, both strong and weak models are able to generate counterfeit samples that equally challenge all models.","In light of our findings, we recommend that care and caution be taken when relying on models to understand their own samples, especially when no external feedback is incorporated."],"url":"http://arxiv.org/abs/2402.19475v1"}
{"created":"2024-02-29 18:59:17","title":"The All-Seeing Project V2: Towards General Relation Comprehension of the Open World","abstract":"We present the All-Seeing Project V2: a new model and dataset designed for understanding object relations in images. Specifically, we propose the All-Seeing Model V2 (ASMv2) that integrates the formulation of text generation, object localization, and relation comprehension into a relation conversation (ReC) task. Leveraging this unified task, our model excels not only in perceiving and recognizing all objects within the image but also in grasping the intricate relation graph between them, diminishing the relation hallucination often encountered by Multi-modal Large Language Models (MLLMs). To facilitate training and evaluation of MLLMs in relation understanding, we created the first high-quality ReC dataset ({AS-V2) which is aligned with the format of standard instruction tuning data. In addition, we design a new benchmark, termed Circular-based Relation Probing Evaluation (CRPE) for comprehensively evaluating the relation comprehension capabilities of MLLMs. Notably, our ASMv2 achieves an overall accuracy of 52.04 on this relation-aware benchmark, surpassing the 43.14 of LLaVA-1.5 by a large margin. We hope that our work can inspire more future research and contribute to the evolution towards artificial general intelligence. Our project is released at https://github.com/OpenGVLab/all-seeing.","sentences":["We present the All-Seeing Project V2: a new model and dataset designed for understanding object relations in images.","Specifically, we propose the All-Seeing Model V2 (ASMv2) that integrates the formulation of text generation, object localization, and relation comprehension into a relation conversation (ReC) task.","Leveraging this unified task, our model excels not only in perceiving and recognizing all objects within the image but also in grasping the intricate relation graph between them, diminishing the relation hallucination often encountered by Multi-modal Large Language Models (MLLMs).","To facilitate training and evaluation of MLLMs in relation understanding, we created the first high-quality ReC dataset ({AS-V2) which is aligned with the format of standard instruction tuning data.","In addition, we design a new benchmark, termed Circular-based Relation Probing Evaluation (CRPE) for comprehensively evaluating the relation comprehension capabilities of MLLMs.","Notably, our ASMv2 achieves an overall accuracy of 52.04 on this relation-aware benchmark, surpassing the 43.14 of LLaVA-1.5 by a large margin.","We hope that our work can inspire more future research and contribute to the evolution towards artificial general intelligence.","Our project is released at https://github.com/OpenGVLab/all-seeing."],"url":"http://arxiv.org/abs/2402.19474v1"}
{"created":"2024-02-29 18:59:01","title":"Retrieval-Augmented Generation for AI-Generated Content: A Survey","abstract":"The development of Artificial Intelligence Generated Content (AIGC) has been facilitated by advancements in model algorithms, scalable foundation model architectures, and the availability of ample high-quality datasets. While AIGC has achieved remarkable performance, it still faces challenges, such as the difficulty of maintaining up-to-date and long-tail knowledge, the risk of data leakage, and the high costs associated with training and inference. Retrieval-Augmented Generation (RAG) has recently emerged as a paradigm to address such challenges. In particular, RAG introduces the information retrieval process, which enhances AIGC results by retrieving relevant objects from available data stores, leading to greater accuracy and robustness. In this paper, we comprehensively review existing efforts that integrate RAG technique into AIGC scenarios. We first classify RAG foundations according to how the retriever augments the generator. We distill the fundamental abstractions of the augmentation methodologies for various retrievers and generators. This unified perspective encompasses all RAG scenarios, illuminating advancements and pivotal technologies that help with potential future progress. We also summarize additional enhancements methods for RAG, facilitating effective engineering and implementation of RAG systems. Then from another view, we survey on practical applications of RAG across different modalities and tasks, offering valuable references for researchers and practitioners. Furthermore, we introduce the benchmarks for RAG, discuss the limitations of current RAG systems, and suggest potential directions for future research. Project: https://github.com/hymie122/RAG-Survey","sentences":["The development of Artificial Intelligence Generated Content (AIGC) has been facilitated by advancements in model algorithms, scalable foundation model architectures, and the availability of ample high-quality datasets.","While AIGC has achieved remarkable performance, it still faces challenges, such as the difficulty of maintaining up-to-date and long-tail knowledge, the risk of data leakage, and the high costs associated with training and inference.","Retrieval-Augmented Generation (RAG) has recently emerged as a paradigm to address such challenges.","In particular, RAG introduces the information retrieval process, which enhances AIGC results by retrieving relevant objects from available data stores, leading to greater accuracy and robustness.","In this paper, we comprehensively review existing efforts that integrate RAG technique into AIGC scenarios.","We first classify RAG foundations according to how the retriever augments the generator.","We distill the fundamental abstractions of the augmentation methodologies for various retrievers and generators.","This unified perspective encompasses all RAG scenarios, illuminating advancements and pivotal technologies that help with potential future progress.","We also summarize additional enhancements methods for RAG, facilitating effective engineering and implementation of RAG systems.","Then from another view, we survey on practical applications of RAG across different modalities and tasks, offering valuable references for researchers and practitioners.","Furthermore, we introduce the benchmarks for RAG, discuss the limitations of current RAG systems, and suggest potential directions for future research.","Project: https://github.com/hymie122/RAG-Survey"],"url":"http://arxiv.org/abs/2402.19473v1"}
{"created":"2024-02-29 18:58:26","title":"Lifelong Benchmarks: Efficient Model Evaluation in an Era of Rapid Progress","abstract":"Standardized benchmarks drive progress in machine learning. However, with repeated testing, the risk of overfitting grows as algorithms over-exploit benchmark idiosyncrasies. In our work, we seek to mitigate this challenge by compiling ever-expanding large-scale benchmarks called Lifelong Benchmarks. As exemplars of our approach, we create Lifelong-CIFAR10 and Lifelong-ImageNet, containing (for now) 1.69M and 1.98M test samples, respectively. While reducing overfitting, lifelong benchmarks introduce a key challenge: the high cost of evaluating a growing number of models across an ever-expanding sample set. To address this challenge, we also introduce an efficient evaluation framework: Sort \\& Search (S&S), which reuses previously evaluated models by leveraging dynamic programming algorithms to selectively rank and sub-select test samples, enabling cost-effective lifelong benchmarking. Extensive empirical evaluations across 31,000 models demonstrate that S&S achieves highly-efficient approximate accuracy measurement, reducing compute cost from 180 GPU days to 5 GPU hours (1000x reduction) on a single A100 GPU, with low approximation error. As such, lifelong benchmarks offer a robust, practical solution to the \"benchmark exhaustion\" problem.","sentences":["Standardized benchmarks drive progress in machine learning.","However, with repeated testing, the risk of overfitting grows as algorithms over-exploit benchmark idiosyncrasies.","In our work, we seek to mitigate this challenge by compiling ever-expanding large-scale benchmarks called Lifelong Benchmarks.","As exemplars of our approach, we create Lifelong-CIFAR10 and Lifelong-ImageNet, containing (for now) 1.69M and 1.98M test samples, respectively.","While reducing overfitting, lifelong benchmarks introduce a key challenge: the high cost of evaluating a growing number of models across an ever-expanding sample set.","To address this challenge, we also introduce an efficient evaluation framework: Sort \\& Search (S&S), which reuses previously evaluated models by leveraging dynamic programming algorithms to selectively rank and sub-select test samples, enabling cost-effective lifelong benchmarking.","Extensive empirical evaluations across 31,000 models demonstrate that S&S achieves highly-efficient approximate accuracy measurement, reducing compute cost from 180 GPU days to 5 GPU hours (1000x reduction) on a single A100 GPU, with low approximation error.","As such, lifelong benchmarks offer a robust, practical solution to the \"benchmark exhaustion\" problem."],"url":"http://arxiv.org/abs/2402.19472v1"}
{"created":"2024-02-29 18:58:15","title":"Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling","abstract":"Questions combine our mastery of language with our remarkable facility for reasoning about uncertainty. How do people navigate vast hypothesis spaces to pose informative questions given limited cognitive resources? We study these tradeoffs in a classic grounded question-asking task based on the board game Battleship. Our language-informed program sampling (LIPS) model uses large language models (LLMs) to generate natural language questions, translate them into symbolic programs, and evaluate their expected information gain. We find that with a surprisingly modest resource budget, this simple Monte Carlo optimization strategy yields informative questions that mirror human performance across varied Battleship board scenarios. In contrast, LLM-only baselines struggle to ground questions in the board state; notably, GPT-4V provides no improvement over non-visual baselines. Our results illustrate how Bayesian models of question-asking can leverage the statistics of language to capture human priors, while highlighting some shortcomings of pure LLMs as grounded reasoners.","sentences":["Questions combine our mastery of language with our remarkable facility for reasoning about uncertainty.","How do people navigate vast hypothesis spaces to pose informative questions given limited cognitive resources?","We study these tradeoffs in a classic grounded question-asking task based on the board game Battleship.","Our language-informed program sampling (LIPS) model uses large language models (LLMs) to generate natural language questions, translate them into symbolic programs, and evaluate their expected information gain.","We find that with a surprisingly modest resource budget, this simple Monte Carlo optimization strategy yields informative questions that mirror human performance across varied Battleship board scenarios.","In contrast, LLM-only baselines struggle to ground questions in the board state; notably, GPT-4V provides no improvement over non-visual baselines.","Our results illustrate how Bayesian models of question-asking can leverage the statistics of language to capture human priors, while highlighting some shortcomings of pure LLMs as grounded reasoners."],"url":"http://arxiv.org/abs/2402.19471v1"}
{"created":"2024-02-29 18:57:37","title":"Humanoid Locomotion as Next Token Prediction","abstract":"We cast real-world humanoid control as a next token prediction problem, akin to predicting the next word in language. Our model is a causal transformer trained via autoregressive prediction of sensorimotor trajectories. To account for the multi-modal nature of the data, we perform prediction in a modality-aligned way, and for each input token predict the next token from the same modality. This general formulation enables us to leverage data with missing modalities, like video trajectories without actions. We train our model on a collection of simulated trajectories coming from prior neural network policies, model-based controllers, motion capture data, and YouTube videos of humans. We show that our model enables a full-sized humanoid to walk in San Francisco zero-shot. Our model can transfer to the real world even when trained on only 27 hours of walking data, and can generalize to commands not seen during training like walking backward. These findings suggest a promising path toward learning challenging real-world control tasks by generative modeling of sensorimotor trajectories.","sentences":["We cast real-world humanoid control as a next token prediction problem, akin to predicting the next word in language.","Our model is a causal transformer trained via autoregressive prediction of sensorimotor trajectories.","To account for the multi-modal nature of the data, we perform prediction in a modality-aligned way, and for each input token predict the next token from the same modality.","This general formulation enables us to leverage data with missing modalities, like video trajectories without actions.","We train our model on a collection of simulated trajectories coming from prior neural network policies, model-based controllers, motion capture data, and YouTube videos of humans.","We show that our model enables a full-sized humanoid to walk in San Francisco zero-shot.","Our model can transfer to the real world even when trained on only 27 hours of walking data, and can generalize to commands not seen during training like walking backward.","These findings suggest a promising path toward learning challenging real-world control tasks by generative modeling of sensorimotor trajectories."],"url":"http://arxiv.org/abs/2402.19469v1"}
{"created":"2024-02-29 18:57:01","title":"TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning","abstract":"It is challenging to perform question-answering over complex, multimodal content such as television clips. This is in part because current video-language models rely on single-modality reasoning, have lowered performance on long inputs, and lack interpetability. We propose TV-TREES, the first multimodal entailment tree generator. TV-TREES serves as an approach to video understanding that promotes interpretable joint-modality reasoning by producing trees of entailment relationships between simple premises directly entailed by the videos and higher-level conclusions. We then introduce the task of multimodal entailment tree generation to evaluate the reasoning quality of such methods. Our method's experimental results on the challenging TVQA dataset demonstrate intepretable, state-of-the-art zero-shot performance on full video clips, illustrating a best of both worlds contrast to black-box methods.","sentences":["It is challenging to perform question-answering over complex, multimodal content such as television clips.","This is in part because current video-language models rely on single-modality reasoning, have lowered performance on long inputs, and lack interpetability.","We propose TV-TREES, the first multimodal entailment tree generator.","TV-TREES serves as an approach to video understanding that promotes interpretable joint-modality reasoning by producing trees of entailment relationships between simple premises directly entailed by the videos and higher-level conclusions.","We then introduce the task of multimodal entailment tree generation to evaluate the reasoning quality of such methods.","Our method's experimental results on the challenging TVQA dataset demonstrate intepretable, state-of-the-art zero-shot performance on full video clips, illustrating a best of both worlds contrast to black-box methods."],"url":"http://arxiv.org/abs/2402.19467v1"}
{"created":"2024-02-29 18:55:06","title":"Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models","abstract":"Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs' trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs' trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness. To begin with, we apply linear probing to LLMs. The high probing accuracy suggests that \\textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}. Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a LLM's pre-training checkpoints to enhance the LLM's trustworthiness. Finally, inspired by~\\citet{choi2023understanding} that mutual information estimation is bounded by linear probing accuracy, we also probe LLMs with mutual information to investigate the dynamics of trustworthiness during pre-training. We are the first to observe a similar two-phase phenomenon: fitting and compression~\\citep{shwartz2017opening}. This research provides an initial exploration of trustworthiness modeling during LLM pre-training, seeking to unveil new insights and spur further developments in the field. We will make our code publicly accessible at \\url{https://github.com/ChnQ/TracingLLM}.","sentences":["Ensuring the trustworthiness of large language models (LLMs) is crucial.","Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs' trustworthiness.","In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs' trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness.","To begin with, we apply linear probing to LLMs.","The high probing accuracy suggests that \\textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}.","Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a LLM's pre-training checkpoints to enhance the LLM's trustworthiness.","Finally, inspired by~\\citet{choi2023understanding} that mutual information estimation is bounded by linear probing accuracy, we also probe LLMs with mutual information to investigate the dynamics of trustworthiness during pre-training.","We are the first to observe a similar two-phase phenomenon: fitting and compression~\\citep{shwartz2017opening}.","This research provides an initial exploration of trustworthiness modeling during LLM pre-training, seeking to unveil new insights and spur further developments in the field.","We will make our code publicly accessible at \\url{https://github.com/ChnQ/TracingLLM}."],"url":"http://arxiv.org/abs/2402.19465v1"}
{"created":"2024-02-29 18:55:03","title":"Curiosity-driven Red-teaming for Large Language Models","abstract":"Large language models (LLMs) hold great potential for many natural language applications but risk generating incorrect or toxic content. To probe when an LLM generates unwanted content, the current paradigm is to recruit a \\textit{red team} of human testers to design input prompts (i.e., test cases) that elicit undesirable responses from LLMs. However, relying solely on human testers is expensive and time-consuming. Recent works automate red teaming by training a separate red team LLM with reinforcement learning (RL) to generate test cases that maximize the chance of eliciting undesirable responses from the target LLM. However, current RL methods are only able to generate a small number of effective test cases resulting in a low coverage of the span of prompts that elicit undesirable responses from the target LLM. To overcome this limitation, we draw a connection between the problem of increasing the coverage of generated test cases and the well-studied approach of curiosity-driven exploration that optimizes for novelty. Our method of curiosity-driven red teaming (CRT) achieves greater coverage of test cases while mantaining or increasing their effectiveness compared to existing methods. Our method, CRT successfully provokes toxic responses from LLaMA2 model that has been heavily fine-tuned using human preferences to avoid toxic outputs. Code is available at \\url{https://github.com/Improbable-AI/curiosity_redteam}","sentences":["Large language models (LLMs) hold great potential for many natural language applications but risk generating incorrect or toxic content.","To probe when an LLM generates unwanted content, the current paradigm is to recruit a \\textit{red team} of human testers to design input prompts (i.e., test cases) that elicit undesirable responses from LLMs.","However, relying solely on human testers is expensive and time-consuming.","Recent works automate red teaming by training a separate red team LLM with reinforcement learning (RL) to generate test cases that maximize the chance of eliciting undesirable responses from the target LLM.","However, current RL methods are only able to generate a small number of effective test cases resulting in a low coverage of the span of prompts that elicit undesirable responses from the target LLM.","To overcome this limitation, we draw a connection between the problem of increasing the coverage of generated test cases and the well-studied approach of curiosity-driven exploration that optimizes for novelty.","Our method of curiosity-driven red teaming (CRT) achieves greater coverage of test cases while mantaining or increasing their effectiveness compared to existing methods.","Our method, CRT successfully provokes toxic responses from LLaMA2 model that has been heavily fine-tuned using human preferences to avoid toxic outputs.","Code is available at \\url{https://github.com/Improbable-AI/curiosity_redteam}"],"url":"http://arxiv.org/abs/2402.19464v1"}
{"created":"2024-02-29 18:54:53","title":"SeMoLi: What Moves Together Belongs Together","abstract":"We tackle semi-supervised object detection based on motion cues. Recent results suggest that heuristic-based clustering methods in conjunction with object trackers can be used to pseudo-label instances of moving objects and use these as supervisory signals to train 3D object detectors in Lidar data without manual supervision. We re-think this approach and suggest that both, object detection, as well as motion-inspired pseudo-labeling, can be tackled in a data-driven manner. We leverage recent advances in scene flow estimation to obtain point trajectories from which we extract long-term, class-agnostic motion patterns. Revisiting correlation clustering in the context of message passing networks, we learn to group those motion patterns to cluster points to object instances. By estimating the full extent of the objects, we obtain per-scan 3D bounding boxes that we use to supervise a Lidar object detection network. Our method not only outperforms prior heuristic-based approaches (57.5 AP, +14 improvement over prior work), more importantly, we show we can pseudo-label and train object detectors across datasets.","sentences":["We tackle semi-supervised object detection based on motion cues.","Recent results suggest that heuristic-based clustering methods in conjunction with object trackers can be used to pseudo-label instances of moving objects and use these as supervisory signals to train 3D object detectors in Lidar data without manual supervision.","We re-think this approach and suggest that both, object detection, as well as motion-inspired pseudo-labeling, can be tackled in a data-driven manner.","We leverage recent advances in scene flow estimation to obtain point trajectories from which we extract long-term, class-agnostic motion patterns.","Revisiting correlation clustering in the context of message passing networks, we learn to group those motion patterns to cluster points to object instances.","By estimating the full extent of the objects, we obtain per-scan 3D bounding boxes that we use to supervise a Lidar object detection network.","Our method not only outperforms prior heuristic-based approaches (57.5 AP, +14 improvement over prior work), more importantly, we show we can pseudo-label and train object detectors across datasets."],"url":"http://arxiv.org/abs/2402.19463v1"}
{"created":"2024-02-29 18:52:56","title":"Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks","abstract":"Uncertainty quantification, once a singular task, has evolved into a spectrum of tasks, including abstained prediction, out-of-distribution detection, and aleatoric uncertainty quantification. The latest goal is disentanglement: the construction of multiple estimators that are each tailored to one and only one task. Hence, there is a plethora of recent advances with different intentions - that often entirely deviate from practical behavior. This paper conducts a comprehensive evaluation of numerous uncertainty estimators across diverse tasks on ImageNet. We find that, despite promising theoretical endeavors, disentanglement is not yet achieved in practice. Additionally, we reveal which uncertainty estimators excel at which specific tasks, providing insights for practitioners and guiding future research toward task-centric and disentangled uncertainty estimation methods. Our code is available at https://github.com/bmucsanyi/bud.","sentences":["Uncertainty quantification, once a singular task, has evolved into a spectrum of tasks, including abstained prediction, out-of-distribution detection, and aleatoric uncertainty quantification.","The latest goal is disentanglement: the construction of multiple estimators that are each tailored to one and only one task.","Hence, there is a plethora of recent advances with different intentions - that often entirely deviate from practical behavior.","This paper conducts a comprehensive evaluation of numerous uncertainty estimators across diverse tasks on ImageNet.","We find that, despite promising theoretical endeavors, disentanglement is not yet achieved in practice.","Additionally, we reveal which uncertainty estimators excel at which specific tasks, providing insights for practitioners and guiding future research toward task-centric and disentangled uncertainty estimation methods.","Our code is available at https://github.com/bmucsanyi/bud."],"url":"http://arxiv.org/abs/2402.19460v1"}
{"created":"2024-02-29 18:51:23","title":"$\\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation","abstract":"Assessing the quality of summarizers poses significant challenges. In response, we propose a novel task-oriented evaluation approach that assesses summarizers based on their capacity to produce summaries that are useful for downstream tasks, while preserving task outcomes. We theoretically establish a direct relationship between the resulting error probability of these tasks and the mutual information between source texts and generated summaries. We introduce $\\texttt{COSMIC}$ as a practical implementation of this metric, demonstrating its strong correlation with human judgment-based metrics and its effectiveness in predicting downstream task performance. Comparative analyses against established metrics like $\\texttt{BERTScore}$ and $\\texttt{ROUGE}$ highlight the competitive performance of $\\texttt{COSMIC}$.","sentences":["Assessing the quality of summarizers poses significant challenges.","In response, we propose a novel task-oriented evaluation approach that assesses summarizers based on their capacity to produce summaries that are useful for downstream tasks, while preserving task outcomes.","We theoretically establish a direct relationship between the resulting error probability of these tasks and the mutual information between source texts and generated summaries.","We introduce $\\texttt{COSMIC}$ as a practical implementation of this metric, demonstrating its strong correlation with human judgment-based metrics and its effectiveness in predicting downstream task performance.","Comparative analyses against established metrics like $\\texttt{BERTScore}$ and $\\texttt{ROUGE}$ highlight the competitive performance of $\\texttt{COSMIC}$."],"url":"http://arxiv.org/abs/2402.19457v1"}
{"created":"2024-02-29 18:48:18","title":"Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap","abstract":"We propose a framework for robust evaluation of reasoning capabilities of language models, using functional variants of benchmarks. Models that solve a reasoning test should exhibit no difference in performance over the static version of a problem compared to a snapshot of the functional variant. We have rewritten the relevant fragment of the MATH benchmark into its functional variant MATH(), with functionalization of other benchmarks to follow. When evaluating current state-of-the-art models over snapshots of MATH(), we find a reasoning gap -- the percentage difference between the static and functional accuracies. We find reasoning gaps from 58.35% to 80.31% among the state-of-the-art closed and open weights models that perform well on static benchmarks, with the caveat that the gaps are likely to be smaller with more sophisticated prompting strategies. Here we show that models which anecdotally have good reasoning performance over real-world tasks, have quantifiable lower gaps, motivating the open problem of building \"gap 0\" models. Code for evaluation and new evaluation datasets, three MATH() snapshots, are publicly available at https://github.com/consequentai/fneval/.","sentences":["We propose a framework for robust evaluation of reasoning capabilities of language models, using functional variants of benchmarks.","Models that solve a reasoning test should exhibit no difference in performance over the static version of a problem compared to a snapshot of the functional variant.","We have rewritten the relevant fragment of the MATH benchmark into its functional variant MATH(), with functionalization of other benchmarks to follow.","When evaluating current state-of-the-art models over snapshots of MATH(), we find a reasoning gap -- the percentage difference between the static and functional accuracies.","We find reasoning gaps from 58.35% to 80.31% among the state-of-the-art closed and open weights models that perform well on static benchmarks, with the caveat that the gaps are likely to be smaller with more sophisticated prompting strategies.","Here we show that models which anecdotally have good reasoning performance over real-world tasks, have quantifiable lower gaps, motivating the open problem of building \"gap 0\" models.","Code for evaluation and new evaluation datasets, three MATH() snapshots, are publicly available at https://github.com/consequentai/fneval/."],"url":"http://arxiv.org/abs/2402.19450v1"}
{"created":"2024-02-29 18:47:52","title":"Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models","abstract":"Adam has been shown to outperform gradient descent in optimizing large language transformers empirically, and by a larger margin than on other tasks, but it is unclear why this happens. We show that the heavy-tailed class imbalance found in language modeling tasks leads to difficulties in the optimization dynamics. When training with gradient descent, the loss associated with infrequent words decreases slower than the loss associated with frequent ones. As most samples come from relatively infrequent words, the average loss decreases slowly with gradient descent. On the other hand, Adam and sign-based methods do not suffer from this problem and improve predictions on all classes. To establish that this behavior is indeed caused by class imbalance, we show empirically that it persist through different architectures and data types, on language transformers, vision CNNs, and linear models. We further study this phenomenon on a linear classification with cross-entropy loss, showing that heavy-tailed class imbalance leads to ill-conditioning, and that the normalization used by Adam can counteract it.","sentences":["Adam has been shown to outperform gradient descent in optimizing large language transformers empirically, and by a larger margin than on other tasks, but it is unclear why this happens.","We show that the heavy-tailed class imbalance found in language modeling tasks leads to difficulties in the optimization dynamics.","When training with gradient descent, the loss associated with infrequent words decreases slower than the loss associated with frequent ones.","As most samples come from relatively infrequent words, the average loss decreases slowly with gradient descent.","On the other hand, Adam and sign-based methods do not suffer from this problem and improve predictions on all classes.","To establish that this behavior is indeed caused by class imbalance, we show empirically that it persist through different architectures and data types, on language transformers, vision CNNs, and linear models.","We further study this phenomenon on a linear classification with cross-entropy loss, showing that heavy-tailed class imbalance leads to ill-conditioning, and that the normalization used by Adam can counteract it."],"url":"http://arxiv.org/abs/2402.19449v1"}
{"created":"2024-02-29 18:45:56","title":"ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL","abstract":"A broad use case of large language models (LLMs) is in goal-directed decision-making tasks (or \"agent\" tasks), where an LLM needs to not just generate completions for a given prompt, but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support). Reinforcement learning (RL) provides a general paradigm to address such agent tasks, but current RL methods for LLMs largely focus on optimizing single-turn rewards. By construction, most single-turn RL methods cannot endow LLMs with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks. This raises the question: how can we design effective and efficient multi-turn RL algorithms for LLMs? In this paper, we develop a framework for building multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility of existing single-turn RL methods for LLMs (e.g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively. To do this, our framework adopts a hierarchical RL approach and runs two RL algorithms in parallel: a high-level off-policy value-based RL algorithm to aggregate reward over utterances, and a low-level RL algorithm that utilizes this high-level value function to train a token policy within each utterance or turn. Our hierarchical framework, Actor-Critic Framework with a Hierarchical Structure (ArCHer), can also give rise to other RL methods. Empirically, we find that ArCHer significantly improves efficiency and performance on agent tasks, attaining a sample efficiency of about 100x over existing methods, while also improving with larger model capacity (upto the 7 billion scale that we tested on).","sentences":["A broad use case of large language models (LLMs) is in goal-directed decision-making tasks (or \"agent\" tasks), where an LLM needs to not just generate completions for a given prompt, but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support).","Reinforcement learning (RL) provides a general paradigm to address such agent tasks, but current RL methods for LLMs largely focus on optimizing single-turn rewards.","By construction, most single-turn RL methods cannot endow LLMs with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks.","This raises the question: how can we design effective and efficient multi-turn RL algorithms for LLMs?","In this paper, we develop a framework for building multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility of existing single-turn RL methods for LLMs (e.g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively.","To do this, our framework adopts a hierarchical RL approach and runs two RL algorithms in parallel: a high-level off-policy value-based RL algorithm to aggregate reward over utterances, and a low-level RL algorithm that utilizes this high-level value function to train a token policy within each utterance or turn.","Our hierarchical framework, Actor-Critic Framework with a Hierarchical Structure (ArCHer), can also give rise to other RL methods.","Empirically, we find that ArCHer significantly improves efficiency and performance on agent tasks, attaining a sample efficiency of about 100x over existing methods, while also improving with larger model capacity (upto the 7 billion scale that we tested on)."],"url":"http://arxiv.org/abs/2402.19446v1"}
{"created":"2024-02-29 18:43:53","title":"Probing the Information Encoded in Neural-based Acoustic Models of Automatic Speech Recognition Systems","abstract":"Deep learning architectures have made significant progress in terms of performance in many research areas. The automatic speech recognition (ASR) field has thus benefited from these scientific and technological advances, particularly for acoustic modeling, now integrating deep neural network architectures. However, these performance gains have translated into increased complexity regarding the information learned and conveyed through these black-box architectures. Following many researches in neural networks interpretability, we propose in this article a protocol that aims to determine which and where information is located in an ASR acoustic model (AM). To do so, we propose to evaluate AM performance on a determined set of tasks using intermediate representations (here, at different layer levels). Regarding the performance variation and targeted tasks, we can emit hypothesis about which information is enhanced or perturbed at different architecture steps. Experiments are performed on both speaker verification, acoustic environment classification, gender classification, tempo-distortion detection systems and speech sentiment/emotion identification. Analysis showed that neural-based AMs hold heterogeneous information that seems surprisingly uncorrelated with phoneme recognition, such as emotion, sentiment or speaker identity. The low-level hidden layers globally appears useful for the structuring of information while the upper ones would tend to delete useless information for phoneme recognition.","sentences":["Deep learning architectures have made significant progress in terms of performance in many research areas.","The automatic speech recognition (ASR) field has thus benefited from these scientific and technological advances, particularly for acoustic modeling, now integrating deep neural network architectures.","However, these performance gains have translated into increased complexity regarding the information learned and conveyed through these black-box architectures.","Following many researches in neural networks interpretability, we propose in this article a protocol that aims to determine which and where information is located in an ASR acoustic model (AM).","To do so, we propose to evaluate AM performance on a determined set of tasks using intermediate representations (here, at different layer levels).","Regarding the performance variation and targeted tasks, we can emit hypothesis about which information is enhanced or perturbed at different architecture steps.","Experiments are performed on both speaker verification, acoustic environment classification, gender classification, tempo-distortion detection systems and speech sentiment/emotion identification.","Analysis showed that neural-based AMs hold heterogeneous information that seems surprisingly uncorrelated with phoneme recognition, such as emotion, sentiment or speaker identity.","The low-level hidden layers globally appears useful for the structuring of information while the upper ones would tend to delete useless information for phoneme recognition."],"url":"http://arxiv.org/abs/2402.19443v1"}
{"created":"2024-02-29 18:43:52","title":"Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality","abstract":"We study the dynamics of gradient flow for training a multi-head softmax attention model for in-context learning of multi-task linear regression. We establish the global convergence of gradient flow under suitable choices of initialization. In addition, we prove that an interesting \"task allocation\" phenomenon emerges during the gradient flow dynamics, where each attention head focuses on solving a single task of the multi-task model. Specifically, we prove that the gradient flow dynamics can be split into three phases -- a warm-up phase where the loss decreases rather slowly and the attention heads gradually build up their inclination towards individual tasks, an emergence phase where each head selects a single task and the loss rapidly decreases, and a convergence phase where the attention parameters converge to a limit. Furthermore, we prove the optimality of gradient flow in the sense that the limiting model learned by gradient flow is on par with the best possible multi-head softmax attention model up to a constant factor. Our analysis also delineates a strict separation in terms of the prediction accuracy of ICL between single-head and multi-head attention models. The key technique for our convergence analysis is to map the gradient flow dynamics in the parameter space to a set of ordinary differential equations in the spectral domain, where the relative magnitudes of the semi-singular values of the attention weights determines task allocation. To our best knowledge, our work provides the first convergence result for the multi-head softmax attention model.","sentences":["We study the dynamics of gradient flow for training a multi-head softmax attention model for in-context learning of multi-task linear regression.","We establish the global convergence of gradient flow under suitable choices of initialization.","In addition, we prove that an interesting \"task allocation\" phenomenon emerges during the gradient flow dynamics, where each attention head focuses on solving a single task of the multi-task model.","Specifically, we prove that the gradient flow dynamics can be split into three phases -- a warm-up phase where the loss decreases rather slowly and the attention heads gradually build up their inclination towards individual tasks, an emergence phase where each head selects a single task and the loss rapidly decreases, and a convergence phase where the attention parameters converge to a limit.","Furthermore, we prove the optimality of gradient flow in the sense that the limiting model learned by gradient flow is on par with the best possible multi-head softmax attention model up to a constant factor.","Our analysis also delineates a strict separation in terms of the prediction accuracy of ICL between single-head and multi-head attention models.","The key technique for our convergence analysis is to map the gradient flow dynamics in the parameter space to a set of ordinary differential equations in the spectral domain, where the relative magnitudes of the semi-singular values of the attention weights determines task allocation.","To our best knowledge, our work provides the first convergence result for the multi-head softmax attention model."],"url":"http://arxiv.org/abs/2402.19442v1"}
{"created":"2024-02-29 18:43:43","title":"3D Gaussian Model for Animation and Texturing","abstract":"3D Gaussian Splatting has made a marked impact on neural rendering by achieving impressive fidelity and performance. Despite this achievement, however, it is not readily applicable to developing interactive applications. Real-time applications like XR apps and games require functions such as animation, UV-mapping, and model editing simultaneously manipulated through the usage of a 3D model. We propose a modeling that is analogous to typical 3D models, which we call 3D Gaussian Model (3DGM); it provides a manipulatable proxy for novel animation and texture transfer. By binding the 3D Gaussians in texture space and re-projecting them back to world space through implicit shell mapping, we show how our 3D modeling can serve as a valid rendering methodology for interactive applications. It is further noted that recently, 3D mesh reconstruction works have been able to produce high-quality mesh for rendering. Our work, on the other hand, only requires an approximated geometry for rendering an object in high fidelity. Applicationwise, we will show that our proxy-based 3DGM is capable of driving novel animation without animated training data and texture transferring via UV mapping of the 3D Gaussians. We believe the result indicates the potential of our work for enabling interactive applications for 3D Gaussian Splatting.","sentences":["3D Gaussian Splatting has made a marked impact on neural rendering by achieving impressive fidelity and performance.","Despite this achievement, however, it is not readily applicable to developing interactive applications.","Real-time applications like XR apps and games require functions such as animation, UV-mapping, and model editing simultaneously manipulated through the usage of a 3D model.","We propose a modeling that is analogous to typical 3D models, which we call 3D Gaussian Model (3DGM); it provides a manipulatable proxy for novel animation and texture transfer.","By binding the 3D Gaussians in texture space and re-projecting them back to world space through implicit shell mapping, we show how our 3D modeling can serve as a valid rendering methodology for interactive applications.","It is further noted that recently, 3D mesh reconstruction works have been able to produce high-quality mesh for rendering.","Our work, on the other hand, only requires an approximated geometry for rendering an object in high fidelity.","Applicationwise, we will show that our proxy-based 3DGM is capable of driving novel animation without animated training data and texture transferring via UV mapping of the 3D Gaussians.","We believe the result indicates the potential of our work for enabling interactive applications for 3D Gaussian Splatting."],"url":"http://arxiv.org/abs/2402.19441v1"}
{"created":"2024-02-29 18:38:20","title":"Differentially Private Worst-group Risk Minimization","abstract":"We initiate a systematic study of worst-group risk minimization under $(\\epsilon, \\delta)$-differential privacy (DP). The goal is to privately find a model that approximately minimizes the maximal risk across $p$ sub-populations (groups) with different distributions, where each group distribution is accessed via a sample oracle. We first present a new algorithm that achieves excess worst-group population risk of $\\tilde{O}(\\frac{p\\sqrt{d}}{K\\epsilon} + \\sqrt{\\frac{p}{K}})$, where $K$ is the total number of samples drawn from all groups and $d$ is the problem dimension. Our rate is nearly optimal when each distribution is observed via a fixed-size dataset of size $K/p$. Our result is based on a new stability-based analysis for the generalization error. In particular, we show that $\\Delta$-uniform argument stability implies $\\tilde{O}(\\Delta + \\frac{1}{\\sqrt{n}})$ generalization error w.r.t. the worst-group risk, where $n$ is the number of samples drawn from each sample oracle. Next, we propose an algorithmic framework for worst-group population risk minimization using any DP online convex optimization algorithm as a subroutine. Hence, we give another excess risk bound of $\\tilde{O}\\left( \\sqrt{\\frac{d^{1/2}}{\\epsilon K}} +\\sqrt{\\frac{p}{K\\epsilon^2}} \\right)$. Assuming the typical setting of $\\epsilon=\\Theta(1)$, this bound is more favorable than our first bound in a certain range of $p$ as a function of $K$ and $d$. Finally, we study differentially private worst-group empirical risk minimization in the offline setting, where each group distribution is observed by a fixed-size dataset. We present a new algorithm with nearly optimal excess risk of $\\tilde{O}(\\frac{p\\sqrt{d}}{K\\epsilon})$.","sentences":["We initiate a systematic study of worst-group risk minimization under $(\\epsilon, \\delta)$-differential privacy (DP).","The goal is to privately find a model that approximately minimizes the maximal risk across $p$ sub-populations (groups) with different distributions, where each group distribution is accessed via a sample oracle.","We first present a new algorithm that achieves excess worst-group population risk of $\\tilde{O}(\\frac{p\\sqrt{d}}{K\\epsilon} + \\sqrt{\\frac{p}{K}})$, where $K$ is the total number of samples drawn from all groups and $d$ is the problem dimension.","Our rate is nearly optimal when each distribution is observed via a fixed-size dataset of size $K/p$. Our result is based on a new stability-based analysis for the generalization error.","In particular, we show that $\\Delta$-uniform argument stability implies $\\tilde{O}(\\Delta + \\frac{1}{\\sqrt{n}})$ generalization error w.r.t.","the worst-group risk, where $n$ is the number of samples drawn from each sample oracle.","Next, we propose an algorithmic framework for worst-group population risk minimization using any DP online convex optimization algorithm as a subroutine.","Hence, we give another excess risk bound of $\\tilde{O}\\left( \\sqrt{\\frac{d^{1/2}}{\\epsilon K}} +\\sqrt{\\frac{p}{K\\epsilon^2}} \\right)$. Assuming the typical setting of $\\epsilon=\\Theta(1)$, this bound is more favorable than our first bound in a certain range of $p$ as a function of $K$ and $d$. Finally, we study differentially private worst-group empirical risk minimization in the offline setting, where each group distribution is observed by a fixed-size dataset.","We present a new algorithm with nearly optimal excess risk of $\\tilde{O}(\\frac{p\\sqrt{d}}{K\\epsilon})$."],"url":"http://arxiv.org/abs/2402.19437v1"}
{"created":"2024-02-29 18:35:12","title":"Digital Twin Aided Massive MIMO: CSI Compression and Feedback","abstract":"Deep learning (DL) approaches have demonstrated high performance in compressing and reconstructing the channel state information (CSI) and reducing the CSI feedback overhead in massive MIMO systems. One key challenge, however, with the DL approaches is the demand for extensive training data. Collecting this real-world CSI data incurs significant overhead that hinders the DL approaches from scaling to a large number of communication sites. To address this challenge, we propose a novel direction that utilizes site-specific \\textit{digital twins} to aid the training of DL models. The proposed digital twin approach generates site-specific synthetic CSI data from the EM 3D model and ray tracing, which can then be used to train the DL model without real-world data collection. To further improve the performance, we adopt online data selection to refine the DL model training with a small real-world CSI dataset. Results show that a DL model trained solely on the digital twin data can achieve high performance when tested in a real-world deployment. Further, leveraging domain adaptation techniques, the proposed approach requires orders of magnitude less real-world data to approach the same performance of the model trained completely on a real-world CSI dataset.","sentences":["Deep learning (DL) approaches have demonstrated high performance in compressing and reconstructing the channel state information (CSI) and reducing the CSI feedback overhead in massive MIMO systems.","One key challenge, however, with the DL approaches is the demand for extensive training data.","Collecting this real-world CSI data incurs significant overhead that hinders the DL approaches from scaling to a large number of communication sites.","To address this challenge, we propose a novel direction that utilizes site-specific \\textit{digital twins} to aid the training of DL models.","The proposed digital twin approach generates site-specific synthetic CSI data from the EM 3D model and ray tracing, which can then be used to train the DL model without real-world data collection.","To further improve the performance, we adopt online data selection to refine the DL model training with a small real-world CSI dataset.","Results show that a DL model trained solely on the digital twin data can achieve high performance when tested in a real-world deployment.","Further, leveraging domain adaptation techniques, the proposed approach requires orders of magnitude less real-world data to approach the same performance of the model trained completely on a real-world CSI dataset."],"url":"http://arxiv.org/abs/2402.19434v1"}
{"created":"2024-02-29 18:30:32","title":"Pushing the Limits of Cross-Embodiment Learning for Manipulation and Navigation","abstract":"Recent years in robotics and imitation learning have shown remarkable progress in training large-scale foundation models by leveraging data across a multitude of embodiments. The success of such policies might lead us to wonder: just how diverse can the robots in the training set be while still facilitating positive transfer? In this work, we study this question in the context of heterogeneous embodiments, examining how even seemingly very different domains, such as robotic navigation and manipulation, can provide benefits when included in the training data for the same model. We train a single goal-conditioned policy that is capable of controlling robotic arms, quadcopters, quadrupeds, and mobile bases. We then investigate the extent to which transfer can occur across navigation and manipulation on these embodiments by framing them as a single goal-reaching task. We find that co-training with navigation data can enhance robustness and performance in goal-conditioned manipulation with a wrist-mounted camera. We then deploy our policy trained only from navigation-only and static manipulation-only data on a mobile manipulator, showing that it can control a novel embodiment in a zero-shot manner. These results provide evidence that large-scale robotic policies can benefit from data collected across various embodiments. Further information and robot videos can be found on our project website http://extreme-cross-embodiment.github.io.","sentences":["Recent years in robotics and imitation learning have shown remarkable progress in training large-scale foundation models by leveraging data across a multitude of embodiments.","The success of such policies might lead us to wonder: just how diverse can the robots in the training set be while still facilitating positive transfer?","In this work, we study this question in the context of heterogeneous embodiments, examining how even seemingly very different domains, such as robotic navigation and manipulation, can provide benefits when included in the training data for the same model.","We train a single goal-conditioned policy that is capable of controlling robotic arms, quadcopters, quadrupeds, and mobile bases.","We then investigate the extent to which transfer can occur across navigation and manipulation on these embodiments by framing them as a single goal-reaching task.","We find that co-training with navigation data can enhance robustness and performance in goal-conditioned manipulation with a wrist-mounted camera.","We then deploy our policy trained only from navigation-only and static manipulation-only data on a mobile manipulator, showing that it can control a novel embodiment in a zero-shot manner.","These results provide evidence that large-scale robotic policies can benefit from data collected across various embodiments.","Further information and robot videos can be found on our project website http://extreme-cross-embodiment.github.io."],"url":"http://arxiv.org/abs/2402.19432v1"}
{"created":"2024-02-29 18:27:27","title":"Compositional API Recommendation for Library-Oriented Code Generation","abstract":"Large language models (LLMs) have achieved exceptional performance in code generation. However, the performance remains unsatisfactory in generating library-oriented code, especially for the libraries not present in the training data of LLMs. Previous work utilizes API recommendation technology to help LLMs use libraries: it retrieves APIs related to the user requirements, then leverages them as context to prompt LLMs. However, developmental requirements can be coarse-grained, requiring a combination of multiple fine-grained APIs. This granularity inconsistency makes API recommendation a challenging task. To address this, we propose CAPIR (Compositional API Recommendation), which adopts a \"divide-and-conquer\" strategy to recommend APIs for coarse-grained requirements. Specifically, CAPIR employs an LLM-based Decomposer to break down a coarse-grained task description into several detailed subtasks. Then, CAPIR applies an embedding-based Retriever to identify relevant APIs corresponding to each subtask. Moreover, CAPIR leverages an LLM-based Reranker to filter out redundant APIs and provides the final recommendation. To facilitate the evaluation of API recommendation methods on coarse-grained requirements, we present two challenging benchmarks, RAPID (Recommend APIs based on Documentation) and LOCG (Library-Oriented Code Generation). Experimental results on these benchmarks, demonstrate the effectiveness of CAPIR in comparison to existing baselines. Specifically, on RAPID's Torchdata-AR dataset, compared to the state-of-the-art API recommendation approach, CAPIR improves recall@5 from 18.7% to 43.2% and precision@5 from 15.5% to 37.1%. On LOCG's Torchdata-Code dataset, compared to code generation without API recommendation, CAPIR improves pass@100 from 16.0% to 28.0%.","sentences":["Large language models (LLMs) have achieved exceptional performance in code generation.","However, the performance remains unsatisfactory in generating library-oriented code, especially for the libraries not present in the training data of LLMs.","Previous work utilizes API recommendation technology to help LLMs use libraries: it retrieves APIs related to the user requirements, then leverages them as context to prompt LLMs.","However, developmental requirements can be coarse-grained, requiring a combination of multiple fine-grained APIs.","This granularity inconsistency makes API recommendation a challenging task.","To address this, we propose CAPIR (Compositional API Recommendation), which adopts a \"divide-and-conquer\" strategy to recommend APIs for coarse-grained requirements.","Specifically, CAPIR employs an LLM-based Decomposer to break down a coarse-grained task description into several detailed subtasks.","Then, CAPIR applies an embedding-based Retriever to identify relevant APIs corresponding to each subtask.","Moreover, CAPIR leverages an LLM-based Reranker to filter out redundant APIs and provides the final recommendation.","To facilitate the evaluation of API recommendation methods on coarse-grained requirements, we present two challenging benchmarks, RAPID (Recommend APIs based on Documentation) and LOCG (Library-Oriented Code Generation).","Experimental results on these benchmarks, demonstrate the effectiveness of CAPIR in comparison to existing baselines.","Specifically, on RAPID's Torchdata-AR dataset, compared to the state-of-the-art API recommendation approach, CAPIR improves recall@5 from 18.7% to 43.2% and precision@5 from 15.5% to 37.1%.","On LOCG's Torchdata-Code dataset, compared to code generation without API recommendation, CAPIR improves pass@100 from 16.0% to 28.0%."],"url":"http://arxiv.org/abs/2402.19431v1"}
{"created":"2024-02-29 18:24:46","title":"Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models","abstract":"Recurrent neural networks (RNNs) have fast inference and scale efficiently on long sequences, but they are difficult to train and hard to scale. We propose Hawk, an RNN with gated linear recurrences, and Griffin, a hybrid model that mixes gated linear recurrences with local attention. Hawk exceeds the reported performance of Mamba on downstream tasks, while Griffin matches the performance of Llama-2 despite being trained on over 6 times fewer tokens. We also show that Griffin can extrapolate on sequences significantly longer than those seen during training. Our models match the hardware efficiency of Transformers during training, and during inference they have lower latency and significantly higher throughput. We scale Griffin up to 14B parameters, and explain how to shard our models for efficient distributed training.","sentences":["Recurrent neural networks (RNNs) have fast inference and scale efficiently on long sequences, but they are difficult to train and hard to scale.","We propose Hawk, an RNN with gated linear recurrences, and Griffin, a hybrid model that mixes gated linear recurrences with local attention.","Hawk exceeds the reported performance of Mamba on downstream tasks, while Griffin matches the performance of Llama-2 despite being trained on over 6 times fewer tokens.","We also show that Griffin can extrapolate on sequences significantly longer than those seen during training.","Our models match the hardware efficiency of Transformers during training, and during inference they have lower latency and significantly higher throughput.","We scale Griffin up to 14B parameters, and explain how to shard our models for efficient distributed training."],"url":"http://arxiv.org/abs/2402.19427v1"}
{"created":"2024-02-29 18:22:12","title":"Leveraging AI Predicted and Expert Revised Annotations in Interactive Segmentation: Continual Tuning or Full Training?","abstract":"Interactive segmentation, an integration of AI algorithms and human expertise, premises to improve the accuracy and efficiency of curating large-scale, detailed-annotated datasets in healthcare. Human experts revise the annotations predicted by AI, and in turn, AI improves its predictions by learning from these revised annotations. This interactive process continues to enhance the quality of annotations until no major revision is needed from experts. The key challenge is how to leverage AI predicted and expert revised annotations to iteratively improve the AI. Two problems arise: (1) The risk of catastrophic forgetting--the AI tends to forget the previously learned classes if it is only retrained using the expert revised classes. (2) Computational inefficiency when retraining the AI using both AI predicted and expert revised annotations; moreover, given the dominant AI predicted annotations in the dataset, the contribution of newly revised annotations--often account for a very small fraction--to the AI training remains marginal. This paper proposes Continual Tuning to address the problems from two perspectives: network design and data reuse. Firstly, we design a shared network for all classes followed by class-specific networks dedicated to individual classes. To mitigate forgetting, we freeze the shared network for previously learned classes and only update the class-specific network for revised classes. Secondly, we reuse a small fraction of data with previous annotations to avoid over-computing. The selection of such data relies on the importance estimate of each data. The importance score is computed by combining the uncertainty and consistency of AI predictions. Our experiments demonstrate that Continual Tuning achieves a speed 16x greater than repeatedly training AI from scratch without compromising the performance.","sentences":["Interactive segmentation, an integration of AI algorithms and human expertise, premises to improve the accuracy and efficiency of curating large-scale, detailed-annotated datasets in healthcare.","Human experts revise the annotations predicted by AI, and in turn, AI improves its predictions by learning from these revised annotations.","This interactive process continues to enhance the quality of annotations until no major revision is needed from experts.","The key challenge is how to leverage AI predicted and expert revised annotations to iteratively improve the AI.","Two problems arise: (1) The risk of catastrophic forgetting--the AI tends to forget the previously learned classes if it is only retrained using the expert revised classes.","(2) Computational inefficiency when retraining the AI using both AI predicted and expert revised annotations; moreover, given the dominant AI predicted annotations in the dataset, the contribution of newly revised annotations--often account for a very small fraction--to the AI training remains marginal.","This paper proposes Continual Tuning to address the problems from two perspectives: network design and data reuse.","Firstly, we design a shared network for all classes followed by class-specific networks dedicated to individual classes.","To mitigate forgetting, we freeze the shared network for previously learned classes and only update the class-specific network for revised classes.","Secondly, we reuse a small fraction of data with previous annotations to avoid over-computing.","The selection of such data relies on the importance estimate of each data.","The importance score is computed by combining the uncertainty and consistency of AI predictions.","Our experiments demonstrate that Continual Tuning achieves a speed 16x greater than repeatedly training AI from scratch without compromising the performance."],"url":"http://arxiv.org/abs/2402.19423v1"}
{"created":"2024-02-29 18:21:54","title":"PEM: Prototype-based Efficient MaskFormer for Image Segmentation","abstract":"Recent transformer-based architectures have shown impressive results in the field of image segmentation. Thanks to their flexibility, they obtain outstanding performance in multiple segmentation tasks, such as semantic and panoptic, under a single unified framework. To achieve such impressive performance, these architectures employ intensive operations and require substantial computational resources, which are often not available, especially on edge devices. To fill this gap, we propose Prototype-based Efficient MaskFormer (PEM), an efficient transformer-based architecture that can operate in multiple segmentation tasks. PEM proposes a novel prototype-based cross-attention which leverages the redundancy of visual features to restrict the computation and improve the efficiency without harming the performance. In addition, PEM introduces an efficient multi-scale feature pyramid network, capable of extracting features that have high semantic content in an efficient way, thanks to the combination of deformable convolutions and context-based self-modulation. We benchmark the proposed PEM architecture on two tasks, semantic and panoptic segmentation, evaluated on two different datasets, Cityscapes and ADE20K. PEM demonstrates outstanding performance on every task and dataset, outperforming task-specific architectures while being comparable and even better than computationally-expensive baselines.","sentences":["Recent transformer-based architectures have shown impressive results in the field of image segmentation.","Thanks to their flexibility, they obtain outstanding performance in multiple segmentation tasks, such as semantic and panoptic, under a single unified framework.","To achieve such impressive performance, these architectures employ intensive operations and require substantial computational resources, which are often not available, especially on edge devices.","To fill this gap, we propose Prototype-based Efficient MaskFormer (PEM), an efficient transformer-based architecture that can operate in multiple segmentation tasks.","PEM proposes a novel prototype-based cross-attention which leverages the redundancy of visual features to restrict the computation and improve the efficiency without harming the performance.","In addition, PEM introduces an efficient multi-scale feature pyramid network, capable of extracting features that have high semantic content in an efficient way, thanks to the combination of deformable convolutions and context-based self-modulation.","We benchmark the proposed PEM architecture on two tasks, semantic and panoptic segmentation, evaluated on two different datasets, Cityscapes and ADE20K. PEM demonstrates outstanding performance on every task and dataset, outperforming task-specific architectures while being comparable and even better than computationally-expensive baselines."],"url":"http://arxiv.org/abs/2402.19422v1"}
{"created":"2024-02-29 18:20:37","title":"Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines","abstract":"In the domain of digital information dissemination, search engines act as pivotal conduits linking information seekers with providers. The advent of chat-based search engines utilizing Large Language Models (LLMs) and Retrieval Augmented Generation (RAG), exemplified by Bing Chat, marks an evolutionary leap in the search ecosystem. They demonstrate metacognitive abilities in interpreting web information and crafting responses with human-like understanding and creativity. Nonetheless, the intricate nature of LLMs renders their \"cognitive\" processes opaque, challenging even their designers' understanding. This research aims to dissect the mechanisms through which an LLM-powered chat-based search engine, specifically Bing Chat, selects information sources for its responses. To this end, an extensive dataset has been compiled through engagements with New Bing, documenting the websites it cites alongside those listed by the conventional search engine. Employing natural language processing (NLP) techniques, the research reveals that Bing Chat exhibits a preference for content that is not only readable and formally structured, but also demonstrates lower perplexity levels, indicating a unique inclination towards text that is predictable by the underlying LLM. Further enriching our analysis, we procure an additional dataset through interactions with the GPT-4 based knowledge retrieval API, unveiling a congruent text preference between the RAG API and Bing Chat. This consensus suggests that these text preferences intrinsically emerge from the underlying language models, rather than being explicitly crafted by Bing Chat's developers. Moreover, our investigation documents a greater similarity among websites cited by RAG technologies compared to those ranked highest by conventional search engines.","sentences":["In the domain of digital information dissemination, search engines act as pivotal conduits linking information seekers with providers.","The advent of chat-based search engines utilizing Large Language Models (LLMs) and Retrieval Augmented Generation (RAG), exemplified by Bing Chat, marks an evolutionary leap in the search ecosystem.","They demonstrate metacognitive abilities in interpreting web information and crafting responses with human-like understanding and creativity.","Nonetheless, the intricate nature of LLMs renders their \"cognitive\" processes opaque, challenging even their designers' understanding.","This research aims to dissect the mechanisms through which an LLM-powered chat-based search engine, specifically Bing Chat, selects information sources for its responses.","To this end, an extensive dataset has been compiled through engagements with New Bing, documenting the websites it cites alongside those listed by the conventional search engine.","Employing natural language processing (NLP) techniques, the research reveals that Bing Chat exhibits a preference for content that is not only readable and formally structured, but also demonstrates lower perplexity levels, indicating a unique inclination towards text that is predictable by the underlying LLM.","Further enriching our analysis, we procure an additional dataset through interactions with the GPT-4 based knowledge retrieval API, unveiling a congruent text preference between the RAG API and Bing Chat.","This consensus suggests that these text preferences intrinsically emerge from the underlying language models, rather than being explicitly crafted by Bing Chat's developers.","Moreover, our investigation documents a greater similarity among websites cited by RAG technologies compared to those ranked highest by conventional search engines."],"url":"http://arxiv.org/abs/2402.19421v1"}
{"created":"2024-02-29 18:16:13","title":"Understanding Iterative Combinatorial Auction Designs via Multi-Agent Reinforcement Learning","abstract":"Iterative combinatorial auctions are widely used in high stakes settings such as spectrum auctions. Such auctions can be hard to understand analytically, making it difficult for bidders to determine how to behave and for designers to optimize auction rules to ensure desirable outcomes such as high revenue or welfare. In this paper, we investigate whether multi-agent reinforcement learning (MARL) algorithms can be used to understand iterative combinatorial auctions, given that these algorithms have recently shown empirical success in several other domains. We find that MARL can indeed benefit auction analysis, but that deploying it effectively is nontrivial. We begin by describing modelling decisions that keep the resulting game tractable without sacrificing important features such as imperfect information or asymmetry between bidders. We also discuss how to navigate pitfalls of various MARL algorithms, how to overcome challenges in verifying convergence, and how to generate and interpret multiple equilibria. We illustrate the promise of our resulting approach by using it to evaluate a specific rule change to a clock auction, finding substantially different auction outcomes due to complex changes in bidders' behavior.","sentences":["Iterative combinatorial auctions are widely used in high stakes settings such as spectrum auctions.","Such auctions can be hard to understand analytically, making it difficult for bidders to determine how to behave and for designers to optimize auction rules to ensure desirable outcomes such as high revenue or welfare.","In this paper, we investigate whether multi-agent reinforcement learning (MARL) algorithms can be used to understand iterative combinatorial auctions, given that these algorithms have recently shown empirical success in several other domains.","We find that MARL can indeed benefit auction analysis, but that deploying it effectively is nontrivial.","We begin by describing modelling decisions that keep the resulting game tractable without sacrificing important features such as imperfect information or asymmetry between bidders.","We also discuss how to navigate pitfalls of various MARL algorithms, how to overcome challenges in verifying convergence, and how to generate and interpret multiple equilibria.","We illustrate the promise of our resulting approach by using it to evaluate a specific rule change to a clock auction, finding substantially different auction outcomes due to complex changes in bidders' behavior."],"url":"http://arxiv.org/abs/2402.19420v1"}
{"created":"2024-02-29 18:14:11","title":"Vision-Radio Experimental Infrastructure Architecture Towards 6G","abstract":"Telecommunications and computer vision have evolved separately so far. Yet, with the shift to sub-terahertz (sub-THz) and terahertz (THz) radio communications, there is an opportunity to explore computer vision technologies together with radio communications, considering the dependency of both technologies on Line of Sight. The combination of radio sensing and computer vision can address challenges such as obstructions and poor lighting. Also, machine learning algorithms, capable of processing multimodal data, play a crucial role in deriving insights from raw and low-level sensing data, offering a new level of abstraction that can enhance various applications and use cases such as beamforming and terminal handovers.   This paper introduces CONVERGE, a pioneering vision-radio paradigm that bridges this gap by leveraging Integrated Sensing and Communication (ISAC) to facilitate a dual \"View-to-Communicate, Communicate-to-View\" approach. CONVERGE offers tools that merge wireless communications and computer vision, establishing a novel Research Infrastructure (RI) that will be open to the scientific community and capable of providing open datasets. This new infrastructure will support future research in 6G and beyond concerning multiple verticals, such as telecommunications, automotive, manufacturing, media, and health.","sentences":["Telecommunications and computer vision have evolved separately so far.","Yet, with the shift to sub-terahertz (sub-THz) and terahertz (THz) radio communications, there is an opportunity to explore computer vision technologies together with radio communications, considering the dependency of both technologies on Line of Sight.","The combination of radio sensing and computer vision can address challenges such as obstructions and poor lighting.","Also, machine learning algorithms, capable of processing multimodal data, play a crucial role in deriving insights from raw and low-level sensing data, offering a new level of abstraction that can enhance various applications and use cases such as beamforming and terminal handovers.   ","This paper introduces CONVERGE, a pioneering vision-radio paradigm that bridges this gap by leveraging Integrated Sensing and Communication (ISAC) to facilitate a dual \"View-to-Communicate, Communicate-to-View\" approach.","CONVERGE offers tools that merge wireless communications and computer vision, establishing a novel Research Infrastructure (RI) that will be open to the scientific community and capable of providing open datasets.","This new infrastructure will support future research in 6G and beyond concerning multiple verticals, such as telecommunications, automotive, manufacturing, media, and health."],"url":"http://arxiv.org/abs/2402.19416v1"}
{"created":"2024-02-29 18:11:25","title":"Higher-Order Networks Representation and Learning: A Survey","abstract":"Network data has become widespread, larger, and more complex over the years. Traditional network data is dyadic, capturing the relations among pairs of entities. With the need to model interactions among more than two entities, significant research has focused on higher-order networks and ways to represent, analyze, and learn from them. There are two main directions to studying higher-order networks. One direction has focused on capturing higher-order patterns in traditional (dyadic) graphs by changing the basic unit of study from nodes to small frequently observed subgraphs, called motifs. As most existing network data comes in the form of pairwise dyadic relationships, studying higher-order structures within such graphs may uncover new insights. The second direction aims to directly model higher-order interactions using new and more complex representations such as simplicial complexes or hypergraphs. Some of these models have long been proposed, but improvements in computational power and the advent of new computational techniques have increased their popularity. Our goal in this paper is to provide a succinct yet comprehensive summary of the advanced higher-order network analysis techniques. We provide a systematic review of its foundations and algorithms, along with use cases and applications of higher-order networks in various scientific domains.","sentences":["Network data has become widespread, larger, and more complex over the years.","Traditional network data is dyadic, capturing the relations among pairs of entities.","With the need to model interactions among more than two entities, significant research has focused on higher-order networks and ways to represent, analyze, and learn from them.","There are two main directions to studying higher-order networks.","One direction has focused on capturing higher-order patterns in traditional (dyadic) graphs by changing the basic unit of study from nodes to small frequently observed subgraphs, called motifs.","As most existing network data comes in the form of pairwise dyadic relationships, studying higher-order structures within such graphs may uncover new insights.","The second direction aims to directly model higher-order interactions using new and more complex representations such as simplicial complexes or hypergraphs.","Some of these models have long been proposed, but improvements in computational power and the advent of new computational techniques have increased their popularity.","Our goal in this paper is to provide a succinct yet comprehensive summary of the advanced higher-order network analysis techniques.","We provide a systematic review of its foundations and algorithms, along with use cases and applications of higher-order networks in various scientific domains."],"url":"http://arxiv.org/abs/2402.19414v1"}
{"created":"2024-02-29 18:09:03","title":"PaECTER: Patent-level Representation Learning using Citation-informed Transformers","abstract":"PaECTER is a publicly available, open-source document-level encoder specific for patents. We fine-tune BERT for Patents with examiner-added citation information to generate numerical representations for patent documents. PaECTER performs better in similarity tasks than current state-of-the-art models used in the patent domain. More specifically, our model outperforms the next-best patent specific pre-trained language model (BERT for Patents) on our patent citation prediction test dataset on two different rank evaluation metrics. PaECTER predicts at least one most similar patent at a rank of 1.32 on average when compared against 25 irrelevant patents. Numerical representations generated by PaECTER from patent text can be used for downstream tasks such as classification, tracing knowledge flows, or semantic similarity search. Semantic similarity search is especially relevant in the context of prior art search for both inventors and patent examiners. PaECTER is available on Hugging Face.","sentences":["PaECTER is a publicly available, open-source document-level encoder specific for patents.","We fine-tune BERT for Patents with examiner-added citation information to generate numerical representations for patent documents.","PaECTER performs better in similarity tasks than current state-of-the-art models used in the patent domain.","More specifically, our model outperforms the next-best patent specific pre-trained language model (BERT for Patents) on our patent citation prediction test dataset on two different rank evaluation metrics.","PaECTER predicts at least one most similar patent at a rank of 1.32 on average when compared against 25 irrelevant patents.","Numerical representations generated by PaECTER from patent text can be used for downstream tasks such as classification, tracing knowledge flows, or semantic similarity search.","Semantic similarity search is especially relevant in the context of prior art search for both inventors and patent examiners.","PaECTER is available on Hugging Face."],"url":"http://arxiv.org/abs/2402.19411v1"}
{"created":"2024-02-29 18:07:58","title":"Genie: Smart ROS-based Caching for Connected Autonomous Robots","abstract":"Despite the promising future of autonomous robots, several key issues currently remain that can lead to compromised performance and safety. One such issue is latency, where we find that even the latest embedded platforms from NVIDIA fail to execute intelligence tasks (e.g., object detection) of autonomous vehicles in a real-time fashion. One remedy to this problem is the promising paradigm of edge computing. Through collaboration with our industry partner, we identify key prohibitive limitations of the current edge mindset: (1) servers are not distributed enough and thus, are not close enough to vehicles, (2) current proposed edge solutions do not provide substantially better performance and extra information specific to autonomous vehicles to warrant their cost to the user, and (3) the state-of-the-art solutions are not compatible with popular frameworks used in autonomous systems, particularly the Robot Operating System (ROS).   To remedy these issues, we provide Genie, an encapsulation technique that can enable transparent caching in ROS in a non-intrusive way (i.e., without modifying the source code), can build the cache in a distributed manner (in contrast to traditional central caching methods), and can construct a collective three-dimensional object map to provide substantially better latency (even on low-power edge servers) and higher quality data to all vehicles in a certain locality. We fully implement our design on state-of-the-art industry-adopted embedded and edge platforms, using the prominent autonomous driving software Autoware, and find that Genie can enhance the latency of Autoware Vision Detector by 82% on average, enable object reusability 31% of the time on average and as much as 67% for the incoming requests, and boost the confidence in its object map considerably over time.","sentences":["Despite the promising future of autonomous robots, several key issues currently remain that can lead to compromised performance and safety.","One such issue is latency, where we find that even the latest embedded platforms from NVIDIA fail to execute intelligence tasks (e.g., object detection) of autonomous vehicles in a real-time fashion.","One remedy to this problem is the promising paradigm of edge computing.","Through collaboration with our industry partner, we identify key prohibitive limitations of the current edge mindset: (1) servers are not distributed enough and thus, are not close enough to vehicles, (2) current proposed edge solutions do not provide substantially better performance and extra information specific to autonomous vehicles to warrant their cost to the user, and (3) the state-of-the-art solutions are not compatible with popular frameworks used in autonomous systems, particularly the Robot Operating System (ROS).   ","To remedy these issues, we provide Genie, an encapsulation technique that can enable transparent caching in ROS in a non-intrusive way (i.e., without modifying the source code), can build the cache in a distributed manner (in contrast to traditional central caching methods), and can construct a collective three-dimensional object map to provide substantially better latency (even on low-power edge servers) and higher quality data to all vehicles in a certain locality.","We fully implement our design on state-of-the-art industry-adopted embedded and edge platforms, using the prominent autonomous driving software Autoware, and find that Genie can enhance the latency of Autoware Vision Detector by 82% on average, enable object reusability 31% of the time on average and as much as 67% for the incoming requests, and boost the confidence in its object map considerably over time."],"url":"http://arxiv.org/abs/2402.19410v1"}
{"created":"2024-02-29 18:06:02","title":"MENTOR: Multi-level Self-supervised Learning for Multimodal Recommendation","abstract":"With the increasing multimedia information, multimodal recommendation has received extensive attention. It utilizes multimodal information to alleviate the data sparsity problem in recommendation systems, thus improving recommendation accuracy. However, the reliance on labeled data severely limits the performance of multimodal recommendation models. Recently, self-supervised learning has been used in multimodal recommendations to mitigate the label sparsity problem. Nevertheless, the state-of-the-art methods cannot avoid the modality noise when aligning multimodal information due to the large differences in the distributions of different modalities. To this end, we propose a Multi-level sElf-supervised learNing for mulTimOdal Recommendation (MENTOR) method to address the label sparsity problem and the modality alignment problem. Specifically, MENTOR first enhances the specific features of each modality using the graph convolutional network (GCN) and fuses the visual and textual modalities. It then enhances the item representation via the item semantic graph for all modalities, including the fused modality. Then, it introduces two multilevel self-supervised tasks: the multilevel cross-modal alignment task and the general feature enhancement task. The multilevel cross-modal alignment task aligns each modality under the guidance of the ID embedding from multiple levels while maintaining the historical interaction information. The general feature enhancement task enhances the general feature from both the graph and feature perspectives to improve the robustness of our model. Extensive experiments on three publicly available datasets demonstrate the effectiveness of our method. Our code is publicly available at https://github.com/Jinfeng-Xu/MENTOR.","sentences":["With the increasing multimedia information, multimodal recommendation has received extensive attention.","It utilizes multimodal information to alleviate the data sparsity problem in recommendation systems, thus improving recommendation accuracy.","However, the reliance on labeled data severely limits the performance of multimodal recommendation models.","Recently, self-supervised learning has been used in multimodal recommendations to mitigate the label sparsity problem.","Nevertheless, the state-of-the-art methods cannot avoid the modality noise when aligning multimodal information due to the large differences in the distributions of different modalities.","To this end, we propose a Multi-level sElf-supervised learNing for mulTimOdal Recommendation (MENTOR) method to address the label sparsity problem and the modality alignment problem.","Specifically, MENTOR first enhances the specific features of each modality using the graph convolutional network (GCN) and fuses the visual and textual modalities.","It then enhances the item representation via the item semantic graph for all modalities, including the fused modality.","Then, it introduces two multilevel self-supervised tasks: the multilevel cross-modal alignment task and the general feature enhancement task.","The multilevel cross-modal alignment task aligns each modality under the guidance of the ID embedding from multiple levels while maintaining the historical interaction information.","The general feature enhancement task enhances the general feature from both the graph and feature perspectives to improve the robustness of our model.","Extensive experiments on three publicly available datasets demonstrate the effectiveness of our method.","Our code is publicly available at https://github.com/Jinfeng-Xu/MENTOR."],"url":"http://arxiv.org/abs/2402.19407v1"}
{"created":"2024-02-29 18:04:11","title":"On the Scaling Laws of Geographical Representation in Language Models","abstract":"Language models have long been shown to embed geographical information in their hidden representations. This line of work has recently been revisited by extending this result to Large Language Models (LLMs). In this paper, we propose to fill the gap between well-established and recent literature by observing how geographical knowledge evolves when scaling language models. We show that geographical knowledge is observable even for tiny models, and that it scales consistently as we increase the model size. Notably, we observe that larger language models cannot mitigate the geographical bias that is inherent to the training data.","sentences":["Language models have long been shown to embed geographical information in their hidden representations.","This line of work has recently been revisited by extending this result to Large Language Models (LLMs).","In this paper, we propose to fill the gap between well-established and recent literature by observing how geographical knowledge evolves when scaling language models.","We show that geographical knowledge is observable even for tiny models, and that it scales consistently as we increase the model size.","Notably, we observe that larger language models cannot mitigate the geographical bias that is inherent to the training data."],"url":"http://arxiv.org/abs/2402.19406v1"}
{"created":"2024-02-29 18:03:23","title":"Navigating Hallucinations for Reasoning of Unintentional Activities","abstract":"In this work we present a novel task of understanding unintentional human activities in videos. We formalize this problem as a reasoning task under zero-shot scenario, where given a video of an unintentional activity we want to know why it transitioned from intentional to unintentional. We first evaluate the effectiveness of current state-of-the-art Large Multimodal Models on this reasoning task and observe that they suffer from hallucination. We further propose a novel prompting technique,termed as Dream of Thoughts (DoT), which allows the model to navigate through hallucinated thoughts to achieve better reasoning. To evaluate the performance on this task, we also introduce three different specialized metrics designed to quantify the models reasoning capability. We perform our experiments on two different datasets, OOPs and UCF-Crimes, and our findings show that DOT prompting technique is able to outperform standard prompting, while minimizing hallucinations.","sentences":["In this work we present a novel task of understanding unintentional human activities in videos.","We formalize this problem as a reasoning task under zero-shot scenario, where given a video of an unintentional activity we want to know why it transitioned from intentional to unintentional.","We first evaluate the effectiveness of current state-of-the-art Large Multimodal Models on this reasoning task and observe that they suffer from hallucination.","We further propose a novel prompting technique,termed as Dream of Thoughts (DoT), which allows the model to navigate through hallucinated thoughts to achieve better reasoning.","To evaluate the performance on this task, we also introduce three different specialized metrics designed to quantify the models reasoning capability.","We perform our experiments on two different datasets, OOPs and UCF-Crimes, and our findings show that DOT prompting technique is able to outperform standard prompting, while minimizing hallucinations."],"url":"http://arxiv.org/abs/2402.19405v1"}
{"created":"2024-02-29 18:03:00","title":"Entity-Aware Multimodal Alignment Framework for News Image Captioning","abstract":"News image captioning task is a variant of image captioning task which requires model to generate a more informative caption with news image and the associated news article. Multimodal Large Language models have developed rapidly in recent years and is promising in news image captioning task. However, according to our experiments, common MLLMs are not good at generating the entities in zero-shot setting. Their abilities to deal with the entities information are still limited after simply fine-tuned on news image captioning dataset. To obtain a more powerful model to handle the multimodal entity information, we design two multimodal entity-aware alignment tasks and an alignment framework to align the model and generate the news image captions. Our method achieves better results than previous state-of-the-art models in CIDEr score (72.33 -> 86.29) on GoodNews dataset and (70.83 -> 85.61) on NYTimes800k dataset.","sentences":["News image captioning task is a variant of image captioning task which requires model to generate a more informative caption with news image and the associated news article.","Multimodal Large Language models have developed rapidly in recent years and is promising in news image captioning task.","However, according to our experiments, common MLLMs are not good at generating the entities in zero-shot setting.","Their abilities to deal with the entities information are still limited after simply fine-tuned on news image captioning dataset.","To obtain a more powerful model to handle the multimodal entity information, we design two multimodal entity-aware alignment tasks and an alignment framework to align the model and generate the news image captions.","Our method achieves better results than previous state-of-the-art models in CIDEr score (72.33 -> 86.29) on GoodNews dataset and (70.83 -> 85.61) on NYTimes800k dataset."],"url":"http://arxiv.org/abs/2402.19404v1"}
{"created":"2024-02-29 18:01:07","title":"A Scalable and Transferable Time Series Prediction Framework for Demand Forecasting","abstract":"Time series forecasting is one of the most essential and ubiquitous tasks in many business problems, including demand forecasting and logistics optimization. Traditional time series forecasting methods, however, have resulted in small models with limited expressive power because they have difficulty in scaling their model size up while maintaining high accuracy. In this paper, we propose Forecasting orchestra (Forchestra), a simple but powerful framework capable of accurately predicting future demand for a diverse range of items. We empirically demonstrate that the model size is scalable to up to 0.8 billion parameters. The proposed method not only outperforms existing forecasting models with a significant margin, but it could generalize well to unseen data points when evaluated in a zero-shot fashion on downstream datasets. Last but not least, we present extensive qualitative and quantitative studies to analyze how the proposed model outperforms baseline models and differs from conventional approaches. The original paper was presented as a full paper at ICDM 2022 and is available at: https://ieeexplore.ieee.org/document/10027662.","sentences":["Time series forecasting is one of the most essential and ubiquitous tasks in many business problems, including demand forecasting and logistics optimization.","Traditional time series forecasting methods, however, have resulted in small models with limited expressive power because they have difficulty in scaling their model size up while maintaining high accuracy.","In this paper, we propose Forecasting orchestra (Forchestra), a simple but powerful framework capable of accurately predicting future demand for a diverse range of items.","We empirically demonstrate that the model size is scalable to up to 0.8 billion parameters.","The proposed method not only outperforms existing forecasting models with a significant margin, but it could generalize well to unseen data points when evaluated in a zero-shot fashion on downstream datasets.","Last but not least, we present extensive qualitative and quantitative studies to analyze how the proposed model outperforms baseline models and differs from conventional approaches.","The original paper was presented as a full paper at ICDM 2022 and is available at: https://ieeexplore.ieee.org/document/10027662."],"url":"http://arxiv.org/abs/2402.19402v1"}
{"created":"2024-02-29 18:00:27","title":"Assessing Visually-Continuous Corruption Robustness of Neural Networks Relative to Human Performance","abstract":"While Neural Networks (NNs) have surpassed human accuracy in image classification on ImageNet, they often lack robustness against image corruption, i.e., corruption robustness. Yet such robustness is seemingly effortless for human perception. In this paper, we propose visually-continuous corruption robustness (VCR) -- an extension of corruption robustness to allow assessing it over the wide and continuous range of changes that correspond to the human perceptive quality (i.e., from the original image to the full distortion of all perceived visual information), along with two novel human-aware metrics for NN evaluation. To compare VCR of NNs with human perception, we conducted extensive experiments on 14 commonly used image corruptions with 7,718 human participants and state-of-the-art robust NN models with different training objectives (e.g., standard, adversarial, corruption robustness), different architectures (e.g., convolution NNs, vision transformers), and different amounts of training data augmentation. Our study showed that: 1) assessing robustness against continuous corruption can reveal insufficient robustness undetected by existing benchmarks; as a result, 2) the gap between NN and human robustness is larger than previously known; and finally, 3) some image corruptions have a similar impact on human perception, offering opportunities for more cost-effective robustness assessments. Our validation set with 14 image corruptions, human robustness data, and the evaluation code is provided as a toolbox and a benchmark.","sentences":["While Neural Networks (NNs) have surpassed human accuracy in image classification on ImageNet, they often lack robustness against image corruption, i.e., corruption robustness.","Yet such robustness is seemingly effortless for human perception.","In this paper, we propose visually-continuous corruption robustness (VCR) -- an extension of corruption robustness to allow assessing it over the wide and continuous range of changes that correspond to the human perceptive quality (i.e., from the original image to the full distortion of all perceived visual information), along with two novel human-aware metrics for NN evaluation.","To compare VCR of NNs with human perception, we conducted extensive experiments on 14 commonly used image corruptions with 7,718 human participants and state-of-the-art robust NN models with different training objectives (e.g., standard, adversarial, corruption robustness), different architectures (e.g., convolution NNs, vision transformers), and different amounts of training data augmentation.","Our study showed that: 1) assessing robustness against continuous corruption can reveal insufficient robustness undetected by existing benchmarks; as a result, 2) the gap between NN and human robustness is larger than previously known; and finally, 3) some image corruptions have a similar impact on human perception, offering opportunities for more cost-effective robustness assessments.","Our validation set with 14 image corruptions, human robustness data, and the evaluation code is provided as a toolbox and a benchmark."],"url":"http://arxiv.org/abs/2402.19401v1"}
{"created":"2024-02-29 17:36:39","title":"Towards Safe and Reliable Autonomous Driving: Dynamic Occupancy Set Prediction","abstract":"In the rapidly evolving field of autonomous driving, accurate trajectory prediction is pivotal for vehicular safety. However, trajectory predictions often deviate from actual paths, particularly in complex and challenging environments, leading to significant errors. To address this issue, our study introduces a novel method for Dynamic Occupancy Set (DOS) prediction, enhancing trajectory prediction capabilities. This method effectively combines advanced trajectory prediction networks with a DOS prediction module, overcoming the shortcomings of existing models. It provides a comprehensive and adaptable framework for predicting the potential occupancy sets of traffic participants. The main contributions of this research include: 1) A novel DOS prediction model tailored for complex scenarios, augmenting traditional trajectory prediction; 2) The development of unique DOS representations and evaluation metrics; 3) Extensive validation through experiments, demonstrating enhanced performance and adaptability. This research contributes to the advancement of safer and more efficient intelligent vehicle and transportation systems.","sentences":["In the rapidly evolving field of autonomous driving, accurate trajectory prediction is pivotal for vehicular safety.","However, trajectory predictions often deviate from actual paths, particularly in complex and challenging environments, leading to significant errors.","To address this issue, our study introduces a novel method for Dynamic Occupancy Set (DOS) prediction, enhancing trajectory prediction capabilities.","This method effectively combines advanced trajectory prediction networks with a DOS prediction module, overcoming the shortcomings of existing models.","It provides a comprehensive and adaptable framework for predicting the potential occupancy sets of traffic participants.","The main contributions of this research include: 1) A novel DOS prediction model tailored for complex scenarios, augmenting traditional trajectory prediction; 2)","The development of unique DOS representations and evaluation metrics; 3) Extensive validation through experiments, demonstrating enhanced performance and adaptability.","This research contributes to the advancement of safer and more efficient intelligent vehicle and transportation systems."],"url":"http://arxiv.org/abs/2402.19385v1"}
{"created":"2024-02-29 17:27:59","title":"Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy","abstract":"Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters. Past work on the forecasting ability of large language models (LLMs) suggests that frontier LLMs, as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate. In Study 1, we expand this research by using an LLM ensemble approach consisting of a crowd of twelve LLMs. We compare the aggregated LLM predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament. Our main analysis shows that the LLM crowd outperforms a simple no-information benchmark and is statistically equivalent to the human crowd. We also observe an acquiescence effect, with mean model predictions being significantly above 50%, despite an almost even split of positive and negative resolutions. Moreover, in Study 2, we test whether LLM predictions (of GPT-4 and Claude 2) can be improved by drawing on human cognitive output. We find that both models' forecasting accuracy benefits from exposure to the median human prediction as information, improving accuracy by between 17% and 28%: though this leads to less accurate predictions than simply averaging human and machine forecasts. Our results suggest that LLMs can achieve forecasting accuracy rivaling that of human crowd forecasting tournaments: via the simple, practically applicable method of forecast aggregation. This replicates the 'wisdom of the crowd' effect for LLMs, and opens up their use for a variety applications throughout society.","sentences":["Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters.","Past work on the forecasting ability of large language models (LLMs) suggests that frontier LLMs, as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate.","In Study 1, we expand this research by using an LLM ensemble approach consisting of a crowd of twelve LLMs.","We compare the aggregated LLM predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament.","Our main analysis shows that the LLM crowd outperforms a simple no-information benchmark and is statistically equivalent to the human crowd.","We also observe an acquiescence effect, with mean model predictions being significantly above 50%, despite an almost even split of positive and negative resolutions.","Moreover, in Study 2, we test whether LLM predictions (of GPT-4 and Claude 2) can be improved by drawing on human cognitive output.","We find that both models' forecasting accuracy benefits from exposure to the median human prediction as information, improving accuracy by between 17% and 28%: though this leads to less accurate predictions than simply averaging human and machine forecasts.","Our results suggest that LLMs can achieve forecasting accuracy rivaling that of human crowd forecasting tournaments: via the simple, practically applicable method of forecast aggregation.","This replicates the 'wisdom of the crowd' effect for LLMs, and opens up their use for a variety applications throughout society."],"url":"http://arxiv.org/abs/2402.19379v1"}
{"created":"2024-02-29 17:24:22","title":"OzMAC: An Energy-Efficient Sparsity-Exploiting Multiply-Accumulate-Unit Design for DL Inference","abstract":"General Matrix Multiply (GEMM) hardware, employing large arrays of multiply-accumulate (MAC) units, perform bulk of the computation in deep learning (DL). Recent trends have established 8-bit integer (INT8) as the most widely used precision for DL inference. This paper proposes a novel MAC design capable of dynamically exploiting bit sparsity (i.e., number of `0' bits within a binary value) in input data to achieve significant improvements on area, power and energy. The proposed architecture, called OzMAC (Omit-zero-MAC), skips over zeros within a binary input value and performs simple shift-and-add-based compute in place of expensive multipliers. We implement OzMAC in SystemVerilog and present post-synthesis performance-power-area (PPA) results using commercial TSMC N5 (5nm) process node. Using eight pretrained INT8 deep neural networks (DNNs) as benchmarks, we demonstrate the existence of high bit sparsity in real DNN workloads and show that 8-bit OzMAC improves all three metrics of area, power, and energy significantly by 21%, 70%, and 28%, respectively. Similar improvements are achieved when scaling data precisions (4, 8, 16 bits) and clock frequencies (0.5 GHz, 1 GHz, 1.5 GHz). For the 8-bit OzMAC, scaling its frequency to normalize the throughput relative to conventional MAC, it still achieves 30% improvement on both power and energy.","sentences":["General Matrix Multiply (GEMM) hardware, employing large arrays of multiply-accumulate (MAC) units, perform bulk of the computation in deep learning (DL).","Recent trends have established 8-bit integer (INT8) as the most widely used precision for DL inference.","This paper proposes a novel MAC design capable of dynamically exploiting bit sparsity (i.e., number of `0' bits within a binary value) in input data to achieve significant improvements on area, power and energy.","The proposed architecture, called OzMAC (Omit-zero-MAC), skips over zeros within a binary input value and performs simple shift-and-add-based compute in place of expensive multipliers.","We implement OzMAC in SystemVerilog and present post-synthesis performance-power-area (PPA) results using commercial TSMC N5 (5nm) process node.","Using eight pretrained INT8 deep neural networks (DNNs) as benchmarks, we demonstrate the existence of high bit sparsity in real DNN workloads and show that 8-bit OzMAC improves all three metrics of area, power, and energy significantly by 21%, 70%, and 28%, respectively.","Similar improvements are achieved when scaling data precisions (4, 8, 16 bits) and clock frequencies (0.5 GHz, 1 GHz, 1.5 GHz).","For the 8-bit OzMAC, scaling its frequency to normalize the throughput relative to conventional MAC, it still achieves 30% improvement on both power and energy."],"url":"http://arxiv.org/abs/2402.19376v1"}
{"created":"2024-02-29 17:21:59","title":"Unveiling Internet Censorship: Analysing the Impact of Nation States' Content Control Efforts on Internet Architecture and Routing Patterns","abstract":"Heightened interest from nation states to perform content censorship make it evermore critical to identify the impact of censorship efforts on the Internet. We undertake a study of Internet architecture, capturing the state of Internet topology with greater completeness than existing state-of-the-art. We describe our methodology for this, including the tooling we create to collect and process data from a wide range of sources. We analyse this data to find key patterns in nation states with higher censorship, discovering a funnelling effect wherein higher Internet censorship effort is reflected in a constraining effect on a state's Internet routing architecture. However, there are a small number of nation states that do not follow this trend, for which we provide an analysis and explanation, demonstrating a relationship between geographical factors in addition to geopolitics. In summary, our work provides a deeper understanding of how these censorship measures impact the overall functioning and dynamics of the Internet.","sentences":["Heightened interest from nation states to perform content censorship make it evermore critical to identify the impact of censorship efforts on the Internet.","We undertake a study of Internet architecture, capturing the state of Internet topology with greater completeness than existing state-of-the-art.","We describe our methodology for this, including the tooling we create to collect and process data from a wide range of sources.","We analyse this data to find key patterns in nation states with higher censorship, discovering a funnelling effect wherein higher Internet censorship effort is reflected in a constraining effect on a state's Internet routing architecture.","However, there are a small number of nation states that do not follow this trend, for which we provide an analysis and explanation, demonstrating a relationship between geographical factors in addition to geopolitics.","In summary, our work provides a deeper understanding of how these censorship measures impact the overall functioning and dynamics of the Internet."],"url":"http://arxiv.org/abs/2402.19375v1"}
{"created":"2024-02-29 17:19:39","title":"OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models","abstract":"LLMs have become increasingly capable at accomplishing a range of specialized-tasks and can be utilized to expand equitable access to medical knowledge. Most medical LLMs have involved extensive fine-tuning, leveraging specialized medical data and significant, thus costly, amounts of computational power. Many of the top performing LLMs are proprietary and their access is limited to very few research groups. However, open-source (OS) models represent a key area of growth for medical LLMs due to significant improvements in performance and an inherent ability to provide the transparency and compliance required in healthcare. We present OpenMedLM, a prompting platform which delivers state-of-the-art (SOTA) performance for OS LLMs on medical benchmarks. We evaluated a range of OS foundation LLMs (7B-70B) on four medical benchmarks (MedQA, MedMCQA, PubMedQA, MMLU medical-subset). We employed a series of prompting strategies, including zero-shot, few-shot, chain-of-thought (random selection and kNN selection), and ensemble/self-consistency voting. We found that OpenMedLM delivers OS SOTA results on three common medical LLM benchmarks, surpassing the previous best performing OS models that leveraged computationally costly extensive fine-tuning. The model delivers a 72.6% accuracy on the MedQA benchmark, outperforming the previous SOTA by 2.4%, and achieves 81.7% accuracy on the MMLU medical-subset, establishing itself as the first OS LLM to surpass 80% accuracy on this benchmark. Our results highlight medical-specific emergent properties in OS LLMs which have not yet been documented to date elsewhere, and showcase the benefits of further leveraging prompt engineering to improve the performance of accessible LLMs for medical applications.","sentences":["LLMs have become increasingly capable at accomplishing a range of specialized-tasks and can be utilized to expand equitable access to medical knowledge.","Most medical LLMs have involved extensive fine-tuning, leveraging specialized medical data and significant, thus costly, amounts of computational power.","Many of the top performing LLMs are proprietary and their access is limited to very few research groups.","However, open-source (OS) models represent a key area of growth for medical LLMs due to significant improvements in performance and an inherent ability to provide the transparency and compliance required in healthcare.","We present OpenMedLM, a prompting platform which delivers state-of-the-art (SOTA) performance for OS LLMs on medical benchmarks.","We evaluated a range of OS foundation LLMs (7B-70B) on four medical benchmarks (MedQA, MedMCQA, PubMedQA, MMLU medical-subset).","We employed a series of prompting strategies, including zero-shot, few-shot, chain-of-thought (random selection and kNN selection), and ensemble/self-consistency voting.","We found that OpenMedLM delivers OS SOTA results on three common medical LLM benchmarks, surpassing the previous best performing OS models that leveraged computationally costly extensive fine-tuning.","The model delivers a 72.6% accuracy on the MedQA benchmark, outperforming the previous SOTA by 2.4%, and achieves 81.7% accuracy on the MMLU medical-subset, establishing itself as the first OS LLM to surpass 80% accuracy on this benchmark.","Our results highlight medical-specific emergent properties in OS LLMs which have not yet been documented to date elsewhere, and showcase the benefits of further leveraging prompt engineering to improve the performance of accessible LLMs for medical applications."],"url":"http://arxiv.org/abs/2402.19371v1"}
{"created":"2024-02-29 17:16:20","title":"Structure Preserving Diffusion Models","abstract":"Diffusion models have become the leading distribution-learning method in recent years. Herein, we introduce structure-preserving diffusion processes, a family of diffusion processes for learning distributions that possess additional structure, such as group symmetries, by developing theoretical conditions under which the diffusion transition steps preserve said symmetry. While also enabling equivariant data sampling trajectories, we exemplify these results by developing a collection of different symmetry equivariant diffusion models capable of learning distributions that are inherently symmetric. Empirical studies, over both synthetic and real-world datasets, are used to validate the developed models adhere to the proposed theory and are capable of achieving improved performance over existing methods in terms of sample equality. We also show how the proposed models can be used to achieve theoretically guaranteed equivariant image noise reduction without prior knowledge of the image orientation.","sentences":["Diffusion models have become the leading distribution-learning method in recent years.","Herein, we introduce structure-preserving diffusion processes, a family of diffusion processes for learning distributions that possess additional structure, such as group symmetries, by developing theoretical conditions under which the diffusion transition steps preserve said symmetry.","While also enabling equivariant data sampling trajectories, we exemplify these results by developing a collection of different symmetry equivariant diffusion models capable of learning distributions that are inherently symmetric.","Empirical studies, over both synthetic and real-world datasets, are used to validate the developed models adhere to the proposed theory and are capable of achieving improved performance over existing methods in terms of sample equality.","We also show how the proposed models can be used to achieve theoretically guaranteed equivariant image noise reduction without prior knowledge of the image orientation."],"url":"http://arxiv.org/abs/2402.19369v1"}
{"created":"2024-02-29 17:13:44","title":"SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency","abstract":"The growing number of cases requiring digital forensic analysis raises concerns about law enforcement's ability to conduct investigations promptly. Consequently, this systemisation of knowledge paper delves into the potential and effectiveness of integrating Large Language Models (LLMs) into digital forensic investigation to address these challenges. A thorough literature review is undertaken, encompassing existing digital forensic models, tools, LLMs, deep learning techniques, and the utilisation of LLMs in investigations. The review identifies current challenges within existing digital forensic processes and explores both the obstacles and possibilities of incorporating LLMs. In conclusion, the study asserts that the adoption of LLMs in digital forensics, with appropriate constraints, holds the potential to enhance investigation efficiency, improve traceability, and alleviate technical and judicial barriers faced by law enforcement entities.","sentences":["The growing number of cases requiring digital forensic analysis raises concerns about law enforcement's ability to conduct investigations promptly.","Consequently, this systemisation of knowledge paper delves into the potential and effectiveness of integrating Large Language Models (LLMs) into digital forensic investigation to address these challenges.","A thorough literature review is undertaken, encompassing existing digital forensic models, tools, LLMs, deep learning techniques, and the utilisation of LLMs in investigations.","The review identifies current challenges within existing digital forensic processes and explores both the obstacles and possibilities of incorporating LLMs.","In conclusion, the study asserts that the adoption of LLMs in digital forensics, with appropriate constraints, holds the potential to enhance investigation efficiency, improve traceability, and alleviate technical and judicial barriers faced by law enforcement entities."],"url":"http://arxiv.org/abs/2402.19366v1"}
{"created":"2024-02-29 17:13:30","title":"On Efficient Computation of DiRe Committees","abstract":"Consider a committee election consisting of (i) a set of candidates who are divided into arbitrary groups each of size \\emph{at most} two and a diversity constraint that stipulates the selection of \\emph{at least} one candidate from each group and (ii) a set of voters who are divided into arbitrary populations each approving \\emph{at most} two candidates and a representation constraint that stipulates the selection of \\emph{at least} one candidate from each population who has a non-null set of approved candidates.   The DiRe (Diverse + Representative) committee feasibility problem (a.k.a. the minimum vertex cover problem on unweighted undirected graphs) concerns the determination of the smallest size committee that satisfies the given constraints. Here, for this problem, we discover an unconditional deterministic polynomial-time algorithm that is an amalgamation of maximum matching, breadth-first search, maximal matching, and local minimization.","sentences":["Consider a committee election consisting of (i) a set of candidates who are divided into arbitrary groups each of size \\emph{at most} two and a diversity constraint that stipulates the selection of \\emph{at least} one candidate from each group and (ii) a set of voters who are divided into arbitrary populations each approving \\emph{at most} two candidates and a representation constraint that stipulates the selection of \\emph{at least} one candidate from each population who has a non-null set of approved candidates.   ","The DiRe (Diverse + Representative) committee feasibility problem (a.k.a.","the minimum vertex cover problem on unweighted undirected graphs) concerns the determination of the smallest size committee that satisfies the given constraints.","Here, for this problem, we discover an unconditional deterministic polynomial-time algorithm that is an amalgamation of maximum matching, breadth-first search, maximal matching, and local minimization."],"url":"http://arxiv.org/abs/2402.19365v1"}
{"created":"2024-02-29 17:13:25","title":"Arrow Matrix Decomposition: A Novel Approach for Communication-Efficient Sparse Matrix Multiplication","abstract":"We propose a novel approach to iterated sparse matrix dense matrix multiplication, a fundamental computational kernel in scientific computing and graph neural network training. In cases where matrix sizes exceed the memory of a single compute node, data transfer becomes a bottleneck. An approach based on dense matrix multiplication algorithms leads to suboptimal scalability and fails to exploit the sparsity in the problem. To address these challenges, we propose decomposing the sparse matrix into a small number of highly structured matrices called arrow matrices, which are connected by permutations. Our approach enables communication-avoiding multiplications, achieving a polynomial reduction in communication volume per iteration for matrices corresponding to planar graphs and other minor-excluded families of graphs. Our evaluation demonstrates that our approach outperforms a state-of-the-art method for sparse matrix multiplication on matrices with hundreds of millions of rows, offering near-linear strong and weak scaling.","sentences":["We propose a novel approach to iterated sparse matrix dense matrix multiplication, a fundamental computational kernel in scientific computing and graph neural network training.","In cases where matrix sizes exceed the memory of a single compute node, data transfer becomes a bottleneck.","An approach based on dense matrix multiplication algorithms leads to suboptimal scalability and fails to exploit the sparsity in the problem.","To address these challenges, we propose decomposing the sparse matrix into a small number of highly structured matrices called arrow matrices, which are connected by permutations.","Our approach enables communication-avoiding multiplications, achieving a polynomial reduction in communication volume per iteration for matrices corresponding to planar graphs and other minor-excluded families of graphs.","Our evaluation demonstrates that our approach outperforms a state-of-the-art method for sparse matrix multiplication on matrices with hundreds of millions of rows, offering near-linear strong and weak scaling."],"url":"http://arxiv.org/abs/2402.19364v1"}
{"created":"2024-02-29 17:12:39","title":"Watermark Stealing in Large Language Models","abstract":"LLM watermarking has attracted attention as a promising way to detect AI-generated content, with some works suggesting that current schemes may already be fit for deployment. In this work we dispute this claim, identifying watermark stealing (WS) as a fundamental vulnerability of these schemes. We show that querying the API of the watermarked LLM to approximately reverse-engineer a watermark enables practical spoofing attacks, as suggested in prior work, but also greatly boosts scrubbing attacks, which was previously unnoticed. We are the first to propose an automated WS algorithm and use it in the first comprehensive study of spoofing and scrubbing in realistic settings. We show that for under $50 an attacker can both spoof and scrub state-of-the-art schemes previously considered safe, with average success rate of over 80%. Our findings challenge common beliefs about LLM watermarking, stressing the need for more robust schemes. We make all our code and additional examples available at https://watermark-stealing.org.","sentences":["LLM watermarking has attracted attention as a promising way to detect AI-generated content, with some works suggesting that current schemes may already be fit for deployment.","In this work we dispute this claim, identifying watermark stealing (WS) as a fundamental vulnerability of these schemes.","We show that querying the API of the watermarked LLM to approximately reverse-engineer a watermark enables practical spoofing attacks, as suggested in prior work, but also greatly boosts scrubbing attacks, which was previously unnoticed.","We are the first to propose an automated WS algorithm and use it in the first comprehensive study of spoofing and scrubbing in realistic settings.","We show that for under $50 an attacker can both spoof and scrub state-of-the-art schemes previously considered safe, with average success rate of over 80%.","Our findings challenge common beliefs about LLM watermarking, stressing the need for more robust schemes.","We make all our code and additional examples available at https://watermark-stealing.org."],"url":"http://arxiv.org/abs/2402.19361v1"}
{"created":"2024-02-29 17:06:52","title":"Unraveling Adversarial Examples against Speaker Identification -- Techniques for Attack Detection and Victim Model Classification","abstract":"Adversarial examples have proven to threaten speaker identification systems, and several countermeasures against them have been proposed. In this paper, we propose a method to detect the presence of adversarial examples, i.e., a binary classifier distinguishing between benign and adversarial examples. We build upon and extend previous work on attack type classification by exploring new architectures. Additionally, we introduce a method for identifying the victim model on which the adversarial attack is carried out. To achieve this, we generate a new dataset containing multiple attacks performed against various victim models. We achieve an AUC of 0.982 for attack detection, with no more than a 0.03 drop in performance for unknown attacks. Our attack classification accuracy (excluding benign) reaches 86.48% across eight attack types using our LightResNet34 architecture, while our victim model classification accuracy reaches 72.28% across four victim models.","sentences":["Adversarial examples have proven to threaten speaker identification systems, and several countermeasures against them have been proposed.","In this paper, we propose a method to detect the presence of adversarial examples, i.e., a binary classifier distinguishing between benign and adversarial examples.","We build upon and extend previous work on attack type classification by exploring new architectures.","Additionally, we introduce a method for identifying the victim model on which the adversarial attack is carried out.","To achieve this, we generate a new dataset containing multiple attacks performed against various victim models.","We achieve an AUC of 0.982 for attack detection, with no more than a 0.03 drop in performance for unknown attacks.","Our attack classification accuracy (excluding benign) reaches 86.48% across eight attack types using our LightResNet34 architecture, while our victim model classification accuracy reaches 72.28% across four victim models."],"url":"http://arxiv.org/abs/2402.19355v1"}
{"created":"2024-02-29 16:56:36","title":"Prompting Explicit and Implicit Knowledge for Multi-hop Question Answering Based on Human Reading Process","abstract":"Pre-trained language models (PLMs) leverage chains-of-thought (CoT) to simulate human reasoning and inference processes, achieving proficient performance in multi-hop QA. However, a gap persists between PLMs' reasoning abilities and those of humans when tackling complex problems. Psychological studies suggest a vital connection between explicit information in passages and human prior knowledge during reading. Nevertheless, current research has given insufficient attention to linking input passages and PLMs' pre-training-based knowledge from the perspective of human cognition studies. In this study, we introduce a \\textbf{P}rompting \\textbf{E}xplicit and \\textbf{I}mplicit knowledge (PEI) framework, which uses prompts to connect explicit and implicit knowledge, aligning with human reading process for multi-hop QA. We consider the input passages as explicit knowledge, employing them to elicit implicit knowledge through unified prompt reasoning. Furthermore, our model incorporates type-specific reasoning via prompts, a form of implicit knowledge. Experimental results show that PEI performs comparably to the state-of-the-art on HotpotQA. Ablation studies confirm the efficacy of our model in bridging and integrating explicit and implicit knowledge.","sentences":["Pre-trained language models (PLMs) leverage chains-of-thought (CoT) to simulate human reasoning and inference processes, achieving proficient performance in multi-hop QA.","However, a gap persists between PLMs' reasoning abilities and those of humans when tackling complex problems.","Psychological studies suggest a vital connection between explicit information in passages and human prior knowledge during reading.","Nevertheless, current research has given insufficient attention to linking input passages and PLMs' pre-training-based knowledge from the perspective of human cognition studies.","In this study, we introduce a \\textbf{P}rompting \\textbf{E}xplicit and \\textbf{I}mplicit knowledge (PEI) framework, which uses prompts to connect explicit and implicit knowledge, aligning with human reading process for multi-hop QA.","We consider the input passages as explicit knowledge, employing them to elicit implicit knowledge through unified prompt reasoning.","Furthermore, our model incorporates type-specific reasoning via prompts, a form of implicit knowledge.","Experimental results show that PEI performs comparably to the state-of-the-art on HotpotQA.","Ablation studies confirm the efficacy of our model in bridging and integrating explicit and implicit knowledge."],"url":"http://arxiv.org/abs/2402.19350v1"}
{"created":"2024-02-29 16:56:23","title":"Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook","abstract":"As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities). Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities. To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing. Specifically, we first delve into data perspective to comprehend the role of each modality and data source. Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods. Thirdly, we further categorize multi-modal urban applications into seven types: urban planning, transportation, economy, public safety, society, environment, and energy. Compared with previous surveys, we focus more on the synergy of deep learning methods with urban computing applications. Furthermore, we shed light on the interplay between Large Language Models (LLMs) and urban computing, postulating future research directions that could revolutionize the field. We firmly believe that the taxonomy, progress, and prospects delineated in our survey stand poised to significantly enrich the research community. The summary of the comprehensive and up-to-date paper list can be found at https://github.com/yoshall/Awesome-Multimodal-Urban-Computing.","sentences":["As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities).","Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities.","To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing.","Specifically, we first delve into data perspective to comprehend the role of each modality and data source.","Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods.","Thirdly, we further categorize multi-modal urban applications into seven types: urban planning, transportation, economy, public safety, society, environment, and energy.","Compared with previous surveys, we focus more on the synergy of deep learning methods with urban computing applications.","Furthermore, we shed light on the interplay between Large Language Models (LLMs) and urban computing, postulating future research directions that could revolutionize the field.","We firmly believe that the taxonomy, progress, and prospects delineated in our survey stand poised to significantly enrich the research community.","The summary of the comprehensive and up-to-date paper list can be found at https://github.com/yoshall/Awesome-Multimodal-Urban-Computing."],"url":"http://arxiv.org/abs/2402.19348v1"}
{"created":"2024-02-29 16:55:44","title":"#PoetsOfInstagram: Navigating The Practices And Challenges Of Novice Poets On Instagram","abstract":"Commencing as a photo-sharing platform, Instagram has since become multifaceted, accommodating diverse art forms, with poetry emerging as a prominent one. However, the academic understanding of Instagram's poetry community is limited, yet its significance emerges from its distinctive utilization of a primarily visual social media platform guided by recommendation algorithms for disseminating poetry, further characterized by a predominantly novice creative population. We employ qualitative analysis to explore motivations, experiences, and algorithmic influence within Instagram's poetry community. We demonstrate that participants prioritize conforming to algorithmic constraints for visibility, yet maintain their community's values of integrity and originality, illustrating the tension between algorithmic growth and participant authenticity. We introduce the concept of Algorithmically Mediated Creative Labor, a phenomenon specific to non-monetizing creative users who are impacted by the prioritization of professional creators and continually adapt their creative endeavors to align with platform logic, thereby affecting their motivation and creative outputs.","sentences":["Commencing as a photo-sharing platform, Instagram has since become multifaceted, accommodating diverse art forms, with poetry emerging as a prominent one.","However, the academic understanding of Instagram's poetry community is limited, yet its significance emerges from its distinctive utilization of a primarily visual social media platform guided by recommendation algorithms for disseminating poetry, further characterized by a predominantly novice creative population.","We employ qualitative analysis to explore motivations, experiences, and algorithmic influence within Instagram's poetry community.","We demonstrate that participants prioritize conforming to algorithmic constraints for visibility, yet maintain their community's values of integrity and originality, illustrating the tension between algorithmic growth and participant authenticity.","We introduce the concept of Algorithmically Mediated Creative Labor, a phenomenon specific to non-monetizing creative users who are impacted by the prioritization of professional creators and continually adapt their creative endeavors to align with platform logic, thereby affecting their motivation and creative outputs."],"url":"http://arxiv.org/abs/2402.19347v1"}
{"created":"2024-02-29 16:49:38","title":"The 6th Affective Behavior Analysis in-the-wild (ABAW) Competition","abstract":"This paper describes the 6th Affective Behavior Analysis in-the-wild (ABAW) Competition, which is part of the respective Workshop held in conjunction with IEEE CVPR 2024. The 6th ABAW Competition addresses contemporary challenges in understanding human emotions and behaviors, crucial for the development of human-centered technologies. In more detail, the Competition focuses on affect related benchmarking tasks and comprises of five sub-challenges: i) Valence-Arousal Estimation (the target is to estimate two continuous affect dimensions, valence and arousal), ii) Expression Recognition (the target is to recognise between the mutually exclusive classes of the 7 basic expressions and 'other'), iii) Action Unit Detection (the target is to detect 12 action units), iv) Compound Expression Recognition (the target is to recognise between the 7 mutually exclusive compound expression classes), and v) Emotional Mimicry Intensity Estimation (the target is to estimate six continuous emotion dimensions). In the paper, we present these Challenges, describe their respective datasets and challenge protocols (we outline the evaluation metrics) and present the baseline systems as well as their obtained performance. More information for the Competition can be found in: \\url{https://affective-behavior-analysis-in-the-wild.github.io/6th}.","sentences":["This paper describes the 6th Affective Behavior Analysis in-the-wild (ABAW) Competition, which is part of the respective Workshop held in conjunction with IEEE CVPR 2024.","The 6th ABAW Competition addresses contemporary challenges in understanding human emotions and behaviors, crucial for the development of human-centered technologies.","In more detail, the Competition focuses on affect related benchmarking tasks and comprises of five sub-challenges: i) Valence-Arousal Estimation (the target is to estimate two continuous affect dimensions, valence and arousal), ii) Expression Recognition (the target is to recognise between the mutually exclusive classes of the 7 basic expressions and 'other'), iii) Action Unit Detection (the target is to detect 12 action units), iv) Compound Expression Recognition (the target is to recognise between the 7 mutually exclusive compound expression classes), and v) Emotional Mimicry Intensity Estimation (the target is to estimate six continuous emotion dimensions).","In the paper, we present these Challenges, describe their respective datasets and challenge protocols (we outline the evaluation metrics) and present the baseline systems as well as their obtained performance.","More information for the Competition can be found in: \\url{https://affective-behavior-analysis-in-the-wild.github.io/6th}."],"url":"http://arxiv.org/abs/2402.19344v1"}
{"created":"2024-02-29 16:47:54","title":"RoadRunner -- Learning Traversability Estimation for Autonomous Off-road Driving","abstract":"Autonomous navigation at high speeds in off-road environments necessitates robots to comprehensively understand their surroundings using onboard sensing only. The extreme conditions posed by the off-road setting can cause degraded camera image quality due to poor lighting and motion blur, as well as limited sparse geometric information available from LiDAR sensing when driving at high speeds. In this work, we present RoadRunner, a novel framework capable of predicting terrain traversability and an elevation map directly from camera and LiDAR sensor inputs. RoadRunner enables reliable autonomous navigation, by fusing sensory information, handling of uncertainty, and generation of contextually informed predictions about the geometry and traversability of the terrain while operating at low latency. In contrast to existing methods relying on classifying handcrafted semantic classes and using heuristics to predict traversability costs, our method is trained end-to-end in a self-supervised fashion. The RoadRunner network architecture builds upon popular sensor fusion network architectures from the autonomous driving domain, which embed LiDAR and camera information into a common Bird's Eye View perspective. Training is enabled by utilizing an existing traversability estimation stack to generate training data in hindsight in a scalable manner from real-world off-road driving datasets. Furthermore, RoadRunner improves the system latency by a factor of roughly 4, from 500 ms to 140 ms, while improving the accuracy for traversability costs and elevation map predictions. We demonstrate the effectiveness of RoadRunner in enabling safe and reliable off-road navigation at high speeds in multiple real-world driving scenarios through unstructured desert environments.","sentences":["Autonomous navigation at high speeds in off-road environments necessitates robots to comprehensively understand their surroundings using onboard sensing only.","The extreme conditions posed by the off-road setting can cause degraded camera image quality due to poor lighting and motion blur, as well as limited sparse geometric information available from LiDAR sensing when driving at high speeds.","In this work, we present RoadRunner, a novel framework capable of predicting terrain traversability and an elevation map directly from camera and LiDAR sensor inputs.","RoadRunner enables reliable autonomous navigation, by fusing sensory information, handling of uncertainty, and generation of contextually informed predictions about the geometry and traversability of the terrain while operating at low latency.","In contrast to existing methods relying on classifying handcrafted semantic classes and using heuristics to predict traversability costs, our method is trained end-to-end in a self-supervised fashion.","The RoadRunner network architecture builds upon popular sensor fusion network architectures from the autonomous driving domain, which embed LiDAR and camera information into a common Bird's Eye View perspective.","Training is enabled by utilizing an existing traversability estimation stack to generate training data in hindsight in a scalable manner from real-world off-road driving datasets.","Furthermore, RoadRunner improves the system latency by a factor of roughly 4, from 500 ms to 140 ms, while improving the accuracy for traversability costs and elevation map predictions.","We demonstrate the effectiveness of RoadRunner in enabling safe and reliable off-road navigation at high speeds in multiple real-world driving scenarios through unstructured desert environments."],"url":"http://arxiv.org/abs/2402.19341v1"}
{"created":"2024-02-29 16:46:49","title":"One model to use them all: Training a segmentation model with complementary datasets","abstract":"Understanding a surgical scene is crucial for computer-assisted surgery systems to provide any intelligent assistance functionality. One way of achieving this scene understanding is via scene segmentation, where every pixel of a frame is classified and therefore identifies the visible structures and tissues. Progress on fully segmenting surgical scenes has been made using machine learning. However, such models require large amounts of annotated training data, containing examples of all relevant object classes. Such fully annotated datasets are hard to create, as every pixel in a frame needs to be annotated by medical experts and, therefore, are rarely available. In this work, we propose a method to combine multiple partially annotated datasets, which provide complementary annotations, into one model, enabling better scene segmentation and the use of multiple readily available datasets. Our method aims to combine available data with complementary labels by leveraging mutual exclusive properties to maximize information. Specifically, we propose to use positive annotations of other classes as negative samples and to exclude background pixels of binary annotations, as we cannot tell if they contain a class not annotated but predicted by the model. We evaluate our method by training a DeepLabV3 on the publicly available Dresden Surgical Anatomy Dataset, which provides multiple subsets of binary segmented anatomical structures. Our approach successfully combines 6 classes into one model, increasing the overall Dice Score by 4.4% compared to an ensemble of models trained on the classes individually. By including information on multiple classes, we were able to reduce confusion between stomach and colon by 24%. Our results demonstrate the feasibility of training a model on multiple datasets. This paves the way for future work further alleviating the need for one large, fully segmented datasets.","sentences":["Understanding a surgical scene is crucial for computer-assisted surgery systems to provide any intelligent assistance functionality.","One way of achieving this scene understanding is via scene segmentation, where every pixel of a frame is classified and therefore identifies the visible structures and tissues.","Progress on fully segmenting surgical scenes has been made using machine learning.","However, such models require large amounts of annotated training data, containing examples of all relevant object classes.","Such fully annotated datasets are hard to create, as every pixel in a frame needs to be annotated by medical experts and, therefore, are rarely available.","In this work, we propose a method to combine multiple partially annotated datasets, which provide complementary annotations, into one model, enabling better scene segmentation and the use of multiple readily available datasets.","Our method aims to combine available data with complementary labels by leveraging mutual exclusive properties to maximize information.","Specifically, we propose to use positive annotations of other classes as negative samples and to exclude background pixels of binary annotations, as we cannot tell if they contain a class not annotated but predicted by the model.","We evaluate our method by training a DeepLabV3 on the publicly available Dresden Surgical Anatomy Dataset, which provides multiple subsets of binary segmented anatomical structures.","Our approach successfully combines 6 classes into one model, increasing the overall Dice Score by 4.4% compared to an ensemble of models trained on the classes individually.","By including information on multiple classes, we were able to reduce confusion between stomach and colon by 24%.","Our results demonstrate the feasibility of training a model on multiple datasets.","This paves the way for future work further alleviating the need for one large, fully segmented datasets."],"url":"http://arxiv.org/abs/2402.19340v1"}
{"created":"2024-02-29 16:46:48","title":"Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision Transformers for High-Level Image Classification","abstract":"The increasing demand for automatic high-level image understanding, particularly in detecting abstract concepts (AC) within images, underscores the necessity for innovative and more interpretable approaches. These approaches need to harmonize traditional deep vision methods with the nuanced, context-dependent knowledge humans employ to interpret images at intricate semantic levels. In this work, we leverage situated perceptual knowledge of cultural images to enhance performance and interpretability in AC image classification. We automatically extract perceptual semantic units from images, which we then model and integrate into the ARTstract Knowledge Graph (AKG). This resource captures situated perceptual semantics gleaned from over 14,000 cultural images labeled with ACs. Additionally, we enhance the AKG with high-level linguistic frames. We compute KG embeddings and experiment with relative representations and hybrid approaches that fuse these embeddings with visual transformer embeddings. Finally, for interpretability, we conduct posthoc qualitative analyses by examining model similarities with training instances. Our results show that our hybrid KGE-ViT methods outperform existing techniques in AC image classification. The posthoc interpretability analyses reveal the visual transformer's proficiency in capturing pixel-level visual attributes, contrasting with our method's efficacy in representing more abstract and semantic scene elements. We demonstrate the synergy and complementarity between KGE embeddings' situated perceptual knowledge and deep visual model's sensory-perceptual understanding for AC image classification. This work suggests a strong potential of neuro-symbolic methods for knowledge integration and robust image representation for use in downstream intricate visual comprehension tasks. All the materials and code are available online.","sentences":["The increasing demand for automatic high-level image understanding, particularly in detecting abstract concepts (AC) within images, underscores the necessity for innovative and more interpretable approaches.","These approaches need to harmonize traditional deep vision methods with the nuanced, context-dependent knowledge humans employ to interpret images at intricate semantic levels.","In this work, we leverage situated perceptual knowledge of cultural images to enhance performance and interpretability in AC image classification.","We automatically extract perceptual semantic units from images, which we then model and integrate into the ARTstract Knowledge Graph (AKG).","This resource captures situated perceptual semantics gleaned from over 14,000 cultural images labeled with ACs.","Additionally, we enhance the AKG with high-level linguistic frames.","We compute KG embeddings and experiment with relative representations and hybrid approaches that fuse these embeddings with visual transformer embeddings.","Finally, for interpretability, we conduct posthoc qualitative analyses by examining model similarities with training instances.","Our results show that our hybrid KGE-ViT methods outperform existing techniques in AC image classification.","The posthoc interpretability analyses reveal the visual transformer's proficiency in capturing pixel-level visual attributes, contrasting with our method's efficacy in representing more abstract and semantic scene elements.","We demonstrate the synergy and complementarity between KGE embeddings' situated perceptual knowledge and deep visual model's sensory-perceptual understanding for AC image classification.","This work suggests a strong potential of neuro-symbolic methods for knowledge integration and robust image representation for use in downstream intricate visual comprehension tasks.","All the materials and code are available online."],"url":"http://arxiv.org/abs/2402.19339v1"}
{"created":"2024-02-29 16:37:08","title":"Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge","abstract":"The democratization of pre-trained language models through open-source initiatives has rapidly advanced innovation and expanded access to cutting-edge technologies. However, this openness also brings significant security risks, including backdoor attacks, where hidden malicious behaviors are triggered by specific inputs, compromising natural language processing (NLP) system integrity and reliability. This paper suggests that merging a backdoored model with other homogeneous models can remediate backdoor vulnerabilities even if such models are not entirely secure. In our experiments, we explore various models (BERT-Base, RoBERTa-Large, Llama2-7B, and Mistral-7B) and datasets (SST-2, OLID, AG News, and QNLI). Compared to multiple advanced defensive approaches, our method offers an effective and efficient inference-stage defense against backdoor attacks without additional resources or specific knowledge. Our approach consistently outperforms the other advanced baselines, leading to an average of 75% reduction in the attack success rate. Since model merging has been an established approach for improving model performance, the extra advantage it provides regarding defense can be seen as a cost-free bonus.","sentences":["The democratization of pre-trained language models through open-source initiatives has rapidly advanced innovation and expanded access to cutting-edge technologies.","However, this openness also brings significant security risks, including backdoor attacks, where hidden malicious behaviors are triggered by specific inputs, compromising natural language processing (NLP) system integrity and reliability.","This paper suggests that merging a backdoored model with other homogeneous models can remediate backdoor vulnerabilities even if such models are not entirely secure.","In our experiments, we explore various models (BERT-Base, RoBERTa-Large, Llama2-7B, and Mistral-7B) and datasets (SST-2, OLID, AG News, and QNLI).","Compared to multiple advanced defensive approaches, our method offers an effective and efficient inference-stage defense against backdoor attacks without additional resources or specific knowledge.","Our approach consistently outperforms the other advanced baselines, leading to an average of 75% reduction in the attack success rate.","Since model merging has been an established approach for improving model performance, the extra advantage it provides regarding defense can be seen as a cost-free bonus."],"url":"http://arxiv.org/abs/2402.19334v1"}
{"created":"2024-02-29 16:36:51","title":"Compact Speech Translation Models via Discrete Speech Units Pretraining","abstract":"Using Self-Supervised Learning (SSL) as model initialization is now common to obtain strong results in Speech Translation (ST). However, they also impose a large memory footprint, hindering on-device deployment. In this paper, we leverage the SSL models by pretraining smaller models on their Discrete Speech Units (DSU). We pretrain encoder-decoder models on 1) Filterbank-to-DSU and 2) DSU-to-Translation data, and take the encoder from 1) and the decoder from 2) to initialise a new model, finetuning this on limited speech-translation data. The final model becomes compact by using the DSU pretraining to distil the knowledge of the SSL model. Our method has several benefits over using DSU as model inputs, such as shorter inference pipeline and robustness over (DSU) tokenization. In contrast to ASR pretraining, it does not require transcripts, making it applicable to low-resource settings. Evaluation on CoVoST-2 X-En shows that our method is >$0.5$ BLEU better than a ST model that directly finetune the SSL model, given only half the model size, and on a par with ASR pretraining.","sentences":["Using Self-Supervised Learning (SSL) as model initialization is now common to obtain strong results in Speech Translation (ST).","However, they also impose a large memory footprint, hindering on-device deployment.","In this paper, we leverage the SSL models by pretraining smaller models on their Discrete Speech Units (DSU).","We pretrain encoder-decoder models on 1) Filterbank-to-DSU and 2) DSU-to-Translation data, and take the encoder from 1) and the decoder from 2) to initialise a new model, finetuning this on limited speech-translation data.","The final model becomes compact by using the DSU pretraining to distil the knowledge of the SSL model.","Our method has several benefits over using DSU as model inputs, such as shorter inference pipeline and robustness over (DSU) tokenization.","In contrast to ASR pretraining, it does not require transcripts, making it applicable to low-resource settings.","Evaluation on CoVoST-2 X-En shows that our method is >$0.5$ BLEU better than a ST model that directly finetune the SSL model, given only half the model size, and on a par with ASR pretraining."],"url":"http://arxiv.org/abs/2402.19333v1"}
{"created":"2024-02-29 16:33:12","title":"A Novel Approach to Industrial Defect Generation through Blended Latent Diffusion Model with Online Adaptation","abstract":"Effectively addressing the challenge of industrial Anomaly Detection (AD) necessitates an ample supply of defective samples, a constraint often hindered by their scarcity in industrial contexts. This paper introduces a novel algorithm designed to augment defective samples, thereby enhancing AD performance. The proposed method tailors the blended latent diffusion model for defect sample generation, employing a diffusion model to generate defective samples in the latent space. A feature editing process, controlled by a \"trimap\" mask and text prompts, refines the generated samples. The image generation inference process is structured into three stages: a free diffusion stage, an editing diffusion stage, and an online decoder adaptation stage. This sophisticated inference strategy yields high-quality synthetic defective samples with diverse pattern variations, leading to significantly improved AD accuracies based on the augmented training set. Specifically, on the widely recognized MVTec AD dataset, the proposed method elevates the state-of-the-art (SOTA) performance of AD with augmented data by 1.5%, 1.9%, and 3.1% for AD metrics AP, IAP, and IAP90, respectively. The implementation code of this work can be found at the GitHub repository https://github.com/GrandpaXun242/AdaBLDM.git","sentences":["Effectively addressing the challenge of industrial Anomaly Detection (AD) necessitates an ample supply of defective samples, a constraint often hindered by their scarcity in industrial contexts.","This paper introduces a novel algorithm designed to augment defective samples, thereby enhancing AD performance.","The proposed method tailors the blended latent diffusion model for defect sample generation, employing a diffusion model to generate defective samples in the latent space.","A feature editing process, controlled by a \"trimap\" mask and text prompts, refines the generated samples.","The image generation inference process is structured into three stages: a free diffusion stage, an editing diffusion stage, and an online decoder adaptation stage.","This sophisticated inference strategy yields high-quality synthetic defective samples with diverse pattern variations, leading to significantly improved AD accuracies based on the augmented training set.","Specifically, on the widely recognized MVTec AD dataset, the proposed method elevates the state-of-the-art (SOTA) performance of AD with augmented data by 1.5%, 1.9%, and 3.1% for AD metrics AP, IAP, and IAP90, respectively.","The implementation code of this work can be found at the GitHub repository https://github.com/GrandpaXun242/AdaBLDM.git"],"url":"http://arxiv.org/abs/2402.19330v1"}
{"created":"2024-02-29 16:30:07","title":"Seeking Soulmate via Voice: Understanding Promises and Challenges of Online Synchronized Voice-Based Mobile Dating","abstract":"Online dating has become a popular way for individuals to connect with potential romantic partners. Many dating apps use personal profiles that include a headshot and self-description, allowing users to present themselves and search for compatible matches. However, this traditional model often has limitations. In this study, we explore a non-traditional voice-based dating app called \"Soul\". Unlike traditional platforms that rely heavily on profile information, Soul facilitates user interactions through voice-based communication. We conducted semi-structured interviews with 18 dedicated Soul users to investigate how they engage with the platform and perceive themselves and others in this unique dating environment. Our findings indicate that the role of voice as a moderator influences impression management and shapes perceptions between the sender and the receiver of the voice. Additionally, the synchronous voice-based and community-based dating model offers benefits to users in the Chinese cultural context. Our study contributes to understanding the affordances introduced by voice-based interactions in online dating in China.","sentences":["Online dating has become a popular way for individuals to connect with potential romantic partners.","Many dating apps use personal profiles that include a headshot and self-description, allowing users to present themselves and search for compatible matches.","However, this traditional model often has limitations.","In this study, we explore a non-traditional voice-based dating app called \"Soul\".","Unlike traditional platforms that rely heavily on profile information, Soul facilitates user interactions through voice-based communication.","We conducted semi-structured interviews with 18 dedicated Soul users to investigate how they engage with the platform and perceive themselves and others in this unique dating environment.","Our findings indicate that the role of voice as a moderator influences impression management and shapes perceptions between the sender and the receiver of the voice.","Additionally, the synchronous voice-based and community-based dating model offers benefits to users in the Chinese cultural context.","Our study contributes to understanding the affordances introduced by voice-based interactions in online dating in China."],"url":"http://arxiv.org/abs/2402.19328v1"}
{"created":"2024-02-29 16:29:53","title":"Generalizable Whole Slide Image Classification with Fine-Grained Visual-Semantic Interaction","abstract":"Whole Slide Image (WSI) classification is often formulated as a Multiple Instance Learning (MIL) problem. Recently, Vision-Language Models (VLMs) have demonstrated remarkable performance in WSI classification. However, existing methods leverage coarse-grained pathogenetic descriptions for visual representation supervision, which are insufficient to capture the complex visual appearance of pathogenetic images, hindering the generalizability of models on diverse downstream tasks. Additionally, processing high-resolution WSIs can be computationally expensive. In this paper, we propose a novel \"Fine-grained Visual-Semantic Interaction\" (FiVE) framework for WSI classification. It is designed to enhance the model's generalizability by leveraging the interplay between localized visual patterns and fine-grained pathological semantics. Specifically, with meticulously designed queries, we start by utilizing a large language model to extract fine-grained pathological descriptions from various non-standardized raw reports. The output descriptions are then reconstructed into fine-grained labels used for training. By introducing a Task-specific Fine-grained Semantics (TFS) module, we enable prompts to capture crucial visual information in WSIs, which enhances representation learning and augments generalization capabilities significantly. Furthermore, given that pathological visual patterns are redundantly distributed across tissue slices, we sample a subset of visual instances during training. Our method demonstrates robust generalizability and strong transferability, dominantly outperforming the counterparts on the TCGA Lung Cancer dataset with at least 9.19% higher accuracy in few-shot experiments.","sentences":["Whole Slide Image (WSI) classification is often formulated as a Multiple Instance Learning (MIL) problem.","Recently, Vision-Language Models (VLMs) have demonstrated remarkable performance in WSI classification.","However, existing methods leverage coarse-grained pathogenetic descriptions for visual representation supervision, which are insufficient to capture the complex visual appearance of pathogenetic images, hindering the generalizability of models on diverse downstream tasks.","Additionally, processing high-resolution WSIs can be computationally expensive.","In this paper, we propose a novel \"Fine-grained Visual-Semantic Interaction\" (FiVE) framework for WSI classification.","It is designed to enhance the model's generalizability by leveraging the interplay between localized visual patterns and fine-grained pathological semantics.","Specifically, with meticulously designed queries, we start by utilizing a large language model to extract fine-grained pathological descriptions from various non-standardized raw reports.","The output descriptions are then reconstructed into fine-grained labels used for training.","By introducing a Task-specific Fine-grained Semantics (TFS) module, we enable prompts to capture crucial visual information in WSIs, which enhances representation learning and augments generalization capabilities significantly.","Furthermore, given that pathological visual patterns are redundantly distributed across tissue slices, we sample a subset of visual instances during training.","Our method demonstrates robust generalizability and strong transferability, dominantly outperforming the counterparts on the TCGA Lung Cancer dataset with at least 9.19% higher accuracy in few-shot experiments."],"url":"http://arxiv.org/abs/2402.19326v1"}
{"created":"2024-02-29 16:28:58","title":"Do End-to-End Neural Diarization Attractors Need to Encode Speaker Characteristic Information?","abstract":"In this paper, we apply the variational information bottleneck approach to end-to-end neural diarization with encoder-decoder attractors (EEND-EDA). This allows us to investigate what information is essential for the model. EEND-EDA utilizes vector representations of the speakers in a conversation - attractors. Our analysis shows that, attractors do not necessarily have to contain speaker characteristic information. On the other hand, giving the attractors more freedom allowing them to encode some extra (possibly speaker-specific) information leads to small but consistent diarization performance improvements. Despite architectural differences in EEND systems, the notion of attractors and frame embeddings is common to most of them and not specific to EEND-EDA. We believe that the main conclusions of this work can apply to other variants of EEND. Thus, we hope this paper will be a valuable contribution to guide the community to make more informed decisions when designing new systems.","sentences":["In this paper, we apply the variational information bottleneck approach to end-to-end neural diarization with encoder-decoder attractors (EEND-EDA).","This allows us to investigate what information is essential for the model.","EEND-EDA utilizes vector representations of the speakers in a conversation - attractors.","Our analysis shows that, attractors do not necessarily have to contain speaker characteristic information.","On the other hand, giving the attractors more freedom allowing them to encode some extra (possibly speaker-specific) information leads to small but consistent diarization performance improvements.","Despite architectural differences in EEND systems, the notion of attractors and frame embeddings is common to most of them and not specific to EEND-EDA.","We believe that the main conclusions of this work can apply to other variants of EEND.","Thus, we hope this paper will be a valuable contribution to guide the community to make more informed decisions when designing new systems."],"url":"http://arxiv.org/abs/2402.19325v1"}
{"created":"2024-02-29 16:27:59","title":"Verification of Neural Networks' Global Robustness","abstract":"Neural networks are successful in various applications but are also susceptible to adversarial attacks. To show the safety of network classifiers, many verifiers have been introduced to reason about the local robustness of a given input to a given perturbation. While successful, local robustness cannot generalize to unseen inputs. Several works analyze global robustness properties, however, neither can provide a precise guarantee about the cases where a network classifier does not change its classification. In this work, we propose a new global robustness property for classifiers aiming at finding the minimal globally robust bound, which naturally extends the popular local robustness property for classifiers. We introduce VHAGaR, an anytime verifier for computing this bound. VHAGaR relies on three main ideas: encoding the problem as a mixed-integer programming and pruning the search space by identifying dependencies stemming from the perturbation or network computation and generalizing adversarial attacks to unknown inputs. We evaluate VHAGaR on several datasets and classifiers and show that, given a three hour timeout, the average gap between the lower and upper bound on the minimal globally robust bound computed by VHAGaR is 1.9, while the gap of an existing global robustness verifier is 154.7. Moreover, VHAGaR is 130.6x faster than this verifier. Our results further indicate that leveraging dependencies and adversarial attacks makes VHAGaR 78.6x faster.","sentences":["Neural networks are successful in various applications but are also susceptible to adversarial attacks.","To show the safety of network classifiers, many verifiers have been introduced to reason about the local robustness of a given input to a given perturbation.","While successful, local robustness cannot generalize to unseen inputs.","Several works analyze global robustness properties, however, neither can provide a precise guarantee about the cases where a network classifier does not change its classification.","In this work, we propose a new global robustness property for classifiers aiming at finding the minimal globally robust bound, which naturally extends the popular local robustness property for classifiers.","We introduce VHAGaR, an anytime verifier for computing this bound.","VHAGaR relies on three main ideas: encoding the problem as a mixed-integer programming and pruning the search space by identifying dependencies stemming from the perturbation or network computation and generalizing adversarial attacks to unknown inputs.","We evaluate VHAGaR on several datasets and classifiers and show that, given a three hour timeout, the average gap between the lower and upper bound on the minimal globally robust bound computed by VHAGaR is 1.9, while the gap of an existing global robustness verifier is 154.7.","Moreover, VHAGaR is 130.6x faster than this verifier.","Our results further indicate that leveraging dependencies and adversarial attacks makes VHAGaR 78.6x faster."],"url":"http://arxiv.org/abs/2402.19322v1"}
{"created":"2024-02-29 16:24:19","title":"Attacks Against Mobility Prediction in 5G Networks","abstract":"The $5^{th}$ generation of mobile networks introduces a new Network Function (NF) that was not present in previous generations, namely the Network Data Analytics Function (NWDAF). Its primary objective is to provide advanced analytics services to various entities within the network and also towards external application services in the 5G ecosystem. One of the key use cases of NWDAF is mobility trajectory prediction, which aims to accurately support efficient mobility management of User Equipment (UE) in the network by allocating ``just in time'' necessary network resources. In this paper, we show that there are potential mobility attacks that can compromise the accuracy of these predictions. In a semi-realistic scenario with 10,000 subscribers, we demonstrate that an adversary equipped with the ability to hijack cellular mobile devices and clone them can significantly reduce the prediction accuracy from 75\\% to 40\\% using just 100 adversarial UEs. While a defense mechanism largely depends on the attack and the mobility types in a particular area, we prove that a basic KMeans clustering is effective in distinguishing legitimate and adversarial UEs.","sentences":["The $5^{th}$ generation of mobile networks introduces a new Network Function (NF) that was not present in previous generations, namely the Network Data Analytics Function (NWDAF).","Its primary objective is to provide advanced analytics services to various entities within the network and also towards external application services in the 5G ecosystem.","One of the key use cases of NWDAF is mobility trajectory prediction, which aims to accurately support efficient mobility management of User Equipment (UE) in the network by allocating ``just in time'' necessary network resources.","In this paper, we show that there are potential mobility attacks that can compromise the accuracy of these predictions.","In a semi-realistic scenario with 10,000 subscribers, we demonstrate that an adversary equipped with the ability to hijack cellular mobile devices and clone them can significantly reduce the prediction accuracy from 75\\% to 40\\% using just 100 adversarial UEs.","While a defense mechanism largely depends on the attack and the mobility types in a particular area, we prove that a basic KMeans clustering is effective in distinguishing legitimate and adversarial UEs."],"url":"http://arxiv.org/abs/2402.19319v1"}
{"created":"2024-02-29 16:24:17","title":"DISCERN: Designing Decision Support Interfaces to Investigate the Complexities of Workplace Social Decision-Making With Line Managers","abstract":"Line managers form the first level of management in organizations, and must make complex decisions, while maintaining relationships with those impacted by their decisions. Amidst growing interest in technology-supported decision-making at work, their needs remain understudied. Further, most existing design knowledge for supporting social decision-making comes from domains where decision-makers are more socially detached from those they decide for. We conducted iterative design research with line managers within a technology organization, investigating decision-making practices, and opportunities for technological support. Through formative research, development of a decision-representation tool -- DISCERN -- and user enactments, we identify their communication and analysis needs that lack adequate support. We found they preferred tools for externalizing reasoning rather than tools that replace interpersonal interactions, and they wanted tools to support a range of intuitive and calculative decision-making. We discuss how design of social decision-making supports, especially in the workplace, can more explicitly support highly interactional social decision-making.","sentences":["Line managers form the first level of management in organizations, and must make complex decisions, while maintaining relationships with those impacted by their decisions.","Amidst growing interest in technology-supported decision-making at work, their needs remain understudied.","Further, most existing design knowledge for supporting social decision-making comes from domains where decision-makers are more socially detached from those they decide for.","We conducted iterative design research with line managers within a technology organization, investigating decision-making practices, and opportunities for technological support.","Through formative research, development of a decision-representation tool -- DISCERN -- and user enactments, we identify their communication and analysis needs that lack adequate support.","We found they preferred tools for externalizing reasoning rather than tools that replace interpersonal interactions, and they wanted tools to support a range of intuitive and calculative decision-making.","We discuss how design of social decision-making supports, especially in the workplace, can more explicitly support highly interactional social decision-making."],"url":"http://arxiv.org/abs/2402.19318v1"}
{"created":"2024-02-29 16:21:14","title":"On the Existence of Static Equilibria of a Cable-Suspended Load with Non-stopping Flying Carriers","abstract":"Aerial cooperative robotic manipulation of cable-suspended objects has been largely studied as it allows handling large and heavy objects, and cables offer multiple advantages, such as their low weight and cost efficiency. Multirotors have been typically considered, which, however, can be unsuitable for long-lasting manipulation tasks due to their scarce endurance. Hence, this work investigates whether non-stop flights are possible for maintaining constant the pose of cable-suspended objects. First, we show that one or two flying carriers alone cannot perform non-stop flights while maintaining a constant pose of the suspended object. Instead, we demonstrate that \\emph{three} flying carriers can achieve this task provided that the orientation of the load at the equilibrium is such that the components of the cable forces that balance the external force (typically gravity) do not belong to the plane of the cable anchoring points on the load. Numerical tests are presented in support of the analytical results.","sentences":["Aerial cooperative robotic manipulation of cable-suspended objects has been largely studied as it allows handling large and heavy objects, and cables offer multiple advantages, such as their low weight and cost efficiency.","Multirotors have been typically considered, which, however, can be unsuitable for long-lasting manipulation tasks due to their scarce endurance.","Hence, this work investigates whether non-stop flights are possible for maintaining constant the pose of cable-suspended objects.","First, we show that one or two flying carriers alone cannot perform non-stop flights while maintaining a constant pose of the suspended object.","Instead, we demonstrate that \\emph{three} flying carriers can achieve this task provided that the orientation of the load at the equilibrium is such that the components of the cable forces that balance the external force (typically gravity) do not belong to the plane of the cable anchoring points on the load.","Numerical tests are presented in support of the analytical results."],"url":"http://arxiv.org/abs/2402.19315v1"}
{"created":"2024-02-29 16:15:34","title":"Loss-Free Machine Unlearning","abstract":"We present a machine unlearning approach that is both retraining- and label-free. Most existing machine unlearning approaches require a model to be fine-tuned to remove information while preserving performance. This is computationally expensive and necessitates the storage of the whole dataset for the lifetime of the model. Retraining-free approaches often utilise Fisher information, which is derived from the loss and requires labelled data which may not be available. Thus, we present an extension to the Selective Synaptic Dampening algorithm, substituting the diagonal of the Fisher information matrix for the gradient of the l2 norm of the model output to approximate sensitivity. We evaluate our method in a range of experiments using ResNet18 and Vision Transformer. Results show our label-free method is competitive with existing state-of-the-art approaches.","sentences":["We present a machine unlearning approach that is both retraining- and label-free.","Most existing machine unlearning approaches require a model to be fine-tuned to remove information while preserving performance.","This is computationally expensive and necessitates the storage of the whole dataset for the lifetime of the model.","Retraining-free approaches often utilise Fisher information, which is derived from the loss and requires labelled data which may not be available.","Thus, we present an extension to the Selective Synaptic Dampening algorithm, substituting the diagonal of the Fisher information matrix for the gradient of the l2 norm of the model output to approximate sensitivity.","We evaluate our method in a range of experiments using ResNet18 and Vision Transformer.","Results show our label-free method is competitive with existing state-of-the-art approaches."],"url":"http://arxiv.org/abs/2402.19308v1"}
{"created":"2024-02-29 16:10:49","title":"HyenaPixel: Global Image Context with Convolutions","abstract":"In vision tasks, a larger effective receptive field (ERF) is associated with better performance. While attention natively supports global context, convolution requires multiple stacked layers and a hierarchical structure for large context. In this work, we extend Hyena, a convolution-based attention replacement, from causal sequences to the non-causal two-dimensional image space. We scale the Hyena convolution kernels beyond the feature map size up to 191$\\times$191 to maximize the ERF while maintaining sub-quadratic complexity in the number of pixels. We integrate our two-dimensional Hyena, HyenaPixel, and bidirectional Hyena into the MetaFormer framework. For image categorization, HyenaPixel and bidirectional Hyena achieve a competitive ImageNet-1k top-1 accuracy of 83.0% and 83.5%, respectively, while outperforming other large-kernel networks. Combining HyenaPixel with attention further increases accuracy to 83.6%. We attribute the success of attention to the lack of spatial bias in later stages and support this finding with bidirectional Hyena.","sentences":["In vision tasks, a larger effective receptive field (ERF) is associated with better performance.","While attention natively supports global context, convolution requires multiple stacked layers and a hierarchical structure for large context.","In this work, we extend Hyena, a convolution-based attention replacement, from causal sequences to the non-causal two-dimensional image space.","We scale the Hyena convolution kernels beyond the feature map size up to 191$\\times$191 to maximize the ERF while maintaining sub-quadratic complexity in the number of pixels.","We integrate our two-dimensional Hyena, HyenaPixel, and bidirectional Hyena into the MetaFormer framework.","For image categorization, HyenaPixel and bidirectional Hyena achieve a competitive ImageNet-1k top-1 accuracy of 83.0% and 83.5%, respectively, while outperforming other large-kernel networks.","Combining HyenaPixel with attention further increases accuracy to 83.6%.","We attribute the success of attention to the lack of spatial bias in later stages and support this finding with bidirectional Hyena."],"url":"http://arxiv.org/abs/2402.19305v1"}
{"created":"2024-02-29 16:09:19","title":"Learnability Gaps of Strategic Classification","abstract":"In contrast with standard classification tasks, strategic classification involves agents strategically modifying their features in an effort to receive favorable predictions. For instance, given a classifier determining loan approval based on credit scores, applicants may open or close their credit cards to fool the classifier. The learning goal is to find a classifier robust against strategic manipulations. Various settings, based on what and when information is known, have been explored in strategic classification. In this work, we focus on addressing a fundamental question: the learnability gaps between strategic classification and standard learning.   We essentially show that any learnable class is also strategically learnable: we first consider a fully informative setting, where the manipulation structure (which is modeled by a manipulation graph $G^\\star$) is known and during training time the learner has access to both the pre-manipulation data and post-manipulation data. We provide nearly tight sample complexity and regret bounds, offering significant improvements over prior results. Then, we relax the fully informative setting by introducing two natural types of uncertainty. First, following Ahmadi et al. (2023), we consider the setting in which the learner only has access to the post-manipulation data. We improve the results of Ahmadi et al. (2023) and close the gap between mistake upper bound and lower bound raised by them. Our second relaxation of the fully informative setting introduces uncertainty to the manipulation structure. That is, we assume that the manipulation graph is unknown but belongs to a known class of graphs. We provide nearly tight bounds on the learning complexity in various unknown manipulation graph settings. Notably, our algorithm in this setting is of independent interest and can be applied to other problems such as multi-label learning.","sentences":["In contrast with standard classification tasks, strategic classification involves agents strategically modifying their features in an effort to receive favorable predictions.","For instance, given a classifier determining loan approval based on credit scores, applicants may open or close their credit cards to fool the classifier.","The learning goal is to find a classifier robust against strategic manipulations.","Various settings, based on what and when information is known, have been explored in strategic classification.","In this work, we focus on addressing a fundamental question: the learnability gaps between strategic classification and standard learning.   ","We essentially show that any learnable class is also strategically learnable: we first consider a fully informative setting, where the manipulation structure (which is modeled by a manipulation graph $G^\\star$) is known and during training time the learner has access to both the pre-manipulation data and post-manipulation data.","We provide nearly tight sample complexity and regret bounds, offering significant improvements over prior results.","Then, we relax the fully informative setting by introducing two natural types of uncertainty.","First, following Ahmadi et al. (2023), we consider the setting in which the learner only has access to the post-manipulation data.","We improve the results of Ahmadi et al. (2023) and close the gap between mistake upper bound and lower bound raised by them.","Our second relaxation of the fully informative setting introduces uncertainty to the manipulation structure.","That is, we assume that the manipulation graph is unknown but belongs to a known class of graphs.","We provide nearly tight bounds on the learning complexity in various unknown manipulation graph settings.","Notably, our algorithm in this setting is of independent interest and can be applied to other problems such as multi-label learning."],"url":"http://arxiv.org/abs/2402.19303v1"}
{"created":"2024-02-29 16:09:12","title":"DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly","abstract":"Reassembly tasks play a fundamental role in many fields and multiple approaches exist to solve specific reassembly problems. In this context, we posit that a general unified model can effectively address them all, irrespective of the input data type (images, 3D, etc.). We introduce DiffAssemble, a Graph Neural Network (GNN)-based architecture that learns to solve reassembly tasks using a diffusion model formulation. Our method treats the elements of a set, whether pieces of 2D patch or 3D object fragments, as nodes of a spatial graph. Training is performed by introducing noise into the position and rotation of the elements and iteratively denoising them to reconstruct the coherent initial pose. DiffAssemble achieves state-of-the-art (SOTA) results in most 2D and 3D reassembly tasks and is the first learning-based approach that solves 2D puzzles for both rotation and translation. Furthermore, we highlight its remarkable reduction in run-time, performing 11 times faster than the quickest optimization-based method for puzzle solving. Code available at https://github.com/IIT-PAVIS/DiffAssemble","sentences":["Reassembly tasks play a fundamental role in many fields and multiple approaches exist to solve specific reassembly problems.","In this context, we posit that a general unified model can effectively address them all, irrespective of the input data type (images, 3D, etc.).","We introduce DiffAssemble, a Graph Neural Network (GNN)-based architecture that learns to solve reassembly tasks using a diffusion model formulation.","Our method treats the elements of a set, whether pieces of 2D patch or 3D object fragments, as nodes of a spatial graph.","Training is performed by introducing noise into the position and rotation of the elements and iteratively denoising them to reconstruct the coherent initial pose.","DiffAssemble achieves state-of-the-art (SOTA) results in most 2D and 3D reassembly tasks and is the first learning-based approach that solves 2D puzzles for both rotation and translation.","Furthermore, we highlight its remarkable reduction in run-time, performing 11 times faster than the quickest optimization-based method for puzzle solving.","Code available at https://github.com/IIT-PAVIS/DiffAssemble"],"url":"http://arxiv.org/abs/2402.19302v1"}
{"created":"2024-02-29 16:07:22","title":"RL-GPT: Integrating Reinforcement Learning and Code-as-policy","abstract":"Large Language Models (LLMs) have demonstrated proficiency in utilizing various tools by coding, yet they face limitations in handling intricate logic and precise control. In embodied tasks, high-level planning is amenable to direct coding, while low-level actions often necessitate task-specific refinement, such as Reinforcement Learning (RL). To seamlessly integrate both modalities, we introduce a two-level hierarchical framework, RL-GPT, comprising a slow agent and a fast agent. The slow agent analyzes actions suitable for coding, while the fast agent executes coding tasks. This decomposition effectively focuses each agent on specific tasks, proving highly efficient within our pipeline. Our approach outperforms traditional RL methods and existing GPT agents, demonstrating superior efficiency. In the Minecraft game, it rapidly obtains diamonds within a single day on an RTX3090. Additionally, it achieves SOTA performance across all designated MineDojo tasks.","sentences":["Large Language Models (LLMs) have demonstrated proficiency in utilizing various tools by coding, yet they face limitations in handling intricate logic and precise control.","In embodied tasks, high-level planning is amenable to direct coding, while low-level actions often necessitate task-specific refinement, such as Reinforcement Learning (RL).","To seamlessly integrate both modalities, we introduce a two-level hierarchical framework, RL-GPT, comprising a slow agent and a fast agent.","The slow agent analyzes actions suitable for coding, while the fast agent executes coding tasks.","This decomposition effectively focuses each agent on specific tasks, proving highly efficient within our pipeline.","Our approach outperforms traditional RL methods and existing GPT agents, demonstrating superior efficiency.","In the Minecraft game, it rapidly obtains diamonds within a single day on an RTX3090.","Additionally, it achieves SOTA performance across all designated MineDojo tasks."],"url":"http://arxiv.org/abs/2402.19299v1"}
{"created":"2024-02-29 16:06:36","title":"Suppress and Rebalance: Towards Generalized Multi-Modal Face Anti-Spoofing","abstract":"Face Anti-Spoofing (FAS) is crucial for securing face recognition systems against presentation attacks. With advancements in sensor manufacture and multi-modal learning techniques, many multi-modal FAS approaches have emerged. However, they face challenges in generalizing to unseen attacks and deployment conditions. These challenges arise from (1) modality unreliability, where some modality sensors like depth and infrared undergo significant domain shifts in varying environments, leading to the spread of unreliable information during cross-modal feature fusion, and (2) modality imbalance, where training overly relies on a dominant modality hinders the convergence of others, reducing effectiveness against attack types that are indistinguishable sorely using the dominant modality. To address modality unreliability, we propose the Uncertainty-Guided Cross-Adapter (U-Adapter) to recognize unreliably detected regions within each modality and suppress the impact of unreliable regions on other modalities. For modality imbalance, we propose a Rebalanced Modality Gradient Modulation (ReGrad) strategy to rebalance the convergence speed of all modalities by adaptively adjusting their gradients. Besides, we provide the first large-scale benchmark for evaluating multi-modal FAS performance under domain generalization scenarios. Extensive experiments demonstrate that our method outperforms state-of-the-art methods. Source code and protocols will be released on https://github.com/OMGGGGG/mmdg.","sentences":["Face Anti-Spoofing (FAS) is crucial for securing face recognition systems against presentation attacks.","With advancements in sensor manufacture and multi-modal learning techniques, many multi-modal FAS approaches have emerged.","However, they face challenges in generalizing to unseen attacks and deployment conditions.","These challenges arise from (1) modality unreliability, where some modality sensors like depth and infrared undergo significant domain shifts in varying environments, leading to the spread of unreliable information during cross-modal feature fusion, and (2) modality imbalance, where training overly relies on a dominant modality hinders the convergence of others, reducing effectiveness against attack types that are indistinguishable sorely using the dominant modality.","To address modality unreliability, we propose the Uncertainty-Guided Cross-Adapter (U-Adapter) to recognize unreliably detected regions within each modality and suppress the impact of unreliable regions on other modalities.","For modality imbalance, we propose a Rebalanced Modality Gradient Modulation (ReGrad) strategy to rebalance the convergence speed of all modalities by adaptively adjusting their gradients.","Besides, we provide the first large-scale benchmark for evaluating multi-modal FAS performance under domain generalization scenarios.","Extensive experiments demonstrate that our method outperforms state-of-the-art methods.","Source code and protocols will be released on https://github.com/OMGGGGG/mmdg."],"url":"http://arxiv.org/abs/2402.19298v1"}
{"created":"2024-02-29 15:59:42","title":"An AI based Digital Score of Tumour-Immune Microenvironment Predicts Benefit to Maintenance Immunotherapy in Advanced Oesophagogastric Adenocarcinoma","abstract":"Gastric and oesophageal (OG) cancers are the leading causes of cancer mortality worldwide. In OG cancers, recent studies have showed that PDL1 immune checkpoint inhibitors (ICI) in combination with chemotherapy improves patient survival. However, our understanding of the tumour immune microenvironment in OG cancers remains limited. In this study, we interrogate multiplex immunofluorescence (mIF) images taken from patients with advanced Oesophagogastric Adenocarcinoma (OGA) who received first-line fluoropyrimidine and platinum-based chemotherapy in the PLATFORM trial (NCT02678182) to predict the efficacy of the treatment and to explore the biological basis of patients responding to maintenance durvalumab (PDL1 inhibitor). Our proposed Artificial Intelligence (AI) based marker successfully identified responder from non-responder (p < 0.05) as well as those who could potentially benefit from ICI with statistical significance (p < 0.05) for both progression free and overall survival. Our findings suggest that T cells that express FOXP3 seem to heavily influence the patient treatment response and survival outcome. We also observed that higher levels of CD8+PD1+ cells are consistently linked to poor prognosis for both OS and PFS, regardless of ICI.","sentences":["Gastric and oesophageal (OG) cancers are the leading causes of cancer mortality worldwide.","In OG cancers, recent studies have showed that PDL1 immune checkpoint inhibitors (ICI) in combination with chemotherapy improves patient survival.","However, our understanding of the tumour immune microenvironment in OG cancers remains limited.","In this study, we interrogate multiplex immunofluorescence (mIF) images taken from patients with advanced Oesophagogastric Adenocarcinoma (OGA) who received first-line fluoropyrimidine and platinum-based chemotherapy in the PLATFORM trial (NCT02678182) to predict the efficacy of the treatment and to explore the biological basis of patients responding to maintenance durvalumab (PDL1 inhibitor).","Our proposed Artificial Intelligence (AI) based marker successfully identified responder from non-responder (p < 0.05) as well as those who could potentially benefit from ICI with statistical significance (p < 0.05) for both progression free and overall survival.","Our findings suggest that T cells that express FOXP3 seem to heavily influence the patient treatment response and survival outcome.","We also observed that higher levels of CD8+PD1+ cells are consistently linked to poor prognosis for both OS and PFS, regardless of ICI."],"url":"http://arxiv.org/abs/2402.19296v1"}
{"created":"2024-02-29 15:58:16","title":"Anomaly Detection in Offshore Wind Turbine Structures using Hierarchical Bayesian Modelling","abstract":"Population-based structural health monitoring (PBSHM), aims to share information between members of a population. An offshore wind (OW) farm could be considered as a population of nominally-identical wind-turbine structures. However, benign variations exist among members, such as geometry, sea-bed conditions and temperature differences. These factors could influence structural properties and therefore the dynamic response, making it more difficult to detect structural problems via traditional SHM techniques. This paper explores the use of a hierarchical Bayesian model to infer expected soil stiffness distributions at both population and local levels, as a basis to perform anomaly detection, in the form of scour, for new and existing turbines. To do this, observations of natural frequency will be generated as though they are from a small population of wind turbines. Differences between individual observations will be introduced by postulating distributions over the soil stiffness and measurement noise, as well as reducing soil depth (to represent scour), in the case of anomaly detection.","sentences":["Population-based structural health monitoring (PBSHM), aims to share information between members of a population.","An offshore wind (OW) farm could be considered as a population of nominally-identical wind-turbine structures.","However, benign variations exist among members, such as geometry, sea-bed conditions and temperature differences.","These factors could influence structural properties and therefore the dynamic response, making it more difficult to detect structural problems via traditional SHM techniques.","This paper explores the use of a hierarchical Bayesian model to infer expected soil stiffness distributions at both population and local levels, as a basis to perform anomaly detection, in the form of scour, for new and existing turbines.","To do this, observations of natural frequency will be generated as though they are from a small population of wind turbines.","Differences between individual observations will be introduced by postulating distributions over the soil stiffness and measurement noise, as well as reducing soil depth (to represent scour), in the case of anomaly detection."],"url":"http://arxiv.org/abs/2402.19295v1"}
{"created":"2024-02-29 15:57:09","title":"Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes","abstract":"Operating units often experience various failure modes in complex systems, leading to distinct degradation paths. Relying on a prognostic model trained on a single failure mode may lead to poor generalization performance across multiple failure modes. Therefore, accurately identifying the failure mode is of critical importance. Current prognostic approaches either ignore failure modes during degradation or assume known failure mode labels, which can be challenging to acquire in practice. Moreover, the high dimensionality and complex relations of sensor signals make it challenging to identify the failure modes accurately. To address these issues, we propose a novel failure mode diagnosis method that leverages a dimension reduction technique called UMAP (Uniform Manifold Approximation and Projection) to project and visualize each unit's degradation trajectory into a lower dimension. Then, using these degradation trajectories, we develop a time series-based clustering method to identify the training units' failure modes. Finally, we introduce a monotonically constrained prognostic model to predict the failure mode labels and RUL of the test units simultaneously using the obtained failure modes of the training units. The proposed prognostic model provides failure mode-specific RUL predictions while preserving the monotonic property of the RUL predictions across consecutive time steps. We evaluate the proposed model using a case study with the aircraft gas turbine engine dataset.","sentences":["Operating units often experience various failure modes in complex systems, leading to distinct degradation paths.","Relying on a prognostic model trained on a single failure mode may lead to poor generalization performance across multiple failure modes.","Therefore, accurately identifying the failure mode is of critical importance.","Current prognostic approaches either ignore failure modes during degradation or assume known failure mode labels, which can be challenging to acquire in practice.","Moreover, the high dimensionality and complex relations of sensor signals make it challenging to identify the failure modes accurately.","To address these issues, we propose a novel failure mode diagnosis method that leverages a dimension reduction technique called UMAP (Uniform Manifold Approximation and Projection) to project and visualize each unit's degradation trajectory into a lower dimension.","Then, using these degradation trajectories, we develop a time series-based clustering method to identify the training units' failure modes.","Finally, we introduce a monotonically constrained prognostic model to predict the failure mode labels and RUL of the test units simultaneously using the obtained failure modes of the training units.","The proposed prognostic model provides failure mode-specific RUL predictions while preserving the monotonic property of the RUL predictions across consecutive time steps.","We evaluate the proposed model using a case study with the aircraft gas turbine engine dataset."],"url":"http://arxiv.org/abs/2402.19294v1"}
{"created":"2024-02-29 15:55:10","title":"Fundamental Limits of Throughput and Availability: Applications to prophet inequalities & transaction fee mechanism design","abstract":"This paper studies the fundamental limits of availability and throughput for independent and heterogeneous demands of a limited resource. Availability is the probability that the demands are below the capacity of the resource. Throughput is the expected fraction of the resource that is utilized by the demands. We offer a concentration inequality generator that gives lower bounds on feasible availability and throughput pairs with a given capacity and independent but not necessarily identical distributions of up-to-unit demands. We show that availability and throughput cannot both be poor. These bounds are analogous to tail inequalities on sums of independent random variables, but hold throughout the support of the demand distribution. This analysis gives analytically tractable bounds supporting the unit-demand characterization of Chawla, Devanur, and Lykouris (2023) and generalizes to up-to-unit demands. Our bounds also provide an approach towards improved multi-unit prophet inequalities (Hajiaghayi, Kleinberg, and Sandholm, 2007). They have applications to transaction fee mechanism design (for blockchains) where high availability limits the probability of profitable user-miner coalitions (Chung and Shi, 2023).","sentences":["This paper studies the fundamental limits of availability and throughput for independent and heterogeneous demands of a limited resource.","Availability is the probability that the demands are below the capacity of the resource.","Throughput is the expected fraction of the resource that is utilized by the demands.","We offer a concentration inequality generator that gives lower bounds on feasible availability and throughput pairs with a given capacity and independent but not necessarily identical distributions of up-to-unit demands.","We show that availability and throughput cannot both be poor.","These bounds are analogous to tail inequalities on sums of independent random variables, but hold throughout the support of the demand distribution.","This analysis gives analytically tractable bounds supporting the unit-demand characterization of Chawla, Devanur, and Lykouris (2023) and generalizes to up-to-unit demands.","Our bounds also provide an approach towards improved multi-unit prophet inequalities (Hajiaghayi, Kleinberg, and Sandholm, 2007).","They have applications to transaction fee mechanism design (for blockchains) where high availability limits the probability of profitable user-miner coalitions (Chung and Shi, 2023)."],"url":"http://arxiv.org/abs/2402.19292v1"}
{"created":"2024-02-29 15:53:47","title":"Estimation and Deconvolution of Second Order Cyclostationary Signals","abstract":"This method solves the dual problem of blind deconvolution and estimation of the time waveform of noisy second-order cyclo-stationary (CS2) signals that traverse a Transfer Function (TF) en route to a sensor. We have proven that the deconvolution filter exists and eliminates the TF effect from signals whose statistics vary over time. This method is blind, meaning it does not require prior knowledge about the signals or TF. Simulations demonstrate the algorithm high precision across various signal types, TFs, and Signal-to-Noise Ratios (SNRs). In this study, the CS2 signals family is restricted to the product of a deterministic periodic function and white noise. Furthermore, this method has the potential to improve the training of Machine Learning models where the aggregation of signals from identical systems but with different TFs is required.","sentences":["This method solves the dual problem of blind deconvolution and estimation of the time waveform of noisy second-order cyclo-stationary (CS2) signals that traverse a Transfer Function (TF) en route to a sensor.","We have proven that the deconvolution filter exists and eliminates the TF effect from signals whose statistics vary over time.","This method is blind, meaning it does not require prior knowledge about the signals or TF.","Simulations demonstrate the algorithm high precision across various signal types, TFs, and Signal-to-Noise Ratios (SNRs).","In this study, the CS2 signals family is restricted to the product of a deterministic periodic function and white noise.","Furthermore, this method has the potential to improve the training of Machine Learning models where the aggregation of signals from identical systems but with different TFs is required."],"url":"http://arxiv.org/abs/2402.19290v1"}
{"created":"2024-02-29 15:52:21","title":"StiefelGen: A Simple, Model Agnostic Approach for Time Series Data Augmentation over Riemannian Manifolds","abstract":"Data augmentation is an area of research which has seen active development in many machine learning fields, such as in image-based learning models, reinforcement learning for self driving vehicles, and general noise injection for point cloud data. However, convincing methods for general time series data augmentation still leaves much to be desired, especially since the methods developed for these models do not readily cross-over. Three common approaches for time series data augmentation include: (i) Constructing a physics-based model and then imbuing uncertainty over the coefficient space (for example), (ii) Adding noise to the observed data set(s), and, (iii) Having access to ample amounts of time series data sets from which a robust generative neural network model can be trained. However, for many practical problems that work with time series data in the industry: (i) One usually does not have access to a robust physical model, (ii) The addition of noise can in of itself require large or difficult assumptions (for example, what probability distribution should be used? Or, how large should the noise variance be?), and, (iii) In practice, it can be difficult to source a large representative time series data base with which to train the neural network model for the underlying problem. In this paper, we propose a methodology which attempts to simultaneously tackle all three of these previous limitations to a large extent. The method relies upon the well-studied matrix differential geometry of the Stiefel manifold, as it proposes a simple way in which time series signals can placed on, and then smoothly perturbed over the manifold. We attempt to clarify how this method works by showcasing several potential use cases which in particular work to take advantage of the unique properties of this underlying manifold.","sentences":["Data augmentation is an area of research which has seen active development in many machine learning fields, such as in image-based learning models, reinforcement learning for self driving vehicles, and general noise injection for point cloud data.","However, convincing methods for general time series data augmentation still leaves much to be desired, especially since the methods developed for these models do not readily cross-over.","Three common approaches for time series data augmentation include: (i) Constructing a physics-based model and then imbuing uncertainty over the coefficient space (for example), (ii) Adding noise to the observed data set(s), and, (iii) Having access to ample amounts of time series data sets from which a robust generative neural network model can be trained.","However, for many practical problems that work with time series data in the industry: (i) One usually does not have access to a robust physical model, (ii) The addition of noise can in of itself require large or difficult assumptions (for example, what probability distribution should be used?","Or, how large should the noise variance be?), and, (iii) In practice, it can be difficult to source a large representative time series data base with which to train the neural network model for the underlying problem.","In this paper, we propose a methodology which attempts to simultaneously tackle all three of these previous limitations to a large extent.","The method relies upon the well-studied matrix differential geometry of the Stiefel manifold, as it proposes a simple way in which time series signals can placed on, and then smoothly perturbed over the manifold.","We attempt to clarify how this method works by showcasing several potential use cases which in particular work to take advantage of the unique properties of this underlying manifold."],"url":"http://arxiv.org/abs/2402.19287v1"}
{"created":"2024-02-29 15:49:15","title":"WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset","abstract":"This paper presents WanJuan-CC, a safe and high-quality open-sourced English webtext dataset derived from Common Crawl data. The study addresses the challenges of constructing large-scale pre-training datasets for language models, which require vast amounts of high-quality data. A comprehensive process was designed to handle Common Crawl data, including extraction, heuristic rule filtering, fuzzy deduplication, content safety filtering, and data quality filtering. From approximately 68 billion original English documents, we obtained 2.22T Tokens of safe data and selected 1.0T Tokens of high-quality data as part of WanJuan-CC. We have open-sourced 300B Tokens from this dataset. The paper also provides statistical information related to data quality, enabling users to select appropriate data according to their needs. To evaluate the quality and utility of the dataset, we trained 1B-parameter and 3B-parameter models using WanJuan-CC and another dataset, RefinedWeb. Results show that WanJuan-CC performs better on validation datasets and downstream tasks.","sentences":["This paper presents WanJuan-CC, a safe and high-quality open-sourced English webtext dataset derived from Common Crawl data.","The study addresses the challenges of constructing large-scale pre-training datasets for language models, which require vast amounts of high-quality data.","A comprehensive process was designed to handle Common Crawl data, including extraction, heuristic rule filtering, fuzzy deduplication, content safety filtering, and data quality filtering.","From approximately 68 billion original English documents, we obtained 2.22T Tokens of safe data and selected 1.0T Tokens of high-quality data as part of WanJuan-CC.","We have open-sourced 300B Tokens from this dataset.","The paper also provides statistical information related to data quality, enabling users to select appropriate data according to their needs.","To evaluate the quality and utility of the dataset, we trained 1B-parameter and 3B-parameter models using WanJuan-CC and another dataset, RefinedWeb.","Results show that WanJuan-CC performs better on validation datasets and downstream tasks."],"url":"http://arxiv.org/abs/2402.19282v1"}
{"created":"2024-02-29 15:48:11","title":"Mobile Health Text Misinformation Identification Using Mobile Data Mining","abstract":"More than six million people died of the COVID-19 by April 2022. The heavy casualties have put people on great and urgent alert and people try to find all kinds of information to keep them from being inflected by the coronavirus. This research tries to find out whether the mobile health text information sent to peoples devices is correct as smartphones becoming the major information source for people. The proposed method uses various mobile information retrieval and data mining technologies including lexical analysis, stopword elimination, stemming, and decision trees to classify the mobile health text information to one of the following classes: (i) true, (ii) fake, (iii) misinformative, (iv) disinformative, and (v) neutral. Experiment results show the accuracy of the proposed method is above the threshold value 50 percentage, but is not optimal. It is because the problem, mobile text misinformation identification, is intrinsically difficult.","sentences":["More than six million people died of the COVID-19 by April 2022.","The heavy casualties have put people on great and urgent alert and people try to find all kinds of information to keep them from being inflected by the coronavirus.","This research tries to find out whether the mobile health text information sent to peoples devices is correct as smartphones becoming the major information source for people.","The proposed method uses various mobile information retrieval and data mining technologies including lexical analysis, stopword elimination, stemming, and decision trees to classify the mobile health text information to one of the following classes: (i) true, (ii) fake, (iii) misinformative, (iv) disinformative, and (v) neutral.","Experiment results show the accuracy of the proposed method is above the threshold value 50 percentage, but is not optimal.","It is because the problem, mobile text misinformation identification, is intrinsically difficult."],"url":"http://arxiv.org/abs/2402.19280v1"}
{"created":"2024-02-29 15:46:48","title":"SIFT-Aided Rectified 2D-DIC for Displacement and Strain Measurements in Asphalt Concrete Testing","abstract":"Two-dimensional digital image correlation (2D-DIC) is a widely used optical technique to measure displacement and strain during asphalt concrete (AC) testing. An accurate 2-D DIC measurement can only be achieved when the camera's principal axis is perpendicular to the planar specimen surface. However, this requirement may not be met during testing due to device constraints. This paper proposes a simple and reliable method to correct errors induced by non-perpendicularity. The method is based on image feature matching and rectification. No additional equipment is needed. A theoretical error analysis was conducted to quantify the effect of a non-perpendicular camera alignment on measurement accuracy. The proposed method was validated numerically using synthetic images and experimentally in an AC fracture test. It achieved relatively high accuracy, even under considerable camera rotation angle and large deformation. As a pre-processing technique, the proposed method showed promising performance in assisting the recently developed CrackPropNet for automated crack propagation measurement under a non-perpendicular camera alignment.","sentences":["Two-dimensional digital image correlation (2D-DIC) is a widely used optical technique to measure displacement and strain during asphalt concrete (AC) testing.","An accurate 2-D DIC measurement can only be achieved when the camera's principal axis is perpendicular to the planar specimen surface.","However, this requirement may not be met during testing due to device constraints.","This paper proposes a simple and reliable method to correct errors induced by non-perpendicularity.","The method is based on image feature matching and rectification.","No additional equipment is needed.","A theoretical error analysis was conducted to quantify the effect of a non-perpendicular camera alignment on measurement accuracy.","The proposed method was validated numerically using synthetic images and experimentally in an AC fracture test.","It achieved relatively high accuracy, even under considerable camera rotation angle and large deformation.","As a pre-processing technique, the proposed method showed promising performance in assisting the recently developed CrackPropNet for automated crack propagation measurement under a non-perpendicular camera alignment."],"url":"http://arxiv.org/abs/2402.19279v1"}
