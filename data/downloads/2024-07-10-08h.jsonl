{"created":"2024-07-09 17:59:56","title":"AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning","abstract":"The pervasive deployment of Large Language Models-LLMs in various sectors often neglects the nuanced requirements of individuals and small organizations, who benefit more from models precisely tailored to their specific business contexts rather than those with broadly superior general capabilities. This work introduces \\textbf{AnyTaskTune}, a novel fine-tuning methodology coined as \\textbf{Task-Fine-Tune}, specifically developed to elevate model performance on a diverse array of domain-specific tasks. This method involves a meticulous process to identify and define targeted sub-tasks within a domain, followed by the creation of specialized enhancement datasets for fine-tuning, thereby optimizing task-specific model performance. We conducted comprehensive fine-tuning experiments not only in the legal domain for tasks such as keyword extraction and sentence prediction but across over twenty different sub-tasks derived from the domains of finance, healthcare, law, psychology, consumer services, and human resources. To substantiate our approach and facilitate community engagement, we will open-source these bilingual task datasets. Our findings demonstrate that models fine-tuned using the \\textbf{Task-Fine-Tune} methodology not only achieve superior performance on these specific tasks but also significantly outperform models with higher general capabilities in their respective domains. Our work is publicly available at \\url{https://github.com/PandaVT/DataTager}.","sentences":["The pervasive deployment of Large Language Models-LLMs in various sectors often neglects the nuanced requirements of individuals and small organizations, who benefit more from models precisely tailored to their specific business contexts rather than those with broadly superior general capabilities.","This work introduces \\textbf{AnyTaskTune}, a novel fine-tuning methodology coined as \\textbf{Task-Fine-Tune}, specifically developed to elevate model performance on a diverse array of domain-specific tasks.","This method involves a meticulous process to identify and define targeted sub-tasks within a domain, followed by the creation of specialized enhancement datasets for fine-tuning, thereby optimizing task-specific model performance.","We conducted comprehensive fine-tuning experiments not only in the legal domain for tasks such as keyword extraction and sentence prediction but across over twenty different sub-tasks derived from the domains of finance, healthcare, law, psychology, consumer services, and human resources.","To substantiate our approach and facilitate community engagement, we will open-source these bilingual task datasets.","Our findings demonstrate that models fine-tuned using the \\textbf{Task-Fine-Tune} methodology not only achieve superior performance on these specific tasks but also significantly outperform models with higher general capabilities in their respective domains.","Our work is publicly available at \\url{https://github.com/PandaVT/DataTager}."],"url":"http://arxiv.org/abs/2407.07094v1"}
{"created":"2024-07-09 17:59:48","title":"FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation","abstract":"This work presents a Fully BInarized Large Language Model (FBI-LLM), demonstrating for the first time how to train a large-scale binary language model from scratch (not the partial binary or ternary LLM like BitNet b1.58) to match the performance of its full-precision counterparts (e.g., FP16 or BF16) in transformer-based LLMs. It achieves this by employing an autoregressive distillation (AD) loss with maintaining equivalent model dimensions (130M, 1.3B, 7B) and training data volume as regular LLM pretraining, while delivering competitive results in terms of perplexity and task-specific effectiveness. Intriguingly, by analyzing the training trajectory, we find that the pretrained weight is not necessary for training binarized LLMs from scratch. This research encourages a new computational framework and may facilitate the future design of specialized hardware tailored for fully 1-bit LLMs. We make all models, code, and training dataset fully accessible and transparent to support further research (Code: https://github.com/LiqunMa/FBI-LLM. Model: https://huggingface.co/LiqunMa/).","sentences":["This work presents a Fully BInarized Large Language Model (FBI-LLM), demonstrating for the first time how to train a large-scale binary language model from scratch (not the partial binary or ternary LLM like BitNet b1.58) to match the performance of its full-precision counterparts (e.g., FP16 or BF16) in transformer-based LLMs.","It achieves this by employing an autoregressive distillation (AD) loss with maintaining equivalent model dimensions (130M, 1.3B, 7B) and training data volume as regular LLM pretraining, while delivering competitive results in terms of perplexity and task-specific effectiveness.","Intriguingly, by analyzing the training trajectory, we find that the pretrained weight is not necessary for training binarized LLMs from scratch.","This research encourages a new computational framework and may facilitate the future design of specialized hardware tailored for fully 1-bit LLMs.","We make all models, code, and training dataset fully accessible and transparent to support further research (Code: https://github.com/LiqunMa/FBI-LLM.","Model: https://huggingface.co/LiqunMa/)."],"url":"http://arxiv.org/abs/2407.07093v1"}
{"created":"2024-07-09 17:59:47","title":"V-VIPE: Variational View Invariant Pose Embedding","abstract":"Learning to represent three dimensional (3D) human pose given a two dimensional (2D) image of a person, is a challenging problem. In order to make the problem less ambiguous it has become common practice to estimate 3D pose in the camera coordinate space. However, this makes the task of comparing two 3D poses difficult. In this paper, we address this challenge by separating the problem of estimating 3D pose from 2D images into two steps. We use a variational autoencoder (VAE) to find an embedding that represents 3D poses in canonical coordinate space. We refer to this embedding as variational view-invariant pose embedding V-VIPE. Using V-VIPE we can encode 2D and 3D poses and use the embedding for downstream tasks, like retrieval and classification. We can estimate 3D poses from these embeddings using the decoder as well as generate unseen 3D poses. The variability of our encoding allows it to generalize well to unseen camera views when mapping from 2D space. To the best of our knowledge, V-VIPE is the only representation to offer this diversity of applications. Code and more information can be found at https://v-vipe.github.io/.","sentences":["Learning to represent three dimensional (3D) human pose given a two dimensional (2D) image of a person, is a challenging problem.","In order to make the problem less ambiguous it has become common practice to estimate 3D pose in the camera coordinate space.","However, this makes the task of comparing two 3D poses difficult.","In this paper, we address this challenge by separating the problem of estimating 3D pose from 2D images into two steps.","We use a variational autoencoder (VAE) to find an embedding that represents 3D poses in canonical coordinate space.","We refer to this embedding as variational view-invariant pose embedding V-VIPE.","Using V-VIPE we can encode 2D and 3D poses and use the embedding for downstream tasks, like retrieval and classification.","We can estimate 3D poses from these embeddings using the decoder as well as generate unseen 3D poses.","The variability of our encoding allows it to generalize well to unseen camera views when mapping from 2D space.","To the best of our knowledge, V-VIPE is the only representation to offer this diversity of applications.","Code and more information can be found at https://v-vipe.github.io/."],"url":"http://arxiv.org/abs/2407.07092v1"}
{"created":"2024-07-09 17:59:30","title":"3D Gaussian Ray Tracing: Fast Tracing of Particle Scenes","abstract":"Particle-based representations of radiance fields such as 3D Gaussian Splatting have found great success for reconstructing and re-rendering of complex scenes. Most existing methods render particles via rasterization, projecting them to screen space tiles for processing in a sorted order. This work instead considers ray tracing the particles, building a bounding volume hierarchy and casting a ray for each pixel using high-performance GPU ray tracing hardware. To efficiently handle large numbers of semi-transparent particles, we describe a specialized rendering algorithm which encapsulates particles with bounding meshes to leverage fast ray-triangle intersections, and shades batches of intersections in depth-order. The benefits of ray tracing are well-known in computer graphics: processing incoherent rays for secondary lighting effects such as shadows and reflections, rendering from highly-distorted cameras common in robotics, stochastically sampling rays, and more. With our renderer, this flexibility comes at little cost compared to rasterization. Experiments demonstrate the speed and accuracy of our approach, as well as several applications in computer graphics and vision. We further propose related improvements to the basic Gaussian representation, including a simple use of generalized kernel functions which significantly reduces particle hit counts.","sentences":["Particle-based representations of radiance fields such as 3D Gaussian Splatting have found great success for reconstructing and re-rendering of complex scenes.","Most existing methods render particles via rasterization, projecting them to screen space tiles for processing in a sorted order.","This work instead considers ray tracing the particles, building a bounding volume hierarchy and casting a ray for each pixel using high-performance GPU ray tracing hardware.","To efficiently handle large numbers of semi-transparent particles, we describe a specialized rendering algorithm which encapsulates particles with bounding meshes to leverage fast ray-triangle intersections, and shades batches of intersections in depth-order.","The benefits of ray tracing are well-known in computer graphics: processing incoherent rays for secondary lighting effects such as shadows and reflections, rendering from highly-distorted cameras common in robotics, stochastically sampling rays, and more.","With our renderer, this flexibility comes at little cost compared to rasterization.","Experiments demonstrate the speed and accuracy of our approach, as well as several applications in computer graphics and vision.","We further propose related improvements to the basic Gaussian representation, including a simple use of generalized kernel functions which significantly reduces particle hit counts."],"url":"http://arxiv.org/abs/2407.07090v1"}
{"created":"2024-07-09 17:59:17","title":"Fine-Tuning Linear Layers Only Is a Simple yet Effective Way for Task Arithmetic","abstract":"Task arithmetic has recently emerged as a cost-effective and scalable approach to edit pre-trained models directly in weight space, by adding the fine-tuned weights of different tasks. The performance has been further improved by a linear property which is illustrated by weight disentanglement. Yet, conventional linearization methods (e.g., NTK linearization) not only double the time and training cost but also have a disadvantage on single-task performance. We propose a simple yet effective and efficient method that only fine-tunes linear layers, which improves weight disentanglement and efficiency simultaneously. Specifically, our study reveals that only fine-tuning the linear layers in the attention modules makes the whole model occur in a linear regime, significantly improving weight disentanglement. To further understand how our method improves the disentanglement of task arithmetic, we present a comprehensive study of task arithmetic by differentiating the role of representation model and task-specific model. In particular, we find that the representation model plays an important role in improving weight disentanglement whereas the task-specific models such as the classification heads can degenerate the weight disentanglement performance. Overall, our work uncovers novel insights into the fundamental mechanisms of task arithmetic and offers a more reliable and effective approach to editing pre-trained models.","sentences":["Task arithmetic has recently emerged as a cost-effective and scalable approach to edit pre-trained models directly in weight space, by adding the fine-tuned weights of different tasks.","The performance has been further improved by a linear property which is illustrated by weight disentanglement.","Yet, conventional linearization methods (e.g., NTK linearization) not only double the time and training cost but also have a disadvantage on single-task performance.","We propose a simple yet effective and efficient method that only fine-tunes linear layers, which improves weight disentanglement and efficiency simultaneously.","Specifically, our study reveals that only fine-tuning the linear layers in the attention modules makes the whole model occur in a linear regime, significantly improving weight disentanglement.","To further understand how our method improves the disentanglement of task arithmetic, we present a comprehensive study of task arithmetic by differentiating the role of representation model and task-specific model.","In particular, we find that the representation model plays an important role in improving weight disentanglement whereas the task-specific models such as the classification heads can degenerate the weight disentanglement performance.","Overall, our work uncovers novel insights into the fundamental mechanisms of task arithmetic and offers a more reliable and effective approach to editing pre-trained models."],"url":"http://arxiv.org/abs/2407.07089v1"}
{"created":"2024-07-09 17:58:50","title":"Safe and Reliable Training of Learning-Based Aerospace Controllers","abstract":"In recent years, deep reinforcement learning (DRL) approaches have generated highly successful controllers for a myriad of complex domains. However, the opaque nature of these models limits their applicability in aerospace systems and safety-critical domains, in which a single mistake can have dire consequences. In this paper, we present novel advancements in both the training and verification of DRL controllers, which can help ensure their safe behavior. We showcase a design-for-verification approach utilizing k-induction and demonstrate its use in verifying liveness properties. In addition, we also give a brief overview of neural Lyapunov Barrier certificates and summarize their capabilities on a case study. Finally, we describe several other novel reachability-based approaches which, despite failing to provide guarantees of interest, could be effective for verification of other DRL systems, and could be of further interest to the community.","sentences":["In recent years, deep reinforcement learning (DRL) approaches have generated highly successful controllers for a myriad of complex domains.","However, the opaque nature of these models limits their applicability in aerospace systems and safety-critical domains, in which a single mistake can have dire consequences.","In this paper, we present novel advancements in both the training and verification of DRL controllers, which can help ensure their safe behavior.","We showcase a design-for-verification approach utilizing k-induction and demonstrate its use in verifying liveness properties.","In addition, we also give a brief overview of neural Lyapunov Barrier certificates and summarize their capabilities on a case study.","Finally, we describe several other novel reachability-based approaches which, despite failing to provide guarantees of interest, could be effective for verification of other DRL systems, and could be of further interest to the community."],"url":"http://arxiv.org/abs/2407.07088v1"}
{"created":"2024-07-09 17:58:18","title":"CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation","abstract":"Evaluating the degree of reproduction of copyright-protected content by language models (LMs) is of significant interest to the AI and legal communities. Although both literal and non-literal similarities are considered by courts when assessing the degree of reproduction, prior research has focused only on literal similarities. To bridge this gap, we introduce CopyBench, a benchmark designed to measure both literal and non-literal copying in LM generations. Using copyrighted fiction books as text sources, we provide automatic evaluation protocols to assess literal and non-literal copying, balanced against the model utility in terms of the ability to recall facts from the copyrighted works and generate fluent completions. We find that, although literal copying is relatively rare, two types of non-literal copying -- event copying and character copying -- occur even in models as small as 7B parameters. Larger models demonstrate significantly more copying, with literal copying rates increasing from 0.2% to 10.5% and non-literal copying from 2.3% to 6.9% when comparing Llama3-8B and 70B models, respectively. We further evaluate the effectiveness of current strategies for mitigating copying and show that (1) training-time alignment can reduce literal copying but may increase non-literal copying, and (2) current inference-time mitigation methods primarily reduce literal but not non-literal copying.","sentences":["Evaluating the degree of reproduction of copyright-protected content by language models (LMs) is of significant interest to the AI and legal communities.","Although both literal and non-literal similarities are considered by courts when assessing the degree of reproduction, prior research has focused only on literal similarities.","To bridge this gap, we introduce CopyBench, a benchmark designed to measure both literal and non-literal copying in LM generations.","Using copyrighted fiction books as text sources, we provide automatic evaluation protocols to assess literal and non-literal copying, balanced against the model utility in terms of the ability to recall facts from the copyrighted works and generate fluent completions.","We find that, although literal copying is relatively rare, two types of non-literal copying -- event copying and character copying -- occur even in models as small as 7B parameters.","Larger models demonstrate significantly more copying, with literal copying rates increasing from 0.2% to 10.5% and non-literal copying from 2.3% to 6.9% when comparing Llama3-8B and 70B models, respectively.","We further evaluate the effectiveness of current strategies for mitigating copying and show that (1) training-time alignment can reduce literal copying but may increase non-literal copying, and (2) current inference-time mitigation methods primarily reduce literal but not non-literal copying."],"url":"http://arxiv.org/abs/2407.07087v1"}
{"created":"2024-07-09 17:57:15","title":"Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models","abstract":"Multi-agent reinforcement learning (MARL) methods struggle with the non-stationarity of multi-agent systems and fail to adaptively learn online when tested with novel agents. Here, we leverage large language models (LLMs) to create an autonomous agent that can handle these challenges. Our agent, Hypothetical Minds, consists of a cognitively-inspired architecture, featuring modular components for perception, memory, and hierarchical planning over two levels of abstraction. We introduce the Theory of Mind module that scaffolds the high-level planning process by generating hypotheses about other agents' strategies in natural language. It then evaluates and iteratively refines these hypotheses by reinforcing hypotheses that make correct predictions about the other agents' behavior. Hypothetical Minds significantly improves performance over previous LLM-agent and RL baselines on a range of competitive, mixed motive, and collaborative domains in the Melting Pot benchmark, including both dyadic and population-based environments. Additionally, comparisons against LLM-agent baselines and ablations reveal the importance of hypothesis evaluation and refinement for succeeding on complex scenarios.","sentences":["Multi-agent reinforcement learning (MARL) methods struggle with the non-stationarity of multi-agent systems and fail to adaptively learn online when tested with novel agents.","Here, we leverage large language models (LLMs) to create an autonomous agent that can handle these challenges.","Our agent, Hypothetical Minds, consists of a cognitively-inspired architecture, featuring modular components for perception, memory, and hierarchical planning over two levels of abstraction.","We introduce the Theory of Mind module that scaffolds the high-level planning process by generating hypotheses about other agents' strategies in natural language.","It then evaluates and iteratively refines these hypotheses by reinforcing hypotheses that make correct predictions about the other agents' behavior.","Hypothetical Minds significantly improves performance over previous LLM-agent and RL baselines on a range of competitive, mixed motive, and collaborative domains in the Melting Pot benchmark, including both dyadic and population-based environments.","Additionally, comparisons against LLM-agent baselines and ablations reveal the importance of hypothesis evaluation and refinement for succeeding on complex scenarios."],"url":"http://arxiv.org/abs/2407.07086v1"}
{"created":"2024-07-09 17:56:29","title":"Stabilized Proximal-Point Methods for Federated Optimization","abstract":"In developing efficient optimization algorithms, it is crucial to account for communication constraints -- a significant challenge in modern federated learning settings. The best-known communication complexity among non-accelerated algorithms is achieved by DANE, a distributed proximal-point algorithm that solves local subproblems in each iteration and that can exploit second-order similarity among individual functions. However, to achieve such communication efficiency, the accuracy requirement for solving the local subproblems is slightly sub-optimal. Inspired by the hybrid projection-proximal point method, in this work, we i) propose a novel distributed algorithm S-DANE. This method adopts a more stabilized prox-center in the proximal step compared with DANE, and matches its deterministic communication complexity. Moreover, the accuracy condition of the subproblem is milder, leading to enhanced local computation efficiency. Furthermore, it supports partial client participation and arbitrary stochastic local solvers, making it more attractive in practice. We further ii) accelerate S-DANE, and show that the resulting algorithm achieves the best-known communication complexity among all existing methods for distributed convex optimization, with the same improved local computation efficiency as S-DANE.","sentences":["In developing efficient optimization algorithms, it is crucial to account for communication constraints -- a significant challenge in modern federated learning settings.","The best-known communication complexity among non-accelerated algorithms is achieved by DANE, a distributed proximal-point algorithm that solves local subproblems in each iteration and that can exploit second-order similarity among individual functions.","However, to achieve such communication efficiency, the accuracy requirement for solving the local subproblems is slightly sub-optimal.","Inspired by the hybrid projection-proximal point method, in this work, we i) propose a novel distributed algorithm S-DANE.","This method adopts a more stabilized prox-center in the proximal step compared with DANE, and matches its deterministic communication complexity.","Moreover, the accuracy condition of the subproblem is milder, leading to enhanced local computation efficiency.","Furthermore, it supports partial client participation and arbitrary stochastic local solvers, making it more attractive in practice.","We further ii) accelerate S-DANE, and show that the resulting algorithm achieves the best-known communication complexity among all existing methods for distributed convex optimization, with the same improved local computation efficiency as S-DANE."],"url":"http://arxiv.org/abs/2407.07084v1"}
{"created":"2024-07-09 17:55:41","title":"Integer Linear-Exponential Programming in NP by Quantifier Elimination","abstract":"This paper provides an NP procedure that decides whether a linear-exponential system of constraints has an integer solution. Linear-exponential systems extend standard integer linear programs with exponential terms $2^x$ and remainder terms ${(x \\bmod 2^y)}$. Our result implies that the existential theory of the structure $(\\mathbb{N},0,1,+,2^{(\\cdot)},V_2(\\cdot,\\cdot),\\leq)$ has an NP-complete satisfiability problem, thus improving upon a recent EXPSPACE upper bound. This theory extends the existential fragment of Presburger arithmetic with the exponentiation function $x \\mapsto 2^x$ and the binary predicate $V_2(x,y)$ that is true whenever $y \\geq 1$ is the largest power of $2$ dividing $x$.   Our procedure for solving linear-exponential systems uses the method of quantifier elimination. As a by-product, we modify the classical Gaussian variable elimination into a non-deterministic polynomial-time procedure for integer linear programming (or: existential Presburger arithmetic).","sentences":["This paper provides an NP procedure that decides whether a linear-exponential system of constraints has an integer solution.","Linear-exponential systems extend standard integer linear programs with exponential terms $2^x$ and remainder terms ${(x \\bmod 2^y)}$. Our result implies that the existential theory of the structure $(\\mathbb{N},0,1,+,2^{(\\cdot)},V_2(\\cdot,\\cdot),\\leq)$ has an NP-complete satisfiability problem, thus improving upon a recent EXPSPACE upper bound.","This theory extends the existential fragment of Presburger arithmetic with the exponentiation function $x \\mapsto 2^x$ and the binary predicate $V_2(x,y)$ that is true whenever $y \\geq 1$ is the largest power of $2$ dividing $x$.   Our procedure for solving linear-exponential systems uses the method of quantifier elimination.","As a by-product, we modify the classical Gaussian variable elimination into a non-deterministic polynomial-time procedure for integer linear programming (or: existential Presburger arithmetic)."],"url":"http://arxiv.org/abs/2407.07083v1"}
{"created":"2024-07-09 17:55:23","title":"Can Learned Optimization Make Reinforcement Learning Less Difficult?","abstract":"While reinforcement learning (RL) holds great potential for decision making in the real world, it suffers from a number of unique difficulties which often need specific consideration. In particular: it is highly non-stationary; suffers from high degrees of plasticity loss; and requires exploration to prevent premature convergence to local optima and maximize return. In this paper, we consider whether learned optimization can help overcome these problems. Our method, Learned Optimization for Plasticity, Exploration and Non-stationarity (OPEN), meta-learns an update rule whose input features and output structure are informed by previously proposed solutions to these difficulties. We show that our parameterization is flexible enough to enable meta-learning in diverse learning contexts, including the ability to use stochasticity for exploration. Our experiments demonstrate that when meta-trained on single and small sets of environments, OPEN outperforms or equals traditionally used optimizers. Furthermore, OPEN shows strong generalization across a distribution of environments and a range of agent architectures.","sentences":["While reinforcement learning (RL) holds great potential for decision making in the real world, it suffers from a number of unique difficulties which often need specific consideration.","In particular: it is highly non-stationary; suffers from high degrees of plasticity loss; and requires exploration to prevent premature convergence to local optima and maximize return.","In this paper, we consider whether learned optimization can help overcome these problems.","Our method, Learned Optimization for Plasticity, Exploration and Non-stationarity (OPEN), meta-learns an update rule whose input features and output structure are informed by previously proposed solutions to these difficulties.","We show that our parameterization is flexible enough to enable meta-learning in diverse learning contexts, including the ability to use stochasticity for exploration.","Our experiments demonstrate that when meta-trained on single and small sets of environments, OPEN outperforms or equals traditionally used optimizers.","Furthermore, OPEN shows strong generalization across a distribution of environments and a range of agent architectures."],"url":"http://arxiv.org/abs/2407.07082v1"}
{"created":"2024-07-09 17:51:37","title":"Adapting LLMs to Hebrew: Unveiling DictaLM 2.0 with Enhanced Vocabulary and Instruction Capabilities","abstract":"Training large language models (LLMs) in low-resource languages such as Hebrew poses unique challenges. In this paper, we introduce DictaLM2.0 and DictaLM2.0-Instruct, two LLMs derived from the Mistral model, trained on a substantial corpus of approximately 200 billion tokens in both Hebrew and English. Adapting a pre-trained model to a new language involves specialized techniques that differ significantly from training a model from scratch or further training existing models on well-resourced languages such as English. We outline these novel training methodologies, which facilitate effective learning and adaptation to the linguistic properties of Hebrew. Additionally, we fine-tuned DictaLM2.0-Instruct on a comprehensive instruct dataset to enhance its performance on task-specific instructions. To rigorously evaluate our models, we introduce a new benchmark suite for Hebrew LLM evaluation, covering a diverse set of tasks including Question Answering, Sentiment Analysis, Winograd Schema Challenge, Translation, and Summarization. Our work not only addresses the intricacies of training LLMs in low-resource languages but also proposes a framework that can be leveraged for adapting other LLMs to various non-English languages, contributing to the broader field of multilingual NLP.","sentences":["Training large language models (LLMs) in low-resource languages such as Hebrew poses unique challenges.","In this paper, we introduce DictaLM2.0 and DictaLM2.0-Instruct, two LLMs derived from the Mistral model, trained on a substantial corpus of approximately 200 billion tokens in both Hebrew and English.","Adapting a pre-trained model to a new language involves specialized techniques that differ significantly from training a model from scratch or further training existing models on well-resourced languages such as English.","We outline these novel training methodologies, which facilitate effective learning and adaptation to the linguistic properties of Hebrew.","Additionally, we fine-tuned DictaLM2.0-Instruct on a comprehensive instruct dataset to enhance its performance on task-specific instructions.","To rigorously evaluate our models, we introduce a new benchmark suite for Hebrew LLM evaluation, covering a diverse set of tasks including Question Answering, Sentiment Analysis, Winograd Schema Challenge, Translation, and Summarization.","Our work not only addresses the intricacies of training LLMs in low-resource languages but also proposes a framework that can be leveraged for adapting other LLMs to various non-English languages, contributing to the broader field of multilingual NLP."],"url":"http://arxiv.org/abs/2407.07080v1"}
{"created":"2024-07-09 17:50:54","title":"MoSt-DSA: Modeling Motion and Structural Interactions for Direct Multi-Frame Interpolation in DSA Images","abstract":"Artificial intelligence has become a crucial tool for medical image analysis. As an advanced cerebral angiography technique, Digital Subtraction Angiography (DSA) poses a challenge where the radiation dose to humans is proportional to the image count. By reducing images and using AI interpolation instead, the radiation can be cut significantly. However, DSA images present more complex motion and structural features than natural scenes, making interpolation more challenging. We propose MoSt-DSA, the first work that uses deep learning for DSA frame interpolation. Unlike natural scene Video Frame Interpolation (VFI) methods that extract unclear or coarse-grained features, we devise a general module that models motion and structural context interactions between frames in an efficient full convolution manner by adjusting optimal context range and transforming contexts into linear functions. Benefiting from this, MoSt-DSA is also the first method that directly achieves any number of interpolations at any time steps with just one forward pass during both training and testing. We conduct extensive comparisons with 7 representative VFI models for interpolating 1 to 3 frames, MoSt-DSA demonstrates robust results across 470 DSA image sequences (each typically 152 images), with average SSIM over 0.93, average PSNR over 38 (standard deviations of less than 0.030 and 3.6, respectively), comprehensively achieving state-of-the-art performance in accuracy, speed, visual effect, and memory usage. Our code is available at https://github.com/ZyoungXu/MoSt-DSA.","sentences":["Artificial intelligence has become a crucial tool for medical image analysis.","As an advanced cerebral angiography technique, Digital Subtraction Angiography (DSA) poses a challenge where the radiation dose to humans is proportional to the image count.","By reducing images and using AI interpolation instead, the radiation can be cut significantly.","However, DSA images present more complex motion and structural features than natural scenes, making interpolation more challenging.","We propose MoSt-DSA, the first work that uses deep learning for DSA frame interpolation.","Unlike natural scene Video Frame Interpolation (VFI) methods that extract unclear or coarse-grained features, we devise a general module that models motion and structural context interactions between frames in an efficient full convolution manner by adjusting optimal context range and transforming contexts into linear functions.","Benefiting from this, MoSt-DSA is also the first method that directly achieves any number of interpolations at any time steps with just one forward pass during both training and testing.","We conduct extensive comparisons with 7 representative VFI models for interpolating 1 to 3 frames, MoSt-DSA demonstrates robust results across 470 DSA image sequences (each typically 152 images), with average SSIM over 0.93, average PSNR over 38 (standard deviations of less than 0.030 and 3.6, respectively), comprehensively achieving state-of-the-art performance in accuracy, speed, visual effect, and memory usage.","Our code is available at https://github.com/ZyoungXu/MoSt-DSA."],"url":"http://arxiv.org/abs/2407.07078v1"}
{"created":"2024-07-09 17:50:28","title":"ConceptExpress: Harnessing Diffusion Models for Single-image Unsupervised Concept Extraction","abstract":"While personalized text-to-image generation has enabled the learning of a single concept from multiple images, a more practical yet challenging scenario involves learning multiple concepts within a single image. However, existing works tackling this scenario heavily rely on extensive human annotations. In this paper, we introduce a novel task named Unsupervised Concept Extraction (UCE) that considers an unsupervised setting without any human knowledge of the concepts. Given an image that contains multiple concepts, the task aims to extract and recreate individual concepts solely relying on the existing knowledge from pretrained diffusion models. To achieve this, we present ConceptExpress that tackles UCE by unleashing the inherent capabilities of pretrained diffusion models in two aspects. Specifically, a concept localization approach automatically locates and disentangles salient concepts by leveraging spatial correspondence from diffusion self-attention; and based on the lookup association between a concept and a conceptual token, a concept-wise optimization process learns discriminative tokens that represent each individual concept. Finally, we establish an evaluation protocol tailored for the UCE task. Extensive experiments demonstrate that ConceptExpress is a promising solution to the UCE task. Our code and data are available at: https://github.com/haoosz/ConceptExpress","sentences":["While personalized text-to-image generation has enabled the learning of a single concept from multiple images, a more practical yet challenging scenario involves learning multiple concepts within a single image.","However, existing works tackling this scenario heavily rely on extensive human annotations.","In this paper, we introduce a novel task named Unsupervised Concept Extraction (UCE) that considers an unsupervised setting without any human knowledge of the concepts.","Given an image that contains multiple concepts, the task aims to extract and recreate individual concepts solely relying on the existing knowledge from pretrained diffusion models.","To achieve this, we present ConceptExpress that tackles UCE by unleashing the inherent capabilities of pretrained diffusion models in two aspects.","Specifically, a concept localization approach automatically locates and disentangles salient concepts by leveraging spatial correspondence from diffusion self-attention; and based on the lookup association between a concept and a conceptual token, a concept-wise optimization process learns discriminative tokens that represent each individual concept.","Finally, we establish an evaluation protocol tailored for the UCE task.","Extensive experiments demonstrate that ConceptExpress is a promising solution to the UCE task.","Our code and data are available at: https://github.com/haoosz/ConceptExpress"],"url":"http://arxiv.org/abs/2407.07077v1"}
{"created":"2024-07-09 17:46:53","title":"Hyperion - A fast, versatile symbolic Gaussian Belief Propagation framework for Continuous-Time SLAM","abstract":"Continuous-Time Simultaneous Localization And Mapping (CTSLAM) has become a promising approach for fusing asynchronous and multi-modal sensor suites. Unlike discrete-time SLAM, which estimates poses discretely, CTSLAM uses continuous-time motion parametrizations, facilitating the integration of a variety of sensors such as rolling-shutter cameras, event cameras and Inertial Measurement Units (IMUs). However, CTSLAM approaches remain computationally demanding and are conventionally posed as centralized Non-Linear Least Squares (NLLS) optimizations. Targeting these limitations, we not only present the fastest SymForce-based [Martiros et al., RSS 2022] B- and Z-Spline implementations achieving speedups between 2.43x and 110.31x over Sommer et al. [CVPR 2020] but also implement a novel continuous-time Gaussian Belief Propagation (GBP) framework, coined Hyperion, which targets decentralized probabilistic inference across agents. We demonstrate the efficacy of our method in motion tracking and localization settings, complemented by empirical ablation studies.","sentences":["Continuous-Time Simultaneous Localization And Mapping (CTSLAM) has become a promising approach for fusing asynchronous and multi-modal sensor suites.","Unlike discrete-time SLAM, which estimates poses discretely, CTSLAM uses continuous-time motion parametrizations, facilitating the integration of a variety of sensors such as rolling-shutter cameras, event cameras and Inertial Measurement Units (IMUs).","However, CTSLAM approaches remain computationally demanding and are conventionally posed as centralized Non-Linear Least Squares (NLLS) optimizations.","Targeting these limitations, we not only present the fastest SymForce-based [Martiros et al., RSS 2022]","B- and Z-Spline implementations achieving speedups between 2.43x and 110.31x over Sommer et al.","[CVPR 2020] but also implement a novel continuous-time Gaussian Belief Propagation (GBP) framework, coined Hyperion, which targets decentralized probabilistic inference across agents.","We demonstrate the efficacy of our method in motion tracking and localization settings, complemented by empirical ablation studies."],"url":"http://arxiv.org/abs/2407.07074v1"}
{"created":"2024-07-09 17:44:34","title":"Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps","abstract":"When asked to summarize articles or answer questions given a passage, large language models (LLMs) can hallucinate details and respond with unsubstantiated answers that are inaccurate with respect to the input context. This paper describes a simple approach for detecting such contextual hallucinations. We hypothesize that contextual hallucinations are related to the extent to which an LLM attends to information in the provided context versus its own generations. Based on this intuition, we propose a simple hallucination detection model whose input features are given by the ratio of attention weights on the context versus newly generated tokens (for each attention head). We find that a linear classifier based on these lookback ratio features is as effective as a richer detector that utilizes the entire hidden states of an LLM or a text-based entailment model. The lookback ratio-based detector -- Lookback Lens -- is found to transfer across tasks and even models, allowing a detector that is trained on a 7B model to be applied (without retraining) to a larger 13B model. We further apply this detector to mitigate contextual hallucinations, and find that a simple classifier-guided decoding approach is able to reduce the amount of hallucination, for example by 9.6% in the XSum summarization task.","sentences":["When asked to summarize articles or answer questions given a passage, large language models (LLMs) can hallucinate details and respond with unsubstantiated answers that are inaccurate with respect to the input context.","This paper describes a simple approach for detecting such contextual hallucinations.","We hypothesize that contextual hallucinations are related to the extent to which an LLM attends to information in the provided context versus its own generations.","Based on this intuition, we propose a simple hallucination detection model whose input features are given by the ratio of attention weights on the context versus newly generated tokens (for each attention head).","We find that a linear classifier based on these lookback ratio features is as effective as a richer detector that utilizes the entire hidden states of an LLM or a text-based entailment model.","The lookback ratio-based detector -- Lookback Lens -- is found to transfer across tasks and even models, allowing a detector that is trained on a 7B model to be applied (without retraining) to a larger 13B model.","We further apply this detector to mitigate contextual hallucinations, and find that a simple classifier-guided decoding approach is able to reduce the amount of hallucination, for example by 9.6% in the XSum summarization task."],"url":"http://arxiv.org/abs/2407.07071v1"}
{"created":"2024-07-09 17:42:26","title":"Explainable Hyperdimensional Computing for Balancing Privacy and Transparency in Additive Manufacturing Monitoring","abstract":"In-situ sensing, in conjunction with learning models, presents a unique opportunity to address persistent defect issues in Additive Manufacturing (AM) processes. However, this integration introduces significant data privacy concerns, such as data leakage, sensor data compromise, and model inversion attacks, revealing critical details about part design, material composition, and machine parameters. Differential Privacy (DP) models, which inject noise into data under mathematical guarantees, offer a nuanced balance between data utility and privacy by obscuring traces of sensing data. However, the introduction of noise into learning models, often functioning as black boxes, complicates the prediction of how specific noise levels impact model accuracy. This study introduces the Differential Privacy-HyperDimensional computing (DP-HD) framework, leveraging the explainability of the vector symbolic paradigm to predict the noise impact on the accuracy of in-situ monitoring, safeguarding sensitive data while maintaining operational efficiency. Experimental results on real-world high-speed melt pool data of AM for detecting overhang anomalies demonstrate that DP-HD achieves superior operational efficiency, prediction accuracy, and robust privacy protection, outperforming state-of-the-art Machine Learning (ML) models. For example, when implementing the same level of privacy protection (with a privacy budget set at 1), our model achieved an accuracy of 94.43\\%, surpassing the performance of traditional models such as ResNet50 (52.30\\%), GoogLeNet (23.85\\%), AlexNet (55.78\\%), DenseNet201 (69.13\\%), and EfficientNet B2 (40.81\\%). Notably, DP-HD maintains high performance under substantial noise additions designed to enhance privacy, unlike current models that suffer significant accuracy declines under high privacy constraints.","sentences":["In-situ sensing, in conjunction with learning models, presents a unique opportunity to address persistent defect issues in Additive Manufacturing (AM) processes.","However, this integration introduces significant data privacy concerns, such as data leakage, sensor data compromise, and model inversion attacks, revealing critical details about part design, material composition, and machine parameters.","Differential Privacy (DP) models, which inject noise into data under mathematical guarantees, offer a nuanced balance between data utility and privacy by obscuring traces of sensing data.","However, the introduction of noise into learning models, often functioning as black boxes, complicates the prediction of how specific noise levels impact model accuracy.","This study introduces the Differential Privacy-HyperDimensional computing (DP-HD) framework, leveraging the explainability of the vector symbolic paradigm to predict the noise impact on the accuracy of in-situ monitoring, safeguarding sensitive data while maintaining operational efficiency.","Experimental results on real-world high-speed melt pool data of AM for detecting overhang anomalies demonstrate that DP-HD achieves superior operational efficiency, prediction accuracy, and robust privacy protection, outperforming state-of-the-art Machine Learning (ML) models.","For example, when implementing the same level of privacy protection (with a privacy budget set at 1), our model achieved an accuracy of 94.43\\%, surpassing the performance of traditional models such as ResNet50 (52.30\\%), GoogLeNet (23.85\\%), AlexNet (55.78\\%), DenseNet201 (69.13\\%), and EfficientNet B2 (40.81\\%).","Notably, DP-HD maintains high performance under substantial noise additions designed to enhance privacy, unlike current models that suffer significant accuracy declines under high privacy constraints."],"url":"http://arxiv.org/abs/2407.07066v1"}
{"created":"2024-07-09 17:38:03","title":"Prompting Techniques for Secure Code Generation: A Systematic Investigation","abstract":"Large Language Models (LLMs) are gaining momentum in software development with prompt-driven programming enabling developers to create code from natural language (NL) instructions. However, studies have questioned their ability to produce secure code and, thereby, the quality of prompt-generated software. Alongside, various prompting techniques that carefully tailor prompts have emerged to elicit optimal responses from LLMs. Still, the interplay between such prompting strategies and secure code generation remains under-explored and calls for further investigations. OBJECTIVE: In this study, we investigate the impact of different prompting techniques on the security of code generated from NL instructions by LLMs. METHOD: First we perform a systematic literature review to identify the existing prompting techniques that can be used for code generation tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5, and GPT-4 models for secure code generation. For this, we used an existing dataset consisting of 150 NL security-relevant code-generation prompts. RESULTS: Our work (i) classifies potential prompting techniques for code generation (ii) adapts and evaluates a subset of the identified techniques for secure code generation tasks and (iii) observes a reduction in security weaknesses across the tested LLMs, especially after using an existing technique called Recursive Criticism and Improvement (RCI), contributing valuable insights to the ongoing discourse on LLM-generated code security.","sentences":["Large Language Models (LLMs) are gaining momentum in software development with prompt-driven programming enabling developers to create code from natural language (NL) instructions.","However, studies have questioned their ability to produce secure code and, thereby, the quality of prompt-generated software.","Alongside, various prompting techniques that carefully tailor prompts have emerged to elicit optimal responses from LLMs.","Still, the interplay between such prompting strategies and secure code generation remains under-explored and calls for further investigations.","OBJECTIVE:","In this study, we investigate the impact of different prompting techniques on the security of code generated from NL instructions by LLMs.","METHOD:","First we perform a systematic literature review to identify the existing prompting techniques that can be used for code generation tasks.","A subset of these techniques are evaluated on GPT-3, GPT-3.5, and GPT-4 models for secure code generation.","For this, we used an existing dataset consisting of 150 NL security-relevant code-generation prompts.","RESULTS:","Our work (i) classifies potential prompting techniques for code generation (ii) adapts and evaluates a subset of the identified techniques for secure code generation tasks and (iii) observes a reduction in security weaknesses across the tested LLMs, especially after using an existing technique called Recursive Criticism and Improvement (RCI), contributing valuable insights to the ongoing discourse on LLM-generated code security."],"url":"http://arxiv.org/abs/2407.07064v1"}
{"created":"2024-07-09 17:33:24","title":"Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence","abstract":"The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents. However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems. They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups. Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements. Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration. IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control. Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate effective collaboration among heterogeneous agents. IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities. Our codebase has been released at \\url{https://github.com/OpenBMB/IoA}.","sentences":["The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents.","However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems.","They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups.","Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements.","Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration.","IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control.","Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate effective collaboration among heterogeneous agents.","IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities.","Our codebase has been released at \\url{https://github.com/OpenBMB/IoA}."],"url":"http://arxiv.org/abs/2407.07061v1"}
{"created":"2024-07-09 17:29:10","title":"An efficient implementation for solving the all pairs minimax path problem in an undirected dense graph","abstract":"We provide an efficient $ O(n^2) $ implementation for solving the all pairs minimax path problem or widest path problem in an undirected dense graph. It is a code implementation of the Algorithm 4 (MMJ distance by Calculation and Copy) in a previous paper. The distance matrix is also called the all points path distance (APPD). We conducted experiments to test the implementation and algorithm, compared it with several other algorithms for solving the APPD matrix. Result shows Algorithm 4 works good for solving the widest path or minimax path APPD matrix. It can drastically improve the efficiency for computing the APPD matrix. There are several theoretical outcomes which claim the APPD matrix can be solved accurately in $ O(n^2) $ . However, they are impractical because there is no code implementation of these algorithms. It seems Algorithm 4 is the first algorithm that has an actual code implementation for solving the APPD matrix of minimax path or widest path problem in $ O(n^2) $, in an undirected dense graph.","sentences":["We provide an efficient $ O(n^2) $ implementation for solving the all pairs minimax path problem or widest path problem in an undirected dense graph.","It is a code implementation of the Algorithm 4 (MMJ distance by Calculation and Copy) in a previous paper.","The distance matrix is also called the all points path distance (APPD).","We conducted experiments to test the implementation and algorithm, compared it with several other algorithms for solving the APPD matrix.","Result shows Algorithm 4 works good for solving the widest path or minimax path APPD matrix.","It can drastically improve the efficiency for computing the APPD matrix.","There are several theoretical outcomes which claim the APPD matrix can be solved accurately in $ O(n^2) $ .","However, they are impractical because there is no code implementation of these algorithms.","It seems Algorithm 4 is the first algorithm that has an actual code implementation for solving the APPD matrix of minimax path or widest path problem in $ O(n^2) $, in an undirected dense graph."],"url":"http://arxiv.org/abs/2407.07058v1"}
{"created":"2024-07-09 17:26:04","title":"Elevating Academic Administration: A Comprehensive Faculty Dashboard for Tracking Student Evaluations and Research","abstract":"The USC Faculty Dashboard is a web application designed to revolutionize how department heads, professors, and instructors monitor progress and make decisions, providing a centralized hub for efficient data storage and analysis. Currently, there's a gap in tools tailored for department heads to concisely manage the performance of their department, which our platform aims to fill. The USC Faculty Dashboard offers easy access to upload and view student evaluation and research information, empowering department heads to evaluate the performance of faculty members and seamlessly track their research grants, publications, and expenditures. Furthermore, professors and instructors gain personalized performance analysis tools, with full access to their own data as well as curated access to peer data to assess their relative performance. The source code as well as the link to the deployed application can be found at https://github.com/SCCapstone/K3MS.","sentences":["The USC Faculty Dashboard is a web application designed to revolutionize how department heads, professors, and instructors monitor progress and make decisions, providing a centralized hub for efficient data storage and analysis.","Currently, there's a gap in tools tailored for department heads to concisely manage the performance of their department, which our platform aims to fill.","The USC Faculty Dashboard offers easy access to upload and view student evaluation and research information, empowering department heads to evaluate the performance of faculty members and seamlessly track their research grants, publications, and expenditures.","Furthermore, professors and instructors gain personalized performance analysis tools, with full access to their own data as well as curated access to peer data to assess their relative performance.","The source code as well as the link to the deployed application can be found at https://github.com/SCCapstone/K3MS."],"url":"http://arxiv.org/abs/2407.07057v1"}
{"created":"2024-07-09 17:25:04","title":"CAPformer: Compression-Aware Pre-trained Transformer for Low-Light Image Enhancement","abstract":"Low-Light Image Enhancement (LLIE) has advanced with the surge in phone photography demand, yet many existing methods neglect compression, a crucial concern for resource-constrained phone photography. Most LLIE methods overlook this, hindering their effectiveness. In this study, we investigate the effects of JPEG compression on low-light images and reveal substantial information loss caused by JPEG due to widespread low pixel values in dark areas. Hence, we propose the Compression-Aware Pre-trained Transformer (CAPformer), employing a novel pre-training strategy to learn lossless information from uncompressed low-light images. Additionally, the proposed Brightness-Guided Self-Attention (BGSA) mechanism enhances rational information gathering. Experiments demonstrate the superiority of our approach in mitigating compression effects on LLIE, showcasing its potential for improving LLIE in resource-constrained scenarios.","sentences":["Low-Light Image Enhancement (LLIE) has advanced with the surge in phone photography demand, yet many existing methods neglect compression, a crucial concern for resource-constrained phone photography.","Most LLIE methods overlook this, hindering their effectiveness.","In this study, we investigate the effects of JPEG compression on low-light images and reveal substantial information loss caused by JPEG due to widespread low pixel values in dark areas.","Hence, we propose the Compression-Aware Pre-trained Transformer (CAPformer), employing a novel pre-training strategy to learn lossless information from uncompressed low-light images.","Additionally, the proposed Brightness-Guided Self-Attention (BGSA) mechanism enhances rational information gathering.","Experiments demonstrate the superiority of our approach in mitigating compression effects on LLIE, showcasing its potential for improving LLIE in resource-constrained scenarios."],"url":"http://arxiv.org/abs/2407.07056v1"}
{"created":"2024-07-09 17:20:49","title":"A Differentially Private Blockchain-Based Approach for Vertical Federated Learning","abstract":"We present the Differentially Private Blockchain-Based Vertical Federal Learning (DP-BBVFL) algorithm that provides verifiability and privacy guarantees for decentralized applications. DP-BBVFL uses a smart contract to aggregate the feature representations, i.e., the embeddings, from clients transparently. We apply local differential privacy to provide privacy for embeddings stored on a blockchain, hence protecting the original data. We provide the first prototype application of differential privacy with blockchain for vertical federated learning. Our experiments with medical data show that DP-BBVFL achieves high accuracy with a tradeoff in training time due to on-chain aggregation. This innovative fusion of differential privacy and blockchain technology in DP-BBVFL could herald a new era of collaborative and trustworthy machine learning applications across several decentralized application domains.","sentences":["We present the Differentially Private Blockchain-Based Vertical Federal Learning (DP-BBVFL) algorithm that provides verifiability and privacy guarantees for decentralized applications.","DP-BBVFL uses a smart contract to aggregate the feature representations, i.e., the embeddings, from clients transparently.","We apply local differential privacy to provide privacy for embeddings stored on a blockchain, hence protecting the original data.","We provide the first prototype application of differential privacy with blockchain for vertical federated learning.","Our experiments with medical data show that DP-BBVFL achieves high accuracy with a tradeoff in training time due to on-chain aggregation.","This innovative fusion of differential privacy and blockchain technology in DP-BBVFL could herald a new era of collaborative and trustworthy machine learning applications across several decentralized application domains."],"url":"http://arxiv.org/abs/2407.07054v1"}
{"created":"2024-07-09 17:18:27","title":"Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model","abstract":"Although most current large multimodal models (LMMs) can already understand photos of natural scenes and portraits, their understanding of abstract images, e.g., charts, maps, or layouts, and visual reasoning capabilities remains quite rudimentary. They often struggle with simple daily tasks, such as reading time from a clock, understanding a flowchart, or planning a route using a road map. In light of this, we design a multi-modal self-instruct, utilizing large language models and their code capabilities to synthesize massive abstract images and visual reasoning instructions across daily scenarios. Our strategy effortlessly creates a multimodal benchmark with 11,193 instructions for eight visual scenarios: charts, tables, simulated maps, dashboards, flowcharts, relation graphs, floor plans, and visual puzzles. \\textbf{This benchmark, constructed with simple lines and geometric elements, exposes the shortcomings of most advanced LMMs} like Claude-3.5-Sonnet and GPT-4o in abstract image understanding, spatial relations reasoning, and visual element induction. Besides, to verify the quality of our synthetic data, we fine-tune an LMM using 62,476 synthetic chart, table and road map instructions. The results demonstrate improved chart understanding and map navigation performance, and also demonstrate potential benefits for other visual reasoning tasks. Our code is available at: \\url{https://github.com/zwq2018/Multi-modal-Self-instruct}.","sentences":["Although most current large multimodal models (LMMs) can already understand photos of natural scenes and portraits, their understanding of abstract images, e.g., charts, maps, or layouts, and visual reasoning capabilities remains quite rudimentary.","They often struggle with simple daily tasks, such as reading time from a clock, understanding a flowchart, or planning a route using a road map.","In light of this, we design a multi-modal self-instruct, utilizing large language models and their code capabilities to synthesize massive abstract images and visual reasoning instructions across daily scenarios.","Our strategy effortlessly creates a multimodal benchmark with 11,193 instructions for eight visual scenarios: charts, tables, simulated maps, dashboards, flowcharts, relation graphs, floor plans, and visual puzzles.","\\textbf{This benchmark, constructed with simple lines and geometric elements, exposes the shortcomings of most advanced LMMs} like Claude-3.5-Sonnet and GPT-4o in abstract image understanding, spatial relations reasoning, and visual element induction.","Besides, to verify the quality of our synthetic data, we fine-tune an LMM using 62,476 synthetic chart, table and road map instructions.","The results demonstrate improved chart understanding and map navigation performance, and also demonstrate potential benefits for other visual reasoning tasks.","Our code is available at: \\url{https://github.com/zwq2018/Multi-modal-Self-instruct}."],"url":"http://arxiv.org/abs/2407.07053v1"}
{"created":"2024-07-09 17:14:28","title":"Counting Small Induced Subgraphs: Hardness via Fourier Analysis","abstract":"For a fixed graph property $\\Phi$ and integer $k \\geq 1$, the problem $\\#\\mathrm{IndSub}(\\Phi,k)$ asks to count the induced $k$-vertex subgraphs satisfying $\\Phi$ in an input graph $G$. If $\\Phi$ is trivial on $k$-vertex graphs (i.e., if $\\Phi$ contains either all or no $k$-vertex graphs), this problem is trivial. Otherwise we prove, among other results:   - If $\\Phi$ is edge-monotone (i.e., closed under deleting edges), then $\\#\\mathrm{IndSub}(\\Phi,k)$ cannot be solved in time $n^{o(k)}$ assuming ETH. This strengthens a result by D\\\"oring, Marx and Wellnitz [STOC 2024] that only ruled out an exponent of $o(\\sqrt{\\log k}/ \\log \\log k)$. Our results also hold when counting modulo fixed primes.   - If there is some fixed $\\varepsilon > 0$ such that at most $(2-\\varepsilon)^{\\binom{k}{2}}$ graphs on $k$ vertices satisfy $\\Phi$, then $\\#\\mathrm{IndSub}(\\Phi,k)$ cannot be solved in time $n^{o(k/\\sqrt{\\log k})}$ assuming ETH. Our results hold even when each of the graphs in $\\Phi$ may come with an arbitrary individual weight. This generalizes previous results for hereditary properties by Focke and Roth [SIAM J.\\ Comput.\\ 2024] up to a $\\sqrt{\\log k}$ factor in the exponent of the lower bound.   - If $\\Phi$ only depends on the number of edges, then $\\#\\mathrm{IndSub}(\\Phi,k)$ cannot be solved in time $n^{o(k)}$ assuming ETH. This improves on a lower bound by Roth, Schmitt and Wellnitz [FOCS 2020] that only ruled out an exponent of $o(k / \\sqrt{\\log k})$.   In all cases, we also obtain $\\mathsf{\\#W[1]}$-hardness if $k$ is part of the input and the problem is parameterized by $k$. We also obtain lower bounds on the Weisfeiler-Leman dimension. Our results follow from relatively straightforward Fourier analysis, and our paper subsumes most of the known $\\mathsf{\\#W[1]}$-hardness results known in the area, often with tighter lower bounds under ETH.","sentences":["For a fixed graph property $\\Phi$ and integer $k \\geq 1$, the problem $\\#\\mathrm{IndSub}(\\Phi,k)$ asks to count the induced $k$-vertex subgraphs satisfying $\\Phi$ in an input graph $G$.","If $\\Phi$ is trivial on $k$-vertex graphs (i.e., if $\\Phi$ contains either all or no $k$-vertex graphs), this problem is trivial.","Otherwise we prove, among other results:   -","If $\\Phi$ is edge-monotone (i.e., closed under deleting edges), then $\\#\\mathrm{IndSub}(\\Phi,k)$ cannot be solved in time $n^{o(k)}$ assuming ETH.","This strengthens a result by D\\\"oring, Marx and Wellnitz","[STOC 2024] that only ruled out an exponent of $o(\\sqrt{\\log k}/ \\log \\log k)$.","Our results also hold when counting modulo fixed primes.   ","- If there is some fixed $\\varepsilon > 0$ such that at most $(2-\\varepsilon)^{\\binom{k}{2}}$ graphs on $k$ vertices satisfy $\\Phi$, then $\\#\\mathrm{IndSub}(\\Phi,k)$ cannot be solved in time $n^{o(k/\\sqrt{\\log k})}$ assuming ETH.","Our results hold even when each of the graphs in $\\Phi$ may come with an arbitrary individual weight.","This generalizes previous results for hereditary properties by Focke and Roth [SIAM J.\\ Comput.\\ 2024] up to a $\\sqrt{\\log k}$ factor in the exponent of the lower bound.   -","If $\\Phi$ only depends on the number of edges, then $\\#\\mathrm{IndSub}(\\Phi,k)$ cannot be solved in time $n^{o(k)}$ assuming ETH.","This improves on a lower bound by Roth, Schmitt and Wellnitz","[FOCS 2020] that only ruled out an exponent of $o(k / \\sqrt{\\log k})$.   In all cases, we also obtain $\\mathsf{\\#W[1]}$-hardness if $k$ is part of the input and the problem is parameterized by $k$. We also obtain lower bounds on the Weisfeiler-Leman dimension.","Our results follow from relatively straightforward Fourier analysis, and our paper subsumes most of the known $\\mathsf{\\#W[1]}$-hardness results known in the area, often with tighter lower bounds under ETH."],"url":"http://arxiv.org/abs/2407.07051v1"}
{"created":"2024-07-09 17:07:29","title":"CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis","abstract":"Multimodal sentiment analysis is an active research area that combines multiple data modalities, e.g., text, image and audio, to analyze human emotions and benefits a variety of applications. Existing multimodal sentiment analysis methods can be classified as modality interaction-based methods, modality transformation-based methods and modality similarity-based methods. However, most of these methods highly rely on the strong correlations between modalities, and cannot fully uncover and utilize the correlations between modalities to enhance sentiment analysis. Therefore, these methods usually achieve bad performance for identifying the sentiment of multimodal data with weak correlations. To address this issue, we proposed a two-stage semi-supervised model termed Correlation-aware Multimodal Transformer (CorMulT) which consists pre-training stage and prediction stage. At the pre-training stage, a modality correlation contrastive learning module is designed to efficiently learn modality correlation coefficients between different modalities. At the prediction stage, the learned correlation coefficients are fused with modality representations to make the sentiment prediction. According to the experiments on the popular multimodal dataset CMU-MOSEI, CorMulT obviously surpasses state-of-the-art multimodal sentiment analysis methods.","sentences":["Multimodal sentiment analysis is an active research area that combines multiple data modalities, e.g., text, image and audio, to analyze human emotions and benefits a variety of applications.","Existing multimodal sentiment analysis methods can be classified as modality interaction-based methods, modality transformation-based methods and modality similarity-based methods.","However, most of these methods highly rely on the strong correlations between modalities, and cannot fully uncover and utilize the correlations between modalities to enhance sentiment analysis.","Therefore, these methods usually achieve bad performance for identifying the sentiment of multimodal data with weak correlations.","To address this issue, we proposed a two-stage semi-supervised model termed Correlation-aware Multimodal Transformer (CorMulT) which consists pre-training stage and prediction stage.","At the pre-training stage, a modality correlation contrastive learning module is designed to efficiently learn modality correlation coefficients between different modalities.","At the prediction stage, the learned correlation coefficients are fused with modality representations to make the sentiment prediction.","According to the experiments on the popular multimodal dataset CMU-MOSEI, CorMulT obviously surpasses state-of-the-art multimodal sentiment analysis methods."],"url":"http://arxiv.org/abs/2407.07046v1"}
{"created":"2024-07-09 17:05:52","title":"Simple and Interpretable Probabilistic Classifiers for Knowledge Graphs","abstract":"Tackling the problem of learning probabilistic classifiers from incomplete data in the context of Knowledge Graphs expressed in Description Logics, we describe an inductive approach based on learning simple belief networks. Specifically, we consider a basic probabilistic model, a Naive Bayes classifier, based on multivariate Bernoullis and its extension to a two-tier network in which this classification model is connected to a lower layer consisting of a mixture of Bernoullis. We show how such models can be converted into (probabilistic) axioms (or rules) thus ensuring more interpretability. Moreover they may be also initialized exploiting expert knowledge. We present and discuss the outcomes of an empirical evaluation which aimed at testing the effectiveness of the models on a number of random classification problems with different ontologies.","sentences":["Tackling the problem of learning probabilistic classifiers from incomplete data in the context of Knowledge Graphs expressed in Description Logics, we describe an inductive approach based on learning simple belief networks.","Specifically, we consider a basic probabilistic model, a Naive Bayes classifier, based on multivariate Bernoullis and its extension to a two-tier network in which this classification model is connected to a lower layer consisting of a mixture of Bernoullis.","We show how such models can be converted into (probabilistic) axioms (or rules) thus ensuring more interpretability.","Moreover they may be also initialized exploiting expert knowledge.","We present and discuss the outcomes of an empirical evaluation which aimed at testing the effectiveness of the models on a number of random classification problems with different ontologies."],"url":"http://arxiv.org/abs/2407.07045v1"}
{"created":"2024-07-09 17:04:08","title":"ProtoSAM - One Shot Medical Image Segmentation With Foundational Models","abstract":"This work introduces a new framework, ProtoSAM, for one-shot medical image segmentation. It combines the use of prototypical networks, known for few-shot segmentation, with SAM - a natural image foundation model. The method proposed creates an initial coarse segmentation mask using the ALPnet prototypical network, augmented with a DINOv2 encoder. Following the extraction of an initial mask, prompts are extracted, such as points and bounding boxes, which are then input into the Segment Anything Model (SAM). State-of-the-art results are shown on several medical image datasets and demonstrate automated segmentation capabilities using a single image example (one shot) with no need for fine-tuning of the foundation model.","sentences":["This work introduces a new framework, ProtoSAM, for one-shot medical image segmentation.","It combines the use of prototypical networks, known for few-shot segmentation, with SAM - a natural image foundation model.","The method proposed creates an initial coarse segmentation mask using the ALPnet prototypical network, augmented with a DINOv2 encoder.","Following the extraction of an initial mask, prompts are extracted, such as points and bounding boxes, which are then input into the Segment Anything Model (SAM).","State-of-the-art results are shown on several medical image datasets and demonstrate automated segmentation capabilities using a single image example (one shot) with no need for fine-tuning of the foundation model."],"url":"http://arxiv.org/abs/2407.07042v1"}
{"created":"2024-07-09 17:03:57","title":"Hiding Local Manipulations on SAR Images: a Counter-Forensic Attack","abstract":"The vast accessibility of Synthetic Aperture Radar (SAR) images through online portals has propelled the research across various fields. This widespread use and easy availability have unfortunately made SAR data susceptible to malicious alterations, such as local editing applied to the images for inserting or covering the presence of sensitive targets. Vulnerability is further emphasized by the fact that most SAR products, despite their original complex nature, are often released as amplitude-only information, allowing even inexperienced attackers to edit and easily alter the pixel content. To contrast malicious manipulations, in the last years the forensic community has begun to dig into the SAR manipulation issue, proposing detectors that effectively localize the tampering traces in amplitude images. Nonetheless, in this paper we demonstrate that an expert practitioner can exploit the complex nature of SAR data to obscure any signs of manipulation within a locally altered amplitude image. We refer to this approach as a counter-forensic attack. To achieve the concealment of manipulation traces, the attacker can simulate a re-acquisition of the manipulated scene by the SAR system that initially generated the pristine image. In doing so, the attacker can obscure any evidence of manipulation, making it appear as if the image was legitimately produced by the system. We assess the effectiveness of the proposed counter-forensic approach across diverse scenarios, examining various manipulation operations. The obtained results indicate that our devised attack successfully eliminates traces of manipulation, deceiving even the most advanced forensic detectors.","sentences":["The vast accessibility of Synthetic Aperture Radar (SAR) images through online portals has propelled the research across various fields.","This widespread use and easy availability have unfortunately made SAR data susceptible to malicious alterations, such as local editing applied to the images for inserting or covering the presence of sensitive targets.","Vulnerability is further emphasized by the fact that most SAR products, despite their original complex nature, are often released as amplitude-only information, allowing even inexperienced attackers to edit and easily alter the pixel content.","To contrast malicious manipulations, in the last years the forensic community has begun to dig into the SAR manipulation issue, proposing detectors that effectively localize the tampering traces in amplitude images.","Nonetheless, in this paper we demonstrate that an expert practitioner can exploit the complex nature of SAR data to obscure any signs of manipulation within a locally altered amplitude image.","We refer to this approach as a counter-forensic attack.","To achieve the concealment of manipulation traces, the attacker can simulate a re-acquisition of the manipulated scene by the SAR system that initially generated the pristine image.","In doing so, the attacker can obscure any evidence of manipulation, making it appear as if the image was legitimately produced by the system.","We assess the effectiveness of the proposed counter-forensic approach across diverse scenarios, examining various manipulation operations.","The obtained results indicate that our devised attack successfully eliminates traces of manipulation, deceiving even the most advanced forensic detectors."],"url":"http://arxiv.org/abs/2407.07041v1"}
{"created":"2024-07-09 17:00:39","title":"Decoding Climate Disagreement: A Graph Neural Network-Based Approach to Understanding Social Media Dynamics","abstract":"This work introduces the ClimateSent-GAT Model, an innovative method that integrates Graph Attention Networks (GATs) with techniques from natural language processing to accurately identify and predict disagreements within Reddit comment-reply pairs. Our model classifies disagreements into three categories: agree, disagree, and neutral. Leveraging the inherent graph structure of Reddit comment-reply pairs, the model significantly outperforms existing benchmarks by capturing complex interaction patterns and sentiment dynamics. This research advances graph-based NLP methodologies and provides actionable insights for policymakers and educators in climate science communication.","sentences":["This work introduces the ClimateSent-GAT Model, an innovative method that integrates Graph Attention Networks (GATs) with techniques from natural language processing to accurately identify and predict disagreements within Reddit comment-reply pairs.","Our model classifies disagreements into three categories: agree, disagree, and neutral.","Leveraging the inherent graph structure of Reddit comment-reply pairs, the model significantly outperforms existing benchmarks by capturing complex interaction patterns and sentiment dynamics.","This research advances graph-based NLP methodologies and provides actionable insights for policymakers and educators in climate science communication."],"url":"http://arxiv.org/abs/2407.07038v1"}
{"created":"2024-07-09 16:53:36","title":"Vision-and-Language Navigation Today and Tomorrow: A Survey in the Era of Foundation Models","abstract":"Vision-and-Language Navigation (VLN) has gained increasing attention over recent years and many approaches have emerged to advance their development. The remarkable achievements of foundation models have shaped the challenges and proposed methods for VLN research. In this survey, we provide a top-down review that adopts a principled framework for embodied planning and reasoning, and emphasizes the current methods and future opportunities leveraging foundation models to address VLN challenges. We hope our in-depth discussions could provide valuable resources and insights: on one hand, to milestone the progress and explore opportunities and potential roles for foundation models in this field, and on the other, to organize different challenges and solutions in VLN to foundation model researchers.","sentences":["Vision-and-Language Navigation (VLN) has gained increasing attention over recent years and many approaches have emerged to advance their development.","The remarkable achievements of foundation models have shaped the challenges and proposed methods for VLN research.","In this survey, we provide a top-down review that adopts a principled framework for embodied planning and reasoning, and emphasizes the current methods and future opportunities leveraging foundation models to address VLN challenges.","We hope our in-depth discussions could provide valuable resources and insights: on one hand, to milestone the progress and explore opportunities and potential roles for foundation models in this field, and on the other, to organize different challenges and solutions in VLN to foundation model researchers."],"url":"http://arxiv.org/abs/2407.07035v1"}
{"created":"2024-07-09 16:50:15","title":"Trajectory Data Mining and Trip Travel Time Prediction on Specific Roads","abstract":"Predicting a trip's travel time is essential for route planning and navigation applications. The majority of research is based on international data that does not apply to Pakistan's road conditions. We designed a complete pipeline for mining trajectories from sensors data. On this data, we employed state-of-the-art approaches, including a shallow artificial neural network, a deep multi-layered perceptron, and a long-short-term memory, to explore the issue of travel time prediction on frequent routes. The experimental results demonstrate an average prediction error ranging from 30 seconds to 1.2 minutes on trips lasting 10 minutes to 60 minutes on six most frequent routes in regions of Islamabad, Pakistan.","sentences":["Predicting a trip's travel time is essential for route planning and navigation applications.","The majority of research is based on international data that does not apply to Pakistan's road conditions.","We designed a complete pipeline for mining trajectories from sensors data.","On this data, we employed state-of-the-art approaches, including a shallow artificial neural network, a deep multi-layered perceptron, and a long-short-term memory, to explore the issue of travel time prediction on frequent routes.","The experimental results demonstrate an average prediction error ranging from 30 seconds to 1.2 minutes on trips lasting 10 minutes to 60 minutes on six most frequent routes in regions of Islamabad, Pakistan."],"url":"http://arxiv.org/abs/2407.07030v1"}
{"created":"2024-07-09 16:48:09","title":"Constructing $k$-ary Orientable Sequences with Asymptotically Optimal Length","abstract":"An orientable sequence of order $n$ over an alphabet $\\{0,1,\\ldots, k{-}1\\}$ is a cyclic sequence such that each length-$n$ substring appears at most once \\emph{in either direction}. When $k= 2$, efficient algorithms are known to construct binary orientable sequences, with asymptotically optimal length, by applying the classic cycle-joining technique. The key to the construction is the definition of a parent rule to construct a cycle-joining tree of asymmetric bracelets. Unfortunately, the parent rule does not generalize to larger alphabets. Furthermore, unlike the binary case, a cycle-joining tree does not immediately lead to a simple successor-rule when $k \\geq 3$ unless the tree has certain properties. In this paper, we derive a parent rule to derive a cycle-joining tree of $k$-ary asymmetric bracelets. This leads to a successor rule that constructs asymptotically optimal $k$-ary orientable sequences in $O(n)$ time per symbol using $O(n)$ space. In the special case when $n=2$, we provide a simple construction of $k$-ary orientable sequences of maximal length.","sentences":["An orientable sequence of order $n$ over an alphabet $\\{0,1,\\ldots, k{-}1\\}$ is a cyclic sequence such that each length-$n$ substring appears at most once \\emph{in either direction}.","When $k= 2$, efficient algorithms are known to construct binary orientable sequences, with asymptotically optimal length, by applying the classic cycle-joining technique.","The key to the construction is the definition of a parent rule to construct a cycle-joining tree of asymmetric bracelets.","Unfortunately, the parent rule does not generalize to larger alphabets.","Furthermore, unlike the binary case, a cycle-joining tree does not immediately lead to a simple successor-rule when $k \\geq 3$ unless the tree has certain properties.","In this paper, we derive a parent rule to derive a cycle-joining tree of $k$-ary asymmetric bracelets.","This leads to a successor rule that constructs asymptotically optimal $k$-ary orientable sequences in $O(n)$ time per symbol using $O(n)$ space.","In the special case when $n=2$, we provide a simple construction of $k$-ary orientable sequences of maximal length."],"url":"http://arxiv.org/abs/2407.07029v1"}
{"created":"2024-07-09 16:46:58","title":"Resolving Sentiment Discrepancy for Multimodal Sentiment Detection via Semantics Completion and Decomposition","abstract":"With the proliferation of social media posts in recent years, the need to detect sentiments in multimodal (image-text) content has grown rapidly. Since posts are user-generated, the image and text from the same post can express different or even contradictory sentiments, leading to potential \\textbf{sentiment discrepancy}. However, existing works mainly adopt a single-branch fusion structure that primarily captures the consistent sentiment between image and text. The ignorance or implicit modeling of discrepant sentiment results in compromised unimodal encoding and limited performances. In this paper, we propose a semantics Completion and Decomposition (CoDe) network to resolve the above issue. In the semantics completion module, we complement image and text representations with the semantics of the OCR text embedded in the image, helping bridge the sentiment gap. In the semantics decomposition module, we decompose image and text representations with exclusive projection and contrastive learning, thereby explicitly capturing the discrepant sentiment between modalities. Finally, we fuse image and text representations by cross-attention and combine them with the learned discrepant sentiment for final classification. Extensive experiments conducted on four multimodal sentiment datasets demonstrate the superiority of CoDe against SOTA methods.","sentences":["With the proliferation of social media posts in recent years, the need to detect sentiments in multimodal (image-text) content has grown rapidly.","Since posts are user-generated, the image and text from the same post can express different or even contradictory sentiments, leading to potential \\textbf{sentiment discrepancy}.","However, existing works mainly adopt a single-branch fusion structure that primarily captures the consistent sentiment between image and text.","The ignorance or implicit modeling of discrepant sentiment results in compromised unimodal encoding and limited performances.","In this paper, we propose a semantics Completion and Decomposition (CoDe) network to resolve the above issue.","In the semantics completion module, we complement image and text representations with the semantics of the OCR text embedded in the image, helping bridge the sentiment gap.","In the semantics decomposition module, we decompose image and text representations with exclusive projection and contrastive learning, thereby explicitly capturing the discrepant sentiment between modalities.","Finally, we fuse image and text representations by cross-attention and combine them with the learned discrepant sentiment for final classification.","Extensive experiments conducted on four multimodal sentiment datasets demonstrate the superiority of CoDe against SOTA methods."],"url":"http://arxiv.org/abs/2407.07026v1"}
{"created":"2024-07-09 16:44:04","title":"Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization","abstract":"The vocabulary size in temporal action localization (TAL) is constrained by the scarcity of large-scale annotated datasets. To address this, recent works incorporate powerful pre-trained vision-language models (VLMs), such as CLIP, to perform open-vocabulary TAL (OV-TAL). However, unlike VLMs trained on extensive image/video-text pairs, existing OV-TAL methods still rely on small, fully labeled TAL datasets for training an action localizer. In this paper, we explore the scalability of self-training with unlabeled YouTube videos for OV-TAL. Our self-training approach consists of two stages. First, a class-agnostic action localizer is trained on a human-labeled TAL dataset and used to generate pseudo-labels for unlabeled videos. Second, the large-scale pseudo-labeled dataset is combined with the human-labeled dataset to train the localizer. Extensive experiments demonstrate that leveraging web-scale videos in self-training significantly enhances the generalizability of an action localizer. Additionally, we highlighted issues with existing OV-TAL evaluation schemes and proposed a new evaluation protocol. Code is released at https://github.com/HYUNJS/STOV-TAL","sentences":["The vocabulary size in temporal action localization (TAL) is constrained by the scarcity of large-scale annotated datasets.","To address this, recent works incorporate powerful pre-trained vision-language models (VLMs), such as CLIP, to perform open-vocabulary TAL (OV-TAL).","However, unlike VLMs trained on extensive image/video-text pairs, existing OV-TAL methods still rely on small, fully labeled TAL datasets for training an action localizer.","In this paper, we explore the scalability of self-training with unlabeled YouTube videos for OV-TAL.","Our self-training approach consists of two stages.","First, a class-agnostic action localizer is trained on a human-labeled TAL dataset and used to generate pseudo-labels for unlabeled videos.","Second, the large-scale pseudo-labeled dataset is combined with the human-labeled dataset to train the localizer.","Extensive experiments demonstrate that leveraging web-scale videos in self-training significantly enhances the generalizability of an action localizer.","Additionally, we highlighted issues with existing OV-TAL evaluation schemes and proposed a new evaluation protocol.","Code is released at https://github.com/HYUNJS/STOV-TAL"],"url":"http://arxiv.org/abs/2407.07024v1"}
{"created":"2024-07-09 16:42:17","title":"Less is More: Efficient Brain-Inspired Learning for Autonomous Driving Trajectory Prediction","abstract":"Accurately and safely predicting the trajectories of surrounding vehicles is essential for fully realizing autonomous driving (AD). This paper presents the Human-Like Trajectory Prediction model (HLTP++), which emulates human cognitive processes to improve trajectory prediction in AD. HLTP++ incorporates a novel teacher-student knowledge distillation framework. The \"teacher\" model equipped with an adaptive visual sector, mimics the dynamic allocation of attention human drivers exhibit based on factors like spatial orientation, proximity, and driving speed. On the other hand, the \"student\" model focuses on real-time interaction and human decision-making, drawing parallels to the human memory storage mechanism. Furthermore, we improve the model's efficiency by introducing a new Fourier Adaptive Spike Neural Network (FA-SNN), allowing for faster and more precise predictions with fewer parameters. Evaluated using the NGSIM, HighD, and MoCAD benchmarks, HLTP++ demonstrates superior performance compared to existing models, which reduces the predicted trajectory error with over 11% on the NGSIM dataset and 25% on the HighD datasets. Moreover, HLTP++ demonstrates strong adaptability in challenging environments with incomplete input data. This marks a significant stride in the journey towards fully AD systems.","sentences":["Accurately and safely predicting the trajectories of surrounding vehicles is essential for fully realizing autonomous driving (AD).","This paper presents the Human-Like Trajectory Prediction model (HLTP++), which emulates human cognitive processes to improve trajectory prediction in AD.","HLTP++ incorporates a novel teacher-student knowledge distillation framework.","The \"teacher\" model equipped with an adaptive visual sector, mimics the dynamic allocation of attention human drivers exhibit based on factors like spatial orientation, proximity, and driving speed.","On the other hand, the \"student\" model focuses on real-time interaction and human decision-making, drawing parallels to the human memory storage mechanism.","Furthermore, we improve the model's efficiency by introducing a new Fourier Adaptive Spike Neural Network (FA-SNN), allowing for faster and more precise predictions with fewer parameters.","Evaluated using the NGSIM, HighD, and MoCAD benchmarks, HLTP++ demonstrates superior performance compared to existing models, which reduces the predicted trajectory error with over 11% on the NGSIM dataset and 25% on the HighD datasets.","Moreover, HLTP++ demonstrates strong adaptability in challenging environments with incomplete input data.","This marks a significant stride in the journey towards fully AD systems."],"url":"http://arxiv.org/abs/2407.07020v1"}
{"created":"2024-07-09 16:40:44","title":"Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies","abstract":"We explore using Large Language Models (LLMs) to generate application code that automates health insurance processes from text-based policies. We target blockchain-based smart contracts as they offer immutability, verifiability, scalability, and a trustless setting: any number of parties can use the smart contracts, and they need not have previously established trust relationships with each other. Our methodology generates outputs at increasing levels of technical detail: (1) textual summaries, (2) declarative decision logic, and (3) smart contract code with unit tests. We ascertain LLMs are good at the task (1), and the structured output is useful to validate tasks (2) and (3). Declarative languages (task 2) are often used to formalize healthcare policies, but their execution on blockchain is non-trivial. Hence, task (3) attempts to directly automate the process using smart contracts. To assess the LLM output, we propose completeness, soundness, clarity, syntax, and functioning code as metrics. Our evaluation employs three health insurance policies (scenarios) with increasing difficulty from Medicare's official booklet. Our evaluation uses GPT-3.5 Turbo, GPT-3.5 Turbo 16K, GPT-4, GPT-4 Turbo and CodeLLaMA. Our findings confirm that LLMs perform quite well in generating textual summaries. Although outputs from tasks (2)-(3) are useful starting points, they require human oversight: in multiple cases, even \"runnable\" code will not yield sound results; the popularity of the target language affects the output quality; and more complex scenarios still seem a bridge too far. Nevertheless, our experiments demonstrate the promise of LLMs for translating textual process descriptions into smart contracts.","sentences":["We explore using Large Language Models (LLMs) to generate application code that automates health insurance processes from text-based policies.","We target blockchain-based smart contracts as they offer immutability, verifiability, scalability, and a trustless setting: any number of parties can use the smart contracts, and they need not have previously established trust relationships with each other.","Our methodology generates outputs at increasing levels of technical detail: (1) textual summaries, (2) declarative decision logic, and (3) smart contract code with unit tests.","We ascertain LLMs are good at the task (1), and the structured output is useful to validate tasks (2) and (3).","Declarative languages (task 2) are often used to formalize healthcare policies, but their execution on blockchain is non-trivial.","Hence, task (3) attempts to directly automate the process using smart contracts.","To assess the LLM output, we propose completeness, soundness, clarity, syntax, and functioning code as metrics.","Our evaluation employs three health insurance policies (scenarios) with increasing difficulty from Medicare's official booklet.","Our evaluation uses GPT-3.5","Turbo, GPT-3.5","Turbo 16K, GPT-4, GPT-4 Turbo and CodeLLaMA.","Our findings confirm that LLMs perform quite well in generating textual summaries.","Although outputs from tasks (2)-(3) are useful starting points, they require human oversight: in multiple cases, even \"runnable\" code will not yield sound results; the popularity of the target language affects the output quality; and more complex scenarios still seem a bridge too far.","Nevertheless, our experiments demonstrate the promise of LLMs for translating textual process descriptions into smart contracts."],"url":"http://arxiv.org/abs/2407.07019v1"}
{"created":"2024-07-09 16:38:48","title":"End-To-End Causal Effect Estimation from Unstructured Natural Language Data","abstract":"Knowing the effect of an intervention is critical for human decision-making, but current approaches for causal effect estimation rely on manual data collection and structuring, regardless of the causal assumptions. This increases both the cost and time-to-completion for studies. We show how large, diverse observational text data can be mined with large language models (LLMs) to produce inexpensive causal effect estimates under appropriate causal assumptions. We introduce NATURAL, a novel family of causal effect estimators built with LLMs that operate over datasets of unstructured text. Our estimators use LLM conditional distributions (over variables of interest, given the text data) to assist in the computation of classical estimators of causal effect. We overcome a number of technical challenges to realize this idea, such as automating data curation and using LLMs to impute missing information. We prepare six (two synthetic and four real) observational datasets, paired with corresponding ground truth in the form of randomized trials, which we used to systematically evaluate each step of our pipeline. NATURAL estimators demonstrate remarkable performance, yielding causal effect estimates that fall within 3 percentage points of their ground truth counterparts, including on real-world Phase 3/4 clinical trials. Our results suggest that unstructured text data is a rich source of causal effect information, and NATURAL is a first step towards an automated pipeline to tap this resource.","sentences":["Knowing the effect of an intervention is critical for human decision-making, but current approaches for causal effect estimation rely on manual data collection and structuring, regardless of the causal assumptions.","This increases both the cost and time-to-completion for studies.","We show how large, diverse observational text data can be mined with large language models (LLMs) to produce inexpensive causal effect estimates under appropriate causal assumptions.","We introduce NATURAL, a novel family of causal effect estimators built with LLMs that operate over datasets of unstructured text.","Our estimators use LLM conditional distributions (over variables of interest, given the text data) to assist in the computation of classical estimators of causal effect.","We overcome a number of technical challenges to realize this idea, such as automating data curation and using LLMs to impute missing information.","We prepare six (two synthetic and four real) observational datasets, paired with corresponding ground truth in the form of randomized trials, which we used to systematically evaluate each step of our pipeline.","NATURAL estimators demonstrate remarkable performance, yielding causal effect estimates that fall within 3 percentage points of their ground truth counterparts, including on real-world Phase 3/4 clinical trials.","Our results suggest that unstructured text data is a rich source of causal effect information, and NATURAL is a first step towards an automated pipeline to tap this resource."],"url":"http://arxiv.org/abs/2407.07018v1"}
{"created":"2024-07-09 16:33:51","title":"A Framework for Multimodal Medical Image Interaction","abstract":"Medical doctors rely on images of the human anatomy, such as magnetic resonance imaging (MRI), to localize regions of interest in the patient during diagnosis and treatment. Despite advances in medical imaging technology, the information conveyance remains unimodal. This visual representation fails to capture the complexity of the real, multisensory interaction with human tissue. However, perceiving multimodal information about the patient's anatomy and disease in real-time is critical for the success of medical procedures and patient outcome. We introduce a Multimodal Medical Image Interaction (MMII) framework to allow medical experts a dynamic, audiovisual interaction with human tissue in three-dimensional space. In a virtual reality environment, the user receives physically informed audiovisual feedback to improve the spatial perception of anatomical structures. MMII uses a model-based sonification approach to generate sounds derived from the geometry and physical properties of tissue, thereby eliminating the need for hand-crafted sound design. Two user studies involving 34 general and nine clinical experts were conducted to evaluate the proposed interaction framework's learnability, usability, and accuracy. Our results showed excellent learnability of audiovisual correspondence as the rate of correct associations significantly improved (p < 0.001) over the course of the study. MMII resulted in superior brain tumor localization accuracy (p < 0.05) compared to conventional medical image interaction. Our findings substantiate the potential of this novel framework to enhance interaction with medical images, for example, during surgical procedures where immediate and precise feedback is needed.","sentences":["Medical doctors rely on images of the human anatomy, such as magnetic resonance imaging (MRI), to localize regions of interest in the patient during diagnosis and treatment.","Despite advances in medical imaging technology, the information conveyance remains unimodal.","This visual representation fails to capture the complexity of the real, multisensory interaction with human tissue.","However, perceiving multimodal information about the patient's anatomy and disease in real-time is critical for the success of medical procedures and patient outcome.","We introduce a Multimodal Medical Image Interaction (MMII) framework to allow medical experts a dynamic, audiovisual interaction with human tissue in three-dimensional space.","In a virtual reality environment, the user receives physically informed audiovisual feedback to improve the spatial perception of anatomical structures.","MMII uses a model-based sonification approach to generate sounds derived from the geometry and physical properties of tissue, thereby eliminating the need for hand-crafted sound design.","Two user studies involving 34 general and nine clinical experts were conducted to evaluate the proposed interaction framework's learnability, usability, and accuracy.","Our results showed excellent learnability of audiovisual correspondence as the rate of correct associations significantly improved (p < 0.001) over the course of the study.","MMII resulted in superior brain tumor localization accuracy (p < 0.05) compared to conventional medical image interaction.","Our findings substantiate the potential of this novel framework to enhance interaction with medical images, for example, during surgical procedures where immediate and precise feedback is needed."],"url":"http://arxiv.org/abs/2407.07015v1"}
{"created":"2024-07-09 16:33:43","title":"An Attempt to Devise a Pairwise Ising-Type Maximum Entropy Model Integrated Cost Function for Optimizing SNN Deployment","abstract":"The deployment process of a spiking neural network (SNN) can involve partitioning a neural network and mapping partitions onto processing units within the neuromorphic hardware. Searching for optimal deployment schemes presents an NP-hard problem. Optimization of deployment schemes encounters challenges in devising computationally effective cost functions for optimization objectives such as communication time consumption and energy efficiency. These kinds of objectives necessitate consideration of network dynamics shaped by neuron activity patterns, demanding intricate mathematical analyses or simulations for integrating them into a cost model for the deployment of an SNN. The network dynamics are hardware-independent and can be modeled separately from specific hardware configurations. Our approach employs a pairwise Ising-type maximum entropy model, which has shown its effectiveness in accurately reproducing pairwise correlations among components in a system. We utilized this model to capture network dynamics, upon which a cost function is built incorporating hardware-specific parameters. We conducted an extremely preliminary investigation using the SpiNNaker machine. We show that the existing model training can also be computationally complex. Currently, we still lack sufficient evidence to substantiate the effectiveness of our proposed methods. Further efforts is needed to explore integrating network dynamics into SNN deployment.","sentences":["The deployment process of a spiking neural network (SNN) can involve partitioning a neural network and mapping partitions onto processing units within the neuromorphic hardware.","Searching for optimal deployment schemes presents an NP-hard problem.","Optimization of deployment schemes encounters challenges in devising computationally effective cost functions for optimization objectives such as communication time consumption and energy efficiency.","These kinds of objectives necessitate consideration of network dynamics shaped by neuron activity patterns, demanding intricate mathematical analyses or simulations for integrating them into a cost model for the deployment of an SNN.","The network dynamics are hardware-independent and can be modeled separately from specific hardware configurations.","Our approach employs a pairwise Ising-type maximum entropy model, which has shown its effectiveness in accurately reproducing pairwise correlations among components in a system.","We utilized this model to capture network dynamics, upon which a cost function is built incorporating hardware-specific parameters.","We conducted an extremely preliminary investigation using the SpiNNaker machine.","We show that the existing model training can also be computationally complex.","Currently, we still lack sufficient evidence to substantiate the effectiveness of our proposed methods.","Further efforts is needed to explore integrating network dynamics into SNN deployment."],"url":"http://arxiv.org/abs/2407.07014v1"}
{"created":"2024-07-09 16:29:21","title":"Induction Heads as an Essential Mechanism for Pattern Matching in In-context Learning","abstract":"Large language models (LLMs) have shown a remarkable ability to learn and perform complex tasks through in-context learning (ICL). However, a comprehensive understanding of its internal mechanisms is still lacking. This paper explores the role of induction heads in a few-shot ICL setting. We analyse two state-of-the-art models, Llama-3-8B and InternLM2-20B on abstract pattern recognition and NLP tasks. Our results show that even a minimal ablation of induction heads leads to ICL performance decreases of up to ~32% for abstract pattern recognition tasks, bringing the performance close to random. For NLP tasks, this ablation substantially decreases the model's ability to benefit from examples, bringing few-shot ICL performance close to that of zero-shot prompts. We further use attention knockout to disable specific induction patterns, and present fine-grained evidence for the role that the induction mechanism plays in ICL.","sentences":["Large language models (LLMs) have shown a remarkable ability to learn and perform complex tasks through in-context learning (ICL).","However, a comprehensive understanding of its internal mechanisms is still lacking.","This paper explores the role of induction heads in a few-shot ICL setting.","We analyse two state-of-the-art models, Llama-3-8B and InternLM2-20B on abstract pattern recognition and NLP tasks.","Our results show that even a minimal ablation of induction heads leads to ICL performance decreases of up to ~32% for abstract pattern recognition tasks, bringing the performance close to random.","For NLP tasks, this ablation substantially decreases the model's ability to benefit from examples, bringing few-shot ICL performance close to that of zero-shot prompts.","We further use attention knockout to disable specific induction patterns, and present fine-grained evidence for the role that the induction mechanism plays in ICL."],"url":"http://arxiv.org/abs/2407.07011v1"}
{"created":"2024-07-09 16:24:21","title":"Explainable AI for Enhancing Efficiency of DL-based Channel Estimation","abstract":"The support of artificial intelligence (AI) based decision-making is a key element in future 6G networks, where the concept of native AI will be introduced. Moreover, AI is widely employed in different critical applications such as autonomous driving and medical diagnosis. In such applications, using AI as black-box models is risky and challenging. Hence, it is crucial to understand and trust the decisions taken by these models. Tackling this issue can be achieved by developing explainable AI (XAI) schemes that aim to explain the logic behind the black-box model behavior, and thus, ensure its efficient and safe deployment. Recently, we proposed a novel perturbation-based XAI-CHEST framework that is oriented toward channel estimation in wireless communications. The core idea of the XAI-CHEST framework is to identify the relevant model inputs by inducing high noise on the irrelevant ones. This manuscript provides the detailed theoretical foundations of the XAI-CHEST framework. In particular, we derive the analytical expressions of the XAI-CHEST loss functions and the noise threshold fine-tuning optimization problem. Hence the designed XAI-CHEST delivers a smart input feature selection methodology that can further improve the overall performance while optimizing the architecture of the employed model. Simulation results show that the XAI-CHEST framework provides valid interpretations, where it offers an improved bit error rate performance while reducing the required computational complexity in comparison to the classical DL-based channel estimation.","sentences":["The support of artificial intelligence (AI) based decision-making is a key element in future 6G networks, where the concept of native AI will be introduced.","Moreover, AI is widely employed in different critical applications such as autonomous driving and medical diagnosis.","In such applications, using AI as black-box models is risky and challenging.","Hence, it is crucial to understand and trust the decisions taken by these models.","Tackling this issue can be achieved by developing explainable AI (XAI) schemes that aim to explain the logic behind the black-box model behavior, and thus, ensure its efficient and safe deployment.","Recently, we proposed a novel perturbation-based XAI-CHEST framework that is oriented toward channel estimation in wireless communications.","The core idea of the XAI-CHEST framework is to identify the relevant model inputs by inducing high noise on the irrelevant ones.","This manuscript provides the detailed theoretical foundations of the XAI-CHEST framework.","In particular, we derive the analytical expressions of the XAI-CHEST loss functions and the noise threshold fine-tuning optimization problem.","Hence the designed XAI-CHEST delivers a smart input feature selection methodology that can further improve the overall performance while optimizing the architecture of the employed model.","Simulation results show that the XAI-CHEST framework provides valid interpretations, where it offers an improved bit error rate performance while reducing the required computational complexity in comparison to the classical DL-based channel estimation."],"url":"http://arxiv.org/abs/2407.07009v1"}
{"created":"2024-07-09 16:21:12","title":"A PSPACE Algorithm for Almost-Sure Rabin Objectives in Multi-Environment MDPs","abstract":"Markov Decision Processes (MDPs) model systems with uncertain transition dynamics. Multiple-environment MDPs (MEMDPs) extend MDPs. They intuitively reflect finite sets of MDPs that share the same state and action spaces but differ in the transition dynamics. The key objective in MEMDPs is to find a single policy that satisfies a given objective in every associated MDP. The main result of this paper is PSPACE-completeness for almost-sure Rabin objectives in MEMDPs. This result clarifies the complexity landscape for MEMDPs and contrasts with results for the more general class of partially observable MDPs (POMDPs), where almost-sure reachability is already EXPTIME-complete, and almost-sure Rabin objectives are undecidable.","sentences":["Markov Decision Processes (MDPs) model systems with uncertain transition dynamics.","Multiple-environment MDPs (MEMDPs) extend MDPs.","They intuitively reflect finite sets of MDPs that share the same state and action spaces but differ in the transition dynamics.","The key objective in MEMDPs is to find a single policy that satisfies a given objective in every associated MDP.","The main result of this paper is PSPACE-completeness for almost-sure Rabin objectives in MEMDPs.","This result clarifies the complexity landscape for MEMDPs and contrasts with results for the more general class of partially observable MDPs (POMDPs), where almost-sure reachability is already EXPTIME-complete, and almost-sure Rabin objectives are undecidable."],"url":"http://arxiv.org/abs/2407.07006v1"}
{"created":"2024-07-09 16:17:16","title":"Empirical analysis of Biding Precedent efficiency in the Brazilian Supreme Court via Similar Case Retrieval","abstract":"Binding precedents (S\\'umulas Vinculantes) constitute a juridical instrument unique to the Brazilian legal system and whose objectives include the protection of the Federal Supreme Court against repetitive demands. Studies of the effectiveness of these instruments in decreasing the Court's exposure to similar cases, however, indicate that they tend to fail in such a direction, with some of the binding precedents seemingly creating new demands. We empirically assess the legal impact of five binding precedents, 11, 14, 17, 26 and 37, at the highest court level through their effects on the legal subjects they address. This analysis is only possible through the comparison of the Court's ruling about the precedents' themes before they are created, which means that these decisions should be detected through techniques of Similar Case Retrieval. The contributions of this article are therefore twofold: on the mathematical side, we compare the uses of different methods of Natural Language Processing -- TF-IDF, LSTM, BERT, and regex -- for Similar Case Retrieval, whereas on the legal side, we contrast the inefficiency of these binding precedents with a set of hypotheses that may justify their repeated usage. We observe that the deep learning models performed significantly worse in the specific Similar Case Retrieval task and that the reasons for binding precedents to fail in responding to repetitive demand are heterogeneous and case-dependent, making it impossible to single out a specific cause.","sentences":["Binding precedents (S\\'umulas Vinculantes) constitute a juridical instrument unique to the Brazilian legal system and whose objectives include the protection of the Federal Supreme Court against repetitive demands.","Studies of the effectiveness of these instruments in decreasing the Court's exposure to similar cases, however, indicate that they tend to fail in such a direction, with some of the binding precedents seemingly creating new demands.","We empirically assess the legal impact of five binding precedents, 11, 14, 17, 26 and 37, at the highest court level through their effects on the legal subjects they address.","This analysis is only possible through the comparison of the Court's ruling about the precedents' themes before they are created, which means that these decisions should be detected through techniques of Similar Case Retrieval.","The contributions of this article are therefore twofold: on the mathematical side, we compare the uses of different methods of Natural Language Processing -- TF-IDF, LSTM, BERT, and regex -- for Similar Case Retrieval, whereas on the legal side, we contrast the inefficiency of these binding precedents with a set of hypotheses that may justify their repeated usage.","We observe that the deep learning models performed significantly worse in the specific Similar Case Retrieval task and that the reasons for binding precedents to fail in responding to repetitive demand are heterogeneous and case-dependent, making it impossible to single out a specific cause."],"url":"http://arxiv.org/abs/2407.07004v1"}
{"created":"2024-07-09 16:16:44","title":"Learning to Complement and to Defer to Multiple Users","abstract":"With the development of Human-AI Collaboration in Classification (HAI-CC), integrating users and AI predictions becomes challenging due to the complex decision-making process. This process has three options: 1) AI autonomously classifies, 2) learning to complement, where AI collaborates with users, and 3) learning to defer, where AI defers to users. Despite their interconnected nature, these options have been studied in isolation rather than as components of a unified system. In this paper, we address this weakness with the novel HAI-CC methodology, called Learning to Complement and to Defer to Multiple Users (LECODU). LECODU not only combines learning to complement and learning to defer strategies, but it also incorporates an estimation of the optimal number of users to engage in the decision process. The training of LECODU maximises classification accuracy and minimises collaboration costs associated with user involvement. Comprehensive evaluations across real-world and synthesized datasets demonstrate LECODU's superior performance compared to state-of-the-art HAI-CC methods. Remarkably, even when relying on unreliable users with high rates of label noise, LECODU exhibits significant improvement over both human decision-makers alone and AI alone.","sentences":["With the development of Human-AI Collaboration in Classification (HAI-CC), integrating users and AI predictions becomes challenging due to the complex decision-making process.","This process has three options: 1) AI autonomously classifies, 2) learning to complement, where AI collaborates with users, and 3) learning to defer, where AI defers to users.","Despite their interconnected nature, these options have been studied in isolation rather than as components of a unified system.","In this paper, we address this weakness with the novel HAI-CC methodology, called Learning to Complement and to Defer to Multiple Users (LECODU).","LECODU not only combines learning to complement and learning to defer strategies, but it also incorporates an estimation of the optimal number of users to engage in the decision process.","The training of LECODU maximises classification accuracy and minimises collaboration costs associated with user involvement.","Comprehensive evaluations across real-world and synthesized datasets demonstrate LECODU's superior performance compared to state-of-the-art HAI-CC methods.","Remarkably, even when relying on unreliable users with high rates of label noise, LECODU exhibits significant improvement over both human decision-makers alone and AI alone."],"url":"http://arxiv.org/abs/2407.07003v1"}
{"created":"2024-07-09 16:13:26","title":"Metron: Holistic Performance Evaluation Framework for LLM Inference Systems","abstract":"Serving large language models (LLMs) in production can incur substantial costs, which has prompted recent advances in inference system optimizations. Today, these systems are evaluated against conventional latency and throughput metrics (eg. TTFT, TBT, Normalised Latency and TPOT). However, these metrics fail to fully capture the nuances of LLM inference, leading to an incomplete assessment of user-facing performance crucial for real-time applications such as chat and translation. In this paper, we first identify the pitfalls of current performance metrics in evaluating LLM inference systems. We then propose Metron, a comprehensive performance evaluation framework that includes fluidity-index -- a novel metric designed to reflect the intricacies of the LLM inference process and its impact on real-time user experience. Finally, we evaluate various existing open-source platforms and model-as-a-service offerings using Metron, discussing their strengths and weaknesses. Metron is available at https://github.com/project-metron/metron.","sentences":["Serving large language models (LLMs) in production can incur substantial costs, which has prompted recent advances in inference system optimizations.","Today, these systems are evaluated against conventional latency and throughput metrics (eg.","TTFT, TBT, Normalised Latency and TPOT).","However, these metrics fail to fully capture the nuances of LLM inference, leading to an incomplete assessment of user-facing performance crucial for real-time applications such as chat and translation.","In this paper, we first identify the pitfalls of current performance metrics in evaluating LLM inference systems.","We then propose Metron, a comprehensive performance evaluation framework that includes fluidity-index -- a novel metric designed to reflect the intricacies of the LLM inference process and its impact on real-time user experience.","Finally, we evaluate various existing open-source platforms and model-as-a-service offerings using Metron, discussing their strengths and weaknesses.","Metron is available at https://github.com/project-metron/metron."],"url":"http://arxiv.org/abs/2407.07000v1"}
{"created":"2024-07-09 16:12:44","title":"Changepoint Detection in Highly-Attributed Dynamic Graphs","abstract":"Detecting anomalous behavior in dynamic networks remains a constant challenge. This problem is further exacerbated when the underlying topology of these networks is affected by individual highly-dimensional node attributes. We address this issue by tracking a network's modularity as a proxy of its community structure. We leverage Graph Neural Networks (GNNs) to estimate each snapshot's modularity. GNNs can account for both network structure and high-dimensional node attributes, providing a comprehensive approach for estimating network statistics. Our method is validated through simulations that demonstrate its ability to detect changes in highly-attributed networks by analyzing shifts in modularity. Moreover, we find our method is able to detect a real-world event within the \\#Iran Twitter reply network, where each node has high-dimensional textual attributes.","sentences":["Detecting anomalous behavior in dynamic networks remains a constant challenge.","This problem is further exacerbated when the underlying topology of these networks is affected by individual highly-dimensional node attributes.","We address this issue by tracking a network's modularity as a proxy of its community structure.","We leverage Graph Neural Networks (GNNs) to estimate each snapshot's modularity.","GNNs can account for both network structure and high-dimensional node attributes, providing a comprehensive approach for estimating network statistics.","Our method is validated through simulations that demonstrate its ability to detect changes in highly-attributed networks by analyzing shifts in modularity.","Moreover, we find our method is able to detect a real-world event within the \\#Iran Twitter reply network, where each node has high-dimensional textual attributes."],"url":"http://arxiv.org/abs/2407.06998v1"}
{"created":"2024-07-09 16:07:01","title":"Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective","abstract":"Recent advances in neural information retrieval (IR) models have significantly enhanced their effectiveness over various IR tasks. The robustness of these models, essential for ensuring their reliability in practice, has also garnered significant attention. With a wide array of research on robust IR being proposed, we believe it is the opportune moment to consolidate the current status, glean insights from existing methodologies, and lay the groundwork for future development. We view the robustness of IR to be a multifaceted concept, emphasizing its necessity against adversarial attacks, out-of-distribution (OOD) scenarios and performance variance. With a focus on adversarial and OOD robustness, we dissect robustness solutions for dense retrieval models (DRMs) and neural ranking models (NRMs), respectively, recognizing them as pivotal components of the neural IR pipeline. We provide an in-depth discussion of existing methods, datasets, and evaluation metrics, shedding light on challenges and future directions in the era of large language models. To the best of our knowledge, this is the first comprehensive survey on the robustness of neural IR models, and we will also be giving our first tutorial presentation at SIGIR 2024 \\url{https://sigir2024-robust-information-retrieval.github.io}. Along with the organization of existing work, we introduce a Benchmark for robust IR (BestIR), a heterogeneous evaluation benchmark for robust neural information retrieval, which is publicly available at \\url{https://github.com/Davion-Liu/BestIR}. We hope that this study provides useful clues for future research on the robustness of IR models and helps to develop trustworthy search engines \\url{https://github.com/Davion-Liu/Awesome-Robustness-in-Information-Retrieval}.","sentences":["Recent advances in neural information retrieval (IR) models have significantly enhanced their effectiveness over various IR tasks.","The robustness of these models, essential for ensuring their reliability in practice, has also garnered significant attention.","With a wide array of research on robust IR being proposed, we believe it is the opportune moment to consolidate the current status, glean insights from existing methodologies, and lay the groundwork for future development.","We view the robustness of IR to be a multifaceted concept, emphasizing its necessity against adversarial attacks, out-of-distribution (OOD) scenarios and performance variance.","With a focus on adversarial and OOD robustness, we dissect robustness solutions for dense retrieval models (DRMs) and neural ranking models (NRMs), respectively, recognizing them as pivotal components of the neural IR pipeline.","We provide an in-depth discussion of existing methods, datasets, and evaluation metrics, shedding light on challenges and future directions in the era of large language models.","To the best of our knowledge, this is the first comprehensive survey on the robustness of neural IR models, and we will also be giving our first tutorial presentation at SIGIR 2024 \\url{https://sigir2024-robust-information-retrieval.github.io}.","Along with the organization of existing work, we introduce a Benchmark for robust IR (BestIR), a heterogeneous evaluation benchmark for robust neural information retrieval, which is publicly available at \\url{https://github.com/Davion-Liu/BestIR}.","We hope that this study provides useful clues for future research on the robustness of IR models and helps to develop trustworthy search engines \\url{https://github.com/Davion-Liu/Awesome-Robustness-in-Information-Retrieval}."],"url":"http://arxiv.org/abs/2407.06992v1"}
{"created":"2024-07-09 16:06:34","title":"Improved Block Merging for 3D Point Cloud Instance Segmentation","abstract":"This paper proposes a novel block merging algorithm suitable for any block-based 3D instance segmentation technique. The proposed work improves over the state-of-the-art by allowing wrongly labelled points of already processed blocks to be corrected through label propagation. By doing so, instance overlap between blocks is not anymore necessary to produce the desirable results, which is the main limitation of the current art. Our experiments show that the proposed block merging algorithm significantly and consistently improves the obtained accuracy for all evaluation metrics employed in literature, regardless of the underlying network architecture.","sentences":["This paper proposes a novel block merging algorithm suitable for any block-based 3D instance segmentation technique.","The proposed work improves over the state-of-the-art by allowing wrongly labelled points of already processed blocks to be corrected through label propagation.","By doing so, instance overlap between blocks is not anymore necessary to produce the desirable results, which is the main limitation of the current art.","Our experiments show that the proposed block merging algorithm significantly and consistently improves the obtained accuracy for all evaluation metrics employed in literature, regardless of the underlying network architecture."],"url":"http://arxiv.org/abs/2407.06991v1"}
{"created":"2024-07-09 16:04:21","title":"Segment-Based Interactive Machine Translation for Pre-trained Models","abstract":"Pre-trained large language models (LLM) are starting to be widely used in many applications. In this work, we explore the use of these models in interactive machine translation (IMT) environments. In particular, we have chosen mBART (multilingual Bidirectional and Auto-Regressive Transformer) and mT5 (multilingual Text-to-Text Transfer Transformer) as the LLMs to perform our experiments. The system generates perfect translations interactively using the feedback provided by the user at each iteration. The Neural Machine Translation (NMT) model generates a preliminary hypothesis with the feedback, and the user validates new correct segments and performs a word correction--repeating the process until the sentence is correctly translated. We compared the performance of mBART, mT5, and a state-of-the-art (SoTA) machine translation model on a benchmark dataset regarding user effort, Word Stroke Ratio (WSR), Key Stroke Ratio (KSR), and Mouse Action Ratio (MAR). The experimental results indicate that mBART performed comparably with SoTA models, suggesting that it is a viable option for this field of IMT. The implications of this finding extend to the development of new machine translation models for interactive environments, as it indicates that some novel pre-trained models exhibit SoTA performance in this domain, highlighting the potential benefits of adapting these models to specific needs.","sentences":["Pre-trained large language models (LLM) are starting to be widely used in many applications.","In this work, we explore the use of these models in interactive machine translation (IMT) environments.","In particular, we have chosen mBART (multilingual Bidirectional and Auto-Regressive Transformer) and mT5 (multilingual Text-to-Text Transfer Transformer) as the LLMs to perform our experiments.","The system generates perfect translations interactively using the feedback provided by the user at each iteration.","The Neural Machine Translation (NMT) model generates a preliminary hypothesis with the feedback, and the user validates new correct segments and performs a word correction--repeating the process until the sentence is correctly translated.","We compared the performance of mBART, mT5, and a state-of-the-art (SoTA) machine translation model on a benchmark dataset regarding user effort, Word Stroke Ratio (WSR), Key Stroke Ratio (KSR), and Mouse Action Ratio (MAR).","The experimental results indicate that mBART performed comparably with SoTA models, suggesting that it is a viable option for this field of IMT.","The implications of this finding extend to the development of new machine translation models for interactive environments, as it indicates that some novel pre-trained models exhibit SoTA performance in this domain, highlighting the potential benefits of adapting these models to specific needs."],"url":"http://arxiv.org/abs/2407.06990v1"}
{"created":"2024-07-09 15:59:28","title":"PEER: Expertizing Domain-Specific Tasks with a Multi-Agent Framework and Tuning Methods","abstract":"In domain-specific applications, GPT-4, augmented with precise prompts or Retrieval-Augmented Generation (RAG), shows notable potential but faces the critical tri-lemma of performance, cost, and data privacy. High performance requires sophisticated processing techniques, yet managing multiple agents within a complex workflow often proves costly and challenging. To address this, we introduce the PEER (Plan, Execute, Express, Review) multi-agent framework. This systematizes domain-specific tasks by integrating precise question decomposition, advanced information retrieval, comprehensive summarization, and rigorous self-assessment. Given the concerns of cost and data privacy, enterprises are shifting from proprietary models like GPT-4 to custom models, striking a balance between cost, security, and performance. We developed industrial practices leveraging online data and user feedback for efficient model tuning. This study provides best practice guidelines for applying multi-agent systems in domain-specific problem-solving and implementing effective agent tuning strategies. Our empirical studies, particularly in the financial question-answering domain, demonstrate that our approach achieves 95.0% of GPT-4's performance, while effectively managing costs and ensuring data privacy.","sentences":["In domain-specific applications, GPT-4, augmented with precise prompts or Retrieval-Augmented Generation (RAG), shows notable potential but faces the critical tri-lemma of performance, cost, and data privacy.","High performance requires sophisticated processing techniques, yet managing multiple agents within a complex workflow often proves costly and challenging.","To address this, we introduce the PEER (Plan, Execute, Express, Review) multi-agent framework.","This systematizes domain-specific tasks by integrating precise question decomposition, advanced information retrieval, comprehensive summarization, and rigorous self-assessment.","Given the concerns of cost and data privacy, enterprises are shifting from proprietary models like GPT-4 to custom models, striking a balance between cost, security, and performance.","We developed industrial practices leveraging online data and user feedback for efficient model tuning.","This study provides best practice guidelines for applying multi-agent systems in domain-specific problem-solving and implementing effective agent tuning strategies.","Our empirical studies, particularly in the financial question-answering domain, demonstrate that our approach achieves 95.0% of GPT-4's performance, while effectively managing costs and ensuring data privacy."],"url":"http://arxiv.org/abs/2407.06985v1"}
{"created":"2024-07-09 15:59:03","title":"Category-level Object Detection, Pose Estimation and Reconstruction from Stereo Images","abstract":"We study the 3D object understanding task for manipulating everyday objects with different material properties (diffuse, specular, transparent and mixed). Existing monocular and RGB-D methods suffer from scale ambiguity due to missing or imprecise depth measurements. We present CODERS, a one-stage approach for Category-level Object Detection, pose Estimation and Reconstruction from Stereo images. The base of our pipeline is an implicit stereo matching module that combines stereo image features with 3D position information. Concatenating this presented module and the following transform-decoder architecture leads to end-to-end learning of multiple tasks required by robot manipulation. Our approach significantly outperforms all competing methods in the public TOD dataset. Furthermore, trained on simulated data, CODERS generalize well to unseen category-level object instances in real-world robot manipulation experiments. Our dataset, code, and demos will be available on our project page.","sentences":["We study the 3D object understanding task for manipulating everyday objects with different material properties (diffuse, specular, transparent and mixed).","Existing monocular and RGB-D methods suffer from scale ambiguity due to missing or imprecise depth measurements.","We present CODERS, a one-stage approach for Category-level Object Detection, pose Estimation and Reconstruction from Stereo images.","The base of our pipeline is an implicit stereo matching module that combines stereo image features with 3D position information.","Concatenating this presented module and the following transform-decoder architecture leads to end-to-end learning of multiple tasks required by robot manipulation.","Our approach significantly outperforms all competing methods in the public TOD dataset.","Furthermore, trained on simulated data, CODERS generalize well to unseen category-level object instances in real-world robot manipulation experiments.","Our dataset, code, and demos will be available on our project page."],"url":"http://arxiv.org/abs/2407.06984v1"}
{"created":"2024-07-09 15:54:06","title":"Can virtual staining for high-throughput screening generalize?","abstract":"The large volume and variety of imaging data from high-throughput screening (HTS) in the pharmaceutical industry present an excellent resource for training virtual staining models. However, the potential of models trained under one set of experimental conditions to generalize to other conditions remains underexplored. This study systematically investigates whether data from three cell types (lung, ovarian, and breast) and two phenotypes (toxic and non-toxic conditions) commonly found in HTS can effectively train virtual staining models to generalize across three typical HTS distribution shifts: unseen phenotypes, unseen cell types, and the combination of both. Utilizing a dataset of 772,416 paired bright-field, cytoplasm, nuclei, and DNA-damage stain images, we evaluate the generalization capabilities of models across pixel-based, instance-wise, and biological-feature-based levels. Our findings indicate that training virtual nuclei and cytoplasm models on non-toxic condition samples not only generalizes to toxic condition samples but leads to improved performance across all evaluation levels compared to training on toxic condition samples. Generalization to unseen cell types shows variability depending on the cell type; models trained on ovarian or lung cell samples often perform well under other conditions, while those trained on breast cell samples consistently show poor generalization. Generalization to unseen cell types and phenotypes shows good generalization across all levels of evaluation compared to addressing unseen cell types alone. This study represents the first large-scale, data-centric analysis of the generalization capability of virtual staining models trained on diverse HTS datasets, providing valuable strategies for experimental training data generation.","sentences":["The large volume and variety of imaging data from high-throughput screening (HTS) in the pharmaceutical industry present an excellent resource for training virtual staining models.","However, the potential of models trained under one set of experimental conditions to generalize to other conditions remains underexplored.","This study systematically investigates whether data from three cell types (lung, ovarian, and breast) and two phenotypes (toxic and non-toxic conditions) commonly found in HTS can effectively train virtual staining models to generalize across three typical HTS distribution shifts: unseen phenotypes, unseen cell types, and the combination of both.","Utilizing a dataset of 772,416 paired bright-field, cytoplasm, nuclei, and DNA-damage stain images, we evaluate the generalization capabilities of models across pixel-based, instance-wise, and biological-feature-based levels.","Our findings indicate that training virtual nuclei and cytoplasm models on non-toxic condition samples not only generalizes to toxic condition samples but leads to improved performance across all evaluation levels compared to training on toxic condition samples.","Generalization to unseen cell types shows variability depending on the cell type; models trained on ovarian or lung cell samples often perform well under other conditions, while those trained on breast cell samples consistently show poor generalization.","Generalization to unseen cell types and phenotypes shows good generalization across all levels of evaluation compared to addressing unseen cell types alone.","This study represents the first large-scale, data-centric analysis of the generalization capability of virtual staining models trained on diverse HTS datasets, providing valuable strategies for experimental training data generation."],"url":"http://arxiv.org/abs/2407.06979v1"}
{"created":"2024-07-09 15:53:46","title":"Exploring the Experiences of Experts: Sustainability in Agile Software Development - Insights from the Finnish Software Industry","abstract":"Agile software development is gaining popularity among software developers due to its benefits. As the interest in agile software development grows, there is an increasing focus on investigating sustainability within this field. This study aimed to explore sustainability within agile software development in the Finnish software industry and, through gathered experiences, contribute to the software engineering roadmap 2030. Using an interview approach, we conducted an empirical study within the Finnish software industry to achieve this goal. The findings indicate a growing interest among experts in integrating sustainability into agile software development. The results show that the Scrum methodology is the most popular approach in the Finnish software industry, and addressing different sustainability dimensions can have a ripple effect on each other. The study proposes three key elements to be considered in the software engineering roadmap 2030: integrating sustainability into software engineering education, creating sustainability tools and frameworks, and assessing the energy efficiency of libraries used in software development.","sentences":["Agile software development is gaining popularity among software developers due to its benefits.","As the interest in agile software development grows, there is an increasing focus on investigating sustainability within this field.","This study aimed to explore sustainability within agile software development in the Finnish software industry and, through gathered experiences, contribute to the software engineering roadmap 2030.","Using an interview approach, we conducted an empirical study within the Finnish software industry to achieve this goal.","The findings indicate a growing interest among experts in integrating sustainability into agile software development.","The results show that the Scrum methodology is the most popular approach in the Finnish software industry, and addressing different sustainability dimensions can have a ripple effect on each other.","The study proposes three key elements to be considered in the software engineering roadmap 2030: integrating sustainability into software engineering education, creating sustainability tools and frameworks, and assessing the energy efficiency of libraries used in software development."],"url":"http://arxiv.org/abs/2407.06978v1"}
{"created":"2024-07-09 15:52:06","title":"Advancing Manuscript Metadata: Work in Progress at the Jagiellonian University","abstract":"As part of ongoing research projects, three Jagiellonian University units -- the Jagiellonian University Museum, the Jagiellonian University Archives, and the Jagiellonian Library -- are collaborating to digitize cultural heritage documents, describe them in detail, and then integrate these descriptions into a linked data cloud. Achieving this goal requires, as a first step, the development of a metadata model that, on the one hand, complies with existing standards, on the other hand, allows interoperability with other systems, and on the third, captures all the elements of description established by the curators of the collections. In this paper, we present a report on the current status of the work, in which we outline the most important requirements for the data model under development and then make a detailed comparison with the two standards that are the most relevant from the point of view of collections: Europeana Data Model used in Europeana and Encoded Archival Description used in Kalliope.","sentences":["As part of ongoing research projects, three Jagiellonian University units -- the Jagiellonian University Museum, the Jagiellonian University Archives, and the Jagiellonian Library -- are collaborating to digitize cultural heritage documents, describe them in detail, and then integrate these descriptions into a linked data cloud.","Achieving this goal requires, as a first step, the development of a metadata model that, on the one hand, complies with existing standards, on the other hand, allows interoperability with other systems, and on the third, captures all the elements of description established by the curators of the collections.","In this paper, we present a report on the current status of the work, in which we outline the most important requirements for the data model under development and then make a detailed comparison with the two standards that are the most relevant from the point of view of collections: Europeana Data Model used in Europeana and Encoded Archival Description used in Kalliope."],"url":"http://arxiv.org/abs/2407.06976v1"}
{"created":"2024-07-09 15:49:47","title":"Microsoft Cloud-based Digitization Workflow with Rich Metadata Acquisition for Cultural Heritage Objects","abstract":"In response to several cultural heritage initiatives at the Jagiellonian University, we have developed a new digitization workflow in collaboration with the Jagiellonian Library (JL). The solution is based on easy-to-access technological solutions -- Microsoft 365 cloud with MS Excel files as metadata acquisition interfaces, Office Script for validation, and MS Sharepoint for storage -- that allows metadata acquisition by domain experts (philologists, historians, philosophers, librarians, archivists, curators, etc.) regardless of their experience with information systems. The ultimate goal is to create a knowledge graph that describes the analyzed holdings, linked to general knowledge bases, as well as to other cultural heritage collections, so careful attention is paid to the high accuracy of metadata and proper links to external sources. The workflow has already been evaluated in two pilots in the DiHeLib project focused on digitizing the so-called \"Berlin Collection\" and in two workshops with international guests, which allowed for its refinement and confirmation of its correctness and usability for JL. As the proposed workflow does not interfere with existing systems or domain guidelines regarding digitization and basic metadata collection in a given institution (e.g., file type, image quality, use of Dublin Core/MARC-21), but extends them in order to enable rich metadata collection, not previously possible, we believe that it could be of interest to all GLAMs (galleries, libraries, archives, and museums).","sentences":["In response to several cultural heritage initiatives at the Jagiellonian University, we have developed a new digitization workflow in collaboration with the Jagiellonian Library (JL).","The solution is based on easy-to-access technological solutions -- Microsoft 365 cloud with MS Excel files as metadata acquisition interfaces, Office Script for validation, and MS Sharepoint for storage -- that allows metadata acquisition by domain experts (philologists, historians, philosophers, librarians, archivists, curators, etc.)","regardless of their experience with information systems.","The ultimate goal is to create a knowledge graph that describes the analyzed holdings, linked to general knowledge bases, as well as to other cultural heritage collections, so careful attention is paid to the high accuracy of metadata and proper links to external sources.","The workflow has already been evaluated in two pilots in the DiHeLib project focused on digitizing the so-called \"Berlin Collection\" and in two workshops with international guests, which allowed for its refinement and confirmation of its correctness and usability for JL.","As the proposed workflow does not interfere with existing systems or domain guidelines regarding digitization and basic metadata collection in a given institution (e.g., file type, image quality, use of Dublin Core/MARC-21), but extends them in order to enable rich metadata collection, not previously possible, we believe that it could be of interest to all GLAMs (galleries, libraries, archives, and museums)."],"url":"http://arxiv.org/abs/2407.06972v1"}
{"created":"2024-07-09 15:47:09","title":"An automata-based approach for synchronizable mailbox communication","abstract":"We revisit finite-state communicating systems with round-based communication under mailbox semantics. Mailboxes correspond to one FIFO buffer per process (instead of one buffer per pair of processes in peer-to-peer systems). Round-based communication corresponds to sequences of rounds in which processes can first send messages, then only receive (and receives must be in the same round as their sends). Our main contribution shows that the problem whether a mailbox communication system complies with the round-based policy, with no size limitation on rounds, is Pspace-complete. For this we use a novel automata-based approach, that also allows to determine the precise complexity (Pspace) of several questions considered in previous literature.","sentences":["We revisit finite-state communicating systems with round-based communication under mailbox semantics.","Mailboxes correspond to one FIFO buffer per process (instead of one buffer per pair of processes in peer-to-peer systems).","Round-based communication corresponds to sequences of rounds in which processes can first send messages, then only receive (and receives must be in the same round as their sends).","Our main contribution shows that the problem whether a mailbox communication system complies with the round-based policy, with no size limitation on rounds, is Pspace-complete.","For this we use a novel automata-based approach, that also allows to determine the precise complexity (Pspace) of several questions considered in previous literature."],"url":"http://arxiv.org/abs/2407.06968v1"}
{"created":"2024-07-09 15:46:52","title":"INTERACT: An authoring tool that facilitates the creation of human centric interaction with 3d objects in virtual reality","abstract":"A widespread adoption of Virtual, Augmented, and Mixed Reality (VR/AR/MR), collectively referred to as Extended Reality (XR), has become a tangible possibility to revolutionize educational and training scenarios by offering immersive, interactive experiences. In this paper we present \\textsf{INTERACT}, an authoring tool for creating advanced 3D physics-based Intelligent Tutoring Systems (ITS) by individual developers or small-scale development teams. \\textsf{INTERACT} is based on a cutting edge physics engine allowing realistic interactions such as collision detection and ergonomic evaluations. We demonstrate the benefits of \\textsf{INTERACT} by developing a set of training scenarios for a use case of a Laser cutting machine. The use case illustrates the numerous possibilities such as creating interaction with objects, ease of configuring a scenario and how to design the visual effects to the machine.","sentences":["A widespread adoption of Virtual, Augmented, and Mixed Reality (VR/AR/MR), collectively referred to as Extended Reality (XR), has become a tangible possibility to revolutionize educational and training scenarios by offering immersive, interactive experiences.","In this paper we present \\textsf{INTERACT}, an authoring tool for creating advanced 3D physics-based Intelligent Tutoring Systems (ITS) by individual developers or small-scale development teams.","\\textsf{INTERACT} is based on a cutting edge physics engine allowing realistic interactions such as collision detection and ergonomic evaluations.","We demonstrate the benefits of \\textsf{INTERACT} by developing a set of training scenarios for a use case of a Laser cutting machine.","The use case illustrates the numerous possibilities such as creating interaction with objects, ease of configuring a scenario and how to design the visual effects to the machine."],"url":"http://arxiv.org/abs/2407.06967v1"}
{"created":"2024-07-09 15:45:27","title":"Creating Centered Trochoids and Co-Centered Ellipses through the Combinations of Uniform Rolling and Sliding Operations by Using Virtual Rotating Circles Technique (VRCT)","abstract":"In this article we present an innovative mental vision for creating uniform rolling and sliding motions for a circle along another circle . Also, we describe methods to combine rolling and sliding motions through VRCT in order to plotting centered trochoids and co-centered ellipses. Traditional mathematical perspective for creating centered trochoids through the pure rolling process for a circle along another circle is changed to a novel mathematical perspective which is based on the combination of uniform rolling and sliding motions of a circle along another one. In this novel vision we have not to define a centered trochoid as a traced path of an attached point to a pure rolling circle along another circle. Instead, a centered trochoid can be defined as a traced path by a certain point on the circumference of a rolling and sliding circle along another circle . Also, through this vision an ellipse can be visualized as a closed plane curve that is the product of uniform combination of rolling and sliding motions due to superposition of two co-polarized rotational motions with different commensurable angular frequencies! Detailed points in the process of plotting centered trochoids and ellipses through the combination of rolling and sliding operations are observable directly by application an innovative instrument that we have named it mechanical Oscilloscope. The function of our device is independent from any other electronic devices such as computer and does not require programming to plot centered trochoids and ellipses.","sentences":["In this article we present an innovative mental vision for creating uniform rolling and sliding motions for a circle along another circle .","Also, we describe methods to combine rolling and sliding motions through VRCT in order to plotting centered trochoids and co-centered ellipses.","Traditional mathematical perspective for creating centered trochoids through the pure rolling process for a circle along another circle is changed to a novel mathematical perspective which is based on the combination of uniform rolling and sliding motions of a circle along another one.","In this novel vision we have not to define a centered trochoid as a traced path of an attached point to a pure rolling circle along another circle.","Instead, a centered trochoid can be defined as a traced path by a certain point on the circumference of a rolling and sliding circle along another circle .","Also, through this vision an ellipse can be visualized as a closed plane curve that is the product of uniform combination of rolling and sliding motions due to superposition of two co-polarized rotational motions with different commensurable angular frequencies!","Detailed points in the process of plotting centered trochoids and ellipses through the combination of rolling and sliding operations are observable directly by application an innovative instrument that we have named it mechanical Oscilloscope.","The function of our device is independent from any other electronic devices such as computer and does not require programming to plot centered trochoids and ellipses."],"url":"http://arxiv.org/abs/2407.06966v1"}
{"created":"2024-07-09 15:45:04","title":"Parameter-Efficient and Memory-Efficient Tuning for Vision Transformer: A Disentangled Approach","abstract":"Recent works on parameter-efficient transfer learning (PETL) show the potential to adapt a pre-trained Vision Transformer to downstream recognition tasks with only a few learnable parameters. However, since they usually insert new structures into the pre-trained model, entire intermediate features of that model are changed and thus need to be stored to be involved in back-propagation, resulting in memory-heavy training. We solve this problem from a novel disentangled perspective, i.e., dividing PETL into two aspects: task-specific learning and pre-trained knowledge utilization. Specifically, we synthesize the task-specific query with a learnable and lightweight module, which is independent of the pre-trained model. The synthesized query equipped with task-specific knowledge serves to extract the useful features for downstream tasks from the intermediate representations of the pre-trained model in a query-only manner. Built upon these features, a customized classification head is proposed to make the prediction for the input sample. lightweight architecture and avoids the use of heavy intermediate features for running gradient descent, it demonstrates limited memory usage in training. Extensive experiments manifest that our method achieves state-of-the-art performance under memory constraints, showcasing its applicability in real-world situations.","sentences":["Recent works on parameter-efficient transfer learning (PETL) show the potential to adapt a pre-trained Vision Transformer to downstream recognition tasks with only a few learnable parameters.","However, since they usually insert new structures into the pre-trained model, entire intermediate features of that model are changed and thus need to be stored to be involved in back-propagation, resulting in memory-heavy training.","We solve this problem from a novel disentangled perspective, i.e., dividing PETL into two aspects: task-specific learning and pre-trained knowledge utilization.","Specifically, we synthesize the task-specific query with a learnable and lightweight module, which is independent of the pre-trained model.","The synthesized query equipped with task-specific knowledge serves to extract the useful features for downstream tasks from the intermediate representations of the pre-trained model in a query-only manner.","Built upon these features, a customized classification head is proposed to make the prediction for the input sample.","lightweight architecture and avoids the use of heavy intermediate features for running gradient descent, it demonstrates limited memory usage in training.","Extensive experiments manifest that our method achieves state-of-the-art performance under memory constraints, showcasing its applicability in real-world situations."],"url":"http://arxiv.org/abs/2407.06964v1"}
{"created":"2024-07-09 15:36:13","title":"Joint prototype and coefficient prediction for 3D instance segmentation","abstract":"3D instance segmentation is crucial for applications demanding comprehensive 3D scene understanding. In this paper, we introduce a novel method that simultaneously learns coefficients and prototypes. Employing an overcomplete sampling strategy, our method produces an overcomplete set of instance predictions, from which the optimal ones are selected through a Non-Maximum Suppression (NMS) algorithm during inference. The obtained prototypes are visualizable and interpretable. Our method demonstrates superior performance on S3DIS-blocks, consistently outperforming existing methods in mRec and mPrec. Moreover, it operates 32.9% faster than the state-of-the-art. Notably, with only 0.8% of the total inference time, our method exhibits an over 20-fold reduction in the variance of inference time compared to existing methods. These attributes render our method well-suited for practical applications requiring both rapid inference and high reliability.","sentences":["3D instance segmentation is crucial for applications demanding comprehensive 3D scene understanding.","In this paper, we introduce a novel method that simultaneously learns coefficients and prototypes.","Employing an overcomplete sampling strategy, our method produces an overcomplete set of instance predictions, from which the optimal ones are selected through a Non-Maximum Suppression (NMS) algorithm during inference.","The obtained prototypes are visualizable and interpretable.","Our method demonstrates superior performance on S3DIS-blocks, consistently outperforming existing methods in mRec and mPrec.","Moreover, it operates 32.9% faster than the state-of-the-art.","Notably, with only 0.8% of the total inference time, our method exhibits an over 20-fold reduction in the variance of inference time compared to existing methods.","These attributes render our method well-suited for practical applications requiring both rapid inference and high reliability."],"url":"http://arxiv.org/abs/2407.06958v1"}
{"created":"2024-07-09 15:35:22","title":"Domain theory in univalent foundations II: Continuous and algebraic domains","abstract":"We develop the theory of continuous and algebraic domains in constructive and predicative univalent foundations, building upon our earlier work on basic domain theory in this setting. That we work predicatively means that we do not assume Voevodsky's propositional resizing axioms. Our work is constructive in the sense that we do not rely on excluded middle or the axiom of (countable) choice. To deal with size issues and give a predicatively suitable definition of continuity of a dcpo, we follow Johnstone and Joyal's work on continuous categories. Adhering to the univalent perspective, we explicitly distinguish between data and property. To ensure that being continuous is a property of a dcpo, we turn to the propositional truncation, although we explain that some care is needed to avoid needing the axiom of choice. We also adapt the notion of a domain-theoretic basis to the predicative setting by imposing suitable smallness conditions, analogous to the categorical concept of an accessible category. All our running examples of continuous dcpos are then actually examples of dcpos with small bases which we show to be well behaved predicatively. In particular, such dcpos are exactly those presented by small ideals. As an application of the theory, we show that Scott's $D_\\infty$ model of the untyped $\\lambda$-calculus is an example of an algebraic dcpo with a small basis. Our work is formalised in the Agda proof assistant and its ability to infer universe levels has been invaluable for our purposes.","sentences":["We develop the theory of continuous and algebraic domains in constructive and predicative univalent foundations, building upon our earlier work on basic domain theory in this setting.","That we work predicatively means that we do not assume Voevodsky's propositional resizing axioms.","Our work is constructive in the sense that we do not rely on excluded middle or the axiom of (countable) choice.","To deal with size issues and give a predicatively suitable definition of continuity of a dcpo, we follow Johnstone and Joyal's work on continuous categories.","Adhering to the univalent perspective, we explicitly distinguish between data and property.","To ensure that being continuous is a property of a dcpo, we turn to the propositional truncation, although we explain that some care is needed to avoid needing the axiom of choice.","We also adapt the notion of a domain-theoretic basis to the predicative setting by imposing suitable smallness conditions, analogous to the categorical concept of an accessible category.","All our running examples of continuous dcpos are then actually examples of dcpos with small bases which we show to be well behaved predicatively.","In particular, such dcpos are exactly those presented by small ideals.","As an application of the theory, we show that Scott's $D_\\infty$ model of the untyped $\\lambda$-calculus is an example of an algebraic dcpo with a small basis.","Our work is formalised in the Agda proof assistant and its ability to infer universe levels has been invaluable for our purposes."],"url":"http://arxiv.org/abs/2407.06956v1"}
{"created":"2024-07-09 15:35:06","title":"ICLGuard: Controlling In-Context Learning Behavior for Applicability Authorization","abstract":"In-context learning (ICL) is a recent advancement in the capabilities of large language models (LLMs). This feature allows users to perform a new task without updating the model. Concretely, users can address tasks during the inference time by conditioning on a few input-label pair demonstrations along with the test input. It is different than the conventional fine-tuning paradigm and offers more flexibility. However, this capability also introduces potential issues. For example, users may use the model on any data without restriction, such as performing tasks with improper or sensitive content, which might violate the model policy or conflict with the model owner's interests. As a model owner, it is crucial to establish a mechanism to control the model's behavior under ICL, depending on the model owner's requirements for various content. To this end, we introduce the concept of \"applicability authorization\" tailored for LLMs, particularly for ICL behavior, and propose a simple approach, ICLGuard. It is a fine-tuning framework designed to allow the model owner to regulate ICL behavior on different data. ICLGuard preserves the original LLM and fine-tunes only a minimal set of additional trainable parameters to \"guard\" the LLM. Empirical results show that the guarded LLM can deactivate its ICL ability on target data without affecting its ICL ability on other data and its general functionality across all data.","sentences":["In-context learning (ICL) is a recent advancement in the capabilities of large language models (LLMs).","This feature allows users to perform a new task without updating the model.","Concretely, users can address tasks during the inference time by conditioning on a few input-label pair demonstrations along with the test input.","It is different than the conventional fine-tuning paradigm and offers more flexibility.","However, this capability also introduces potential issues.","For example, users may use the model on any data without restriction, such as performing tasks with improper or sensitive content, which might violate the model policy or conflict with the model owner's interests.","As a model owner, it is crucial to establish a mechanism to control the model's behavior under ICL, depending on the model owner's requirements for various content.","To this end, we introduce the concept of \"applicability authorization\" tailored for LLMs, particularly for ICL behavior, and propose a simple approach, ICLGuard.","It is a fine-tuning framework designed to allow the model owner to regulate ICL behavior on different data.","ICLGuard preserves the original LLM and fine-tunes only a minimal set of additional trainable parameters to \"guard\" the LLM.","Empirical results show that the guarded LLM can deactivate its ICL ability on target data without affecting its ICL ability on other data and its general functionality across all data."],"url":"http://arxiv.org/abs/2407.06955v1"}
{"created":"2024-07-09 15:32:51","title":"SP-Chain: Boosting Intra-Shard and Cross-Shard Security and Performance in Blockchain Sharding","abstract":"A promising way to overcome the scalability limitations of the current blockchain is to use sharding, which is to split the transaction processing among multiple, smaller groups of nodes. A well-performed blockchain sharding system requires both high performance and high security in both intra- and cross-shard perspectives. However, existing protocols either have issues on protecting security or trade off great performance for security. In this paper, we propose SP-Chain, a blockchain sharding system with enhanced Security and Performance for both intra- and cross-shard perspectives. For intra-shard aspect, we design a two-phase concurrent voting scheme to provide high system throughput and low transaction confirmation latency. Moreover, we propose an efficient unbiased leader rotation scheme to ensure high performance under malicious behavior. For cross-shard aspect, a proof-assisted efficient cross-shard transaction processing mechanism is proposed to guard the cross-shard transactions with low overhead. We implement SP-Chain based on Harmony, and evaluate its performance via large-scale deployment. Extensive evaluations suggest that SP-Chain can process more than 10,000 tx/sec under malicious behaviors with a confirmation latency of 7.6s in a network of 4,000 nodes.","sentences":["A promising way to overcome the scalability limitations of the current blockchain is to use sharding, which is to split the transaction processing among multiple, smaller groups of nodes.","A well-performed blockchain sharding system requires both high performance and high security in both intra- and cross-shard perspectives.","However, existing protocols either have issues on protecting security or trade off great performance for security.","In this paper, we propose SP-Chain, a blockchain sharding system with enhanced Security and Performance for both intra- and cross-shard perspectives.","For intra-shard aspect, we design a two-phase concurrent voting scheme to provide high system throughput and low transaction confirmation latency.","Moreover, we propose an efficient unbiased leader rotation scheme to ensure high performance under malicious behavior.","For cross-shard aspect, a proof-assisted efficient cross-shard transaction processing mechanism is proposed to guard the cross-shard transactions with low overhead.","We implement SP-Chain based on Harmony, and evaluate its performance via large-scale deployment.","Extensive evaluations suggest that SP-Chain can process more than 10,000 tx/sec under malicious behaviors with a confirmation latency of 7.6s in a network of 4,000 nodes."],"url":"http://arxiv.org/abs/2407.06953v1"}
{"created":"2024-07-09 15:32:21","title":"Domain theory in univalent foundations I: Directed complete posets and Scott's $D_\\infty$","abstract":"We develop domain theory in constructive and predicative univalent foundations (also known as homotopy type theory). That we work predicatively means that we do not assume Voevodsky's propositional resizing axioms. Our work is constructive in the sense that we do not rely on excluded middle or the axiom of (countable) choice. Domain theory studies so-called directed complete posets (dcpos) and Scott continuous maps between them and has applications in a variety of fields, such as programming language semantics, higher-type computability and topology. A common approach to deal with size issues in a predicative foundation is to work with information systems, abstract bases or formal topologies rather than dcpos, and approximable relations rather than Scott continuous functions. In our type-theoretic approach, we instead accept that dcpos may be large and work with type universes to account for this. A priori one might expect that iterative constructions of dcpos may result in a need for ever-increasing universes and are predicatively impossible. We show, through a careful tracking of type universe parameters, that such constructions can be carried out in a predicative setting. In particular, we give a predicative reconstruction of Scott's $D_\\infty$ model of the untyped $\\lambda$-calculus. Our work is formalised in the Agda proof assistant and its ability to infer universe levels has been invaluable for our purposes.","sentences":["We develop domain theory in constructive and predicative univalent foundations (also known as homotopy type theory).","That we work predicatively means that we do not assume Voevodsky's propositional resizing axioms.","Our work is constructive in the sense that we do not rely on excluded middle or the axiom of (countable) choice.","Domain theory studies so-called directed complete posets (dcpos) and Scott continuous maps between them and has applications in a variety of fields, such as programming language semantics, higher-type computability and topology.","A common approach to deal with size issues in a predicative foundation is to work with information systems, abstract bases or formal topologies rather than dcpos, and approximable relations rather than Scott continuous functions.","In our type-theoretic approach, we instead accept that dcpos may be large and work with type universes to account for this.","A priori one might expect that iterative constructions of dcpos may result in a need for ever-increasing universes and are predicatively impossible.","We show, through a careful tracking of type universe parameters, that such constructions can be carried out in a predicative setting.","In particular, we give a predicative reconstruction of Scott's $D_\\infty$ model of the untyped $\\lambda$-calculus.","Our work is formalised in the Agda proof assistant and its ability to infer universe levels has been invaluable for our purposes."],"url":"http://arxiv.org/abs/2407.06952v1"}
{"created":"2024-07-09 15:32:17","title":"RoboCAS: A Benchmark for Robotic Manipulation in Complex Object Arrangement Scenarios","abstract":"Foundation models hold significant potential for enabling robots to perform long-horizon general manipulation tasks. However, the simplicity of tasks and the uniformity of environments in existing benchmarks restrict their effective deployment in complex scenarios. To address this limitation, this paper introduces the \\textit{RoboCAS} benchmark, the first benchmark specifically designed for complex object arrangement scenarios in robotic manipulation. This benchmark employs flexible and concise scripted policies to efficiently collect a diverse array of demonstrations, showcasing scattered, orderly, and stacked object arrangements within a highly realistic physical simulation environment. It includes complex processes such as target retrieval, obstacle clearance, and robot manipulation, testing agents' abilities to perform long-horizon planning for spatial reasoning and predicting chain reactions under ambiguous instructions. Extensive experiments on multiple baseline models reveal their limitations in managing complex object arrangement scenarios, underscoring the urgent need for intelligent agents capable of performing long-horizon operations in practical deployments and providing valuable insights for future research directions. Project website: \\url{https://github.com/notFoundThisPerson/RoboCAS-v0}.","sentences":["Foundation models hold significant potential for enabling robots to perform long-horizon general manipulation tasks.","However, the simplicity of tasks and the uniformity of environments in existing benchmarks restrict their effective deployment in complex scenarios.","To address this limitation, this paper introduces the \\textit{RoboCAS} benchmark, the first benchmark specifically designed for complex object arrangement scenarios in robotic manipulation.","This benchmark employs flexible and concise scripted policies to efficiently collect a diverse array of demonstrations, showcasing scattered, orderly, and stacked object arrangements within a highly realistic physical simulation environment.","It includes complex processes such as target retrieval, obstacle clearance, and robot manipulation, testing agents' abilities to perform long-horizon planning for spatial reasoning and predicting chain reactions under ambiguous instructions.","Extensive experiments on multiple baseline models reveal their limitations in managing complex object arrangement scenarios, underscoring the urgent need for intelligent agents capable of performing long-horizon operations in practical deployments and providing valuable insights for future research directions.","Project website: \\url{https://github.com/notFoundThisPerson/RoboCAS-v0}."],"url":"http://arxiv.org/abs/2407.06951v1"}
{"created":"2024-07-09 15:31:41","title":"Spanish TrOCR: Leveraging Transfer Learning for Language Adaptation","abstract":"This study explores the transfer learning capabilities of the TrOCR architecture to Spanish. TrOCR is a transformer-based Optical Character Recognition (OCR) model renowned for its state-of-the-art performance in English benchmarks. Inspired by Li et al. assertion regarding its adaptability to multilingual text recognition, we investigate two distinct approaches to adapt the model to a new language: integrating an English TrOCR encoder with a language specific decoder and train the model on this specific language, and fine-tuning the English base TrOCR model on a new language data. Due to the scarcity of publicly available datasets, we present a resource-efficient pipeline for creating OCR datasets in any language, along with a comprehensive benchmark of the different image generation methods employed with a focus on Visual Rich Documents (VRDs). Additionally, we offer a comparative analysis of the two approaches for the Spanish language, demonstrating that fine-tuning the English TrOCR on Spanish yields superior recognition than the language specific decoder for a fixed dataset size. We evaluate our model employing character and word error rate metrics on a public available printed dataset, comparing the performance against other open-source and cloud OCR spanish models. As far as we know, these resources represent the best open-source model for OCR in Spanish. The Spanish TrOCR models are publicly available on HuggingFace [20] and the code to generate the dataset is available on Github [25].","sentences":["This study explores the transfer learning capabilities of the TrOCR architecture to Spanish.","TrOCR is a transformer-based Optical Character Recognition (OCR) model renowned for its state-of-the-art performance in English benchmarks.","Inspired by Li et al. assertion regarding its adaptability to multilingual text recognition, we investigate two distinct approaches to adapt the model to a new language: integrating an English TrOCR encoder with a language specific decoder and train the model on this specific language, and fine-tuning the English base TrOCR model on a new language data.","Due to the scarcity of publicly available datasets, we present a resource-efficient pipeline for creating OCR datasets in any language, along with a comprehensive benchmark of the different image generation methods employed with a focus on Visual Rich Documents (VRDs).","Additionally, we offer a comparative analysis of the two approaches for the Spanish language, demonstrating that fine-tuning the English TrOCR on Spanish yields superior recognition than the language specific decoder for a fixed dataset size.","We evaluate our model employing character and word error rate metrics on a public available printed dataset, comparing the performance against other open-source and cloud OCR spanish models.","As far as we know, these resources represent the best open-source model for OCR in Spanish.","The Spanish TrOCR models are publicly available on HuggingFace","[20] and the code to generate the dataset is available on Github","[25]."],"url":"http://arxiv.org/abs/2407.06950v1"}
{"created":"2024-07-09 15:23:35","title":"Audio-Language Datasets of Scenes and Events: A Survey","abstract":"Audio-language models (ALMs) process sounds to provide a linguistic description of sound-producing events and scenes. Recent advances in computing power and dataset creation have led to significant progress in this domain. This paper surveys existing datasets used for training audio-language models, emphasizing the recent trend towards using large, diverse datasets to enhance model performance. Key sources of these datasets include the Freesound platform and AudioSet that have contributed to the field's rapid growth. Although prior surveys primarily address techniques and training details, this survey categorizes and evaluates a wide array of datasets, addressing their origins, characteristics, and use cases. It also performs a data leak analysis to ensure dataset integrity and mitigate bias between datasets. This survey was conducted by analyzing research papers up to and including December 2023, and does not contain any papers after that period.","sentences":["Audio-language models (ALMs) process sounds to provide a linguistic description of sound-producing events and scenes.","Recent advances in computing power and dataset creation have led to significant progress in this domain.","This paper surveys existing datasets used for training audio-language models, emphasizing the recent trend towards using large, diverse datasets to enhance model performance.","Key sources of these datasets include the Freesound platform and AudioSet that have contributed to the field's rapid growth.","Although prior surveys primarily address techniques and training details, this survey categorizes and evaluates a wide array of datasets, addressing their origins, characteristics, and use cases.","It also performs a data leak analysis to ensure dataset integrity and mitigate bias between datasets.","This survey was conducted by analyzing research papers up to and including December 2023, and does not contain any papers after that period."],"url":"http://arxiv.org/abs/2407.06947v1"}
{"created":"2024-07-09 15:23:28","title":"Self-Recognition in Language Models","abstract":"A rapidly growing number of applications rely on a small set of closed-source language models (LMs). This dependency might introduce novel security risks if LMs develop self-recognition capabilities. Inspired by human identity verification methods, we propose a novel approach for assessing self-recognition in LMs using model-generated \"security questions\". Our test can be externally administered to keep track of frontier models as it does not require access to internal model parameters or output probabilities. We use our test to examine self-recognition in ten of the most capable open- and closed-source LMs currently publicly available. Our extensive experiments found no empirical evidence of general or consistent self-recognition in any examined LM. Instead, our results suggest that given a set of alternatives, LMs seek to pick the \"best\" answer, regardless of its origin. Moreover, we find indications that preferences about which models produce the best answers are consistent across LMs. We additionally uncover novel insights on position bias considerations for LMs in multiple-choice settings.","sentences":["A rapidly growing number of applications rely on a small set of closed-source language models (LMs).","This dependency might introduce novel security risks if LMs develop self-recognition capabilities.","Inspired by human identity verification methods, we propose a novel approach for assessing self-recognition in LMs using model-generated \"security questions\".","Our test can be externally administered to keep track of frontier models as it does not require access to internal model parameters or output probabilities.","We use our test to examine self-recognition in ten of the most capable open- and closed-source LMs currently publicly available.","Our extensive experiments found no empirical evidence of general or consistent self-recognition in any examined LM.","Instead, our results suggest that given a set of alternatives, LMs seek to pick the \"best\" answer, regardless of its origin.","Moreover, we find indications that preferences about which models produce the best answers are consistent across LMs.","We additionally uncover novel insights on position bias considerations for LMs in multiple-choice settings."],"url":"http://arxiv.org/abs/2407.06946v1"}
{"created":"2024-07-09 15:19:13","title":"A Starter's Kit for Concentric Tube Robots","abstract":"Concentric Tube Robots (CTRs) have garnered significant interest within the surgical robotics community because of their flexibility, dexterity, and ease of miniaturization. However, mastering the unique kinematics and design principles of CTRs can be challenging for newcomers to the field. In this paper, we present an educational kit aimed at lowering the barriers to entry into concentric tube robot research. Our goal is to provide accessible learning resources for CTRs, bridging the knowledge gap between traditional robotic arms and these specialized devices. The proposed kit includes (1) An open-source design and assembly instructions for an economical (cost of materials $\\approx$ 700 USD) modular CTR; (2) A set of self-study materials to learn the basics of CTR modeling and control, including automatically-graded assignments. To evaluate the effectiveness of our educational kit, we conducted a human subjects study involving first-year graduate students in engineering. Over a four-week period, participants -- none of whom had any prior knowledge of concentric tube robots -- successfully built their first CTR using the provided materials, implemented the robot's kinematics in MATLAB, and conducted a tip-tracking experiment with an optical tracking device. Our findings suggest that the proposed kit facilitates learning and hands-on experience with CTRs, and furthermore, it has the potential to help early-stage graduate students get rapidly started with CTR research. By disseminating these resources, we hope to broaden participation in concentric tube robot research to a wider a more diverse group of researchers.","sentences":["Concentric Tube Robots (CTRs) have garnered significant interest within the surgical robotics community because of their flexibility, dexterity, and ease of miniaturization.","However, mastering the unique kinematics and design principles of CTRs can be challenging for newcomers to the field.","In this paper, we present an educational kit aimed at lowering the barriers to entry into concentric tube robot research.","Our goal is to provide accessible learning resources for CTRs, bridging the knowledge gap between traditional robotic arms and these specialized devices.","The proposed kit includes (1) An open-source design and assembly instructions for an economical (cost of materials $\\approx$ 700 USD) modular CTR; (2) A set of self-study materials to learn the basics of CTR modeling and control, including automatically-graded assignments.","To evaluate the effectiveness of our educational kit, we conducted a human subjects study involving first-year graduate students in engineering.","Over a four-week period, participants -- none of whom had any prior knowledge of concentric tube robots -- successfully built their first CTR using the provided materials, implemented the robot's kinematics in MATLAB, and conducted a tip-tracking experiment with an optical tracking device.","Our findings suggest that the proposed kit facilitates learning and hands-on experience with CTRs, and furthermore, it has the potential to help early-stage graduate students get rapidly started with CTR research.","By disseminating these resources, we hope to broaden participation in concentric tube robot research to a wider a more diverse group of researchers."],"url":"http://arxiv.org/abs/2407.06943v1"}
{"created":"2024-07-09 15:19:09","title":"An Improved Two-Step Attack on CRYSTALS-Kyber","abstract":"After three rounds of post-quantum cryptography (PQC) strict evaluations conducted by the national institute of standards and technology (NIST), CRYSTALS-Kyber has successfully been selected and drafted for standardization from the mid of 2022. It becomes urgent to further evaluate Kyber's physical security for the upcoming deployment phase. In this paper, we present an improved two-step attack on Kyber to quickly recover the full secret key, s, by using much fewer energy traces and less time. In the first step, we use the correlation power analysis (CPA) attack to obtain a portion of guess values of s with a small number of energy traces. The CPA attack is enhanced by utilizing both the Pearson and Kendall's rank correlation coefficients and modifying the leakage model to improve the accuracy. In the second step, we adopt the lattice attack to recover s based on the results of CPA. The success rate is largely built up by constructing a trail-and-error method. We implement the proposed attack for the reference implementation of Kyber512 (4 128-value groups of s) on ARM Cortex-M4 and successfully recover a 128-value group of s in about 9 minutes using a 16-core machine. Additionally, in that case, we only cost at most 60 CPA guess values for a group and 15 power traces for a guess.","sentences":["After three rounds of post-quantum cryptography (PQC) strict evaluations conducted by the national institute of standards and technology (NIST), CRYSTALS-Kyber has successfully been selected and drafted for standardization from the mid of 2022.","It becomes urgent to further evaluate Kyber's physical security for the upcoming deployment phase.","In this paper, we present an improved two-step attack on Kyber to quickly recover the full secret key, s, by using much fewer energy traces and less time.","In the first step, we use the correlation power analysis (CPA) attack to obtain a portion of guess values of s with a small number of energy traces.","The CPA attack is enhanced by utilizing both the Pearson and Kendall's rank correlation coefficients and modifying the leakage model to improve the accuracy.","In the second step, we adopt the lattice attack to recover s based on the results of CPA.","The success rate is largely built up by constructing a trail-and-error method.","We implement the proposed attack for the reference implementation of Kyber512 (4 128-value groups of s) on ARM Cortex-M4 and successfully recover a 128-value group of s in about 9 minutes using a 16-core machine.","Additionally, in that case, we only cost at most 60 CPA guess values for a group and 15 power traces for a guess."],"url":"http://arxiv.org/abs/2407.06942v1"}
{"created":"2024-07-09 15:18:56","title":"Raply: A profanity-mitigated rap generator","abstract":"The task of writing rap is challenging and involves producing complex rhyming schemes, yet meaningful lyrics. In this work, we propose Raply, a fine-tuned GPT-2 model capable of producing meaningful rhyming text in the style of rap. In addition to its rhyming capabilities, the model is able to generate less offensive content. It was achieved through the fine-tuning the model on a new dataset Mitislurs, a profanity-mitigated corpus. We evaluate the output of the model on two criteria: 1) rhyming based on the rhyme density metric; 2) profanity content, using the list of profanities for the English language. To our knowledge, this is the first attempt at profanity mitigation for rap lyrics generation.","sentences":["The task of writing rap is challenging and involves producing complex rhyming schemes, yet meaningful lyrics.","In this work, we propose Raply, a fine-tuned GPT-2 model capable of producing meaningful rhyming text in the style of rap.","In addition to its rhyming capabilities, the model is able to generate less offensive content.","It was achieved through the fine-tuning the model on a new dataset Mitislurs, a profanity-mitigated corpus.","We evaluate the output of the model on two criteria: 1) rhyming based on the rhyme density metric; 2) profanity content, using the list of profanities for the English language.","To our knowledge, this is the first attempt at profanity mitigation for rap lyrics generation."],"url":"http://arxiv.org/abs/2407.06941v1"}
{"created":"2024-07-09 15:15:01","title":"Towards Open-World Mobile Manipulation in Homes: Lessons from the Neurips 2023 HomeRobot Open Vocabulary Mobile Manipulation Challenge","abstract":"In order to develop robots that can effectively serve as versatile and capable home assistants, it is crucial for them to reliably perceive and interact with a wide variety of objects across diverse environments. To this end, we proposed Open Vocabulary Mobile Manipulation as a key benchmark task for robotics: finding any object in a novel environment and placing it on any receptacle surface within that environment. We organized a NeurIPS 2023 competition featuring both simulation and real-world components to evaluate solutions to this task. Our baselines on the most challenging version of this task, using real perception in simulation, achieved only an 0.8% success rate; by the end of the competition, the best participants achieved an 10.8\\% success rate, a 13x improvement. We observed that the most successful teams employed a variety of methods, yet two common threads emerged among the best solutions: enhancing error detection and recovery, and improving the integration of perception with decision-making processes. In this paper, we detail the results and methodologies used, both in simulation and real-world settings. We discuss the lessons learned and their implications for future research. Additionally, we compare performance in real and simulated environments, emphasizing the necessity for robust generalization to novel settings.","sentences":["In order to develop robots that can effectively serve as versatile and capable home assistants, it is crucial for them to reliably perceive and interact with a wide variety of objects across diverse environments.","To this end, we proposed Open Vocabulary Mobile Manipulation as a key benchmark task for robotics: finding any object in a novel environment and placing it on any receptacle surface within that environment.","We organized a NeurIPS 2023 competition featuring both simulation and real-world components to evaluate solutions to this task.","Our baselines on the most challenging version of this task, using real perception in simulation, achieved only an 0.8% success rate; by the end of the competition, the best participants achieved an 10.8\\% success rate, a 13x improvement.","We observed that the most successful teams employed a variety of methods, yet two common threads emerged among the best solutions: enhancing error detection and recovery, and improving the integration of perception with decision-making processes.","In this paper, we detail the results and methodologies used, both in simulation and real-world settings.","We discuss the lessons learned and their implications for future research.","Additionally, we compare performance in real and simulated environments, emphasizing the necessity for robust generalization to novel settings."],"url":"http://arxiv.org/abs/2407.06939v1"}
{"created":"2024-07-09 15:14:45","title":"RodinHD: High-Fidelity 3D Avatar Generation with Diffusion Models","abstract":"We present RodinHD, which can generate high-fidelity 3D avatars from a portrait image. Existing methods fail to capture intricate details such as hairstyles which we tackle in this paper. We first identify an overlooked problem of catastrophic forgetting that arises when fitting triplanes sequentially on many avatars, caused by the MLP decoder sharing scheme. To overcome this issue, we raise a novel data scheduling strategy and a weight consolidation regularization term, which improves the decoder's capability of rendering sharper details. Additionally, we optimize the guiding effect of the portrait image by computing a finer-grained hierarchical representation that captures rich 2D texture cues, and injecting them to the 3D diffusion model at multiple layers via cross-attention. When trained on 46K avatars with a noise schedule optimized for triplanes, the resulting model can generate 3D avatars with notably better details than previous methods and can generalize to in-the-wild portrait input.","sentences":["We present RodinHD, which can generate high-fidelity 3D avatars from a portrait image.","Existing methods fail to capture intricate details such as hairstyles which we tackle in this paper.","We first identify an overlooked problem of catastrophic forgetting that arises when fitting triplanes sequentially on many avatars, caused by the MLP decoder sharing scheme.","To overcome this issue, we raise a novel data scheduling strategy and a weight consolidation regularization term, which improves the decoder's capability of rendering sharper details.","Additionally, we optimize the guiding effect of the portrait image by computing a finer-grained hierarchical representation that captures rich 2D texture cues, and injecting them to the 3D diffusion model at multiple layers via cross-attention.","When trained on 46K avatars with a noise schedule optimized for triplanes, the resulting model can generate 3D avatars with notably better details than previous methods and can generalize to in-the-wild portrait input."],"url":"http://arxiv.org/abs/2407.06938v1"}
{"created":"2024-07-09 15:14:41","title":"HumanRefiner: Benchmarking Abnormal Human Generation and Refining with Coarse-to-fine Pose-Reversible Guidance","abstract":"Text-to-image diffusion models have significantly advanced in conditional image generation. However, these models usually struggle with accurately rendering images featuring humans, resulting in distorted limbs and other anomalies. This issue primarily stems from the insufficient recognition and evaluation of limb qualities in diffusion models. To address this issue, we introduce AbHuman, the first large-scale synthesized human benchmark focusing on anatomical anomalies. This benchmark consists of 56K synthesized human images, each annotated with detailed, bounding-box level labels identifying 147K human anomalies in 18 different categories. Based on this, the recognition of human anomalies can be established, which in turn enhances image generation through traditional techniques such as negative prompting and guidance. To further boost the improvement, we propose HumanRefiner, a novel plug-and-play approach for the coarse-to-fine refinement of human anomalies in text-to-image generation. Specifically, HumanRefiner utilizes a self-diagnostic procedure to detect and correct issues related to both coarse-grained abnormal human poses and fine-grained anomaly levels, facilitating pose-reversible diffusion generation. Experimental results on the AbHuman benchmark demonstrate that HumanRefiner significantly reduces generative discrepancies, achieving a 2.9x improvement in limb quality compared to the state-of-the-art open-source generator SDXL and a 1.4x improvement over DALL-E 3 in human evaluations. Our data and code are available at https://github.com/Enderfga/HumanRefiner.","sentences":["Text-to-image diffusion models have significantly advanced in conditional image generation.","However, these models usually struggle with accurately rendering images featuring humans, resulting in distorted limbs and other anomalies.","This issue primarily stems from the insufficient recognition and evaluation of limb qualities in diffusion models.","To address this issue, we introduce AbHuman, the first large-scale synthesized human benchmark focusing on anatomical anomalies.","This benchmark consists of 56K synthesized human images, each annotated with detailed, bounding-box level labels identifying 147K human anomalies in 18 different categories.","Based on this, the recognition of human anomalies can be established, which in turn enhances image generation through traditional techniques such as negative prompting and guidance.","To further boost the improvement, we propose HumanRefiner, a novel plug-and-play approach for the coarse-to-fine refinement of human anomalies in text-to-image generation.","Specifically, HumanRefiner utilizes a self-diagnostic procedure to detect and correct issues related to both coarse-grained abnormal human poses and fine-grained anomaly levels, facilitating pose-reversible diffusion generation.","Experimental results on the AbHuman benchmark demonstrate that HumanRefiner significantly reduces generative discrepancies, achieving a 2.9x improvement in limb quality compared to the state-of-the-art open-source generator SDXL and a 1.4x improvement over DALL-E 3 in human evaluations.","Our data and code are available at https://github.com/Enderfga/HumanRefiner."],"url":"http://arxiv.org/abs/2407.06937v1"}
{"created":"2024-07-09 15:10:59","title":"Bayesian Federated Learning with Hamiltonian Monte Carlo: Algorithm and Theory","abstract":"This work introduces a novel and efficient Bayesian federated learning algorithm, namely, the Federated Averaging stochastic Hamiltonian Monte Carlo (FA-HMC), for parameter estimation and uncertainty quantification. We establish rigorous convergence guarantees of FA-HMC on non-iid distributed data sets, under the strong convexity and Hessian smoothness assumptions. Our analysis investigates the effects of parameter space dimension, noise on gradients and momentum, and the frequency of communication (between the central node and local nodes) on the convergence and communication costs of FA-HMC. Beyond that, we establish the tightness of our analysis by showing that the convergence rate cannot be improved even for continuous FA-HMC process. Moreover, extensive empirical studies demonstrate that FA-HMC outperforms the existing Federated Averaging-Langevin Monte Carlo (FA-LD) algorithm.","sentences":["This work introduces a novel and efficient Bayesian federated learning algorithm, namely, the Federated Averaging stochastic Hamiltonian Monte Carlo (FA-HMC), for parameter estimation and uncertainty quantification.","We establish rigorous convergence guarantees of FA-HMC on non-iid distributed data sets, under the strong convexity and Hessian smoothness assumptions.","Our analysis investigates the effects of parameter space dimension, noise on gradients and momentum, and the frequency of communication (between the central node and local nodes) on the convergence and communication costs of FA-HMC.","Beyond that, we establish the tightness of our analysis by showing that the convergence rate cannot be improved even for continuous FA-HMC process.","Moreover, extensive empirical studies demonstrate that FA-HMC outperforms the existing Federated Averaging-Langevin Monte Carlo (FA-LD) algorithm."],"url":"http://arxiv.org/abs/2407.06935v1"}
{"created":"2024-07-09 15:06:52","title":"A Unified Approach to Multi-task Legged Navigation: Temporal Logic Meets Reinforcement Learning","abstract":"This study examines the problem of hopping robot navigation planning to achieve simultaneous goal-directed and environment exploration tasks. We consider a scenario in which the robot has mandatory goal-directed tasks defined using Linear Temporal Logic (LTL) specifications as well as optional exploration tasks represented using a reward function. Additionally, there exists uncertainty in the robot dynamics which results in motion perturbation. We first propose an abstraction of 3D hopping robot dynamics which enables high-level planning and a neural-network-based optimization for low-level control. We then introduce a Multi-task Product IMDP (MT-PIMDP) model of the system and tasks. We propose a unified control policy synthesis algorithm which enables both task-directed goal-reaching behaviors as well as task-agnostic exploration to learn perturbations and reward. We provide a formal proof of the trade-off induced by prioritizing either LTL or RL actions. We demonstrate our methods with simulation case studies in a 2D world navigation environment.","sentences":["This study examines the problem of hopping robot navigation planning to achieve simultaneous goal-directed and environment exploration tasks.","We consider a scenario in which the robot has mandatory goal-directed tasks defined using Linear Temporal Logic (LTL) specifications as well as optional exploration tasks represented using a reward function.","Additionally, there exists uncertainty in the robot dynamics which results in motion perturbation.","We first propose an abstraction of 3D hopping robot dynamics which enables high-level planning and a neural-network-based optimization for low-level control.","We then introduce a Multi-task Product IMDP (MT-PIMDP) model of the system and tasks.","We propose a unified control policy synthesis algorithm which enables both task-directed goal-reaching behaviors as well as task-agnostic exploration to learn perturbations and reward.","We provide a formal proof of the trade-off induced by prioritizing either LTL or RL actions.","We demonstrate our methods with simulation case studies in a 2D world navigation environment."],"url":"http://arxiv.org/abs/2407.06931v1"}
{"created":"2024-07-09 15:06:47","title":"Integrating Ontology Design with the CRISP-DM in the context of Cyber-Physical Systems Maintenance","abstract":"In the following contribution, a method is introduced that integrates domain expert-centric ontology design with the Cross-Industry Standard Process for Data Mining (CRISP-DM). This approach aims to efficiently build an application-specific ontology tailored to the corrective maintenance of Cyber-Physical Systems (CPS). The proposed method is divided into three phases. In phase one, ontology requirements are systematically specified, defining the relevant knowledge scope. Accordingly, CPS life cycle data is contextualized in phase two using domain-specific ontological artifacts. This formalized domain knowledge is then utilized in the CRISP-DM to efficiently extract new insights from the data. Finally, the newly developed data-driven model is employed to populate and expand the ontology. Thus, information extracted from this model is semantically annotated and aligned with the existing ontology in phase three. The applicability of this method has been evaluated in an anomaly detection case study for a modular process plant.","sentences":["In the following contribution, a method is introduced that integrates domain expert-centric ontology design with the Cross-Industry Standard Process for Data Mining (CRISP-DM).","This approach aims to efficiently build an application-specific ontology tailored to the corrective maintenance of Cyber-Physical Systems (CPS).","The proposed method is divided into three phases.","In phase one, ontology requirements are systematically specified, defining the relevant knowledge scope.","Accordingly, CPS life cycle data is contextualized in phase two using domain-specific ontological artifacts.","This formalized domain knowledge is then utilized in the CRISP-DM to efficiently extract new insights from the data.","Finally, the newly developed data-driven model is employed to populate and expand the ontology.","Thus, information extracted from this model is semantically annotated and aligned with the existing ontology in phase three.","The applicability of this method has been evaluated in an anomaly detection case study for a modular process plant."],"url":"http://arxiv.org/abs/2407.06930v1"}
{"created":"2024-07-09 14:58:12","title":"foetus - Termination Checker for Simple Functional Programs","abstract":"We introduce a simple functional language foetus (lambda calculus with tuples, constructors and pattern matching) supplied with a termination checker. This checker tries to find a well-founded structural order on the parameters on the given function to prove termination. The components of the check algorithm are: function call extraction out of the program text, call graph completion and finding a lexical order for the function parameters.","sentences":["We introduce a simple functional language foetus (lambda calculus with tuples, constructors and pattern matching) supplied with a termination checker.","This checker tries to find a well-founded structural order on the parameters on the given function to prove termination.","The components of the check algorithm are: function call extraction out of the program text, call graph completion and finding a lexical order for the function parameters."],"url":"http://arxiv.org/abs/2407.06924v1"}
{"created":"2024-07-09 14:52:52","title":"Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models","abstract":"Large language models (LLMs) have been shown to propagate and amplify harmful stereotypes, particularly those that disproportionately affect marginalised communities. To understand the effect of these stereotypes more comprehensively, we introduce GlobalBias, a dataset of 876k sentences incorporating 40 distinct gender-by-ethnicity groups alongside descriptors typically used in bias literature, which enables us to study a broad set of stereotypes from around the world. We use GlobalBias to directly probe a suite of LMs via perplexity, which we use as a proxy to determine how certain stereotypes are represented in the model's internal representations. Following this, we generate character profiles based on given names and evaluate the prevalence of stereotypes in model outputs. We find that the demographic groups associated with various stereotypes remain consistent across model likelihoods and model outputs. Furthermore, larger models consistently display higher levels of stereotypical outputs, even when explicitly instructed not to.","sentences":["Large language models (LLMs) have been shown to propagate and amplify harmful stereotypes, particularly those that disproportionately affect marginalised communities.","To understand the effect of these stereotypes more comprehensively, we introduce GlobalBias, a dataset of 876k sentences incorporating 40 distinct gender-by-ethnicity groups alongside descriptors typically used in bias literature, which enables us to study a broad set of stereotypes from around the world.","We use GlobalBias to directly probe a suite of LMs via perplexity, which we use as a proxy to determine how certain stereotypes are represented in the model's internal representations.","Following this, we generate character profiles based on given names and evaluate the prevalence of stereotypes in model outputs.","We find that the demographic groups associated with various stereotypes remain consistent across model likelihoods and model outputs.","Furthermore, larger models consistently display higher levels of stereotypical outputs, even when explicitly instructed not to."],"url":"http://arxiv.org/abs/2407.06917v1"}
{"created":"2024-07-09 14:50:14","title":"FE-GUT: Factor Graph Optimization hybrid with Extended Kalman Filter for tightly coupled GNSS/UWB Integration","abstract":"Precise positioning and navigation information has been increasingly important with the development of the consumer electronics market. Due to some deficits of Global Navigation Satellite System (GNSS), such as susceptible to interferences, integrating of GNSS with additional alternative sensors is a promising approach to overcome the performance limitations of GNSS-based localization systems. Ultra-Wideband (UWB) can be used to enhance GNSS in constructing an integrated localization system. However, most low-cost UWB devices lack a hardware-level time synchronization feature, which necessitates the estimation and compensation of the time-offset in the tightly coupled GNSS/UWB integration. Given the flexibility of probabilistic graphical models, the time-offset can be modeled as an invariant constant in the discretization of the continuous model. This work proposes a novel architecture in which Factor Graph Optimization (FGO) is hybrid with Extend Kalman Filter (EKF) for tightly coupled GNSS/UWB integration with online Temporal calibration (FE-GUT). FGO is utilized to precisely estimate the time-offset, while EKF provides initailization for the new factors and performs time-offset compensation. Simulation-based experiments validate the integrated localization performance of FE-GUT. In a four-wheeled robot scenario, the results demonstrate that, compared to EKF, FE-GUT can improve horizontal and vertical localization accuracy by 58.59\\% and 34.80\\%, respectively, while the time-offset estimation accuracy is improved by 76.80\\%. All the source codes and datasets can be gotten via https://github.com/zhaoqj23/FE-GUT/.","sentences":["Precise positioning and navigation information has been increasingly important with the development of the consumer electronics market.","Due to some deficits of Global Navigation Satellite System (GNSS), such as susceptible to interferences, integrating of GNSS with additional alternative sensors is a promising approach to overcome the performance limitations of GNSS-based localization systems.","Ultra-Wideband (UWB) can be used to enhance GNSS in constructing an integrated localization system.","However, most low-cost UWB devices lack a hardware-level time synchronization feature, which necessitates the estimation and compensation of the time-offset in the tightly coupled GNSS/UWB integration.","Given the flexibility of probabilistic graphical models, the time-offset can be modeled as an invariant constant in the discretization of the continuous model.","This work proposes a novel architecture in which Factor Graph Optimization (FGO) is hybrid with Extend Kalman Filter (EKF) for tightly coupled GNSS/UWB integration with online Temporal calibration (FE-GUT).","FGO is utilized to precisely estimate the time-offset, while EKF provides initailization for the new factors and performs time-offset compensation.","Simulation-based experiments validate the integrated localization performance of FE-GUT.","In a four-wheeled robot scenario, the results demonstrate that, compared to EKF, FE-GUT can improve horizontal and vertical localization accuracy by 58.59\\% and 34.80\\%, respectively, while the time-offset estimation accuracy is improved by 76.80\\%.","All the source codes and datasets can be gotten via https://github.com/zhaoqj23/FE-GUT/."],"url":"http://arxiv.org/abs/2407.06915v1"}
{"created":"2024-07-09 14:48:30","title":"A Simple, Nearly-Optimal Algorithm for Differentially Private All-Pairs Shortest Distances","abstract":"The all-pairs shortest distances (APSD) with differential privacy (DP) problem takes as input an undirected, weighted graph $G = (V,E, \\mathbf{w})$ and outputs a private estimate of the shortest distances in $G$ between all pairs of vertices. In this paper, we present a simple $\\widetilde{O}(n^{1/3}/\\varepsilon)$-accurate algorithm to solve APSD with $\\varepsilon$-DP, which reduces to $\\widetilde{O}(n^{1/4}/\\varepsilon)$ in the $(\\varepsilon, \\delta)$-DP setting, where $n = |V|$. Our algorithm greatly improves upon the error of prior algorithms, namely $\\widetilde{O}(n^{2/3}/\\varepsilon)$ and $\\widetilde{O}(\\sqrt{n}/\\varepsilon)$ in the two respective settings, and is the first to be optimal up to a polylogarithmic factor, based on a lower bound of $\\widetilde{\\Omega}(n^{1/4})$.   In the case where a multiplicative approximation is allowed, we give two different constructions of algorithms with reduced additive error. Our first construction allows a multiplicative approximation of $O(k\\log{\\log{n}})$ and has additive error $\\widetilde{O}(k\\cdot n^{1/k}/\\varepsilon)$ in the $\\varepsilon$-DP case and $\\widetilde{O}(\\sqrt{k}\\cdot n^{1/(2k)}/\\varepsilon)$ in the $(\\varepsilon, \\delta)$-DP case. Our second construction allows multiplicative approximation $2k-1$ and has the same asymptotic additive error as the first construction. Both constructions significantly improve upon the currently best-known additive error of, $\\widetilde{O}(k\\cdot n^{1/2 + 1/(4k+2)}/\\varepsilon)$ and $\\widetilde{O}(k\\cdot n^{1/3 + 2/(9k+3)}/\\varepsilon)$, respectively. Our algorithms are straightforward and work by decomposing a graph into a set of spanning trees, and applying a key observation that we can privately release APSD in trees with $O(\\text{polylog}(n))$ error.","sentences":["The all-pairs shortest distances (APSD) with differential privacy (DP) problem takes as input an undirected, weighted graph $G = (V,E, \\mathbf{w})$ and outputs a private estimate of the shortest distances in $G$ between all pairs of vertices.","In this paper, we present a simple $\\widetilde{O}(n^{1/3}/\\varepsilon)$-accurate algorithm to solve APSD with $\\varepsilon$-DP, which reduces to $\\widetilde{O}(n^{1/4}/\\varepsilon)$ in the $(\\varepsilon, \\delta)$-DP setting, where $n = |V|$.","Our algorithm greatly improves upon the error of prior algorithms, namely $\\widetilde{O}(n^{2/3}/\\varepsilon)$ and $\\widetilde{O}(\\sqrt{n}/\\varepsilon)$ in the two respective settings, and is the first to be optimal up to a polylogarithmic factor, based on a lower bound of $\\widetilde{\\Omega}(n^{1/4})$.   ","In the case where a multiplicative approximation is allowed, we give two different constructions of algorithms with reduced additive error.","Our first construction allows a multiplicative approximation of $O(k\\log{\\log{n}})$ and has additive error $\\widetilde{O}(k\\cdot n^{1/k}/\\varepsilon)$ in the $\\varepsilon$-DP case and $\\widetilde{O}(\\sqrt{k}\\cdot n^{1/(2k)}/\\varepsilon)$ in the $(\\varepsilon, \\delta)$-DP case.","Our second construction allows multiplicative approximation $2k-1$ and has the same asymptotic additive error as the first construction.","Both constructions significantly improve upon the currently best-known additive error of, $\\widetilde{O}(k\\cdot n^{1/2 + 1/(4k+2)}/\\varepsilon)$ and $\\widetilde{O}(k\\cdot n^{1/3 + 2/(9k+3)}/\\varepsilon)$, respectively.","Our algorithms are straightforward and work by decomposing a graph into a set of spanning trees, and applying a key observation that we can privately release APSD in trees with $O(\\text{polylog}(n))$ error."],"url":"http://arxiv.org/abs/2407.06913v1"}
{"created":"2024-07-09 14:48:02","title":"Optimal Neighborhood Exploration for Dynamic Independent Sets","abstract":"A dynamic graph algorithm is a data structure that supports edge insertions, deletions, and specific problem queries. While extensive research exists on dynamic algorithms for graph problems solvable in polynomial time, most of these algorithms have not been implemented or empirically evaluated.   This work addresses the NP-complete maximum weight and cardinality independent set problems in a dynamic setting, applicable to areas like dynamic map-labeling and vehicle routing. Real-world instances can be vast, with millions of vertices and edges, making it challenging to find near-optimal solutions quickly. Exact solvers can find optimal solutions but have exponential worst-case runtimes. Conversely, heuristic algorithms use local search techniques to improve solutions by optimizing vertices.   In this work, we introduce a novel local search technique called optimal neighborhood exploration. This technique creates independent subproblems that are solved to optimality, leading to improved overall solutions. Through numerous experiments, we assess the effectiveness of our approach and compare it with other state-of-the-art dynamic solvers. Our algorithm features a parameter, the subproblem size, that balances running time and solution quality. With this parameter, our configuration matches state-of-the-art performance for the cardinality independent set problem. By increasing the parameter, we significantly enhance solution quality.","sentences":["A dynamic graph algorithm is a data structure that supports edge insertions, deletions, and specific problem queries.","While extensive research exists on dynamic algorithms for graph problems solvable in polynomial time, most of these algorithms have not been implemented or empirically evaluated.   ","This work addresses the NP-complete maximum weight and cardinality independent set problems in a dynamic setting, applicable to areas like dynamic map-labeling and vehicle routing.","Real-world instances can be vast, with millions of vertices and edges, making it challenging to find near-optimal solutions quickly.","Exact solvers can find optimal solutions but have exponential worst-case runtimes.","Conversely, heuristic algorithms use local search techniques to improve solutions by optimizing vertices.   ","In this work, we introduce a novel local search technique called optimal neighborhood exploration.","This technique creates independent subproblems that are solved to optimality, leading to improved overall solutions.","Through numerous experiments, we assess the effectiveness of our approach and compare it with other state-of-the-art dynamic solvers.","Our algorithm features a parameter, the subproblem size, that balances running time and solution quality.","With this parameter, our configuration matches state-of-the-art performance for the cardinality independent set problem.","By increasing the parameter, we significantly enhance solution quality."],"url":"http://arxiv.org/abs/2407.06912v1"}
{"created":"2024-07-09 14:46:33","title":"Differentially Private Multiway and $k$-Cut","abstract":"In this paper, we address the challenge of differential privacy in the context of graph cuts, specifically focusing on the minimum $k$-cut and multiway cut problems. We introduce edge-differentially private algorithms that achieve nearly optimal performance for these problems.   For the multiway cut problem, we first provide a private algorithm with a multiplicative approximation ratio that matches the state-of-the-art non-private algorithm. We then present a tight information-theoretic lower bound on the additive error, demonstrating that our algorithm on weighted graphs is near-optimal for constant $k$. For the minimum $k$-cut problem, our algorithms leverage a known bound on the number of approximate $k$-cuts, resulting in a private algorithm with optimal additive error $O(k\\log n)$ for fixed privacy parameter. We also establish a information-theoretic lower bound that matches this additive error. Additionally, we give an efficient private algorithm for $k$-cut even for non-constant $k$, including a polynomial-time 2-approximation with an additive error of $\\widetilde{O}(k^{1.5})$.","sentences":["In this paper, we address the challenge of differential privacy in the context of graph cuts, specifically focusing on the minimum $k$-cut and multiway cut problems.","We introduce edge-differentially private algorithms that achieve nearly optimal performance for these problems.   ","For the multiway cut problem, we first provide a private algorithm with a multiplicative approximation ratio that matches the state-of-the-art non-private algorithm.","We then present a tight information-theoretic lower bound on the additive error, demonstrating that our algorithm on weighted graphs is near-optimal for constant $k$. For the minimum $k$-cut problem, our algorithms leverage a known bound on the number of approximate $k$-cuts, resulting in a private algorithm with optimal additive error $O(k\\log n)$ for fixed privacy parameter.","We also establish a information-theoretic lower bound that matches this additive error.","Additionally, we give an efficient private algorithm for $k$-cut even for non-constant $k$, including a polynomial-time 2-approximation with an additive error of $\\widetilde{O}(k^{1.5})$."],"url":"http://arxiv.org/abs/2407.06911v1"}
{"created":"2024-07-09 14:46:09","title":"Fine-grained large-scale content recommendations for MSX sellers","abstract":"One of the most critical tasks of Microsoft sellers is to meticulously track and nurture potential business opportunities through proactive engagement and tailored solutions. Recommender systems play a central role to help sellers achieve their goals. In this paper, we present a content recommendation model which surfaces various types of content (technical documentation, comparison with competitor products, customer success stories etc.) that sellers can share with their customers or use for their own self-learning. The model operates at the opportunity level which is the lowest possible granularity and the most relevant one for sellers. It is based on semantic matching between metadata from the contents and carefully selected attributes of the opportunities. Considering the volume of seller-managed opportunities in organizations such as Microsoft, we show how to perform efficient semantic matching over a very large number of opportunity-content combinations. The main challenge is to ensure that the top-5 relevant contents for each opportunity are recommended out of a total of $\\approx 40,000$ published contents. We achieve this target through an extensive comparison of different model architectures and feature selection. Finally, we further examine the quality of the recommendations in a quantitative manner using a combination of human domain experts as well as by using the recently proposed \"LLM as a judge\" framework.","sentences":["One of the most critical tasks of Microsoft sellers is to meticulously track and nurture potential business opportunities through proactive engagement and tailored solutions.","Recommender systems play a central role to help sellers achieve their goals.","In this paper, we present a content recommendation model which surfaces various types of content (technical documentation, comparison with competitor products, customer success stories etc.) that sellers can share with their customers or use for their own self-learning.","The model operates at the opportunity level which is the lowest possible granularity and the most relevant one for sellers.","It is based on semantic matching between metadata from the contents and carefully selected attributes of the opportunities.","Considering the volume of seller-managed opportunities in organizations such as Microsoft, we show how to perform efficient semantic matching over a very large number of opportunity-content combinations.","The main challenge is to ensure that the top-5 relevant contents for each opportunity are recommended out of a total of $\\approx 40,000$ published contents.","We achieve this target through an extensive comparison of different model architectures and feature selection.","Finally, we further examine the quality of the recommendations in a quantitative manner using a combination of human domain experts as well as by using the recently proposed \"LLM as a judge\" framework."],"url":"http://arxiv.org/abs/2407.06910v1"}
{"created":"2024-07-09 14:45:47","title":"Intercepting Unauthorized Aerial Robots in Controlled Airspace Using Reinforcement Learning","abstract":"The proliferation of unmanned aerial vehicles (UAVs) in controlled airspace presents significant risks, including potential collisions, disruptions to air traffic, and security threats. Ensuring the safe and efficient operation of airspace, particularly in urban environments and near critical infrastructure, necessitates effective methods to intercept unauthorized or non-cooperative UAVs. This work addresses the critical need for robust, adaptive systems capable of managing such threats through the use of Reinforcement Learning (RL). We present a novel approach utilizing RL to train fixed-wing UAV pursuer agents for intercepting dynamic evader targets. Our methodology explores both model-based and model-free RL algorithms, specifically DreamerV3, Truncated Quantile Critics (TQC), and Soft Actor-Critic (SAC). The training and evaluation of these algorithms were conducted under diverse scenarios, including unseen evasion strategies and environmental perturbations. Our approach leverages high-fidelity flight dynamics simulations to create realistic training environments. This research underscores the importance of developing intelligent, adaptive control systems for UAV interception, significantly contributing to the advancement of secure and efficient airspace management. It demonstrates the potential of RL to train systems capable of autonomously achieving these critical tasks.","sentences":["The proliferation of unmanned aerial vehicles (UAVs) in controlled airspace presents significant risks, including potential collisions, disruptions to air traffic, and security threats.","Ensuring the safe and efficient operation of airspace, particularly in urban environments and near critical infrastructure, necessitates effective methods to intercept unauthorized or non-cooperative UAVs.","This work addresses the critical need for robust, adaptive systems capable of managing such threats through the use of Reinforcement Learning (RL).","We present a novel approach utilizing RL to train fixed-wing UAV pursuer agents for intercepting dynamic evader targets.","Our methodology explores both model-based and model-free RL algorithms, specifically DreamerV3, Truncated Quantile Critics (TQC), and Soft Actor-Critic (SAC).","The training and evaluation of these algorithms were conducted under diverse scenarios, including unseen evasion strategies and environmental perturbations.","Our approach leverages high-fidelity flight dynamics simulations to create realistic training environments.","This research underscores the importance of developing intelligent, adaptive control systems for UAV interception, significantly contributing to the advancement of secure and efficient airspace management.","It demonstrates the potential of RL to train systems capable of autonomously achieving these critical tasks."],"url":"http://arxiv.org/abs/2407.06909v1"}
{"created":"2024-07-09 14:45:15","title":"Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models","abstract":"Emotions play important epistemological and cognitive roles in our lives, revealing our values and guiding our actions. Previous work has shown that LLMs display biases in emotion attribution along gender lines. However, unlike gender, which says little about our values, religion, as a socio-cultural system, prescribes a set of beliefs and values for its followers. Religions, therefore, cultivate certain emotions. Moreover, these rules are explicitly laid out and interpreted by religious leaders. Using emotion attribution, we explore how different religions are represented in LLMs. We find that: Major religions in the US and European countries are represented with more nuance, displaying a more shaded model of their beliefs. Eastern religions like Hinduism and Buddhism are strongly stereotyped. Judaism and Islam are stigmatized -- the models' refusal skyrocket. We ascribe these to cultural bias in LLMs and the scarcity of NLP literature on religion. In the rare instances where religion is discussed, it is often in the context of toxic language, perpetuating the perception of these religions as inherently toxic. This finding underscores the urgent need to address and rectify these biases. Our research underscores the crucial role emotions play in our lives and how our values influence them.","sentences":["Emotions play important epistemological and cognitive roles in our lives, revealing our values and guiding our actions.","Previous work has shown that LLMs display biases in emotion attribution along gender lines.","However, unlike gender, which says little about our values, religion, as a socio-cultural system, prescribes a set of beliefs and values for its followers.","Religions, therefore, cultivate certain emotions.","Moreover, these rules are explicitly laid out and interpreted by religious leaders.","Using emotion attribution, we explore how different religions are represented in LLMs.","We find that: Major religions in the US and European countries are represented with more nuance, displaying a more shaded model of their beliefs.","Eastern religions like Hinduism and Buddhism are strongly stereotyped.","Judaism and Islam are stigmatized -- the models' refusal skyrocket.","We ascribe these to cultural bias in LLMs and the scarcity of NLP literature on religion.","In the rare instances where religion is discussed, it is often in the context of toxic language, perpetuating the perception of these religions as inherently toxic.","This finding underscores the urgent need to address and rectify these biases.","Our research underscores the crucial role emotions play in our lives and how our values influence them."],"url":"http://arxiv.org/abs/2407.06908v1"}
{"created":"2024-07-09 14:35:49","title":"Hypergraph based Understanding for Document Semantic Entity Recognition","abstract":"Semantic entity recognition is an important task in the field of visually-rich document understanding. It distinguishes the semantic types of text by analyzing the position relationship between text nodes and the relation between text content. The existing document understanding models mainly focus on entity categories while ignoring the extraction of entity boundaries. We build a novel hypergraph attention document semantic entity recognition framework, HGA, which uses hypergraph attention to focus on entity boundaries and entity categories at the same time. It can conduct a more detailed analysis of the document text representation analyzed by the upstream model and achieves a better performance of semantic information. We apply this method on the basis of GraphLayoutLM to construct a new semantic entity recognition model HGALayoutLM. Our experiment results on FUNSD, CORD, XFUND and SROIE show that our method can effectively improve the performance of semantic entity recognition tasks based on the original model. The results of HGALayoutLM on FUNSD and XFUND reach the new state-of-the-art results.","sentences":["Semantic entity recognition is an important task in the field of visually-rich document understanding.","It distinguishes the semantic types of text by analyzing the position relationship between text nodes and the relation between text content.","The existing document understanding models mainly focus on entity categories while ignoring the extraction of entity boundaries.","We build a novel hypergraph attention document semantic entity recognition framework, HGA, which uses hypergraph attention to focus on entity boundaries and entity categories at the same time.","It can conduct a more detailed analysis of the document text representation analyzed by the upstream model and achieves a better performance of semantic information.","We apply this method on the basis of GraphLayoutLM to construct a new semantic entity recognition model HGALayoutLM.","Our experiment results on FUNSD, CORD, XFUND and SROIE show that our method can effectively improve the performance of semantic entity recognition tasks based on the original model.","The results of HGALayoutLM on FUNSD and XFUND reach the new state-of-the-art results."],"url":"http://arxiv.org/abs/2407.06904v1"}
{"created":"2024-07-09 14:32:28","title":"RespEar: Earable-Based Robust Respiratory Rate Monitoring","abstract":"Respiratory rate (RR) monitoring is integral to understanding physical and mental health and tracking fitness. Existing studies have demonstrated the feasibility of RR monitoring under specific user conditions (e.g., while remaining still, or while breathing heavily). Yet, performing accurate, continuous and non-obtrusive RR monitoring across diverse daily routines and activities remains challenging. In this work, we present RespEar, an earable-based system for robust RR monitoring. By leveraging the unique properties of in-ear microphones in earbuds, RespEar enables the use of Respiratory Sinus Arrhythmia (RSA) and Locomotor Respiratory Coupling (LRC), physiological couplings between cardiovascular activity, gait and respiration, to indirectly determine RR. This effectively addresses the challenges posed by the almost imperceptible breathing signals under daily activities. We further propose a suite of meticulously crafted signal processing schemes to improve RR estimation accuracy and robustness. With data collected from 18 subjects over 8 activities, RespEar measures RR with a mean absolute error (MAE) of 1.48 breaths per minutes (BPM) and a mean absolute percent error (MAPE) of 9.12% in sedentary conditions, and a MAE of 2.28 BPM and a MAPE of 11.04% in active conditions, respectively, which is unprecedented for a method capable of generalizing across conditions with a single modality.","sentences":["Respiratory rate (RR) monitoring is integral to understanding physical and mental health and tracking fitness.","Existing studies have demonstrated the feasibility of RR monitoring under specific user conditions (e.g., while remaining still, or while breathing heavily).","Yet, performing accurate, continuous and non-obtrusive RR monitoring across diverse daily routines and activities remains challenging.","In this work, we present RespEar, an earable-based system for robust RR monitoring.","By leveraging the unique properties of in-ear microphones in earbuds, RespEar enables the use of Respiratory Sinus Arrhythmia (RSA) and Locomotor Respiratory Coupling (LRC), physiological couplings between cardiovascular activity, gait and respiration, to indirectly determine RR.","This effectively addresses the challenges posed by the almost imperceptible breathing signals under daily activities.","We further propose a suite of meticulously crafted signal processing schemes to improve RR estimation accuracy and robustness.","With data collected from 18 subjects over 8 activities, RespEar measures RR with a mean absolute error (MAE) of 1.48 breaths per minutes (BPM) and a mean absolute percent error (MAPE) of 9.12% in sedentary conditions, and a MAE of 2.28 BPM and a MAPE of 11.04% in active conditions, respectively, which is unprecedented for a method capable of generalizing across conditions with a single modality."],"url":"http://arxiv.org/abs/2407.06901v1"}
{"created":"2024-07-09 14:25:47","title":"RIS-Assisted Received Adaptive Spatial Modulation for Wireless Communication","abstract":"A novel wireless transmission scheme, as named the reconfigurable intelligent surface (RIS)-assisted received adaptive spatial modulation (RASM) scheme, is proposed in this paper. In this scheme, the adaptive spatial modulation (ASM)-based antennas selection works at the receiver by employing the characteristics of the RIS in each time slot, where the signal-to-noise ratio at specific selected antennas can be further enhanced with near few powers. Besides for the bits from constellation symbols, the extra bits can be mapped into the indices of receive antenna combinations and conveyed to the receiver through the ASM-based antenna-combination selection, thus providing higher spectral efficiency. To explicitly present the RASM scheme, the analytical performance of bit error rate of it is discussed in this paper. As a trade-off selection, the proposed scheme shows higher spectral efficiency and remains the satisfactory error performance. Simulation and analytical results demonstrate the better performance and exhibit more potential to apply in practical wireless communication.","sentences":["A novel wireless transmission scheme, as named the reconfigurable intelligent surface (RIS)-assisted received adaptive spatial modulation (RASM) scheme, is proposed in this paper.","In this scheme, the adaptive spatial modulation (ASM)-based antennas selection works at the receiver by employing the characteristics of the RIS in each time slot, where the signal-to-noise ratio at specific selected antennas can be further enhanced with near few powers.","Besides for the bits from constellation symbols, the extra bits can be mapped into the indices of receive antenna combinations and conveyed to the receiver through the ASM-based antenna-combination selection, thus providing higher spectral efficiency.","To explicitly present the RASM scheme, the analytical performance of bit error rate of it is discussed in this paper.","As a trade-off selection, the proposed scheme shows higher spectral efficiency and remains the satisfactory error performance.","Simulation and analytical results demonstrate the better performance and exhibit more potential to apply in practical wireless communication."],"url":"http://arxiv.org/abs/2407.06894v1"}
{"created":"2024-07-09 14:25:23","title":"Measuring Sustainability Intention of ESG Fund Disclosure using Few-Shot Learning","abstract":"Global sustainable fund universe encompasses open-end funds and exchange-traded funds (ETF) that, by prospectus or other regulatory filings, claim to focus on Environment, Social and Governance (ESG). Challengingly, the claims can only be confirmed by examining the textual disclosures to check if there is presence of intentionality and ESG focus on its investment strategy. Currently, there is no regulation to enforce sustainability in ESG products space. This paper proposes a unique method and system to classify and score the fund prospectuses in the sustainable universe regarding specificity and transparency of language. We aim to employ few-shot learners to identify specific, ambiguous, and generic sustainable investment-related language. Additionally, we construct a ratio metric to determine language score and rating to rank products and quantify sustainability claims for US sustainable universe. As a by-product, we publish manually annotated quality training dataset on Hugging Face (ESG-Prospectus-Clarity-Category under cc-by-nc-sa-4.0) of more than 1K ESG textual statements. The performance of the few-shot finetuning approach is compared with zero-shot models e.g., Llama-13B, GPT 3.5 Turbo etc. We found that prompting large language models are not accurate for domain specific tasks due to misalignment issues. The few-shot finetuning techniques outperform zero-shot models by large margins of more than absolute ~30% in precision, recall and F1 metrics on completely unseen ESG languages (test set). Overall, the paper attempts to establish a systematic and scalable approach to measure and rate sustainability intention quantitatively for sustainable funds using texts in prospectus. Regulatory bodies, investors, and advisors may utilize the findings of this research to reduce cognitive load in investigating or screening of ESG funds which accurately reflects the ESG intention.","sentences":["Global sustainable fund universe encompasses open-end funds and exchange-traded funds (ETF) that, by prospectus or other regulatory filings, claim to focus on Environment, Social and Governance (ESG).","Challengingly, the claims can only be confirmed by examining the textual disclosures to check if there is presence of intentionality and ESG focus on its investment strategy.","Currently, there is no regulation to enforce sustainability in ESG products space.","This paper proposes a unique method and system to classify and score the fund prospectuses in the sustainable universe regarding specificity and transparency of language.","We aim to employ few-shot learners to identify specific, ambiguous, and generic sustainable investment-related language.","Additionally, we construct a ratio metric to determine language score and rating to rank products and quantify sustainability claims for US sustainable universe.","As a by-product, we publish manually annotated quality training dataset on Hugging Face (ESG-Prospectus-Clarity-Category under cc-by-nc-sa-4.0) of more than 1K ESG textual statements.","The performance of the few-shot finetuning approach is compared with zero-shot models e.g., Llama-13B, GPT 3.5 Turbo etc.","We found that prompting large language models are not accurate for domain specific tasks due to misalignment issues.","The few-shot finetuning techniques outperform zero-shot models by large margins of more than absolute ~30% in precision, recall and F1 metrics on completely unseen ESG languages (test set).","Overall, the paper attempts to establish a systematic and scalable approach to measure and rate sustainability intention quantitatively for sustainable funds using texts in prospectus.","Regulatory bodies, investors, and advisors may utilize the findings of this research to reduce cognitive load in investigating or screening of ESG funds which accurately reflects the ESG intention."],"url":"http://arxiv.org/abs/2407.06893v1"}
