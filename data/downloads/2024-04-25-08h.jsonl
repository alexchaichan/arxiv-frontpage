{"created":"2024-04-24 03:29:45","title":"Biologically-Informed Excitatory and Inhibitory Balance for Robust Spiking Neural Network Training","abstract":"Spiking neural networks drawing inspiration from biological constraints of the brain promise an energy-efficient paradigm for artificial intelligence. However, challenges exist in identifying guiding principles to train these networks in a robust fashion. In addition, training becomes an even more difficult problem when incorporating biological constraints of excitatory and inhibitory connections. In this work, we identify several key factors, such as low initial firing rates and diverse inhibitory spiking patterns, that determine the overall ability to train spiking networks with various ratios of excitatory to inhibitory neurons on AI-relevant datasets. The results indicate networks with the biologically realistic 80:20 excitatory:inhibitory balance can reliably train at low activity levels and in noisy environments. Additionally, the Van Rossum distance, a measure of spike train synchrony, provides insight into the importance of inhibitory neurons to increase network robustness to noise. This work supports further biologically-informed large-scale networks and energy efficient hardware implementations.","sentences":["Spiking neural networks drawing inspiration from biological constraints of the brain promise an energy-efficient paradigm for artificial intelligence.","However, challenges exist in identifying guiding principles to train these networks in a robust fashion.","In addition, training becomes an even more difficult problem when incorporating biological constraints of excitatory and inhibitory connections.","In this work, we identify several key factors, such as low initial firing rates and diverse inhibitory spiking patterns, that determine the overall ability to train spiking networks with various ratios of excitatory to inhibitory neurons on AI-relevant datasets.","The results indicate networks with the biologically realistic 80:20 excitatory:inhibitory balance can reliably train at low activity levels and in noisy environments.","Additionally, the Van Rossum distance, a measure of spike train synchrony, provides insight into the importance of inhibitory neurons to increase network robustness to noise.","This work supports further biologically-informed large-scale networks and energy efficient hardware implementations."],"url":"http://arxiv.org/abs/2404.15627v1"}
{"created":"2024-04-24 03:27:02","title":"An Electromagnetism-Inspired Method for Estimating In-Grasp Torque from Visuotactile Sensors","abstract":"Tactile sensing has become a popular sensing modality for robot manipulators, due to the promise of providing robots with the ability to measure the rich contact information that gets transmitted through its sense of touch. Among the diverse range of information accessible from tactile sensors, torques transmitted from the grasped object to the fingers through extrinsic environmental contact may be particularly important for tasks such as object insertion. However, tactile torque estimation has received relatively little attention when compared to other sensing modalities, such as force, texture, or slip identification. In this work, we introduce the notion of the Tactile Dipole Moment, which we use to estimate tilt torques from gel-based visuotactile sensors. This method does not rely on deep learning, sensor-specific mechanical, or optical modeling, and instead takes inspiration from electromechanics to analyze the vector field produced from 2D marker displacements. Despite the simplicity of our technique, we demonstrate its ability to provide accurate torque readings over two different tactile sensors and three object geometries, and highlight its practicality for the task of USB stick insertion with a compliant robot arm. These results suggest that simple analytical calculations based on dipole moments can sufficiently extract physical quantities from visuotactile sensors.","sentences":["Tactile sensing has become a popular sensing modality for robot manipulators, due to the promise of providing robots with the ability to measure the rich contact information that gets transmitted through its sense of touch.","Among the diverse range of information accessible from tactile sensors, torques transmitted from the grasped object to the fingers through extrinsic environmental contact may be particularly important for tasks such as object insertion.","However, tactile torque estimation has received relatively little attention when compared to other sensing modalities, such as force, texture, or slip identification.","In this work, we introduce the notion of the Tactile Dipole Moment, which we use to estimate tilt torques from gel-based visuotactile sensors.","This method does not rely on deep learning, sensor-specific mechanical, or optical modeling, and instead takes inspiration from electromechanics to analyze the vector field produced from 2D marker displacements.","Despite the simplicity of our technique, we demonstrate its ability to provide accurate torque readings over two different tactile sensors and three object geometries, and highlight its practicality for the task of USB stick insertion with a compliant robot arm.","These results suggest that simple analytical calculations based on dipole moments can sufficiently extract physical quantities from visuotactile sensors."],"url":"http://arxiv.org/abs/2404.15626v1"}
{"created":"2024-04-24 03:25:53","title":"Optimizing OOD Detection in Molecular Graphs: A Novel Approach with Diffusion Models","abstract":"The open-world test dataset is often mixed with out-of-distribution (OOD) samples, where the deployed models will struggle to make accurate predictions. Traditional detection methods need to trade off OOD detection and in-distribution (ID) classification performance since they share the same representation learning model. In this work, we propose to detect OOD molecules by adopting an auxiliary diffusion model-based framework, which compares similarities between input molecules and reconstructed graphs. Due to the generative bias towards reconstructing ID training samples, the similarity scores of OOD molecules will be much lower to facilitate detection. Although it is conceptually simple, extending this vanilla framework to practical detection applications is still limited by two significant challenges. First, the popular similarity metrics based on Euclidian distance fail to consider the complex graph structure. Second, the generative model involving iterative denoising steps is time-consuming especially when it runs on the enormous pool of drugs. To address these challenges, our research pioneers an approach of Prototypical Graph Reconstruction for Molecular OOD Detection, dubbed as PGR-MOOD and hinges on three innovations: i) An effective metric to comprehensively quantify the matching degree of input and reconstructed molecules; ii) A creative graph generator to construct prototypical graphs that are in line with ID but away from OOD; iii) An efficient and scalable OOD detector to compare the similarity between test samples and pre-constructed prototypical graphs and omit the generative process on every new molecule. Extensive experiments on ten benchmark datasets and six baselines are conducted to demonstrate our superiority.","sentences":["The open-world test dataset is often mixed with out-of-distribution (OOD) samples, where the deployed models will struggle to make accurate predictions.","Traditional detection methods need to trade off OOD detection and in-distribution (ID) classification performance since they share the same representation learning model.","In this work, we propose to detect OOD molecules by adopting an auxiliary diffusion model-based framework, which compares similarities between input molecules and reconstructed graphs.","Due to the generative bias towards reconstructing ID training samples, the similarity scores of OOD molecules will be much lower to facilitate detection.","Although it is conceptually simple, extending this vanilla framework to practical detection applications is still limited by two significant challenges.","First, the popular similarity metrics based on Euclidian distance fail to consider the complex graph structure.","Second, the generative model involving iterative denoising steps is time-consuming especially when it runs on the enormous pool of drugs.","To address these challenges, our research pioneers an approach of Prototypical Graph Reconstruction for Molecular OOD Detection, dubbed as PGR-MOOD and hinges on three innovations: i)","An effective metric to comprehensively quantify the matching degree of input and reconstructed molecules; ii) A creative graph generator to construct prototypical graphs that are in line with ID but away from OOD; iii)","An efficient and scalable OOD detector to compare the similarity between test samples and pre-constructed prototypical graphs and omit the generative process on every new molecule.","Extensive experiments on ten benchmark datasets and six baselines are conducted to demonstrate our superiority."],"url":"http://arxiv.org/abs/2404.15625v1"}
{"created":"2024-04-24 03:23:13","title":"Characterizing the Age of Information with Multiple Coexisting Data Streams","abstract":"In this paper we analyze the distribution of the Age of Information (AoI) of a tagged data stream sharing a processor with a set of other data streams. We do so in the highly general setting in which the interarrival times pertaining to the tagged stream can have any distribution, and also the service times of both the tagged stream and the background stream are generally distributed. The packet arrival times of the background process are assumed to constitute a Poisson process, which is justified by the fact that it typically is a superposition of many relatively homogeneous streams. The first major contribution is that we derive an expression for the Laplace-Stieltjes transform of the AoI in the resulting GI+M/GI+GI/1 model. Second, we use stochastic ordering techniques to identify tight stochastic bounds on the AoI. In addition, when approximating the tagged stream's inter-generation times through a phase-type distribution (which can be done at any precision), we present a computational algorithm for the mean AoI. As illustrated through a sequence of numerical experiments, the analysis enables us to assess the impact of background traffic on the AoI of the tagged stream.","sentences":["In this paper we analyze the distribution of the Age of Information (AoI) of a tagged data stream sharing a processor with a set of other data streams.","We do so in the highly general setting in which the interarrival times pertaining to the tagged stream can have any distribution, and also the service times of both the tagged stream and the background stream are generally distributed.","The packet arrival times of the background process are assumed to constitute a Poisson process, which is justified by the fact that it typically is a superposition of many relatively homogeneous streams.","The first major contribution is that we derive an expression for the Laplace-Stieltjes transform of the AoI in the resulting GI+M/GI+GI/1 model.","Second, we use stochastic ordering techniques to identify tight stochastic bounds on the AoI. In addition, when approximating the tagged stream's inter-generation times through a phase-type distribution (which can be done at any precision), we present a computational algorithm for the mean AoI. As illustrated through a sequence of numerical experiments, the analysis enables us to assess the impact of background traffic on the AoI of the tagged stream."],"url":"http://arxiv.org/abs/2404.15623v1"}
{"created":"2024-04-24 03:22:49","title":"FR-NAS: Forward-and-Reverse Graph Predictor for Efficient Neural Architecture Search","abstract":"Neural Architecture Search (NAS) has emerged as a key tool in identifying optimal configurations of deep neural networks tailored to specific tasks. However, training and assessing numerous architectures introduces considerable computational overhead. One method to mitigating this is through performance predictors, which offer a means to estimate the potential of an architecture without exhaustive training. Given that neural architectures fundamentally resemble Directed Acyclic Graphs (DAGs), Graph Neural Networks (GNNs) become an apparent choice for such predictive tasks. Nevertheless, the scarcity of training data can impact the precision of GNN-based predictors. To address this, we introduce a novel GNN predictor for NAS. This predictor renders neural architectures into vector representations by combining both the conventional and inverse graph views. Additionally, we incorporate a customized training loss within the GNN predictor to ensure efficient utilization of both types of representations. We subsequently assessed our method through experiments on benchmark datasets including NAS-Bench-101, NAS-Bench-201, and the DARTS search space, with a training dataset ranging from 50 to 400 samples. Benchmarked against leading GNN predictors, the experimental results showcase a significant improvement in prediction accuracy, with a 3%--16% increase in Kendall-tau correlation. Source codes are available at https://github.com/EMI-Group/fr-nas.","sentences":["Neural Architecture Search (NAS) has emerged as a key tool in identifying optimal configurations of deep neural networks tailored to specific tasks.","However, training and assessing numerous architectures introduces considerable computational overhead.","One method to mitigating this is through performance predictors, which offer a means to estimate the potential of an architecture without exhaustive training.","Given that neural architectures fundamentally resemble Directed Acyclic Graphs (DAGs), Graph Neural Networks (GNNs) become an apparent choice for such predictive tasks.","Nevertheless, the scarcity of training data can impact the precision of GNN-based predictors.","To address this, we introduce a novel GNN predictor for NAS.","This predictor renders neural architectures into vector representations by combining both the conventional and inverse graph views.","Additionally, we incorporate a customized training loss within the GNN predictor to ensure efficient utilization of both types of representations.","We subsequently assessed our method through experiments on benchmark datasets including NAS-Bench-101, NAS-Bench-201, and the DARTS search space, with a training dataset ranging from 50 to 400 samples.","Benchmarked against leading GNN predictors, the experimental results showcase a significant improvement in prediction accuracy, with a 3%--16% increase in Kendall-tau correlation.","Source codes are available at https://github.com/EMI-Group/fr-nas."],"url":"http://arxiv.org/abs/2404.15622v1"}
{"created":"2024-04-24 03:19:31","title":"Layer Ensemble Averaging for Improving Memristor-Based Artificial Neural Network Performance","abstract":"Artificial neural networks have advanced due to scaling dimensions, but conventional computing faces inefficiency due to the von Neumann bottleneck. In-memory computation architectures, like memristors, offer promise but face challenges due to hardware non-idealities. This work proposes and experimentally demonstrates layer ensemble averaging, a technique to map pre-trained neural network solutions from software to defective hardware crossbars of emerging memory devices and reliably attain near-software performance on inference. The approach is investigated using a custom 20,000-device hardware prototyping platform on a continual learning problem where a network must learn new tasks without catastrophically forgetting previously learned information. Results demonstrate that by trading off the number of devices required for layer mapping, layer ensemble averaging can reliably boost defective memristive network performance up to the software baseline. For the investigated problem, the average multi-task classification accuracy improves from 61 % to 72 % (< 1 % of software baseline) using the proposed approach.","sentences":["Artificial neural networks have advanced due to scaling dimensions, but conventional computing faces inefficiency due to the von Neumann bottleneck.","In-memory computation architectures, like memristors, offer promise but face challenges due to hardware non-idealities.","This work proposes and experimentally demonstrates layer ensemble averaging, a technique to map pre-trained neural network solutions from software to defective hardware crossbars of emerging memory devices and reliably attain near-software performance on inference.","The approach is investigated using a custom 20,000-device hardware prototyping platform on a continual learning problem where a network must learn new tasks without catastrophically forgetting previously learned information.","Results demonstrate that by trading off the number of devices required for layer mapping, layer ensemble averaging can reliably boost defective memristive network performance up to the software baseline.","For the investigated problem, the average multi-task classification accuracy improves from 61 % to 72 % (< 1 % of software baseline) using the proposed approach."],"url":"http://arxiv.org/abs/2404.15621v1"}
{"created":"2024-04-24 03:11:12","title":"DPO: Differential reinforcement learning with application to optimal configuration search","abstract":"Reinforcement learning (RL) with continuous state and action spaces remains one of the most challenging problems within the field. Most current learning methods focus on integral identities such as value functions to derive an optimal strategy for the learning agent. In this paper, we instead study the dual form of the original RL formulation to propose the first differential RL framework that can handle settings with limited training samples and short-length episodes. Our approach introduces Differential Policy Optimization (DPO), a pointwise and stage-wise iteration method that optimizes policies encoded by local-movement operators. We prove a pointwise convergence estimate for DPO and provide a regret bound comparable with current theoretical works. Such pointwise estimate ensures that the learned policy matches the optimal path uniformly across different steps. We then apply DPO to a class of practical RL problems which search for optimal configurations with Lagrangian rewards. DPO is easy to implement, scalable, and shows competitive results on benchmarking experiments against several popular RL methods.","sentences":["Reinforcement learning (RL) with continuous state and action spaces remains one of the most challenging problems within the field.","Most current learning methods focus on integral identities such as value functions to derive an optimal strategy for the learning agent.","In this paper, we instead study the dual form of the original RL formulation to propose the first differential RL framework that can handle settings with limited training samples and short-length episodes.","Our approach introduces Differential Policy Optimization (DPO), a pointwise and stage-wise iteration method that optimizes policies encoded by local-movement operators.","We prove a pointwise convergence estimate for DPO and provide a regret bound comparable with current theoretical works.","Such pointwise estimate ensures that the learned policy matches the optimal path uniformly across different steps.","We then apply DPO to a class of practical RL problems which search for optimal configurations with Lagrangian rewards.","DPO is easy to implement, scalable, and shows competitive results on benchmarking experiments against several popular RL methods."],"url":"http://arxiv.org/abs/2404.15617v1"}
{"created":"2024-04-24 03:08:25","title":"MDDD: Manifold-based Domain Adaptation with Dynamic Distribution for Non-Deep Transfer Learning in Cross-subject and Cross-session EEG-based Emotion Recognition","abstract":"Emotion decoding using Electroencephalography (EEG)-based affective brain-computer interfaces represents a significant area within the field of affective computing. In the present study, we propose a novel non-deep transfer learning method, termed as Manifold-based Domain adaptation with Dynamic Distribution (MDDD). The proposed MDDD includes four main modules: manifold feature transformation, dynamic distribution alignment, classifier learning, and ensemble learning. The data undergoes a transformation onto an optimal Grassmann manifold space, enabling dynamic alignment of the source and target domains. This process prioritizes both marginal and conditional distributions according to their significance, ensuring enhanced adaptation efficiency across various types of data. In the classifier learning, the principle of structural risk minimization is integrated to develop robust classification models. This is complemented by dynamic distribution alignment, which refines the classifier iteratively. Additionally, the ensemble learning module aggregates the classifiers obtained at different stages of the optimization process, which leverages the diversity of the classifiers to enhance the overall prediction accuracy. The experimental results indicate that MDDD outperforms traditional non-deep learning methods, achieving an average improvement of 3.54%, and is comparable to deep learning methods. This suggests that MDDD could be a promising method for enhancing the utility and applicability of aBCIs in real-world scenarios.","sentences":["Emotion decoding using Electroencephalography (EEG)-based affective brain-computer interfaces represents a significant area within the field of affective computing.","In the present study, we propose a novel non-deep transfer learning method, termed as Manifold-based Domain adaptation with Dynamic Distribution (MDDD).","The proposed MDDD includes four main modules: manifold feature transformation, dynamic distribution alignment, classifier learning, and ensemble learning.","The data undergoes a transformation onto an optimal Grassmann manifold space, enabling dynamic alignment of the source and target domains.","This process prioritizes both marginal and conditional distributions according to their significance, ensuring enhanced adaptation efficiency across various types of data.","In the classifier learning, the principle of structural risk minimization is integrated to develop robust classification models.","This is complemented by dynamic distribution alignment, which refines the classifier iteratively.","Additionally, the ensemble learning module aggregates the classifiers obtained at different stages of the optimization process, which leverages the diversity of the classifiers to enhance the overall prediction accuracy.","The experimental results indicate that MDDD outperforms traditional non-deep learning methods, achieving an average improvement of 3.54%, and is comparable to deep learning methods.","This suggests that MDDD could be a promising method for enhancing the utility and applicability of aBCIs in real-world scenarios."],"url":"http://arxiv.org/abs/2404.15615v1"}
{"created":"2024-04-24 03:07:43","title":"A nearly-$4\\log n$ depth lower bound for formulas with restriction on top","abstract":"One of the major open problems in complexity theory is to demonstrate an explicit function which requires super logarithmic depth, a.k.a, the $\\mathbf{P}$ versus $\\mathbf{NC^1}$ problem. The current best depth lower bound is $(3-o(1))\\cdot \\log n$, and it is widely open how to prove a super-$3\\log n$ depth lower bound. Recently Mihajlin and Sofronova (CCC'22) show if considering formulas with restriction on top, we can break the $3\\log n$ barrier. Formally, they prove there exist two functions $f:\\{0,1\\}^n \\rightarrow \\{0,1\\},g:\\{0,1\\}^n \\rightarrow \\{0,1\\}^n$, such that for any constant $0<\\alpha<0.4$ and constant $0<\\epsilon<\\alpha/2$, their XOR composition $f(g(x)\\oplus y)$ is not computable by an AND of $2^{(\\alpha-\\epsilon)n}$ formulas of size at most $2^{(1-\\alpha/2-\\epsilon)n}$. This implies a modified version of Andreev function is not computable by any circuit of depth $(3.2-\\epsilon)\\log n$ with the restriction that top $0.4-\\epsilon$ layers only consist of AND gates for any small constant $\\epsilon>0$. They ask whether the parameter $\\alpha$ can be push up to nearly $1$ thus implying a nearly-$3.5\\log n$ depth lower bound.   In this paper, we provide a stronger answer to their question. We show there exist two functions $f:\\{0,1\\}^n \\rightarrow \\{0,1\\},g:\\{0,1\\}^n \\rightarrow \\{0,1\\}^n$, such that for any constant $0<\\alpha<2-o(1)$, their XOR composition $f(g(x)\\oplus y)$ is not computable by an AND of $2^{\\alpha n}$ formulas of size at most $2^{(1-\\alpha/2-o(1))n}$. This implies a $(4-o(1))\\log n$ depth lower bound with the restriction that top $2-o(1)$ layers only consist of AND gates. We prove it by observing that one crucial component in Mihajlin and Sofronova's work, called the well-mixed set of functions, can be significantly simplified thus improved. Then with this observation and a more careful analysis, we obtain these nearly tight results.","sentences":["One of the major open problems in complexity theory is to demonstrate an explicit function which requires super logarithmic depth, a.k.a, the $\\mathbf{P}$ versus $\\mathbf{NC^1}$ problem.","The current best depth lower bound is $(3-o(1))\\cdot \\log n$, and it is widely open how to prove a super-$3\\log n$ depth lower bound.","Recently Mihajlin and Sofronova (CCC'22) show if considering formulas with restriction on top, we can break the $3\\log n$ barrier.","Formally, they prove there exist two functions $f:\\{0,1\\}^n \\rightarrow \\{0,1\\},g:\\{0,1\\}^n \\rightarrow \\{0,1\\}^n$, such that for any constant $0<\\alpha<0.4$ and constant $0<\\epsilon<\\alpha/2$, their XOR composition $f(g(x)\\oplus y)$ is not computable by an AND of $2^{(\\alpha-\\epsilon)n}$ formulas of size at most $2^{(1-\\alpha/2-\\epsilon)n}$. This implies a modified version of Andreev function is not computable by any circuit of depth $(3.2-\\epsilon)\\log n$ with the restriction that top $0.4-\\epsilon$ layers only consist of AND gates for any small constant $\\epsilon>0$. They ask whether the parameter $\\alpha$ can be push up to nearly $1$ thus implying a nearly-$3.5\\log n$ depth lower bound.   ","In this paper, we provide a stronger answer to their question.","We show there exist two functions $f:\\{0,1\\}^n \\rightarrow \\{0,1\\},g:\\{0,1\\}^n \\rightarrow \\{0,1\\}^n$, such that for any constant $0<\\alpha<2-o(1)$, their XOR composition $f(g(x)\\oplus y)$ is not computable by an AND of $2^{\\alpha n}$ formulas of size at most $2^{(1-\\alpha/2-o(1))n}$.","This implies a $(4-o(1))\\log n$ depth lower bound with the restriction that top $2-o(1)$ layers only consist of AND gates.","We prove it by observing that one crucial component in Mihajlin and Sofronova's work, called the well-mixed set of functions, can be significantly simplified thus improved.","Then with this observation and a more careful analysis, we obtain these nearly tight results."],"url":"http://arxiv.org/abs/2404.15613v1"}
{"created":"2024-04-24 03:06:01","title":"DyGCL: Dynamic Graph Contrastive Learning For Event Prediction","abstract":"Predicting events such as political protests, flu epidemics, and criminal activities is crucial to proactively taking necessary measures and implementing required responses to address emerging challenges. Capturing contextual information from textual data for event forecasting poses significant challenges due to the intricate structure of the documents and the evolving nature of events. Recently, dynamic Graph Neural Networks (GNNs) have been introduced to capture the dynamic patterns of input text graphs. However, these models only utilize node-level representation, causing the loss of the global information from graph-level representation. On the other hand, both node-level and graph-level representations are essential for effective event prediction as node-level representation gives insight into the local structure, and the graph-level representation provides an understanding of the global structure of the temporal graph. To address these challenges, in this paper, we propose a Dynamic Graph Contrastive Learning (DyGCL) method for event prediction. Our model DyGCL employs a local view encoder to learn the evolving node representations, which effectively captures the local dynamic structure of input graphs. Additionally, it harnesses a global view encoder to perceive the hierarchical dynamic graph representation of the input graphs. Then we update the graph representations from both encoders using contrastive learning. In the final stage, DyGCL combines both representations using an attention mechanism and optimizes its capability to predict future events. Our extensive experiment demonstrates that our proposed method outperforms the baseline methods for event prediction on six real-world datasets.","sentences":["Predicting events such as political protests, flu epidemics, and criminal activities is crucial to proactively taking necessary measures and implementing required responses to address emerging challenges.","Capturing contextual information from textual data for event forecasting poses significant challenges due to the intricate structure of the documents and the evolving nature of events.","Recently, dynamic Graph Neural Networks (GNNs) have been introduced to capture the dynamic patterns of input text graphs.","However, these models only utilize node-level representation, causing the loss of the global information from graph-level representation.","On the other hand, both node-level and graph-level representations are essential for effective event prediction as node-level representation gives insight into the local structure, and the graph-level representation provides an understanding of the global structure of the temporal graph.","To address these challenges, in this paper, we propose a Dynamic Graph Contrastive Learning (DyGCL) method for event prediction.","Our model DyGCL employs a local view encoder to learn the evolving node representations, which effectively captures the local dynamic structure of input graphs.","Additionally, it harnesses a global view encoder to perceive the hierarchical dynamic graph representation of the input graphs.","Then we update the graph representations from both encoders using contrastive learning.","In the final stage, DyGCL combines both representations using an attention mechanism and optimizes its capability to predict future events.","Our extensive experiment demonstrates that our proposed method outperforms the baseline methods for event prediction on six real-world datasets."],"url":"http://arxiv.org/abs/2404.15612v1"}
{"created":"2024-04-24 03:02:21","title":"PoisonedFL: Model Poisoning Attacks to Federated Learning via Multi-Round Consistency","abstract":"Model poisoning attacks are critical security threats to Federated Learning (FL). Existing model poisoning attacks suffer from two key limitations: 1) they achieve suboptimal effectiveness when defenses are deployed, and/or 2) they require knowledge of the model updates or local training data on genuine clients. In this work, we make a key observation that their suboptimal effectiveness arises from only leveraging model-update consistency among malicious clients within individual training rounds, making the attack effect self-cancel across training rounds. In light of this observation, we propose PoisonedFL, which enforces multi-round consistency among the malicious clients' model updates while not requiring any knowledge about the genuine clients. Our empirical evaluation on five benchmark datasets shows that PoisonedFL breaks eight state-of-the-art defenses and outperforms seven existing model poisoning attacks. Moreover, we also explore new defenses that are tailored to PoisonedFL, but our results show that we can still adapt PoisonedFL to break them. Our study shows that FL systems are considerably less robust than previously thought, underlining the urgency for the development of new defense mechanisms.","sentences":["Model poisoning attacks are critical security threats to Federated Learning (FL).","Existing model poisoning attacks suffer from two key limitations: 1) they achieve suboptimal effectiveness when defenses are deployed, and/or 2) they require knowledge of the model updates or local training data on genuine clients.","In this work, we make a key observation that their suboptimal effectiveness arises from only leveraging model-update consistency among malicious clients within individual training rounds, making the attack effect self-cancel across training rounds.","In light of this observation, we propose PoisonedFL, which enforces multi-round consistency among the malicious clients' model updates while not requiring any knowledge about the genuine clients.","Our empirical evaluation on five benchmark datasets shows that PoisonedFL breaks eight state-of-the-art defenses and outperforms seven existing model poisoning attacks.","Moreover, we also explore new defenses that are tailored to PoisonedFL, but our results show that we can still adapt PoisonedFL to break them.","Our study shows that FL systems are considerably less robust than previously thought, underlining the urgency for the development of new defense mechanisms."],"url":"http://arxiv.org/abs/2404.15611v1"}
{"created":"2024-04-24 03:01:34","title":"Revealing Aspects of Hawai'i Tourism Using Situated Augmented Reality","abstract":"In this position paper, we present a process artifact that aims to bring awareness to historical context, contemporary issues, and identity harm inflicted by tourism in Hawaii. First, we introduce the historical background and how the work is informed by the positionality of the authors. We discuss how related augmented reality work can inform strategy for building augmented reality experiences that address cultural issues. Then, we present a mockup of the artifact, aimed to bring awareness to 20th century colonialism, recent Kanaka Maoli art exclusion, and cultural prostitution. We describe how we will share the app at the workshop and list topics for discussion.","sentences":["In this position paper, we present a process artifact that aims to bring awareness to historical context, contemporary issues, and identity harm inflicted by tourism in Hawaii.","First, we introduce the historical background and how the work is informed by the positionality of the authors.","We discuss how related augmented reality work can inform strategy for building augmented reality experiences that address cultural issues.","Then, we present a mockup of the artifact, aimed to bring awareness to 20th century colonialism, recent Kanaka Maoli art exclusion, and cultural prostitution.","We describe how we will share the app at the workshop and list topics for discussion."],"url":"http://arxiv.org/abs/2404.15610v1"}
{"created":"2024-04-24 02:51:13","title":"Understanding and Improving CNNs with Complex Structure Tensor: A Biometrics Study","abstract":"Our study provides evidence that CNNs struggle to effectively extract orientation features. We show that the use of Complex Structure Tensor, which contains compact orientation features with certainties, as input to CNNs consistently improves identification accuracy compared to using grayscale inputs alone. Experiments also demonstrated that our inputs, which were provided by mini complex conv-nets, combined with reduced CNN sizes, outperformed full-fledged, prevailing CNN architectures. This suggests that the upfront use of orientation features in CNNs, a strategy seen in mammalian vision, not only mitigates their limitations but also enhances their explainability and relevance to thin-clients. Experiments were done on publicly available data sets comprising periocular images for biometric identification and verification (Close and Open World) using 6 State of the Art CNN architectures. We reduced SOA Equal Error Rate (EER) on the PolyU dataset by 5-26% depending on data and scenario.","sentences":["Our study provides evidence that CNNs struggle to effectively extract orientation features.","We show that the use of Complex Structure Tensor, which contains compact orientation features with certainties, as input to CNNs consistently improves identification accuracy compared to using grayscale inputs alone.","Experiments also demonstrated that our inputs, which were provided by mini complex conv-nets, combined with reduced CNN sizes, outperformed full-fledged, prevailing CNN architectures.","This suggests that the upfront use of orientation features in CNNs, a strategy seen in mammalian vision, not only mitigates their limitations but also enhances their explainability and relevance to thin-clients.","Experiments were done on publicly available data sets comprising periocular images for biometric identification and verification (Close and Open World) using 6 State of the Art CNN architectures.","We reduced SOA Equal Error Rate (EER) on the PolyU dataset by 5-26% depending on data and scenario."],"url":"http://arxiv.org/abs/2404.15608v1"}
{"created":"2024-04-24 02:50:37","title":"A Note on Approximating Weighted Nash Social Welfare with Additive Valuations","abstract":"We give the first $O(1)$-approximation for the weighted Nash Social Welfare problem with additive valuations. The approximation ratio we obtain is $e^{1/e} + \\epsilon \\approx 1.445 + \\epsilon$, which matches the best known approximation ratio for the unweighted case \\cite{BKV18}.   Both our algorithm and analysis are simple. We solve a natural configuration LP for the problem, and obtain the allocation of items to agents using a randomized version of the Shmoys-Tardos rounding algorithm developed for unrelated machine scheduling problems. In the analysis, we show that the approximation ratio of the algorithm is at most the worst gap between the Nash social welfare of the optimum allocation and that of an EF1 allocation, for an unweighted Nash Social Welfare instance with identical additive valuations. This was shown to be at most $e^{1/e} \\approx 1.445$ by Barman et al., leading to our approximation ratio.","sentences":["We give the first $O(1)$-approximation for the weighted Nash Social Welfare problem with additive valuations.","The approximation ratio we obtain is $e^{1/e} + \\epsilon \\approx 1.445 + \\epsilon$, which matches the best known approximation ratio for the unweighted case \\cite{BKV18}.   ","Both our algorithm and analysis are simple.","We solve a natural configuration LP for the problem, and obtain the allocation of items to agents using a randomized version of the Shmoys-Tardos rounding algorithm developed for unrelated machine scheduling problems.","In the analysis, we show that the approximation ratio of the algorithm is at most the worst gap between the Nash social welfare of the optimum allocation and that of an EF1 allocation, for an unweighted Nash Social Welfare instance with identical additive valuations.","This was shown to be at most $e^{1/e} \\approx 1.445$ by Barman et al., leading to our approximation ratio."],"url":"http://arxiv.org/abs/2404.15607v1"}
{"created":"2024-04-24 02:42:24","title":"Hybrid LLM/Rule-based Approaches to Business Insights Generation from Structured Data","abstract":"In the field of business data analysis, the ability to extract actionable insights from vast and varied datasets is essential for informed decision-making and maintaining a competitive edge. Traditional rule-based systems, while reliable, often fall short when faced with the complexity and dynamism of modern business data. Conversely, Artificial Intelligence (AI) models, particularly Large Language Models (LLMs), offer significant potential in pattern recognition and predictive analytics but can lack the precision necessary for specific business applications. This paper explores the efficacy of hybrid approaches that integrate the robustness of rule-based systems with the adaptive power of LLMs in generating actionable business insights.","sentences":["In the field of business data analysis, the ability to extract actionable insights from vast and varied datasets is essential for informed decision-making and maintaining a competitive edge.","Traditional rule-based systems, while reliable, often fall short when faced with the complexity and dynamism of modern business data.","Conversely, Artificial Intelligence (AI) models, particularly Large Language Models (LLMs), offer significant potential in pattern recognition and predictive analytics but can lack the precision necessary for specific business applications.","This paper explores the efficacy of hybrid approaches that integrate the robustness of rule-based systems with the adaptive power of LLMs in generating actionable business insights."],"url":"http://arxiv.org/abs/2404.15604v1"}
{"created":"2024-04-24 02:41:10","title":"Decentralized Multi-Agent Trajectory Planning in Dynamic Environments with Spatiotemporal Occupancy Grid Maps","abstract":"This paper proposes a decentralized trajectory planning framework for the collision avoidance problem of multiple micro aerial vehicles (MAVs) in environments with static and dynamic obstacles. The framework utilizes spatiotemporal occupancy grid maps (SOGM), which forecast the occupancy status of neighboring space in the near future, as the environment representation. Based on this representation, we extend the kinodynamic A* and the corridor-constrained trajectory optimization algorithms to efficiently tackle static and dynamic obstacles with arbitrary shapes. Collision avoidance between communicating robots is integrated by sharing planned trajectories and projecting them onto the SOGM. The simulation results show that our method achieves competitive performance against state-of-the-art methods in dynamic environments with different numbers and shapes of obstacles. Finally, the proposed method is validated in real experiments.","sentences":["This paper proposes a decentralized trajectory planning framework for the collision avoidance problem of multiple micro aerial vehicles (MAVs) in environments with static and dynamic obstacles.","The framework utilizes spatiotemporal occupancy grid maps (SOGM), which forecast the occupancy status of neighboring space in the near future, as the environment representation.","Based on this representation, we extend the kinodynamic A* and the corridor-constrained trajectory optimization algorithms to efficiently tackle static and dynamic obstacles with arbitrary shapes.","Collision avoidance between communicating robots is integrated by sharing planned trajectories and projecting them onto the SOGM.","The simulation results show that our method achieves competitive performance against state-of-the-art methods in dynamic environments with different numbers and shapes of obstacles.","Finally, the proposed method is validated in real experiments."],"url":"http://arxiv.org/abs/2404.15602v1"}
{"created":"2024-04-24 02:40:58","title":"Deepfakes and Higher Education: A Research Agenda and Scoping Review of Synthetic Media","abstract":"The availability of software which can produce convincing yet synthetic media poses both threats and benefits to tertiary education globally. While other forms of synthetic media exist, this study focuses on deepfakes, which are advanced Generative AI (GenAI) fakes of real people. This conceptual paper assesses the current literature on deepfakes across multiple disciplines by conducting an initial scoping review of 182 peer-reviewed publications.   The review reveals three major trends: detection methods, malicious applications, and potential benefits, although no specific studies on deepfakes in the tertiary educational context were found. Following a discussion of these trends, this study applies the findings to postulate the major risks and potential mitigation strategies of deepfake technologies in higher education, as well as potential beneficial uses to aid the teaching and learning of both deepfakes and synthetic media. This culminates in the proposal of a research agenda to build a comprehensive, cross-cultural approach to investigate deepfakes in higher education.","sentences":["The availability of software which can produce convincing yet synthetic media poses both threats and benefits to tertiary education globally.","While other forms of synthetic media exist, this study focuses on deepfakes, which are advanced Generative AI (GenAI) fakes of real people.","This conceptual paper assesses the current literature on deepfakes across multiple disciplines by conducting an initial scoping review of 182 peer-reviewed publications.   ","The review reveals three major trends: detection methods, malicious applications, and potential benefits, although no specific studies on deepfakes in the tertiary educational context were found.","Following a discussion of these trends, this study applies the findings to postulate the major risks and potential mitigation strategies of deepfake technologies in higher education, as well as potential beneficial uses to aid the teaching and learning of both deepfakes and synthetic media.","This culminates in the proposal of a research agenda to build a comprehensive, cross-cultural approach to investigate deepfakes in higher education."],"url":"http://arxiv.org/abs/2404.15601v1"}
{"created":"2024-04-24 02:23:12","title":"Human-in-the-loop Learning for Dynamic Congestion Games","abstract":"Today mobile users learn and share their traffic observations via crowdsourcing platforms (e.g., Waze). Yet such platforms simply cater to selfish users' myopic interests to recommend the shortest path, and do not encourage enough users to travel and learn other paths for future others. Prior studies focus on one-shot congestion games without considering users' information learning, while our work studies how users learn and alter traffic conditions on stochastic paths in a human-in-the-loop manner. Our analysis shows that the myopic routing policy leads to severe under-exploration of stochastic paths. This results in a price of anarchy (PoA) greater than $2$, as compared to the socially optimal policy in minimizing the long-term social cost. Besides, the myopic policy fails to ensure the correct learning convergence about users' traffic hazard beliefs. To address this, we focus on informational (non-monetary) mechanisms as they are easier to implement than pricing. We first show that existing information-hiding mechanisms and deterministic path-recommendation mechanisms in Bayesian persuasion literature do not work with even (\\text{PoA}=\\infty). Accordingly, we propose a new combined hiding and probabilistic recommendation (CHAR) mechanism to hide all information from a selected user group and provide state-dependent probabilistic recommendations to the other user group. Our CHAR successfully ensures PoA less than (\\frac{5}{4}), which cannot be further reduced by any other informational (non-monetary) mechanism. Besides the parallel network, we further extend our analysis and CHAR to more general linear path graphs with multiple intermediate nodes, and we prove that the PoA results remain unchanged. Additionally, we carry out experiments with real-world datasets to further extend our routing graphs and verify the close-to-optimal performance of our CHAR.","sentences":["Today mobile users learn and share their traffic observations via crowdsourcing platforms (e.g., Waze).","Yet such platforms simply cater to selfish users' myopic interests to recommend the shortest path, and do not encourage enough users to travel and learn other paths for future others.","Prior studies focus on one-shot congestion games without considering users' information learning, while our work studies how users learn and alter traffic conditions on stochastic paths in a human-in-the-loop manner.","Our analysis shows that the myopic routing policy leads to severe under-exploration of stochastic paths.","This results in a price of anarchy (PoA) greater than $2$, as compared to the socially optimal policy in minimizing the long-term social cost.","Besides, the myopic policy fails to ensure the correct learning convergence about users' traffic hazard beliefs.","To address this, we focus on informational (non-monetary) mechanisms as they are easier to implement than pricing.","We first show that existing information-hiding mechanisms and deterministic path-recommendation mechanisms in Bayesian persuasion literature do not work with even (\\text{PoA}=\\infty).","Accordingly, we propose a new combined hiding and probabilistic recommendation (CHAR) mechanism to hide all information from a selected user group and provide state-dependent probabilistic recommendations to the other user group.","Our CHAR successfully ensures PoA less than (\\frac{5}{4}), which cannot be further reduced by any other informational (non-monetary) mechanism.","Besides the parallel network, we further extend our analysis and CHAR to more general linear path graphs with multiple intermediate nodes, and we prove that the PoA results remain unchanged.","Additionally, we carry out experiments with real-world datasets to further extend our routing graphs and verify the close-to-optimal performance of our CHAR."],"url":"http://arxiv.org/abs/2404.15599v1"}
{"created":"2024-04-24 02:22:50","title":"Federated Learning with Only Positive Labels by Exploring Label Correlations","abstract":"Federated learning aims to collaboratively learn a model by using the data from multiple users under privacy constraints. In this paper, we study the multi-label classification problem under the federated learning setting, where trivial solution and extremely poor performance may be obtained, especially when only positive data w.r.t. a single class label are provided for each client. This issue can be addressed by adding a specially designed regularizer on the server-side. Although effective sometimes, the label correlations are simply ignored and thus sub-optimal performance may be obtained. Besides, it is expensive and unsafe to exchange user's private embeddings between server and clients frequently, especially when training model in the contrastive way. To remedy these drawbacks, we propose a novel and generic method termed Federated Averaging by exploring Label Correlations (FedALC). Specifically, FedALC estimates the label correlations in the class embedding learning for different label pairs and utilizes it to improve the model training. To further improve the safety and also reduce the communication overhead, we propose a variant to learn fixed class embedding for each client, so that the server and clients only need to exchange class embeddings once. Extensive experiments on multiple popular datasets demonstrate that our FedALC can significantly outperform existing counterparts.","sentences":["Federated learning aims to collaboratively learn a model by using the data from multiple users under privacy constraints.","In this paper, we study the multi-label classification problem under the federated learning setting, where trivial solution and extremely poor performance may be obtained, especially when only positive data w.r.t.","a single class label are provided for each client.","This issue can be addressed by adding a specially designed regularizer on the server-side.","Although effective sometimes, the label correlations are simply ignored and thus sub-optimal performance may be obtained.","Besides, it is expensive and unsafe to exchange user's private embeddings between server and clients frequently, especially when training model in the contrastive way.","To remedy these drawbacks, we propose a novel and generic method termed Federated Averaging by exploring Label Correlations (FedALC).","Specifically, FedALC estimates the label correlations in the class embedding learning for different label pairs and utilizes it to improve the model training.","To further improve the safety and also reduce the communication overhead, we propose a variant to learn fixed class embedding for each client, so that the server and clients only need to exchange class embeddings once.","Extensive experiments on multiple popular datasets demonstrate that our FedALC can significantly outperform existing counterparts."],"url":"http://arxiv.org/abs/2404.15598v1"}
{"created":"2024-04-24 02:20:50","title":"GRSN: Gated Recurrent Spiking Neurons for POMDPs and MARL","abstract":"Spiking neural networks (SNNs) are widely applied in various fields due to their energy-efficient and fast-inference capabilities. Applying SNNs to reinforcement learning (RL) can significantly reduce the computational resource requirements for agents and improve the algorithm's performance under resource-constrained conditions. However, in current spiking reinforcement learning (SRL) algorithms, the simulation results of multiple time steps can only correspond to a single-step decision in RL. This is quite different from the real temporal dynamics in the brain and also fails to fully exploit the capacity of SNNs to process temporal data. In order to address this temporal mismatch issue and further take advantage of the inherent temporal dynamics of spiking neurons, we propose a novel temporal alignment paradigm (TAP) that leverages the single-step update of spiking neurons to accumulate historical state information in RL and introduces gated units to enhance the memory capacity of spiking neurons. Experimental results show that our method can solve partially observable Markov decision processes (POMDPs) and multi-agent cooperation problems with similar performance as recurrent neural networks (RNNs) but with about 50% power consumption.","sentences":["Spiking neural networks (SNNs) are widely applied in various fields due to their energy-efficient and fast-inference capabilities.","Applying SNNs to reinforcement learning (RL) can significantly reduce the computational resource requirements for agents and improve the algorithm's performance under resource-constrained conditions.","However, in current spiking reinforcement learning (SRL) algorithms, the simulation results of multiple time steps can only correspond to a single-step decision in RL.","This is quite different from the real temporal dynamics in the brain and also fails to fully exploit the capacity of SNNs to process temporal data.","In order to address this temporal mismatch issue and further take advantage of the inherent temporal dynamics of spiking neurons, we propose a novel temporal alignment paradigm (TAP) that leverages the single-step update of spiking neurons to accumulate historical state information in RL and introduces gated units to enhance the memory capacity of spiking neurons.","Experimental results show that our method can solve partially observable Markov decision processes (POMDPs) and multi-agent cooperation problems with similar performance as recurrent neural networks (RNNs) but with about 50% power consumption."],"url":"http://arxiv.org/abs/2404.15597v1"}
{"created":"2024-04-24 02:16:11","title":"VulEval: Towards Repository-Level Evaluation of Software Vulnerability Detection","abstract":"Deep Learning (DL)-based methods have proven to be effective for software vulnerability detection, with a potential for substantial productivity enhancements for detecting vulnerabilities. Current methods mainly focus on detecting single functions (i.e., intra-procedural vulnerabilities), ignoring the more complex inter-procedural vulnerability detection scenarios in practice. For example, developers routinely engage with program analysis to detect vulnerabilities that span multiple functions within repositories. In addition, the widely-used benchmark datasets generally contain only intra-procedural vulnerabilities, leaving the assessment of inter-procedural vulnerability detection capabilities unexplored.   To mitigate the issues, we propose a repository-level evaluation system, named \\textbf{VulEval}, aiming at evaluating the detection performance of inter- and intra-procedural vulnerabilities simultaneously. Specifically, VulEval consists of three interconnected evaluation tasks: \\textbf{(1) Function-Level Vulnerability Detection}, aiming at detecting intra-procedural vulnerability given a code snippet; \\textbf{(2) Vulnerability-Related Dependency Prediction}, aiming at retrieving the most relevant dependencies from call graphs for providing developers with explanations about the vulnerabilities; and \\textbf{(3) Repository-Level Vulnerability Detection}, aiming at detecting inter-procedural vulnerabilities by combining with the dependencies identified in the second task. VulEval also consists of a large-scale dataset, with a total of 4,196 CVE entries, 232,239 functions, and corresponding 4,699 repository-level source code in C/C++ programming languages. Our analysis highlights the current progress and future directions for software vulnerability detection.","sentences":["Deep Learning (DL)-based methods have proven to be effective for software vulnerability detection, with a potential for substantial productivity enhancements for detecting vulnerabilities.","Current methods mainly focus on detecting single functions (i.e., intra-procedural vulnerabilities), ignoring the more complex inter-procedural vulnerability detection scenarios in practice.","For example, developers routinely engage with program analysis to detect vulnerabilities that span multiple functions within repositories.","In addition, the widely-used benchmark datasets generally contain only intra-procedural vulnerabilities, leaving the assessment of inter-procedural vulnerability detection capabilities unexplored.   ","To mitigate the issues, we propose a repository-level evaluation system, named \\textbf{VulEval}, aiming at evaluating the detection performance of inter- and intra-procedural vulnerabilities simultaneously.","Specifically, VulEval consists of three interconnected evaluation tasks: \\textbf{(1) Function-Level Vulnerability Detection}, aiming at detecting intra-procedural vulnerability given a code snippet; \\textbf{(2) Vulnerability-Related Dependency Prediction}, aiming at retrieving the most relevant dependencies from call graphs for providing developers with explanations about the vulnerabilities; and \\textbf{(3)","Repository-Level Vulnerability Detection}, aiming at detecting inter-procedural vulnerabilities by combining with the dependencies identified in the second task.","VulEval also consists of a large-scale dataset, with a total of 4,196 CVE entries, 232,239 functions, and corresponding 4,699 repository-level source code in C/C++ programming languages.","Our analysis highlights the current progress and future directions for software vulnerability detection."],"url":"http://arxiv.org/abs/2404.15596v1"}
{"created":"2024-04-24 02:16:00","title":"Variational Deep Survival Machines: Survival Regression with Censored Outcomes","abstract":"Survival regression aims to predict the time when an event of interest will take place, typically a death or a failure. A fully parametric method [18] is proposed to estimate the survival function as a mixture of individual parametric distributions in the presence of censoring. In this paper, We present a novel method to predict the survival time by better clustering the survival data and combine primitive distributions. We propose two variants of variational auto-encoder (VAE), discrete and continuous, to generate the latent variables for clustering input covariates. The model is trained end to end by jointly optimizing the VAE loss and regression loss. Thorough experiments on dataset SUPPORT and FLCHAIN show that our method can effectively improve the clustering result and reach competitive scores with previous methods. We demonstrate the superior result of our model prediction in the long-term. Our code is available at https://github.com/qinzzz/auton-survival-785.","sentences":["Survival regression aims to predict the time when an event of interest will take place, typically a death or a failure.","A fully parametric method [18] is proposed to estimate the survival function as a mixture of individual parametric distributions in the presence of censoring.","In this paper, We present a novel method to predict the survival time by better clustering the survival data and combine primitive distributions.","We propose two variants of variational auto-encoder (VAE), discrete and continuous, to generate the latent variables for clustering input covariates.","The model is trained end to end by jointly optimizing the VAE loss and regression loss.","Thorough experiments on dataset SUPPORT and FLCHAIN show that our method can effectively improve the clustering result and reach competitive scores with previous methods.","We demonstrate the superior result of our model prediction in the long-term.","Our code is available at https://github.com/qinzzz/auton-survival-785."],"url":"http://arxiv.org/abs/2404.15595v1"}
{"created":"2024-04-24 01:59:02","title":"A Survey of Deep Long-Tail Classification Advancements","abstract":"Many data distributions in the real world are hardly uniform. Instead, skewed and long-tailed distributions of various kinds are commonly observed. This poses an interesting problem for machine learning, where most algorithms assume or work well with uniformly distributed data. The problem is further exacerbated by current state-of-the-art deep learning models requiring large volumes of training data. As such, learning from imbalanced data remains a challenging research problem and a problem that must be solved as we move towards more real-world applications of deep learning. In the context of class imbalance, state-of-the-art (SOTA) accuracies on standard benchmark datasets for classification typically fall less than 75%, even for less challenging datasets such as CIFAR100. Nonetheless, there has been progress in this niche area of deep learning. To this end, in this survey, we provide a taxonomy of various methods proposed for addressing the problem of long-tail classification, focusing on works that happened in the last few years under a single mathematical framework. We also discuss standard performance metrics, convergence studies, feature distribution and classifier analysis. We also provide a quantitative comparison of the performance of different SOTA methods and conclude the survey by discussing the remaining challenges and future research direction.","sentences":["Many data distributions in the real world are hardly uniform.","Instead, skewed and long-tailed distributions of various kinds are commonly observed.","This poses an interesting problem for machine learning, where most algorithms assume or work well with uniformly distributed data.","The problem is further exacerbated by current state-of-the-art deep learning models requiring large volumes of training data.","As such, learning from imbalanced data remains a challenging research problem and a problem that must be solved as we move towards more real-world applications of deep learning.","In the context of class imbalance, state-of-the-art (SOTA) accuracies on standard benchmark datasets for classification typically fall less than 75%, even for less challenging datasets such as CIFAR100.","Nonetheless, there has been progress in this niche area of deep learning.","To this end, in this survey, we provide a taxonomy of various methods proposed for addressing the problem of long-tail classification, focusing on works that happened in the last few years under a single mathematical framework.","We also discuss standard performance metrics, convergence studies, feature distribution and classifier analysis.","We also provide a quantitative comparison of the performance of different SOTA methods and conclude the survey by discussing the remaining challenges and future research direction."],"url":"http://arxiv.org/abs/2404.15593v1"}
{"created":"2024-04-24 01:54:40","title":"ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for Implicit Attribute Value Extraction","abstract":"Existing datasets for attribute value extraction (AVE) predominantly focus on explicit attribute values while neglecting the implicit ones, lack product images, are often not publicly available, and lack an in-depth human inspection across diverse domains. To address these limitations, we present ImplicitAVE, the first, publicly available multimodal dataset for implicit attribute value extraction. ImplicitAVE, sourced from the MAVE dataset, is carefully curated and expanded to include implicit AVE and multimodality, resulting in a refined dataset of 68k training and 1.6k testing data across five domains. We also explore the application of multimodal large language models (MLLMs) to implicit AVE, establishing a comprehensive benchmark for MLLMs on the ImplicitAVE dataset. Six recent MLLMs with eleven variants are evaluated across diverse settings, revealing that implicit value extraction remains a challenging task for MLLMs. The contributions of this work include the development and release of ImplicitAVE, and the exploration and benchmarking of various MLLMs for implicit AVE, providing valuable insights and potential future research directions. Dataset and code are available at https://github.com/HenryPengZou/ImplicitAVE","sentences":["Existing datasets for attribute value extraction (AVE) predominantly focus on explicit attribute values while neglecting the implicit ones, lack product images, are often not publicly available, and lack an in-depth human inspection across diverse domains.","To address these limitations, we present ImplicitAVE, the first, publicly available multimodal dataset for implicit attribute value extraction.","ImplicitAVE, sourced from the MAVE dataset, is carefully curated and expanded to include implicit AVE and multimodality, resulting in a refined dataset of 68k training and 1.6k testing data across five domains.","We also explore the application of multimodal large language models (MLLMs) to implicit AVE, establishing a comprehensive benchmark for MLLMs on the ImplicitAVE dataset.","Six recent MLLMs with eleven variants are evaluated across diverse settings, revealing that implicit value extraction remains a challenging task for MLLMs.","The contributions of this work include the development and release of ImplicitAVE, and the exploration and benchmarking of various MLLMs for implicit AVE, providing valuable insights and potential future research directions.","Dataset and code are available at https://github.com/HenryPengZou/ImplicitAVE"],"url":"http://arxiv.org/abs/2404.15592v1"}
{"created":"2024-04-24 01:50:36","title":"Domain Adaptation for Learned Image Compression with Supervised Adapters","abstract":"In Learned Image Compression (LIC), a model is trained at encoding and decoding images sampled from a source domain, often outperforming traditional codecs on natural images; yet its performance may be far from optimal on images sampled from different domains. In this work, we tackle the problem of adapting a pre-trained model to multiple target domains by plugging into the decoder an adapter module for each of them, including the source one. Each adapter improves the decoder performance on a specific domain, without the model forgetting about the images seen at training time. A gate network computes the weights to optimally blend the contributions from the adapters when the bitstream is decoded. We experimentally validate our method over two state-of-the-art pre-trained models, observing improved rate-distortion efficiency on the target domains without penalties on the source domain. Furthermore, the gate's ability to find similarities with the learned target domains enables better encoding efficiency also for images outside them.","sentences":["In Learned Image Compression (LIC), a model is trained at encoding and decoding images sampled from a source domain, often outperforming traditional codecs on natural images; yet its performance may be far from optimal on images sampled from different domains.","In this work, we tackle the problem of adapting a pre-trained model to multiple target domains by plugging into the decoder an adapter module for each of them, including the source one.","Each adapter improves the decoder performance on a specific domain, without the model forgetting about the images seen at training time.","A gate network computes the weights to optimally blend the contributions from the adapters when the bitstream is decoded.","We experimentally validate our method over two state-of-the-art pre-trained models, observing improved rate-distortion efficiency on the target domains without penalties on the source domain.","Furthermore, the gate's ability to find similarities with the learned target domains enables better encoding efficiency also for images outside them."],"url":"http://arxiv.org/abs/2404.15591v1"}
{"created":"2024-04-24 01:44:09","title":"Minimal Evidence Group Identification for Claim Verification","abstract":"Claim verification in real-world settings (e.g. against a large collection of candidate evidences retrieved from the web) typically requires identifying and aggregating a complete set of evidence pieces that collectively provide full support to the claim. The problem becomes particularly challenging when there exists distinct sets of evidence that could be used to verify the claim from different perspectives. In this paper, we formally define and study the problem of identifying such minimal evidence groups (MEGs) for claim verification. We show that MEG identification can be reduced from Set Cover problem, based on entailment inference of whether a given evidence group provides full/partial support to a claim. Our proposed approach achieves 18.4% and 34.8% absolute improvements on the WiCE and SciFact datasets over LLM prompting. Finally, we demonstrate the benefits of MEGs in downstream applications such as claim generation.","sentences":["Claim verification in real-world settings (e.g. against a large collection of candidate evidences retrieved from the web) typically requires identifying and aggregating a complete set of evidence pieces that collectively provide full support to the claim.","The problem becomes particularly challenging when there exists distinct sets of evidence that could be used to verify the claim from different perspectives.","In this paper, we formally define and study the problem of identifying such minimal evidence groups (MEGs) for claim verification.","We show that MEG identification can be reduced from Set Cover problem, based on entailment inference of whether a given evidence group provides full/partial support to a claim.","Our proposed approach achieves 18.4% and 34.8% absolute improvements on the WiCE and SciFact datasets over LLM prompting.","Finally, we demonstrate the benefits of MEGs in downstream applications such as claim generation."],"url":"http://arxiv.org/abs/2404.15588v1"}
{"created":"2024-04-24 01:43:07","title":"Security Analysis of WiFi-based Sensing Systems: Threats from Perturbation Attacks","abstract":"Deep learning technologies are pivotal in enhancing the performance of WiFi-based wireless sensing systems. However, they are inherently vulnerable to adversarial perturbation attacks, and regrettably, there is lacking serious attention to this security issue within the WiFi sensing community. In this paper, we elaborate such an attack, called WiIntruder, distinguishing itself with universality, robustness, and stealthiness, which serves as a catalyst to assess the security of existing WiFi-based sensing systems. This attack encompasses the following salient features: (1) Maximizing transferability by differentiating user-state-specific feature spaces across sensing models, leading to a universally effective perturbation attack applicable to common applications; (2) Addressing perturbation signal distortion caused by device synchronization and wireless propagation when critical parameters are optimized through a heuristic particle swarm-driven perturbation generation algorithm; and (3) Enhancing attack pattern diversity and stealthiness through random switching of perturbation surrogates generated by a generative adversarial network. Extensive experimental results confirm the practical threats of perturbation attacks to common WiFi-based services, including user authentication and respiratory monitoring.","sentences":["Deep learning technologies are pivotal in enhancing the performance of WiFi-based wireless sensing systems.","However, they are inherently vulnerable to adversarial perturbation attacks, and regrettably, there is lacking serious attention to this security issue within the WiFi sensing community.","In this paper, we elaborate such an attack, called WiIntruder, distinguishing itself with universality, robustness, and stealthiness, which serves as a catalyst to assess the security of existing WiFi-based sensing systems.","This attack encompasses the following salient features: (1) Maximizing transferability by differentiating user-state-specific feature spaces across sensing models, leading to a universally effective perturbation attack applicable to common applications; (2) Addressing perturbation signal distortion caused by device synchronization and wireless propagation when critical parameters are optimized through a heuristic particle swarm-driven perturbation generation algorithm; and (3) Enhancing attack pattern diversity and stealthiness through random switching of perturbation surrogates generated by a generative adversarial network.","Extensive experimental results confirm the practical threats of perturbation attacks to common WiFi-based services, including user authentication and respiratory monitoring."],"url":"http://arxiv.org/abs/2404.15587v1"}
{"created":"2024-04-24 01:37:20","title":"Brain Storm Optimization Based Swarm Learning for Diabetic Retinopathy Image Classification","abstract":"The application of deep learning techniques to medical problems has garnered widespread research interest in recent years, such as applying convolutional neural networks to medical image classification tasks. However, data in the medical field is often highly private, preventing different hospitals from sharing data to train an accurate model. Federated learning, as a privacy-preserving machine learning architecture, has shown promising performance in balancing data privacy and model utility by keeping private data on the client's side and using a central server to coordinate a set of clients for model training through aggregating their uploaded model parameters. Yet, this architecture heavily relies on a trusted third-party server, which is challenging to achieve in real life. Swarm learning, as a specialized decentralized federated learning architecture that does not require a central server, utilizes blockchain technology to enable direct parameter exchanges between clients. However, the mining of blocks requires significant computational resources, limiting its scalability. To address this issue, this paper integrates the brain storm optimization algorithm into the swarm learning framework, named BSO-SL. This approach clusters similar clients into different groups based on their model distributions. Additionally, leveraging the architecture of BSO, clients are given the probability to engage in collaborative learning both within their cluster and with clients outside their cluster, preventing the model from converging to local optima. The proposed method has been validated on a real-world diabetic retinopathy image classification dataset, and the experimental results demonstrate the effectiveness of the proposed approach.","sentences":["The application of deep learning techniques to medical problems has garnered widespread research interest in recent years, such as applying convolutional neural networks to medical image classification tasks.","However, data in the medical field is often highly private, preventing different hospitals from sharing data to train an accurate model.","Federated learning, as a privacy-preserving machine learning architecture, has shown promising performance in balancing data privacy and model utility by keeping private data on the client's side and using a central server to coordinate a set of clients for model training through aggregating their uploaded model parameters.","Yet, this architecture heavily relies on a trusted third-party server, which is challenging to achieve in real life.","Swarm learning, as a specialized decentralized federated learning architecture that does not require a central server, utilizes blockchain technology to enable direct parameter exchanges between clients.","However, the mining of blocks requires significant computational resources, limiting its scalability.","To address this issue, this paper integrates the brain storm optimization algorithm into the swarm learning framework, named BSO-SL.","This approach clusters similar clients into different groups based on their model distributions.","Additionally, leveraging the architecture of BSO, clients are given the probability to engage in collaborative learning both within their cluster and with clients outside their cluster, preventing the model from converging to local optima.","The proposed method has been validated on a real-world diabetic retinopathy image classification dataset, and the experimental results demonstrate the effectiveness of the proposed approach."],"url":"http://arxiv.org/abs/2404.15585v1"}
{"created":"2024-04-24 01:35:27","title":"Multi-Agent Reinforcement Learning for Energy Networks: Computational Challenges, Progress and Open Problems","abstract":"The rapidly changing architecture and functionality of electrical networks and the increasing penetration of renewable and distributed energy resources have resulted in various technological and managerial challenges. These have rendered traditional centralized energy-market paradigms insufficient due to their inability to support the dynamic and evolving nature of the network. This survey explores how multi-agent reinforcement learning (MARL) can support the decentralization and decarbonization of energy networks and mitigate the 12 associated challenges. This is achieved by specifying key computational challenges in managing energy networks, reviewing recent research progress on addressing them, and highlighting open challenges that may be addressed using MARL.","sentences":["The rapidly changing architecture and functionality of electrical networks and the increasing penetration of renewable and distributed energy resources have resulted in various technological and managerial challenges.","These have rendered traditional centralized energy-market paradigms insufficient due to their inability to support the dynamic and evolving nature of the network.","This survey explores how multi-agent reinforcement learning (MARL) can support the decentralization and decarbonization of energy networks and mitigate the 12 associated challenges.","This is achieved by specifying key computational challenges in managing energy networks, reviewing recent research progress on addressing them, and highlighting open challenges that may be addressed using MARL."],"url":"http://arxiv.org/abs/2404.15583v1"}
{"created":"2024-04-24 01:31:23","title":"Armored Core of PKI: Remove Signing Keys for CA via Physically Unclonable Function","abstract":"The protection of CA's signing keys is one of the most crucial security concerns in PKI. However, these keys can still be exposed today by human errors or various carefully designed attacks. Traditional protections like TEE and HSM fail to eliminate this risk since they can be bypassed by skilled attackers. This dilemma motivates us to consider removing CA' signing keys and propose Armored Core, a PKI security extension applying the physically trusted binding provided by Physically Unclonable Function (PUF) for CA.   CAs in Armored Core issue PUF-based X509v3 TLS certificates, where they use PUF instead of signing algorithms to generate endorsements for domain public keys. The new transparency logging mechanism, built upon CT, will record the PUF calling behaviors of CA, ensuring the monitoring of PUF usage. We provide a formal cryptographic proof of Armored Core's main functions. We also implement it on the real-world PKI codebase. The results show that the incorporation of Armored Core into original systems do not cause any extra overhead, but instead improves computing efficiency by >4.9% and saves >20% of certificate storage.","sentences":["The protection of CA's signing keys is one of the most crucial security concerns in PKI.","However, these keys can still be exposed today by human errors or various carefully designed attacks.","Traditional protections like TEE and HSM fail to eliminate this risk since they can be bypassed by skilled attackers.","This dilemma motivates us to consider removing CA' signing keys and propose Armored Core, a PKI security extension applying the physically trusted binding provided by Physically Unclonable Function (PUF) for CA.   CAs in Armored Core issue PUF-based X509v3 TLS certificates, where they use PUF instead of signing algorithms to generate endorsements for domain public keys.","The new transparency logging mechanism, built upon CT, will record the PUF calling behaviors of CA, ensuring the monitoring of PUF usage.","We provide a formal cryptographic proof of Armored Core's main functions.","We also implement it on the real-world PKI codebase.","The results show that the incorporation of Armored Core into original systems do not cause any extra overhead, but instead improves computing efficiency by >4.9% and saves >20% of certificate storage."],"url":"http://arxiv.org/abs/2404.15582v1"}
{"created":"2024-04-24 01:14:33","title":"MiM: Mask in Mask Self-Supervised Pre-Training for 3D Medical Image Analysis","abstract":"The Vision Transformer (ViT) has demonstrated remarkable performance in Self-Supervised Learning (SSL) for 3D medical image analysis. Mask AutoEncoder (MAE) for feature pre-training can further unleash the potential of ViT on various medical vision tasks. However, due to large spatial sizes with much higher dimensions of 3D medical images, the lack of hierarchical design for MAE may hinder the performance of downstream tasks. In this paper, we propose a novel \\textit{Mask in Mask (MiM)} pre-training framework for 3D medical images, which aims to advance MAE by learning discriminative representation from hierarchical visual tokens across varying scales. We introduce multiple levels of granularity for masked inputs from the volume, which are then reconstructed simultaneously ranging at both fine and coarse levels. Additionally, a cross-level alignment mechanism is applied to adjacent level volumes to enforce anatomical similarity hierarchically. Furthermore, we adopt a hybrid backbone to enhance the hierarchical representation learning efficiently during the pre-training. MiM was pre-trained on a large scale of available 3D volumetric images, \\textit{i.e.,} Computed Tomography (CT) images containing various body parts. Extensive experiments on thirteen public datasets demonstrate the superiority of MiM over other SSL methods in organ/lesion/tumor segmentation and disease classification. We further scale up the MiM to large pre-training datasets with more than 10k volumes, showing that large-scale pre-training can further enhance the performance of downstream tasks. The improvement also concluded that the research community should pay more attention to the scale of the pre-training dataset towards the healthcare foundation model for 3D medical images.","sentences":["The Vision Transformer (ViT) has demonstrated remarkable performance in Self-Supervised Learning (SSL) for 3D medical image analysis.","Mask AutoEncoder (MAE) for feature pre-training can further unleash the potential of ViT on various medical vision tasks.","However, due to large spatial sizes with much higher dimensions of 3D medical images, the lack of hierarchical design for MAE may hinder the performance of downstream tasks.","In this paper, we propose a novel \\textit{Mask in Mask (MiM)} pre-training framework for 3D medical images, which aims to advance MAE by learning discriminative representation from hierarchical visual tokens across varying scales.","We introduce multiple levels of granularity for masked inputs from the volume, which are then reconstructed simultaneously ranging at both fine and coarse levels.","Additionally, a cross-level alignment mechanism is applied to adjacent level volumes to enforce anatomical similarity hierarchically.","Furthermore, we adopt a hybrid backbone to enhance the hierarchical representation learning efficiently during the pre-training.","MiM was pre-trained on a large scale of available 3D volumetric images, \\textit{i.e.,} Computed Tomography (CT) images containing various body parts.","Extensive experiments on thirteen public datasets demonstrate the superiority of MiM over other SSL methods in organ/lesion/tumor segmentation and disease classification.","We further scale up the MiM to large pre-training datasets with more than 10k volumes, showing that large-scale pre-training can further enhance the performance of downstream tasks.","The improvement also concluded that the research community should pay more attention to the scale of the pre-training dataset towards the healthcare foundation model for 3D medical images."],"url":"http://arxiv.org/abs/2404.15580v1"}
{"created":"2024-04-24 00:56:22","title":"Can Foundational Large Language Models Assist with Conducting Pharmaceuticals Manufacturing Investigations?","abstract":"General purpose Large Language Models (LLM) such as the Generative Pretrained Transformer (GPT) and Large Language Model Meta AI (LLaMA) have attracted much attention in recent years. There is strong evidence that these models can perform remarkably well in various natural language processing tasks. However, how to leverage them to approach domain-specific use cases and drive value remains an open question. In this work, we focus on a specific use case, pharmaceutical manufacturing investigations, and propose that leveraging historical records of manufacturing incidents and deviations in an organization can be beneficial for addressing and closing new cases, or de-risking new manufacturing campaigns. Using a small but diverse dataset of real manufacturing deviations selected from different product lines, we evaluate and quantify the power of three general purpose LLMs (GPT-3.5, GPT-4, and Claude-2) in performing tasks related to the above goal. In particular, (1) the ability of LLMs in automating the process of extracting specific information such as root cause of a case from unstructured data, as well as (2) the possibility of identifying similar or related deviations by performing semantic search on the database of historical records are examined. While our results point to the high accuracy of GPT-4 and Claude-2 in the information extraction task, we discuss cases of complex interplay between the apparent reasoning and hallucination behavior of LLMs as a risk factor. Furthermore, we show that semantic search on vector embedding of deviation descriptions can be used to identify similar records, such as those with a similar type of defect, with a high level of accuracy. We discuss further improvements to enhance the accuracy of similar record identification.","sentences":["General purpose Large Language Models (LLM) such as the Generative Pretrained Transformer (GPT) and Large Language Model Meta AI (LLaMA) have attracted much attention in recent years.","There is strong evidence that these models can perform remarkably well in various natural language processing tasks.","However, how to leverage them to approach domain-specific use cases and drive value remains an open question.","In this work, we focus on a specific use case, pharmaceutical manufacturing investigations, and propose that leveraging historical records of manufacturing incidents and deviations in an organization can be beneficial for addressing and closing new cases, or de-risking new manufacturing campaigns.","Using a small but diverse dataset of real manufacturing deviations selected from different product lines, we evaluate and quantify the power of three general purpose LLMs (GPT-3.5, GPT-4, and Claude-2) in performing tasks related to the above goal.","In particular, (1) the ability of LLMs in automating the process of extracting specific information such as root cause of a case from unstructured data, as well as (2) the possibility of identifying similar or related deviations by performing semantic search on the database of historical records are examined.","While our results point to the high accuracy of GPT-4 and Claude-2 in the information extraction task, we discuss cases of complex interplay between the apparent reasoning and hallucination behavior of LLMs as a risk factor.","Furthermore, we show that semantic search on vector embedding of deviation descriptions can be used to identify similar records, such as those with a similar type of defect, with a high level of accuracy.","We discuss further improvements to enhance the accuracy of similar record identification."],"url":"http://arxiv.org/abs/2404.15578v1"}
{"created":"2024-04-24 00:35:40","title":"Designing AI-Enabled Games to Support Social-Emotional Learning for Children with Autism Spectrum Disorders","abstract":"Children with autism spectrum disorder (ASD) experience challenges in grasping social-emotional cues, which can result in difficulties in recognizing emotions and understanding and responding to social interactions. Social-emotional intervention is an effective method to improve emotional understanding and facial expression recognition among individuals with ASD. Existing work emphasizes the importance of personalizing interventions to meet individual needs and motivate engagement for optimal outcomes in daily settings. We design a social-emotional game for ASD children, which generates personalized stories by leveraging the current advancement of artificial intelligence. Via a co-design process with five domain experts, this work offers several design insights into developing future AI-enabled gamified systems for families with autistic children. We also propose a fine-tuned AI model and a dataset of social stories for different basic emotions.","sentences":["Children with autism spectrum disorder (ASD) experience challenges in grasping social-emotional cues, which can result in difficulties in recognizing emotions and understanding and responding to social interactions.","Social-emotional intervention is an effective method to improve emotional understanding and facial expression recognition among individuals with ASD.","Existing work emphasizes the importance of personalizing interventions to meet individual needs and motivate engagement for optimal outcomes in daily settings.","We design a social-emotional game for ASD children, which generates personalized stories by leveraging the current advancement of artificial intelligence.","Via a co-design process with five domain experts, this work offers several design insights into developing future AI-enabled gamified systems for families with autistic children.","We also propose a fine-tuned AI model and a dataset of social stories for different basic emotions."],"url":"http://arxiv.org/abs/2404.15576v1"}
{"created":"2024-04-24 00:24:03","title":"Retrieval Head Mechanistically Explains Long-Context Factuality","abstract":"Despite the recent progress in long-context language models, it remains elusive how transformer-based models exhibit the capability to retrieve relevant information from arbitrary locations within the long context. This paper aims to address this question. Our systematic investigation across a wide spectrum of models reveals that a special type of attention heads are largely responsible for retrieving information, which we dub retrieval heads. We identify intriguing properties of retrieval heads:(1) universal: all the explored models with long-context capability have a set of retrieval heads; (2) sparse: only a small portion (less than 5\\%) of the attention heads are retrieval. (3) intrinsic: retrieval heads already exist in models pretrained with short context. When extending the context length by continual pretraining, it is still the same set of heads that perform information retrieval. (4) dynamically activated: take Llama-2 7B for example, 12 retrieval heads always attend to the required information no matter how the context is changed. The rest of the retrieval heads are activated in different contexts. (5) causal: completely pruning retrieval heads leads to failure in retrieving relevant information and results in hallucination, while pruning random non-retrieval heads does not affect the model's retrieval ability. We further show that retrieval heads strongly influence chain-of-thought (CoT) reasoning, where the model needs to frequently refer back the question and previously-generated context. Conversely, tasks where the model directly generates the answer using its intrinsic knowledge are less impacted by masking out retrieval heads. These observations collectively explain which internal part of the model seeks information from the input tokens. We believe our insights will foster future research on reducing hallucination, improving reasoning, and compressing the KV cache.","sentences":["Despite the recent progress in long-context language models, it remains elusive how transformer-based models exhibit the capability to retrieve relevant information from arbitrary locations within the long context.","This paper aims to address this question.","Our systematic investigation across a wide spectrum of models reveals that a special type of attention heads are largely responsible for retrieving information, which we dub retrieval heads.","We identify intriguing properties of retrieval heads:(1) universal: all the explored models with long-context capability have a set of retrieval heads; (2) sparse: only a small portion (less than 5\\%) of the attention heads are retrieval.","(3) intrinsic: retrieval heads already exist in models pretrained with short context.","When extending the context length by continual pretraining, it is still the same set of heads that perform information retrieval.","(4) dynamically activated: take Llama-2 7B for example, 12 retrieval heads always attend to the required information no matter how the context is changed.","The rest of the retrieval heads are activated in different contexts.","(5) causal: completely pruning retrieval heads leads to failure in retrieving relevant information and results in hallucination, while pruning random non-retrieval heads does not affect the model's retrieval ability.","We further show that retrieval heads strongly influence chain-of-thought (CoT) reasoning, where the model needs to frequently refer back the question and previously-generated context.","Conversely, tasks where the model directly generates the answer using its intrinsic knowledge are less impacted by masking out retrieval heads.","These observations collectively explain which internal part of the model seeks information from the input tokens.","We believe our insights will foster future research on reducing hallucination, improving reasoning, and compressing the KV cache."],"url":"http://arxiv.org/abs/2404.15574v1"}
{"created":"2024-04-23 23:27:29","title":"CASPR: Automated Evaluation Metric for Contrastive Summarization","abstract":"Summarizing comparative opinions about entities (e.g., hotels, phones) from a set of source reviews, often referred to as contrastive summarization, can considerably aid users in decision making. However, reliably measuring the contrastiveness of the output summaries without relying on human evaluations remains an open problem. Prior work has proposed token-overlap based metrics, Distinctiveness Score, to measure contrast which does not take into account the sensitivity to meaning-preserving lexical variations. In this work, we propose an automated evaluation metric CASPR to better measure contrast between a pair of summaries. Our metric is based on a simple and light-weight method that leverages natural language inference (NLI) task to measure contrast by segmenting reviews into single-claim sentences and carefully aggregating NLI scores between them to come up with a summary-level score. We compare CASPR with Distinctiveness Score and a simple yet powerful baseline based on BERTScore. Our results on a prior dataset CoCoTRIP demonstrate that CASPR can more reliably capture the contrastiveness of the summary pairs compared to the baselines.","sentences":["Summarizing comparative opinions about entities (e.g., hotels, phones) from a set of source reviews, often referred to as contrastive summarization, can considerably aid users in decision making.","However, reliably measuring the contrastiveness of the output summaries without relying on human evaluations remains an open problem.","Prior work has proposed token-overlap based metrics, Distinctiveness Score, to measure contrast which does not take into account the sensitivity to meaning-preserving lexical variations.","In this work, we propose an automated evaluation metric CASPR to better measure contrast between a pair of summaries.","Our metric is based on a simple and light-weight method that leverages natural language inference (NLI) task to measure contrast by segmenting reviews into single-claim sentences and carefully aggregating NLI scores between them to come up with a summary-level score.","We compare CASPR with Distinctiveness Score and a simple yet powerful baseline based on BERTScore.","Our results on a prior dataset CoCoTRIP demonstrate that CASPR can more reliably capture the contrastiveness of the summary pairs compared to the baselines."],"url":"http://arxiv.org/abs/2404.15565v1"}
{"created":"2024-04-23 23:26:02","title":"Guided AbsoluteGrad: Magnitude of Gradients Matters to Explanation's Localization and Saliency","abstract":"This paper proposes a new gradient-based XAI method called Guided AbsoluteGrad for saliency map explanations. We utilize both positive and negative gradient magnitudes and employ gradient variance to distinguish the important areas for noise deduction. We also introduce a novel evaluation metric named ReCover And Predict (RCAP), which considers the Localization and Visual Noise Level objectives of the explanations. We propose two propositions for these two objectives and prove the necessity of evaluating them. We evaluate Guided AbsoluteGrad with seven gradient-based XAI methods using the RCAP metric and other SOTA metrics in three case studies: (1) ImageNet dataset with ResNet50 model; (2) International Skin Imaging Collaboration (ISIC) dataset with EfficientNet model; (3) the Places365 dataset with DenseNet161 model. Our method surpasses other gradient-based approaches, showcasing the quality of enhanced saliency map explanations through gradient magnitude.","sentences":["This paper proposes a new gradient-based XAI method called Guided AbsoluteGrad for saliency map explanations.","We utilize both positive and negative gradient magnitudes and employ gradient variance to distinguish the important areas for noise deduction.","We also introduce a novel evaluation metric named ReCover And Predict (RCAP), which considers the Localization and Visual Noise Level objectives of the explanations.","We propose two propositions for these two objectives and prove the necessity of evaluating them.","We evaluate Guided AbsoluteGrad with seven gradient-based XAI methods using the RCAP metric and other SOTA metrics in three case studies: (1) ImageNet dataset with ResNet50 model; (2) International Skin Imaging Collaboration (ISIC) dataset with EfficientNet model; (3) the Places365 dataset with DenseNet161 model.","Our method surpasses other gradient-based approaches, showcasing the quality of enhanced saliency map explanations through gradient magnitude."],"url":"http://arxiv.org/abs/2404.15564v1"}
{"created":"2024-04-23 23:15:05","title":"Low-Bandwidth Matrix Multiplication: Faster Algorithms and More General Forms of Sparsity","abstract":"In prior work, Gupta et al. (SPAA 2022) presented a distributed algorithm for multiplying sparse $n \\times n$ matrices, using $n$ computers. They assumed that the input matrices are uniformly sparse -- there are at most $d$ non-zeros in each row and column -- and the task is to compute a uniformly sparse part of the product matrix. Initially each computer knows one row of each input matrix, and eventually each computer needs to know one row of the product matrix. In each communication round each computer can send and receive one $O(\\log n)$-bit message. Their algorithm solves this task in $O(d^{1.907})$ rounds, while the trivial bound is $O(d^2)$. We improve on the prior work in two dimensions: First, we show that we can solve the same task faster, in only $O(d^{1.832})$ rounds. Second, we explore what happens when matrices are not uniformly sparse. We consider the following alternative notions of sparsity: row-sparse matrices (at most $d$ non-zeros per row), column-sparse matrices, matrices with bounded degeneracy (we can recursively delete a row or column with at most $d$ non-zeros), average-sparse matrices (at most $dn$ non-zeros in total), and general matrices. We show that we can still compute $X = AB$ in $O(d^{1.832})$ rounds even if one of the three matrices ($A$, $B$, or $X$) is average-sparse instead of uniformly sparse. We present algorithms that handle a much broader range of sparsity in $O(d^2 + \\log n)$ rounds, and present conditional hardness results that put limits on further improvements and generalizations.","sentences":["In prior work, Gupta et al. (SPAA 2022) presented a distributed algorithm for multiplying sparse $n \\times n$ matrices, using $n$ computers.","They assumed that the input matrices are uniformly sparse -- there are at most $d$ non-zeros in each row and column -- and the task is to compute a uniformly sparse part of the product matrix.","Initially each computer knows one row of each input matrix, and eventually each computer needs to know one row of the product matrix.","In each communication round each computer can send and receive one $O(\\log n)$-bit message.","Their algorithm solves this task in $O(d^{1.907})$ rounds, while the trivial bound is $O(d^2)$. We improve on the prior work in two dimensions:","First, we show that we can solve the same task faster, in only $O(d^{1.832})$ rounds.","Second, we explore what happens when matrices are not uniformly sparse.","We consider the following alternative notions of sparsity: row-sparse matrices (at most $d$ non-zeros per row), column-sparse matrices, matrices with bounded degeneracy (we can recursively delete a row or column with at most $d$ non-zeros), average-sparse matrices (at most $dn$ non-zeros in total), and general matrices.","We show that we can still compute $X = AB$ in $O(d^{1.832})$ rounds even if one of the three matrices ($A$, $B$, or $X$) is average-sparse instead of uniformly sparse.","We present algorithms that handle a much broader range of sparsity in $O(d^2 + \\log n)$ rounds, and present conditional hardness results that put limits on further improvements and generalizations."],"url":"http://arxiv.org/abs/2404.15559v1"}
{"created":"2024-04-23 23:11:42","title":"Safe POMDP Online Planning among Dynamic Agents via Adaptive Conformal Prediction","abstract":"Online planning for partially observable Markov decision processes (POMDPs) provides efficient techniques for robot decision-making under uncertainty. However, existing methods fall short of preventing safety violations in dynamic environments. This work presents a novel safe POMDP online planning approach that offers probabilistic safety guarantees amidst environments populated by multiple dynamic agents. Our approach utilizes data-driven trajectory prediction models of dynamic agents and applies Adaptive Conformal Prediction (ACP) for assessing the uncertainties in these predictions. Leveraging the obtained ACP-based trajectory predictions, our approach constructs safety shields on-the-fly to prevent unsafe actions within POMDP online planning. Through experimental evaluation in various dynamic environments using real-world pedestrian trajectory data, the proposed approach has been shown to effectively maintain probabilistic safety guarantees while accommodating up to hundreds of dynamic agents.","sentences":["Online planning for partially observable Markov decision processes (POMDPs) provides efficient techniques for robot decision-making under uncertainty.","However, existing methods fall short of preventing safety violations in dynamic environments.","This work presents a novel safe POMDP online planning approach that offers probabilistic safety guarantees amidst environments populated by multiple dynamic agents.","Our approach utilizes data-driven trajectory prediction models of dynamic agents and applies Adaptive Conformal Prediction (ACP) for assessing the uncertainties in these predictions.","Leveraging the obtained ACP-based trajectory predictions, our approach constructs safety shields on-the-fly to prevent unsafe actions within POMDP online planning.","Through experimental evaluation in various dynamic environments using real-world pedestrian trajectory data, the proposed approach has been shown to effectively maintain probabilistic safety guarantees while accommodating up to hundreds of dynamic agents."],"url":"http://arxiv.org/abs/2404.15557v1"}
{"created":"2024-04-23 23:04:52","title":"Online Disjoint Set Covers: Randomization is not Necessary","abstract":"In the online disjoint set covers problem, the edges of a hypergraph are revealed online, and the goal is to partition them into a maximum number of disjoint set covers. That is, n nodes of a hypergraph are given at the beginning, and then a sequence of hyperedges (subsets of [n]) is presented to an algorithm. For each hyperedge, an online algorithm must assign a color (an integer). Once an input terminates, the gain of the algorithm is the number of colors that correspond to valid set covers (i.e., the union of hyperedges that have that color contains all n nodes).   We present a deterministic online algorithm that is O(log^2 n)-competitive, exponentially improving on the previous bound of O(n) and matching the performance of the best randomized algorithm by Emek et al. [ESA 2019].   For color selection, our algorithm uses a novel potential function, which can be seen as an online counterpart of the derandomization method of conditional probabilities and pessimistic estimators. There are only a few cases where derandomization has been successfully used in the field of online algorithms. In contrast to previous approaches, our result extends this tool to tackle the following new challenges: (i) the potential function derandomizes not only the Chernoff bound, but also the coupon collector's problem, (ii) the value of OPT of the maximization problem is not bounded a priori, and (iii) we do not produce a fractional solution first, but work directly on the input.","sentences":["In the online disjoint set covers problem, the edges of a hypergraph are revealed online, and the goal is to partition them into a maximum number of disjoint set covers.","That is, n nodes of a hypergraph are given at the beginning, and then a sequence of hyperedges (subsets of [n]) is presented to an algorithm.","For each hyperedge, an online algorithm must assign a color (an integer).","Once an input terminates, the gain of the algorithm is the number of colors that correspond to valid set covers (i.e., the union of hyperedges that have that color contains all n nodes).   ","We present a deterministic online algorithm that is O(log^2 n)-competitive, exponentially improving on the previous bound of O(n) and matching the performance of the best randomized algorithm by Emek et al.","[ESA 2019].   ","For color selection, our algorithm uses a novel potential function, which can be seen as an online counterpart of the derandomization method of conditional probabilities and pessimistic estimators.","There are only a few cases where derandomization has been successfully used in the field of online algorithms.","In contrast to previous approaches, our result extends this tool to tackle the following new challenges: (i) the potential function derandomizes not only the Chernoff bound, but also the coupon collector's problem, (ii) the value of OPT of the maximization problem is not bounded a priori, and (iii) we do not produce a fractional solution first, but work directly on the input."],"url":"http://arxiv.org/abs/2404.15554v1"}
{"created":"2024-04-23 22:54:51","title":"Cross-Temporal Spectrogram Autoencoder (CTSAE): Unsupervised Dimensionality Reduction for Clustering Gravitational Wave Glitches","abstract":"The advancement of The Laser Interferometer Gravitational-Wave Observatory (LIGO) has significantly enhanced the feasibility and reliability of gravitational wave detection. However, LIGO's high sensitivity makes it susceptible to transient noises known as glitches, which necessitate effective differentiation from real gravitational wave signals. Traditional approaches predominantly employ fully supervised or semi-supervised algorithms for the task of glitch classification and clustering. In the future task of identifying and classifying glitches across main and auxiliary channels, it is impractical to build a dataset with manually labeled ground-truth. In addition, the patterns of glitches can vary with time, generating new glitches without manual labels. In response to this challenge, we introduce the Cross-Temporal Spectrogram Autoencoder (CTSAE), a pioneering unsupervised method for the dimensionality reduction and clustering of gravitational wave glitches. CTSAE integrates a novel four-branch autoencoder with a hybrid of Convolutional Neural Networks (CNN) and Vision Transformers (ViT). To further extract features across multi-branches, we introduce a novel multi-branch fusion method using the CLS (Class) token. Our model, trained and evaluated on the GravitySpy O3 dataset on the main channel, demonstrates superior performance in clustering tasks when compared to state-of-the-art semi-supervised learning methods. To the best of our knowledge, CTSAE represents the first unsupervised approach tailored specifically for clustering LIGO data, marking a significant step forward in the field of gravitational wave research. The code of this paper is available at https://github.com/Zod-L/CTSAE","sentences":["The advancement of The Laser Interferometer Gravitational-Wave Observatory (LIGO) has significantly enhanced the feasibility and reliability of gravitational wave detection.","However, LIGO's high sensitivity makes it susceptible to transient noises known as glitches, which necessitate effective differentiation from real gravitational wave signals.","Traditional approaches predominantly employ fully supervised or semi-supervised algorithms for the task of glitch classification and clustering.","In the future task of identifying and classifying glitches across main and auxiliary channels, it is impractical to build a dataset with manually labeled ground-truth.","In addition, the patterns of glitches can vary with time, generating new glitches without manual labels.","In response to this challenge, we introduce the Cross-Temporal Spectrogram Autoencoder (CTSAE), a pioneering unsupervised method for the dimensionality reduction and clustering of gravitational wave glitches.","CTSAE integrates a novel four-branch autoencoder with a hybrid of Convolutional Neural Networks (CNN) and Vision Transformers (ViT).","To further extract features across multi-branches, we introduce a novel multi-branch fusion method using the CLS (Class) token.","Our model, trained and evaluated on the GravitySpy O3 dataset on the main channel, demonstrates superior performance in clustering tasks when compared to state-of-the-art semi-supervised learning methods.","To the best of our knowledge, CTSAE represents the first unsupervised approach tailored specifically for clustering LIGO data, marking a significant step forward in the field of gravitational wave research.","The code of this paper is available at https://github.com/Zod-L/CTSAE"],"url":"http://arxiv.org/abs/2404.15552v1"}
{"created":"2024-04-23 22:33:19","title":"PRISM: Patient Records Interpretation for Semantic Clinical Trial Matching using Large Language Models","abstract":"Clinical trial matching is the task of identifying trials for which patients may be potentially eligible. Typically, this task is labor-intensive and requires detailed verification of patient electronic health records (EHRs) against the stringent inclusion and exclusion criteria of clinical trials. This process is manual, time-intensive, and challenging to scale up, resulting in many patients missing out on potential therapeutic options. Recent advancements in Large Language Models (LLMs) have made automating patient-trial matching possible, as shown in multiple concurrent research studies. However, the current approaches are confined to constrained, often synthetic datasets that do not adequately mirror the complexities encountered in real-world medical data. In this study, we present the first, end-to-end large-scale empirical evaluation of clinical trial matching using real-world EHRs. Our study showcases the capability of LLMs to accurately match patients with appropriate clinical trials. We perform experiments with proprietary LLMs, including GPT-4 and GPT-3.5, as well as our custom fine-tuned model called OncoLLM and show that OncoLLM, despite its significantly smaller size, not only outperforms GPT-3.5 but also matches the performance of qualified medical doctors. All experiments were carried out on real-world EHRs that include clinical notes and available clinical trials from a single cancer center in the United States.","sentences":["Clinical trial matching is the task of identifying trials for which patients may be potentially eligible.","Typically, this task is labor-intensive and requires detailed verification of patient electronic health records (EHRs) against the stringent inclusion and exclusion criteria of clinical trials.","This process is manual, time-intensive, and challenging to scale up, resulting in many patients missing out on potential therapeutic options.","Recent advancements in Large Language Models (LLMs) have made automating patient-trial matching possible, as shown in multiple concurrent research studies.","However, the current approaches are confined to constrained, often synthetic datasets that do not adequately mirror the complexities encountered in real-world medical data.","In this study, we present the first, end-to-end large-scale empirical evaluation of clinical trial matching using real-world EHRs.","Our study showcases the capability of LLMs to accurately match patients with appropriate clinical trials.","We perform experiments with proprietary LLMs, including GPT-4 and GPT-3.5, as well as our custom fine-tuned model called OncoLLM and show that OncoLLM, despite its significantly smaller size, not only outperforms GPT-3.5 but also matches the performance of qualified medical doctors.","All experiments were carried out on real-world EHRs that include clinical notes and available clinical trials from a single cancer center in the United States."],"url":"http://arxiv.org/abs/2404.15549v1"}
{"created":"2024-04-23 21:57:14","title":"DreamCraft: Text-Guided Generation of Functional 3D Environments in Minecraft","abstract":"Procedural Content Generation (PCG) algorithms enable the automatic generation of complex and diverse artifacts. However, they don't provide high-level control over the generated content and typically require domain expertise. In contrast, text-to-3D methods allow users to specify desired characteristics in natural language, offering a high amount of flexibility and expressivity. But unlike PCG, such approaches cannot guarantee functionality, which is crucial for certain applications like game design. In this paper, we present a method for generating functional 3D artifacts from free-form text prompts in the open-world game Minecraft. Our method, DreamCraft, trains quantized Neural Radiance Fields (NeRFs) to represent artifacts that, when viewed in-game, match given text descriptions. We find that DreamCraft produces more aligned in-game artifacts than a baseline that post-processes the output of an unconstrained NeRF. Thanks to the quantized representation of the environment, functional constraints can be integrated using specialized loss terms. We show how this can be leveraged to generate 3D structures that match a target distribution or obey certain adjacency rules over the block types. DreamCraft inherits a high degree of expressivity and controllability from the NeRF, while still being able to incorporate functional constraints through domain-specific objectives.","sentences":["Procedural Content Generation (PCG) algorithms enable the automatic generation of complex and diverse artifacts.","However, they don't provide high-level control over the generated content and typically require domain expertise.","In contrast, text-to-3D methods allow users to specify desired characteristics in natural language, offering a high amount of flexibility and expressivity.","But unlike PCG, such approaches cannot guarantee functionality, which is crucial for certain applications like game design.","In this paper, we present a method for generating functional 3D artifacts from free-form text prompts in the open-world game Minecraft.","Our method, DreamCraft, trains quantized Neural Radiance Fields (NeRFs) to represent artifacts that, when viewed in-game, match given text descriptions.","We find that DreamCraft produces more aligned in-game artifacts than a baseline that post-processes the output of an unconstrained NeRF.","Thanks to the quantized representation of the environment, functional constraints can be integrated using specialized loss terms.","We show how this can be leveraged to generate 3D structures that match a target distribution or obey certain adjacency rules over the block types.","DreamCraft inherits a high degree of expressivity and controllability from the NeRF, while still being able to incorporate functional constraints through domain-specific objectives."],"url":"http://arxiv.org/abs/2404.15538v1"}
{"created":"2024-04-23 21:40:25","title":"The Ability of Virtual Reality Technologies to Improve Comprehension of Speech Therapy Device Training","abstract":"This study evaluates the usage of virtual reality (VR) technologies as a teaching tool in oral placement therapy, a subset of speech therapy. The researcher distributed instructional videos using traditional lecture and modified three-dimensional video to prompt responses. Data was gathered with a two-part Google Form: In \"Section 1: Knowledge Test\" participants were asked to determine how well they received the information displayed to them. In \"Section 2: Opinion Test\" participants were asked diagnostic and subjective questions via Likert scale ranging from 1 (\"Strongly Disagree\") to 5 (\"Strongly Agree\") to determine how well they enjoyed viewing the information displayed to them. Averages for Section 1 were 92.00% for the control group (viewing 2D, unmodified video) and 77.88% for the experimental group (viewing 3D, VR video). Almost all participants answered at least 60% of the questions correctly. Averages for 2D and 3D participants were 4.53/5 and 3.82/5, respectively for \"positive\" prompts. Exactly 50% of participants experiencing VR video preferred the method to a traditional lecture. This study determines that virtual reality is viable as a learning tool, but knowledge obtained is not necessarily as high as using traditional lecture. Further experimentation is required to determine how well oral placement therapists respond to physically interacting with a model instead of only viewing it. Copies of the Google Form used to collect responses, all raw data, and a flowchart outlining each step used to construct the 3D video can be found in the Appendix.","sentences":["This study evaluates the usage of virtual reality (VR) technologies as a teaching tool in oral placement therapy, a subset of speech therapy.","The researcher distributed instructional videos using traditional lecture and modified three-dimensional video to prompt responses.","Data was gathered with a two-part Google Form: In \"Section 1: Knowledge Test\" participants were asked to determine how well they received the information displayed to them.","In \"Section 2: Opinion Test\" participants were asked diagnostic and subjective questions via Likert scale ranging from 1 (\"Strongly Disagree\") to 5 (\"Strongly Agree\") to determine how well they enjoyed viewing the information displayed to them.","Averages for Section 1 were 92.00% for the control group (viewing 2D, unmodified video) and 77.88% for the experimental group (viewing 3D, VR video).","Almost all participants answered at least 60% of the questions correctly.","Averages for 2D and 3D participants were 4.53/5 and 3.82/5, respectively for \"positive\" prompts.","Exactly 50% of participants experiencing VR video preferred the method to a traditional lecture.","This study determines that virtual reality is viable as a learning tool, but knowledge obtained is not necessarily as high as using traditional lecture.","Further experimentation is required to determine how well oral placement therapists respond to physically interacting with a model instead of only viewing it.","Copies of the Google Form used to collect responses, all raw data, and a flowchart outlining each step used to construct the 3D video can be found in the Appendix."],"url":"http://arxiv.org/abs/2404.15534v1"}
{"created":"2024-04-23 21:37:22","title":"BattleAgent: Multi-modal Dynamic Emulation on Historical Battles to Complement Historical Analysis","abstract":"This paper presents BattleAgent, an emulation system that combines the Large Vision-Language Model and Multi-agent System. This novel system aims to simulate complex dynamic interactions among multiple agents, as well as between agents and their environments, over a period of time. It emulates both the decision-making processes of leaders and the viewpoints of ordinary participants, such as soldiers. The emulation showcases the current capabilities of agents, featuring fine-grained multi-modal interactions between agents and landscapes. It develops customizable agent structures to meet specific situational requirements, for example, a variety of battle-related activities like scouting and trench digging. These components collaborate to recreate historical events in a lively and comprehensive manner while offering insights into the thoughts and feelings of individuals from diverse viewpoints. The technological foundations of BattleAgent establish detailed and immersive settings for historical battles, enabling individual agents to partake in, observe, and dynamically respond to evolving battle scenarios. This methodology holds the potential to substantially deepen our understanding of historical events, particularly through individual accounts. Such initiatives can also aid historical research, as conventional historical narratives often lack documentation and prioritize the perspectives of decision-makers, thereby overlooking the experiences of ordinary individuals. BattelAgent illustrates AI's potential to revitalize the human aspect in crucial social events, thereby fostering a more nuanced collective understanding and driving the progressive development of human society.","sentences":["This paper presents BattleAgent, an emulation system that combines the Large Vision-Language Model and Multi-agent System.","This novel system aims to simulate complex dynamic interactions among multiple agents, as well as between agents and their environments, over a period of time.","It emulates both the decision-making processes of leaders and the viewpoints of ordinary participants, such as soldiers.","The emulation showcases the current capabilities of agents, featuring fine-grained multi-modal interactions between agents and landscapes.","It develops customizable agent structures to meet specific situational requirements, for example, a variety of battle-related activities like scouting and trench digging.","These components collaborate to recreate historical events in a lively and comprehensive manner while offering insights into the thoughts and feelings of individuals from diverse viewpoints.","The technological foundations of BattleAgent establish detailed and immersive settings for historical battles, enabling individual agents to partake in, observe, and dynamically respond to evolving battle scenarios.","This methodology holds the potential to substantially deepen our understanding of historical events, particularly through individual accounts.","Such initiatives can also aid historical research, as conventional historical narratives often lack documentation and prioritize the perspectives of decision-makers, thereby overlooking the experiences of ordinary individuals.","BattelAgent illustrates AI's potential to revitalize the human aspect in crucial social events, thereby fostering a more nuanced collective understanding and driving the progressive development of human society."],"url":"http://arxiv.org/abs/2404.15532v1"}
{"created":"2024-04-23 21:25:07","title":"Co-existing/Cooperating Multicell Massive MIMO and Cell-Free Massive MIMO Deployments: Heuristic Designs and Performance Analysis","abstract":"Cell-free massive MIMO (CF-mMIMO) represent a deeply investigated evolution from the conventional multicell co-located massive MIMO (MC-mMIMO) network deployments. Anticipating a gradual integration of CF-mMIMO systems alongside pre-existing MC-mMIMO network elements, this paper considers a scenario where both deployments coexist, in order to serve a large number of users using a shared set of frequencies. The investigation explores the impact of this coexistence on the network's downlink performance, considering various degrees of mutual cooperation, precoder selection, and power control strategies. Moreover, to take into account the effect of the proposed cooperation scenarios on the fronthaul links, this paper also provides a fronthaul-aware heuristic association algorithm between users and network elements, which permits fulfilling the fronthaul requirement on each link. The research is finally completed by extensive simulations, shedding light on the performance outcomes associated with the diverse cooperation levels and several solutions delineated in the paper.","sentences":["Cell-free massive MIMO (CF-mMIMO) represent a deeply investigated evolution from the conventional multicell co-located massive MIMO (MC-mMIMO) network deployments.","Anticipating a gradual integration of CF-mMIMO systems alongside pre-existing MC-mMIMO network elements, this paper considers a scenario where both deployments coexist, in order to serve a large number of users using a shared set of frequencies.","The investigation explores the impact of this coexistence on the network's downlink performance, considering various degrees of mutual cooperation, precoder selection, and power control strategies.","Moreover, to take into account the effect of the proposed cooperation scenarios on the fronthaul links, this paper also provides a fronthaul-aware heuristic association algorithm between users and network elements, which permits fulfilling the fronthaul requirement on each link.","The research is finally completed by extensive simulations, shedding light on the performance outcomes associated with the diverse cooperation levels and several solutions delineated in the paper."],"url":"http://arxiv.org/abs/2404.15530v1"}
{"created":"2024-04-23 21:13:17","title":"A Rapid Adapting and Continual Learning Spiking Neural Network Path Planning Algorithm for Mobile Robots","abstract":"Mapping traversal costs in an environment and planning paths based on this map are important for autonomous navigation. We present a neurobotic navigation system that utilizes a Spiking Neural Network Wavefront Planner and E-prop learning to concurrently map and plan paths in a large and complex environment. We incorporate a novel method for mapping which, when combined with the Spiking Wavefront Planner, allows for adaptive planning by selectively considering any combination of costs. The system is tested on a mobile robot platform in an outdoor environment with obstacles and varying terrain. Results indicate that the system is capable of discerning features in the environment using three measures of cost, (1) energy expenditure by the wheels, (2) time spent in the presence of obstacles, and (3) terrain slope. In just twelve hours of online training, E-prop learns and incorporates traversal costs into the path planning maps by updating the delays in the Spiking Wavefront Planner. On simulated paths, the Spiking Wavefront Planner plans significantly shorter and lower cost paths than A* and RRT*. The spiking wavefront planner is compatible with neuromorphic hardware and could be used for applications requiring low size, weight, and power.","sentences":["Mapping traversal costs in an environment and planning paths based on this map are important for autonomous navigation.","We present a neurobotic navigation system that utilizes a Spiking Neural Network Wavefront Planner and E-prop learning to concurrently map and plan paths in a large and complex environment.","We incorporate a novel method for mapping which, when combined with the Spiking Wavefront Planner, allows for adaptive planning by selectively considering any combination of costs.","The system is tested on a mobile robot platform in an outdoor environment with obstacles and varying terrain.","Results indicate that the system is capable of discerning features in the environment using three measures of cost, (1) energy expenditure by the wheels, (2) time spent in the presence of obstacles, and (3) terrain slope.","In just twelve hours of online training, E-prop learns and incorporates traversal costs into the path planning maps by updating the delays in the Spiking Wavefront Planner.","On simulated paths, the Spiking Wavefront Planner plans significantly shorter and lower cost paths than A* and RRT*.","The spiking wavefront planner is compatible with neuromorphic hardware and could be used for applications requiring low size, weight, and power."],"url":"http://arxiv.org/abs/2404.15524v1"}
{"created":"2024-04-23 21:11:30","title":"Understanding Hyperbolic Metric Learning through Hard Negative Sampling","abstract":"In recent years, there has been a growing trend of incorporating hyperbolic geometry methods into computer vision. While these methods have achieved state-of-the-art performance on various metric learning tasks using hyperbolic distance measurements, the underlying theoretical analysis supporting this superior performance remains under-exploited. In this study, we investigate the effects of integrating hyperbolic space into metric learning, particularly when training with contrastive loss. We identify a need for a comprehensive comparison between Euclidean and hyperbolic spaces regarding the temperature effect in the contrastive loss within the existing literature. To address this gap, we conduct an extensive investigation to benchmark the results of Vision Transformers (ViTs) using a hybrid objective function that combines loss from Euclidean and hyperbolic spaces. Additionally, we provide a theoretical analysis of the observed performance improvement. We also reveal that hyperbolic metric learning is highly related to hard negative sampling, providing insights for future work. This work will provide valuable data points and experience in understanding hyperbolic image embeddings. To shed more light on problem-solving and encourage further investigation into our approach, our code is available online (https://github.com/YunYunY/HypMix).","sentences":["In recent years, there has been a growing trend of incorporating hyperbolic geometry methods into computer vision.","While these methods have achieved state-of-the-art performance on various metric learning tasks using hyperbolic distance measurements, the underlying theoretical analysis supporting this superior performance remains under-exploited.","In this study, we investigate the effects of integrating hyperbolic space into metric learning, particularly when training with contrastive loss.","We identify a need for a comprehensive comparison between Euclidean and hyperbolic spaces regarding the temperature effect in the contrastive loss within the existing literature.","To address this gap, we conduct an extensive investigation to benchmark the results of Vision Transformers (ViTs) using a hybrid objective function that combines loss from Euclidean and hyperbolic spaces.","Additionally, we provide a theoretical analysis of the observed performance improvement.","We also reveal that hyperbolic metric learning is highly related to hard negative sampling, providing insights for future work.","This work will provide valuable data points and experience in understanding hyperbolic image embeddings.","To shed more light on problem-solving and encourage further investigation into our approach, our code is available online (https://github.com/YunYunY/HypMix)."],"url":"http://arxiv.org/abs/2404.15523v1"}
{"created":"2024-04-23 21:08:49","title":"Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models","abstract":"Recently developed large language models (LLMs) have been shown to perform remarkably well on a wide range of language understanding tasks. But, can they really \"reason\" over the natural language? This question has been receiving significant research attention and many reasoning skills such as commonsense, numerical, and qualitative have been studied. However, the crucial skill pertaining to 'logical reasoning' has remained underexplored. Existing work investigating this reasoning ability of LLMs has focused only on a couple of inference rules (such as modus ponens and modus tollens) of propositional and first-order logic. Addressing the above limitation, we comprehensively evaluate the logical reasoning ability of LLMs on 25 different reasoning patterns spanning over propositional, first-order, and non-monotonic logics. To enable systematic evaluation, we introduce LogicBench, a natural language question-answering dataset focusing on the use of a single inference rule. We conduct detailed analysis with a range of LLMs such as GPT-4, ChatGPT, Gemini, Llama-2, and Mistral using chain-of-thought prompting. Experimental results show that existing LLMs do not fare well on LogicBench; especially, they struggle with instances involving complex reasoning and negations. Furthermore, they sometimes overlook contextual information necessary for reasoning to arrive at the correct conclusion. We believe that our work and findings facilitate future research for evaluating and enhancing the logical reasoning ability of LLMs. Data and code are available at https://github.com/Mihir3009/LogicBench.","sentences":["Recently developed large language models (LLMs) have been shown to perform remarkably well on a wide range of language understanding tasks.","But, can they really \"reason\" over the natural language?","This question has been receiving significant research attention and many reasoning skills such as commonsense, numerical, and qualitative have been studied.","However, the crucial skill pertaining to 'logical reasoning' has remained underexplored.","Existing work investigating this reasoning ability of LLMs has focused only on a couple of inference rules (such as modus ponens and modus tollens) of propositional and first-order logic.","Addressing the above limitation, we comprehensively evaluate the logical reasoning ability of LLMs on 25 different reasoning patterns spanning over propositional, first-order, and non-monotonic logics.","To enable systematic evaluation, we introduce LogicBench, a natural language question-answering dataset focusing on the use of a single inference rule.","We conduct detailed analysis with a range of LLMs such as GPT-4, ChatGPT, Gemini, Llama-2, and Mistral using chain-of-thought prompting.","Experimental results show that existing LLMs do not fare well on LogicBench; especially, they struggle with instances involving complex reasoning and negations.","Furthermore, they sometimes overlook contextual information necessary for reasoning to arrive at the correct conclusion.","We believe that our work and findings facilitate future research for evaluating and enhancing the logical reasoning ability of LLMs.","Data and code are available at https://github.com/Mihir3009/LogicBench."],"url":"http://arxiv.org/abs/2404.15522v1"}
{"created":"2024-04-23 21:02:58","title":"An MRP Formulation for Supervised Learning: Generalized Temporal Difference Learning Models","abstract":"In traditional statistical learning, data points are usually assumed to be independently and identically distributed (i.i.d.) following an unknown probability distribution. This paper presents a contrasting viewpoint, perceiving data points as interconnected and employing a Markov reward process (MRP) for data modeling. We reformulate the typical supervised learning as an on-policy policy evaluation problem within reinforcement learning (RL), introducing a generalized temporal difference (TD) learning algorithm as a resolution. Theoretically, our analysis draws connections between the solutions of linear TD learning and ordinary least squares (OLS). We also show that under specific conditions, particularly when noises are correlated, the TD's solution proves to be a more effective estimator than OLS. Furthermore, we establish the convergence of our generalized TD algorithms under linear function approximation. Empirical studies verify our theoretical results, examine the vital design of our TD algorithm and show practical utility across various datasets, encompassing tasks such as regression and image classification with deep learning.","sentences":["In traditional statistical learning, data points are usually assumed to be independently and identically distributed (i.i.d.)","following an unknown probability distribution.","This paper presents a contrasting viewpoint, perceiving data points as interconnected and employing a Markov reward process (MRP) for data modeling.","We reformulate the typical supervised learning as an on-policy policy evaluation problem within reinforcement learning (RL), introducing a generalized temporal difference (TD) learning algorithm as a resolution.","Theoretically, our analysis draws connections between the solutions of linear TD learning and ordinary least squares (OLS).","We also show that under specific conditions, particularly when noises are correlated, the TD's solution proves to be a more effective estimator than OLS.","Furthermore, we establish the convergence of our generalized TD algorithms under linear function approximation.","Empirical studies verify our theoretical results, examine the vital design of our TD algorithm and show practical utility across various datasets, encompassing tasks such as regression and image classification with deep learning."],"url":"http://arxiv.org/abs/2404.15518v1"}
{"created":"2024-04-23 21:00:22","title":"Visual Delta Generator with Large Multi-modal Models for Semi-supervised Composed Image Retrieval","abstract":"Composed Image Retrieval (CIR) is a task that retrieves images similar to a query, based on a provided textual modification. Current techniques rely on supervised learning for CIR models using labeled triplets of the reference image, text, target image. These specific triplets are not as commonly available as simple image-text pairs, limiting the widespread use of CIR and its scalability. On the other hand, zero-shot CIR can be relatively easily trained with image-caption pairs without considering the image-to-image relation, but this approach tends to yield lower accuracy. We propose a new semi-supervised CIR approach where we search for a reference and its related target images in auxiliary data and learn our large language model-based Visual Delta Generator (VDG) to generate text describing the visual difference (i.e., visual delta) between the two. VDG, equipped with fluent language knowledge and being model agnostic, can generate pseudo triplets to boost the performance of CIR models. Our approach significantly improves the existing supervised learning approaches and achieves state-of-the-art results on the CIR benchmarks.","sentences":["Composed Image Retrieval (CIR) is a task that retrieves images similar to a query, based on a provided textual modification.","Current techniques rely on supervised learning for CIR models using labeled triplets of the reference image, text, target image.","These specific triplets are not as commonly available as simple image-text pairs, limiting the widespread use of CIR and its scalability.","On the other hand, zero-shot CIR can be relatively easily trained with image-caption pairs without considering the image-to-image relation, but this approach tends to yield lower accuracy.","We propose a new semi-supervised CIR approach where we search for a reference and its related target images in auxiliary data and learn our large language model-based Visual Delta Generator (VDG) to generate text describing the visual difference (i.e., visual delta) between the two.","VDG, equipped with fluent language knowledge and being model agnostic, can generate pseudo triplets to boost the performance of CIR models.","Our approach significantly improves the existing supervised learning approaches and achieves state-of-the-art results on the CIR benchmarks."],"url":"http://arxiv.org/abs/2404.15516v1"}
{"created":"2024-04-23 20:59:03","title":"ToM-LM: Delegating Theory Of Mind Reasoning to External Symbolic Executors in Large Language Models","abstract":"Theory of Mind (ToM) refers to the ability of individuals to attribute mental states to others. While Large Language Models (LLMs) have shown some promise with ToM ability, they still struggle with complex ToM reasoning. Our approach leverages an external symbolic executor, specifically the SMCDEL model checker, and fine-tuning to improve the ToM reasoning ability of LLMs. In our approach, an LLM is first fine-tuned through pairs of natural language and symbolic formulation representation of ToM problems and is then instructed to generate the symbolic formulation with a one-shot in-context example. The generated symbolic formulation is then executed by the SMCDEL model checker to perform transparent and verifiable ToM reasoning and give the final result. We demonstrate that our approach, ToM-LM, shows a significant improvement over all the constructed baselines. Our study proposes a novel view about externalizing a particular component of ToM reasoning, mainly reasoning about beliefs, and suggests generalizing it to other aspects of ToM reasoning.","sentences":["Theory of Mind (ToM) refers to the ability of individuals to attribute mental states to others.","While Large Language Models (LLMs) have shown some promise with ToM ability, they still struggle with complex ToM reasoning.","Our approach leverages an external symbolic executor, specifically the SMCDEL model checker, and fine-tuning to improve the ToM reasoning ability of LLMs.","In our approach, an LLM is first fine-tuned through pairs of natural language and symbolic formulation representation of ToM problems and is then instructed to generate the symbolic formulation with a one-shot in-context example.","The generated symbolic formulation is then executed by the SMCDEL model checker to perform transparent and verifiable ToM reasoning and give the final result.","We demonstrate that our approach, ToM-LM, shows a significant improvement over all the constructed baselines.","Our study proposes a novel view about externalizing a particular component of ToM reasoning, mainly reasoning about beliefs, and suggests generalizing it to other aspects of ToM reasoning."],"url":"http://arxiv.org/abs/2404.15515v1"}
{"created":"2024-04-23 20:51:09","title":"NeuraChip: Accelerating GNN Computations with a Hash-based Decoupled Spatial Accelerator","abstract":"Graph Neural Networks (GNNs) are emerging as a formidable tool for processing non-euclidean data across various domains, ranging from social network analysis to bioinformatics. Despite their effectiveness, their adoption has not been pervasive because of scalability challenges associated with large-scale graph datasets, particularly when leveraging message passing.   To tackle these challenges, we introduce NeuraChip, a novel GNN spatial accelerator based on Gustavson's algorithm. NeuraChip decouples the multiplication and addition computations in sparse matrix multiplication. This separation allows for independent exploitation of their unique data dependencies, facilitating efficient resource allocation. We introduce a rolling eviction strategy to mitigate data idling in on-chip memory as well as address the prevalent issue of memory bloat in sparse graph computations. Furthermore, the compute resource load balancing is achieved through a dynamic reseeding hash-based mapping, ensuring uniform utilization of computing resources agnostic of sparsity patterns. Finally, we present NeuraSim, an open-source, cycle-accurate, multi-threaded, modular simulator for comprehensive performance analysis.   Overall, NeuraChip presents a significant improvement, yielding an average speedup of 22.1x over Intel's MKL, 17.1x over NVIDIA's cuSPARSE, 16.7x over AMD's hipSPARSE, and 1.5x over prior state-of-the-art SpGEMM accelerator and 1.3x over GNN accelerator. The source code for our open-sourced simulator and performance visualizer is publicly accessible on GitHub https://neurachip.us","sentences":["Graph Neural Networks (GNNs) are emerging as a formidable tool for processing non-euclidean data across various domains, ranging from social network analysis to bioinformatics.","Despite their effectiveness, their adoption has not been pervasive because of scalability challenges associated with large-scale graph datasets, particularly when leveraging message passing.   ","To tackle these challenges, we introduce NeuraChip, a novel GNN spatial accelerator based on Gustavson's algorithm.","NeuraChip decouples the multiplication and addition computations in sparse matrix multiplication.","This separation allows for independent exploitation of their unique data dependencies, facilitating efficient resource allocation.","We introduce a rolling eviction strategy to mitigate data idling in on-chip memory as well as address the prevalent issue of memory bloat in sparse graph computations.","Furthermore, the compute resource load balancing is achieved through a dynamic reseeding hash-based mapping, ensuring uniform utilization of computing resources agnostic of sparsity patterns.","Finally, we present NeuraSim, an open-source, cycle-accurate, multi-threaded, modular simulator for comprehensive performance analysis.   ","Overall, NeuraChip presents a significant improvement, yielding an average speedup of 22.1x over Intel's MKL, 17.1x over NVIDIA's cuSPARSE, 16.7x over AMD's hipSPARSE, and 1.5x over prior state-of-the-art SpGEMM accelerator and 1.3x over GNN accelerator.","The source code for our open-sourced simulator and performance visualizer is publicly accessible on GitHub https://neurachip.us"],"url":"http://arxiv.org/abs/2404.15510v1"}
{"created":"2024-04-23 20:49:05","title":"SMI-5: Five Dimensions of Social Media Interaction for Platform (De)Centralization","abstract":"Web 3.0 focuses on the decentralization of the internet and creating a system of interconnected and independent computers for improved privacy and security. We extend the idea of the decentralization of the web to the social media space: whereby we ask: in the context of the social media space, what does \"decentralization\" mean? Does decentralization of social media affect user interactions? We put forth the notion that decentralization in the social media does not solely take place on the physical network level, but can be compartmentalized across the entire social media stack. This paper puts forth SMI-5: the five dimensions of social media interaction for describing the (de)centralization of social platforms. We then illustrate a case study that the user interactions differ based on the slices of the SMI layer analyzed, highlighting the importance of understanding the (de)centralization of social media platforms from an a more encompassing perspective rather than only the physical network.","sentences":["Web 3.0 focuses on the decentralization of the internet and creating a system of interconnected and independent computers for improved privacy and security.","We extend the idea of the decentralization of the web to the social media space: whereby we ask: in the context of the social media space, what does \"decentralization\" mean?","Does decentralization of social media affect user interactions?","We put forth the notion that decentralization in the social media does not solely take place on the physical network level, but can be compartmentalized across the entire social media stack.","This paper puts forth SMI-5: the five dimensions of social media interaction for describing the (de)centralization of social platforms.","We then illustrate a case study that the user interactions differ based on the slices of the SMI layer analyzed, highlighting the importance of understanding the (de)centralization of social media platforms from an a more encompassing perspective rather than only the physical network."],"url":"http://arxiv.org/abs/2404.15509v1"}
{"created":"2024-04-23 20:37:26","title":"FedGreen: Carbon-aware Federated Learning with Model Size Adaptation","abstract":"Federated learning (FL) provides a promising collaborative framework to build a model from distributed clients, and this work investigates the carbon emission of the FL process. Cloud and edge servers hosting FL clients may exhibit diverse carbon footprints influenced by their geographical locations with varying power sources, offering opportunities to reduce carbon emissions by training local models with adaptive computations and communications. In this paper, we propose FedGreen, a carbon-aware FL approach to efficiently train models by adopting adaptive model sizes shared with clients based on their carbon profiles and locations using ordered dropout as a model compression technique. We theoretically analyze the trade-offs between the produced carbon emissions and the convergence accuracy, considering the carbon intensity discrepancy across countries to choose the parameters optimally. Empirical studies show that FedGreen can substantially reduce the carbon footprints of FL compared to the state-of-the-art while maintaining competitive model accuracy.","sentences":["Federated learning (FL) provides a promising collaborative framework to build a model from distributed clients, and this work investigates the carbon emission of the FL process.","Cloud and edge servers hosting FL clients may exhibit diverse carbon footprints influenced by their geographical locations with varying power sources, offering opportunities to reduce carbon emissions by training local models with adaptive computations and communications.","In this paper, we propose FedGreen, a carbon-aware FL approach to efficiently train models by adopting adaptive model sizes shared with clients based on their carbon profiles and locations using ordered dropout as a model compression technique.","We theoretically analyze the trade-offs between the produced carbon emissions and the convergence accuracy, considering the carbon intensity discrepancy across countries to choose the parameters optimally.","Empirical studies show that FedGreen can substantially reduce the carbon footprints of FL compared to the state-of-the-art while maintaining competitive model accuracy."],"url":"http://arxiv.org/abs/2404.15503v1"}
{"created":"2024-04-23 20:26:07","title":"Killkan: The Automatic Speech Recognition Dataset for Kichwa with Morphosyntactic Information","abstract":"This paper presents Killkan, the first dataset for automatic speech recognition (ASR) in the Kichwa language, an indigenous language of Ecuador. Kichwa is an extremely low-resource endangered language, and there have been no resources before Killkan for Kichwa to be incorporated in applications of natural language processing. The dataset contains approximately 4 hours of audio with transcription, translation into Spanish, and morphosyntactic annotation in the format of Universal Dependencies. The audio data was retrieved from a publicly available radio program in Kichwa. This paper also provides corpus-linguistic analyses of the dataset with a special focus on the agglutinative morphology of Kichwa and frequent code-switching with Spanish. The experiments show that the dataset makes it possible to develop the first ASR system for Kichwa with reliable quality despite its small dataset size. This dataset, the ASR model, and the code used to develop them will be publicly available. Thus, our study positively showcases resource building and its applications for low-resource languages and their community.","sentences":["This paper presents Killkan, the first dataset for automatic speech recognition (ASR) in the Kichwa language, an indigenous language of Ecuador.","Kichwa is an extremely low-resource endangered language, and there have been no resources before Killkan for Kichwa to be incorporated in applications of natural language processing.","The dataset contains approximately 4 hours of audio with transcription, translation into Spanish, and morphosyntactic annotation in the format of Universal Dependencies.","The audio data was retrieved from a publicly available radio program in Kichwa.","This paper also provides corpus-linguistic analyses of the dataset with a special focus on the agglutinative morphology of Kichwa and frequent code-switching with Spanish.","The experiments show that the dataset makes it possible to develop the first ASR system for Kichwa with reliable quality despite its small dataset size.","This dataset, the ASR model, and the code used to develop them will be publicly available.","Thus, our study positively showcases resource building and its applications for low-resource languages and their community."],"url":"http://arxiv.org/abs/2404.15501v1"}
{"created":"2024-04-23 20:23:37","title":"GeoLLM-Engine: A Realistic Environment for Building Geospatial Copilots","abstract":"Geospatial Copilots unlock unprecedented potential for performing Earth Observation (EO) applications through natural language instructions. However, existing agents rely on overly simplified single tasks and template-based prompts, creating a disconnect with real-world scenarios. In this work, we present GeoLLM-Engine, an environment for tool-augmented agents with intricate tasks routinely executed by analysts on remote sensing platforms. We enrich our environment with geospatial API tools, dynamic maps/UIs, and external multimodal knowledge bases to properly gauge an agent's proficiency in interpreting realistic high-level natural language commands and its functional correctness in task completions. By alleviating overheads typically associated with human-in-the-loop benchmark curation, we harness our massively parallel engine across 100 GPT-4-Turbo nodes, scaling to over half a million diverse multi-tool tasks and across 1.1 million satellite images. By moving beyond traditional single-task image-caption paradigms, we investigate state-of-the-art agents and prompting techniques against long-horizon prompts.","sentences":["Geospatial Copilots unlock unprecedented potential for performing Earth Observation (EO) applications through natural language instructions.","However, existing agents rely on overly simplified single tasks and template-based prompts, creating a disconnect with real-world scenarios.","In this work, we present GeoLLM-Engine, an environment for tool-augmented agents with intricate tasks routinely executed by analysts on remote sensing platforms.","We enrich our environment with geospatial API tools, dynamic maps/UIs, and external multimodal knowledge bases to properly gauge an agent's proficiency in interpreting realistic high-level natural language commands and its functional correctness in task completions.","By alleviating overheads typically associated with human-in-the-loop benchmark curation, we harness our massively parallel engine across 100 GPT-4-Turbo nodes, scaling to over half a million diverse multi-tool tasks and across 1.1 million satellite images.","By moving beyond traditional single-task image-caption paradigms, we investigate state-of-the-art agents and prompting techniques against long-horizon prompts."],"url":"http://arxiv.org/abs/2404.15500v1"}
{"created":"2024-04-23 20:20:27","title":"Drop-Connect as a Fault-Tolerance Approach for RRAM-based Deep Neural Network Accelerators","abstract":"Resistive random-access memory (RRAM) is widely recognized as a promising emerging hardware platform for deep neural networks (DNNs). Yet, due to manufacturing limitations, current RRAM devices are highly susceptible to hardware defects, which poses a significant challenge to their practical applicability. In this paper, we present a machine learning technique that enables the deployment of defect-prone RRAM accelerators for DNN applications, without necessitating modifying the hardware, retraining of the neural network, or implementing additional detection circuitry/logic. The key idea involves incorporating a drop-connect inspired approach during the training phase of a DNN, where random subsets of weights are selected to emulate fault effects (e.g., set to zero to mimic stuck-at-1 faults), thereby equipping the DNN with the ability to learn and adapt to RRAM defects with the corresponding fault rates. Our results demonstrate the viability of the drop-connect approach, coupled with various algorithm and system-level design and trade-off considerations. We show that, even in the presence of high defect rates (e.g., up to 30%), the degradation of DNN accuracy can be as low as less than 1% compared to that of the fault-free version, while incurring minimal system-level runtime/energy costs.","sentences":["Resistive random-access memory (RRAM) is widely recognized as a promising emerging hardware platform for deep neural networks (DNNs).","Yet, due to manufacturing limitations, current RRAM devices are highly susceptible to hardware defects, which poses a significant challenge to their practical applicability.","In this paper, we present a machine learning technique that enables the deployment of defect-prone RRAM accelerators for DNN applications, without necessitating modifying the hardware, retraining of the neural network, or implementing additional detection circuitry/logic.","The key idea involves incorporating a drop-connect inspired approach during the training phase of a DNN, where random subsets of weights are selected to emulate fault effects (e.g., set to zero to mimic stuck-at-1 faults), thereby equipping the DNN with the ability to learn and adapt to RRAM defects with the corresponding fault rates.","Our results demonstrate the viability of the drop-connect approach, coupled with various algorithm and system-level design and trade-off considerations.","We show that, even in the presence of high defect rates (e.g., up to 30%), the degradation of DNN accuracy can be as low as less than 1% compared to that of the fault-free version, while incurring minimal system-level runtime/energy costs."],"url":"http://arxiv.org/abs/2404.15498v1"}
{"created":"2024-04-23 20:19:17","title":"The Algebras for Automatic Relations","abstract":"We introduce \"synchronous algebras\", an algebraic structure tailored to recognize automatic relations (a.k.a. synchronous relations, or regular relations). They are the equivalent of monoids for regular languages, however they conceptually differ in two points: first, they are typed and second, they are equipped with a dependency relation expressing constraints between elements of different types.   We first show that the three pillars of algebraic language theory hold for synchronous algebras: (a) any relation admits a syntactic synchronous algebra recognizing it, and moreover, the relation is synchronous if, and only if, its minimal algebra is finite; (b) classes of synchronous relations with desirable closure properties (called \"pseudovarieties\") correspond to pseudovarieties of synchronous algebras; and (c) pseudovarieties of synchronous algebras are exactly the classes of synchronous algebras defined by a generalization of profinite equations called \"profinite dependencies\".   Building on these results, we show how algebraic characterizations of pseudovarieties of regular languages can be lifted to the pseudovarieties of synchronous relations that they induce. A typical (and running) example of such a pseudovariety is the class of \"group relations\", defined as the relations recognized by finite-state synchronous permutation automata.","sentences":["We introduce \"synchronous algebras\", an algebraic structure tailored to recognize automatic relations (a.k.a. synchronous relations, or regular relations).","They are the equivalent of monoids for regular languages, however they conceptually differ in two points: first, they are typed and second, they are equipped with a dependency relation expressing constraints between elements of different types.   ","We first show that the three pillars of algebraic language theory hold for synchronous algebras: (a) any relation admits a syntactic synchronous algebra recognizing it, and moreover, the relation is synchronous if, and only if, its minimal algebra is finite; (b) classes of synchronous relations with desirable closure properties (called \"pseudovarieties\") correspond to pseudovarieties of synchronous algebras; and (c) pseudovarieties of synchronous algebras are exactly the classes of synchronous algebras defined by a generalization of profinite equations called \"profinite dependencies\".   ","Building on these results, we show how algebraic characterizations of pseudovarieties of regular languages can be lifted to the pseudovarieties of synchronous relations that they induce.","A typical (and running) example of such a pseudovariety is the class of \"group relations\", defined as the relations recognized by finite-state synchronous permutation automata."],"url":"http://arxiv.org/abs/2404.15496v1"}
{"created":"2024-04-23 20:06:56","title":"Multi-scale Intervention Planning based on Generative Design","abstract":"The scarcity of green spaces, in urban environments, consists a critical challenge. There are multiple adverse effects, impacting the health and well-being of the citizens. Small scale interventions, e.g. pocket parks, is a viable solution, but comes with multiple constraints, involving the design and implementation over a specific area. In this study, we harness the capabilities of generative AI for multi-scale intervention planning, focusing on nature based solutions. By leveraging image-to-image and image inpainting algorithms, we propose a methodology to address the green space deficit in urban areas. Focusing on two alleys in Thessaloniki, where greenery is lacking, we demonstrate the efficacy of our approach in visualizing NBS interventions. Our findings underscore the transformative potential of emerging technologies in shaping the future of urban intervention planning processes.","sentences":["The scarcity of green spaces, in urban environments, consists a critical challenge.","There are multiple adverse effects, impacting the health and well-being of the citizens.","Small scale interventions, e.g. pocket parks, is a viable solution, but comes with multiple constraints, involving the design and implementation over a specific area.","In this study, we harness the capabilities of generative AI for multi-scale intervention planning, focusing on nature based solutions.","By leveraging image-to-image and image inpainting algorithms, we propose a methodology to address the green space deficit in urban areas.","Focusing on two alleys in Thessaloniki, where greenery is lacking, we demonstrate the efficacy of our approach in visualizing NBS interventions.","Our findings underscore the transformative potential of emerging technologies in shaping the future of urban intervention planning processes."],"url":"http://arxiv.org/abs/2404.15492v1"}
{"created":"2024-04-23 20:00:37","title":"IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents","abstract":"In natural language processing applied to the clinical domain, utilizing large language models has emerged as a promising avenue for error detection and correction on clinical notes, a knowledge-intensive task for which annotated data is scarce. This paper presents MedReAct'N'MedReFlex, which leverages a suite of four LLM-based medical agents. The MedReAct agent initiates the process by observing, analyzing, and taking action, generating trajectories to guide the search to target a potential error in the clinical notes. Subsequently, the MedEval agent employs five evaluators to assess the targeted error and the proposed correction. In cases where MedReAct's actions prove insufficient, the MedReFlex agent intervenes, engaging in reflective analysis and proposing alternative strategies. Finally, the MedFinalParser agent formats the final output, preserving the original style while ensuring the integrity of the error correction process. One core component of our method is our RAG pipeline based on our ClinicalCorp corpora. Among other well-known sources containing clinical guidelines and information, we preprocess and release the open-source MedWiki dataset for clinical RAG application. Our results demonstrate the central role of our RAG approach with ClinicalCorp leveraged through the MedReAct'N'MedReFlex framework. It achieved the ninth rank on the MEDIQA-CORR 2024 final leaderboard.","sentences":["In natural language processing applied to the clinical domain, utilizing large language models has emerged as a promising avenue for error detection and correction on clinical notes, a knowledge-intensive task for which annotated data is scarce.","This paper presents MedReAct'N'MedReFlex, which leverages a suite of four LLM-based medical agents.","The MedReAct agent initiates the process by observing, analyzing, and taking action, generating trajectories to guide the search to target a potential error in the clinical notes.","Subsequently, the MedEval agent employs five evaluators to assess the targeted error and the proposed correction.","In cases where MedReAct's actions prove insufficient, the MedReFlex agent intervenes, engaging in reflective analysis and proposing alternative strategies.","Finally, the MedFinalParser agent formats the final output, preserving the original style while ensuring the integrity of the error correction process.","One core component of our method is our RAG pipeline based on our ClinicalCorp corpora.","Among other well-known sources containing clinical guidelines and information, we preprocess and release the open-source MedWiki dataset for clinical RAG application.","Our results demonstrate the central role of our RAG approach with ClinicalCorp leveraged through the MedReAct'N'MedReFlex framework.","It achieved the ninth rank on the MEDIQA-CORR 2024 final leaderboard."],"url":"http://arxiv.org/abs/2404.15488v1"}
{"created":"2024-04-23 19:59:03","title":"Minimum Consistent Subset in Trees and Interval Graphs","abstract":"In the Minimum Consistent Subset (MCS) problem, we are presented with a connected simple undirected graph $G=(V,E)$, consisting of a vertex set $V$ of size $n$ and an edge set $E$. Each vertex in $V$ is assigned a color from the set $\\{1,2,\\ldots, c\\}$. The objective is to determine a subset $V' \\subseteq V$ with minimum possible cardinality, such that for every vertex $v \\in V$, at least one of its nearest neighbors in $V'$ (measured in terms of the hop distance) shares the same color as $v$. The decision problem, indicating whether there exists a subset $V'$ of cardinality at most $l$ for some positive integer $l$, is known to be NP-complete even for planar graphs.   In this paper, we establish that the MCS problem for trees, when the number of colors $c$ is considered an input parameter, is NP-complete. We propose a fixed-parameter tractable (FPT) algorithm for MCS on trees running in $O(2^{6c}n^6)$ time, significantly improving the currently best-known algorithm whose running time is $O(2^{4c}n^{2c+3})$.   In an effort to comprehensively understand the computational complexity of the MCS problem across different graph classes, we extend our investigation to interval graphs. We show that it remains NP-complete for interval graphs, thus enriching graph classes where MCS remains intractable.","sentences":["In the Minimum Consistent Subset (MCS) problem, we are presented with a connected simple undirected graph $G=(V,E)$, consisting of a vertex set $V$ of size $n$ and an edge set $E$. Each vertex in $V$ is assigned a color from the set $\\{1,2,\\ldots, c\\}$. The objective is to determine a subset $V' \\subseteq V$ with minimum possible cardinality, such that for every vertex $v \\in V$, at least one of its nearest neighbors in $V'$ (measured in terms of the hop distance) shares the same color as $v$. The decision problem, indicating whether there exists a subset $V'$ of cardinality at most $l$ for some positive integer $l$, is known to be NP-complete even for planar graphs.   ","In this paper, we establish that the MCS problem for trees, when the number of colors $c$ is considered an input parameter, is NP-complete.","We propose a fixed-parameter tractable (FPT) algorithm for MCS on trees running in $O(2^{6c}n^6)$ time, significantly improving the currently best-known algorithm whose running time is $O(2^{4c}n^{2c+3})$.   In an effort to comprehensively understand the computational complexity of the MCS problem across different graph classes, we extend our investigation to interval graphs.","We show that it remains NP-complete for interval graphs, thus enriching graph classes where MCS remains intractable."],"url":"http://arxiv.org/abs/2404.15487v1"}
{"created":"2024-04-23 19:55:18","title":"Large Language Models Spot Phishing Emails with Surprising Accuracy: A Comparative Analysis of Performance","abstract":"Phishing, a prevalent cybercrime tactic for decades, remains a significant threat in today's digital world. By leveraging clever social engineering elements and modern technology, cybercrime targets many individuals, businesses, and organizations to exploit trust and security. These cyber-attackers are often disguised in many trustworthy forms to appear as legitimate sources. By cleverly using psychological elements like urgency, fear, social proof, and other manipulative strategies, phishers can lure individuals into revealing sensitive and personalized information. Building on this pervasive issue within modern technology, this paper aims to analyze the effectiveness of 15 Large Language Models (LLMs) in detecting phishing attempts, specifically focusing on a randomized set of \"419 Scam\" emails. The objective is to determine which LLMs can accurately detect phishing emails by analyzing a text file containing email metadata based on predefined criteria. The experiment concluded that the following models, ChatGPT 3.5, GPT-3.5-Turbo-Instruct, and ChatGPT, were the most effective in detecting phishing emails.","sentences":["Phishing, a prevalent cybercrime tactic for decades, remains a significant threat in today's digital world.","By leveraging clever social engineering elements and modern technology, cybercrime targets many individuals, businesses, and organizations to exploit trust and security.","These cyber-attackers are often disguised in many trustworthy forms to appear as legitimate sources.","By cleverly using psychological elements like urgency, fear, social proof, and other manipulative strategies, phishers can lure individuals into revealing sensitive and personalized information.","Building on this pervasive issue within modern technology, this paper aims to analyze the effectiveness of 15 Large Language Models (LLMs) in detecting phishing attempts, specifically focusing on a randomized set of \"419 Scam\" emails.","The objective is to determine which LLMs can accurately detect phishing emails by analyzing a text file containing email metadata based on predefined criteria.","The experiment concluded that the following models, ChatGPT 3.5, GPT-3.5-Turbo-Instruct, and ChatGPT, were the most effective in detecting phishing emails."],"url":"http://arxiv.org/abs/2404.15485v1"}
{"created":"2024-04-23 19:49:50","title":"Strategy Complexity of B\u00fcchi Objectives in Concurrent Stochastic Games","abstract":"We study 2-player concurrent stochastic B\\\"uchi games on countable graphs. Two players, Max and Min, seek respectively to maximize and minimize the probability of visiting a set of target states infinitely often. We show that there always exist $\\varepsilon$-optimal Max strategies that use just a step counter plus 1 bit of public memory. This upper bound holds for all countable graphs, but it is a new result even for the special case of finite graphs. The upper bound is tight in the sense that Max strategies that use just a step counter, or just finite memory, are not sufficient even on finite game graphs.   The upper bound is a consequence of a slightly stronger new result: $\\varepsilon$-optimal Max strategies for the combined B\\\"uchi and Transience objective require just 1 bit of public memory (but cannot be memoryless). Our proof techniques also yield a closely related result, that $\\varepsilon$-optimal Max strategies for the Transience objective alone (which is only meaningful in infinite graphs) can be memoryless.","sentences":["We study 2-player concurrent stochastic B\\\"uchi games on countable graphs.","Two players, Max and Min, seek respectively to maximize and minimize the probability of visiting a set of target states infinitely often.","We show that there always exist $\\varepsilon$-optimal Max strategies that use just a step counter plus 1 bit of public memory.","This upper bound holds for all countable graphs, but it is a new result even for the special case of finite graphs.","The upper bound is tight in the sense that Max strategies that use just a step counter, or just finite memory, are not sufficient even on finite game graphs.   ","The upper bound is a consequence of a slightly stronger new result: $\\varepsilon$-optimal Max strategies for the combined B\\\"uchi and Transience objective require just 1 bit of public memory (but cannot be memoryless).","Our proof techniques also yield a closely related result, that $\\varepsilon$-optimal Max strategies for the Transience objective alone (which is only meaningful in infinite graphs) can be memoryless."],"url":"http://arxiv.org/abs/2404.15483v1"}
{"created":"2024-04-23 19:26:28","title":"An Annotated Glossary for Data Commons, Data Meshes, and Other Data Platforms","abstract":"Cloud-based data commons, data meshes, data hubs, and other data platforms are important ways to manage, analyze and share data to accelerate research and to support reproducible research. This is an annotated glossary of some of the more common terms used in articles and discussions about these platforms.","sentences":["Cloud-based data commons, data meshes, data hubs, and other data platforms are important ways to manage, analyze and share data to accelerate research and to support reproducible research.","This is an annotated glossary of some of the more common terms used in articles and discussions about these platforms."],"url":"http://arxiv.org/abs/2404.15475v1"}
{"created":"2024-04-23 19:21:08","title":"Understanding Robot Minds: Leveraging Machine Teaching for Transparent Human-Robot Collaboration Across Diverse Groups","abstract":"In this work, we aim to improve transparency and efficacy in human-robot collaboration by developing machine teaching algorithms suitable for groups with varied learning capabilities. While previous approaches focused on tailored approaches for teaching individuals, our method teaches teams with various compositions of diverse learners using team belief representations to address personalization challenges within groups. We investigate various group teaching strategies, such as focusing on individual beliefs or the group's collective beliefs, and assess their impact on learning robot policies for different team compositions. Our findings reveal that team belief strategies yield less variation in learning duration and better accommodate diverse teams compared to individual belief strategies, suggesting their suitability in mixed-proficiency settings with limited resources. Conversely, individual belief strategies provide a more uniform knowledge level, particularly effective for homogeneously inexperienced groups. Our study indicates that the teaching strategy's efficacy is significantly influenced by team composition and learner proficiency, highlighting the importance of real-time assessment of learner proficiency and adapting teaching approaches based on learner proficiency for optimal teaching outcomes.","sentences":["In this work, we aim to improve transparency and efficacy in human-robot collaboration by developing machine teaching algorithms suitable for groups with varied learning capabilities.","While previous approaches focused on tailored approaches for teaching individuals, our method teaches teams with various compositions of diverse learners using team belief representations to address personalization challenges within groups.","We investigate various group teaching strategies, such as focusing on individual beliefs or the group's collective beliefs, and assess their impact on learning robot policies for different team compositions.","Our findings reveal that team belief strategies yield less variation in learning duration and better accommodate diverse teams compared to individual belief strategies, suggesting their suitability in mixed-proficiency settings with limited resources.","Conversely, individual belief strategies provide a more uniform knowledge level, particularly effective for homogeneously inexperienced groups.","Our study indicates that the teaching strategy's efficacy is significantly influenced by team composition and learner proficiency, highlighting the importance of real-time assessment of learner proficiency and adapting teaching approaches based on learner proficiency for optimal teaching outcomes."],"url":"http://arxiv.org/abs/2404.15472v1"}
{"created":"2024-04-23 19:20:41","title":"Training all-mechanical neural networks for task learning through in situ backpropagation","abstract":"Recent advances unveiled physical neural networks as promising machine learning platforms, offering faster and more energy-efficient information processing. Compared with extensively-studied optical neural networks, the development of mechanical neural networks (MNNs) remains nascent and faces significant challenges, including heavy computational demands and learning with approximate gradients. Here, we introduce the mechanical analogue of in situ backpropagation to enable highly efficient training of MNNs. We demonstrate that the exact gradient can be obtained locally in MNNs, enabling learning through their immediate vicinity. With the gradient information, we showcase the successful training of MNNs for behavior learning and machine learning tasks, achieving high accuracy in regression and classification. Furthermore, we present the retrainability of MNNs involving task-switching and damage, demonstrating the resilience. Our findings, which integrate the theory for training MNNs and experimental and numerical validations, pave the way for mechanical machine learning hardware and autonomous self-learning material systems.","sentences":["Recent advances unveiled physical neural networks as promising machine learning platforms, offering faster and more energy-efficient information processing.","Compared with extensively-studied optical neural networks, the development of mechanical neural networks (MNNs) remains nascent and faces significant challenges, including heavy computational demands and learning with approximate gradients.","Here, we introduce the mechanical analogue of in situ backpropagation to enable highly efficient training of MNNs.","We demonstrate that the exact gradient can be obtained locally in MNNs, enabling learning through their immediate vicinity.","With the gradient information, we showcase the successful training of MNNs for behavior learning and machine learning tasks, achieving high accuracy in regression and classification.","Furthermore, we present the retrainability of MNNs involving task-switching and damage, demonstrating the resilience.","Our findings, which integrate the theory for training MNNs and experimental and numerical validations, pave the way for mechanical machine learning hardware and autonomous self-learning material systems."],"url":"http://arxiv.org/abs/2404.15471v1"}
{"created":"2024-04-23 19:19:18","title":"NMBEnet: Efficient Near-field mmWave Beam Training for Multiuser OFDM Systems Using Sub-6 GHz Pilots","abstract":"Combining millimetre-wave (mmWave) communications with an extremely large-scale antenna array (ELAA) presents a promising avenue for meeting the spectral efficiency demands of the future sixth generation (6G) mobile communications. However, beam training for mmWave ELAA systems is challenged by excessive pilot overheads as well as insufficient accuracy, as the huge near-field codebook has to be accounted for. In this paper, inspired by the similarity between far-field sub-6 GHz channels and near-field mmWave channels, we propose to leverage sub-6 GHz uplink pilot signals to directly estimate the optimal near-field mmWave codeword, which aims to reduce pilot overhead and bypass the channel estimation. Moreover, we adopt deep learning to perform this dual mapping function, i.e., sub-6 GHz to mmWave, far-field to near-field, and a novel neural network structure called NMBEnet is designed to enhance the precision of beam training. Specifically, when considering the orthogonal frequency division multiplexing (OFDM) communication scenarios with high user density, correlations arise both between signals from different users and between signals from different subcarriers. Accordingly, the convolutional neural network (CNN) module and graph neural network (GNN) module included in the proposed NMBEnet can leverage these two correlations to further enhance the precision of beam training.","sentences":["Combining millimetre-wave (mmWave) communications with an extremely large-scale antenna array (ELAA) presents a promising avenue for meeting the spectral efficiency demands of the future sixth generation (6G) mobile communications.","However, beam training for mmWave ELAA systems is challenged by excessive pilot overheads as well as insufficient accuracy, as the huge near-field codebook has to be accounted for.","In this paper, inspired by the similarity between far-field sub-6 GHz channels and near-field mmWave channels, we propose to leverage sub-6 GHz uplink pilot signals to directly estimate the optimal near-field mmWave codeword, which aims to reduce pilot overhead and bypass the channel estimation.","Moreover, we adopt deep learning to perform this dual mapping function, i.e., sub-6 GHz to mmWave, far-field to near-field, and a novel neural network structure called NMBEnet is designed to enhance the precision of beam training.","Specifically, when considering the orthogonal frequency division multiplexing (OFDM) communication scenarios with high user density, correlations arise both between signals from different users and between signals from different subcarriers.","Accordingly, the convolutional neural network (CNN) module and graph neural network (GNN) module included in the proposed NMBEnet can leverage these two correlations to further enhance the precision of beam training."],"url":"http://arxiv.org/abs/2404.15469v1"}
{"created":"2024-04-23 19:15:47","title":"A Review on Message Complexity of the Algorithms for Clock Synchronization in Distributed Systems","abstract":"In this work, we present an extensive analysis of clock synchronization algorithms, with a specific focus on message complexity. We begin by introducing fundamental concepts in clock synchronization, such as the Byzantine generals problem and specific concepts like clock accuracy, precision, skew, offset, timestamping, and clock drift estimation. Describing the concept of logical clocks, their implementation in distributed systems is discussed, highlighting their significance and various approaches. The paper then examines four prominent clock synchronization algorithms: Lamport's Algorithm, Ricart-Agrawala Algorithm, Vector Clocks Algorithm, and Christian's Algorithm. Special attention is given to the analysis of message complexity, providing insights into the efficiency of each algorithm. Finally, we compare the message complexities of the discussed algorithms.","sentences":["In this work, we present an extensive analysis of clock synchronization algorithms, with a specific focus on message complexity.","We begin by introducing fundamental concepts in clock synchronization, such as the Byzantine generals problem and specific concepts like clock accuracy, precision, skew, offset, timestamping, and clock drift estimation.","Describing the concept of logical clocks, their implementation in distributed systems is discussed, highlighting their significance and various approaches.","The paper then examines four prominent clock synchronization algorithms: Lamport's Algorithm, Ricart-Agrawala Algorithm, Vector Clocks Algorithm, and Christian's Algorithm.","Special attention is given to the analysis of message complexity, providing insights into the efficiency of each algorithm.","Finally, we compare the message complexities of the discussed algorithms."],"url":"http://arxiv.org/abs/2404.15467v1"}
{"created":"2024-04-23 19:00:45","title":"Hidden in Plain Sight: Exploring the Intersections of Mental Health, Eating Disorders, and Content Moderation on TikTok","abstract":"Social media platforms actively moderate content glorifying harmful behaviors like eating disorders, which include anorexia and bulimia. However, users have adapted to evade moderation by using coded hashtags. Our study investigates the prevalence of moderation evaders on the popular social media platform TikTok and contrasts their use and emotional valence with mainstream hashtags. We notice that moderation evaders and mainstream hashtags appear together, indicating that vulnerable users might inadvertently encounter harmful content even when searching for mainstream terms. Additionally, through an analysis of emotional expressions in video descriptions and comments, we find that mainstream hashtags generally promote positive engagement, while moderation evaders evoke a wider range of emotions, including heightened negativity. These findings provide valuable insights for content creators, platform moderation efforts, and interventions aimed at cultivating a supportive online environment for discussions on mental health and eating disorders.","sentences":["Social media platforms actively moderate content glorifying harmful behaviors like eating disorders, which include anorexia and bulimia.","However, users have adapted to evade moderation by using coded hashtags.","Our study investigates the prevalence of moderation evaders on the popular social media platform TikTok and contrasts their use and emotional valence with mainstream hashtags.","We notice that moderation evaders and mainstream hashtags appear together, indicating that vulnerable users might inadvertently encounter harmful content even when searching for mainstream terms.","Additionally, through an analysis of emotional expressions in video descriptions and comments, we find that mainstream hashtags generally promote positive engagement, while moderation evaders evoke a wider range of emotions, including heightened negativity.","These findings provide valuable insights for content creators, platform moderation efforts, and interventions aimed at cultivating a supportive online environment for discussions on mental health and eating disorders."],"url":"http://arxiv.org/abs/2404.15457v1"}
{"created":"2024-04-23 18:46:07","title":"CFPFormer: Feature-pyramid like Transformer Decoder for Segmentation and Detection","abstract":"Feature pyramids have been widely adopted in convolutional neural networks (CNNs) and transformers for tasks like medical image segmentation and object detection. However, the currently existing models generally focus on the Encoder-side Transformer to extract features, from which decoder improvement can bring further potential with well-designed architecture. We propose CFPFormer, a novel decoder block that integrates feature pyramids and transformers. Specifically, by leveraging patch embedding, cross-layer feature concatenation, and Gaussian attention mechanisms, CFPFormer enhances feature extraction capabilities while promoting generalization across diverse tasks. Benefiting from Transformer structure and U-shaped Connections, our introduced model gains the ability to capture long-range dependencies and effectively up-sample feature maps. Our model achieves superior performance in detecting small objects compared to existing methods. We evaluate CFPFormer on medical image segmentation datasets and object detection benchmarks (VOC 2007, VOC2012, MS-COCO), demonstrating its effectiveness and versatility. On the ACDC Post-2017-MICCAI-Challenge online test set, our model reaches exceptionally impressive accuracy, and performed well compared with the original decoder setting in Synapse multi-organ segmentation dataset.","sentences":["Feature pyramids have been widely adopted in convolutional neural networks (CNNs) and transformers for tasks like medical image segmentation and object detection.","However, the currently existing models generally focus on the Encoder-side Transformer to extract features, from which decoder improvement can bring further potential with well-designed architecture.","We propose CFPFormer, a novel decoder block that integrates feature pyramids and transformers.","Specifically, by leveraging patch embedding, cross-layer feature concatenation, and Gaussian attention mechanisms, CFPFormer enhances feature extraction capabilities while promoting generalization across diverse tasks.","Benefiting from Transformer structure and U-shaped Connections, our introduced model gains the ability to capture long-range dependencies and effectively up-sample feature maps.","Our model achieves superior performance in detecting small objects compared to existing methods.","We evaluate CFPFormer on medical image segmentation datasets and object detection benchmarks (VOC 2007, VOC2012, MS-COCO), demonstrating its effectiveness and versatility.","On the ACDC Post-2017-MICCAI-Challenge online test set, our model reaches exceptionally impressive accuracy, and performed well compared with the original decoder setting in Synapse multi-organ segmentation dataset."],"url":"http://arxiv.org/abs/2404.15451v1"}
{"created":"2024-04-23 18:41:56","title":"ID-Aligner: Enhancing Identity-Preserving Text-to-Image Generation with Reward Feedback Learning","abstract":"The rapid development of diffusion models has triggered diverse applications. Identity-preserving text-to-image generation (ID-T2I) particularly has received significant attention due to its wide range of application scenarios like AI portrait and advertising. While existing ID-T2I methods have demonstrated impressive results, several key challenges remain: (1) It is hard to maintain the identity characteristics of reference portraits accurately, (2) The generated images lack aesthetic appeal especially while enforcing identity retention, and (3) There is a limitation that cannot be compatible with LoRA-based and Adapter-based methods simultaneously. To address these issues, we present \\textbf{ID-Aligner}, a general feedback learning framework to enhance ID-T2I performance. To resolve identity features lost, we introduce identity consistency reward fine-tuning to utilize the feedback from face detection and recognition models to improve generated identity preservation. Furthermore, we propose identity aesthetic reward fine-tuning leveraging rewards from human-annotated preference data and automatically constructed feedback on character structure generation to provide aesthetic tuning signals. Thanks to its universal feedback fine-tuning framework, our method can be readily applied to both LoRA and Adapter models, achieving consistent performance gains. Extensive experiments on SD1.5 and SDXL diffusion models validate the effectiveness of our approach. \\textbf{Project Page: \\url{https://idaligner.github.io/}}","sentences":["The rapid development of diffusion models has triggered diverse applications.","Identity-preserving text-to-image generation (ID-T2I) particularly has received significant attention due to its wide range of application scenarios like AI portrait and advertising.","While existing ID-T2I methods have demonstrated impressive results, several key challenges remain: (1) It is hard to maintain the identity characteristics of reference portraits accurately, (2) The generated images lack aesthetic appeal especially while enforcing identity retention, and (3) There is a limitation that cannot be compatible with LoRA-based and Adapter-based methods simultaneously.","To address these issues, we present \\textbf{ID-Aligner}, a general feedback learning framework to enhance ID-T2I performance.","To resolve identity features lost, we introduce identity consistency reward fine-tuning to utilize the feedback from face detection and recognition models to improve generated identity preservation.","Furthermore, we propose identity aesthetic reward fine-tuning leveraging rewards from human-annotated preference data and automatically constructed feedback on character structure generation to provide aesthetic tuning signals.","Thanks to its universal feedback fine-tuning framework, our method can be readily applied to both LoRA and Adapter models, achieving consistent performance gains.","Extensive experiments on SD1.5 and SDXL diffusion models validate the effectiveness of our approach.","\\textbf{Project","Page: \\url{https://idaligner.github.io/}}"],"url":"http://arxiv.org/abs/2404.15449v1"}
{"created":"2024-04-23 18:39:57","title":"GLoD: Composing Global Contexts and Local Details in Image Generation","abstract":"Diffusion models have demonstrated their capability to synthesize high-quality and diverse images from textual prompts. However, simultaneous control over both global contexts (e.g., object layouts and interactions) and local details (e.g., colors and emotions) still remains a significant challenge. The models often fail to understand complex descriptions involving multiple objects and reflect specified visual attributes to wrong targets or ignore them. This paper presents Global-Local Diffusion (\\textit{GLoD}), a novel framework which allows simultaneous control over the global contexts and the local details in text-to-image generation without requiring training or fine-tuning. It assigns multiple global and local prompts to corresponding layers and composes their noises to guide a denoising process using pre-trained diffusion models. Our framework enables complex global-local compositions, conditioning objects in the global prompt with the local prompts while preserving other unspecified identities. Our quantitative and qualitative evaluations demonstrate that GLoD effectively generates complex images that adhere to both user-provided object interactions and object details.","sentences":["Diffusion models have demonstrated their capability to synthesize high-quality and diverse images from textual prompts.","However, simultaneous control over both global contexts (e.g., object layouts and interactions) and local details (e.g., colors and emotions) still remains a significant challenge.","The models often fail to understand complex descriptions involving multiple objects and reflect specified visual attributes to wrong targets or ignore them.","This paper presents Global-Local Diffusion (\\textit{GLoD}), a novel framework which allows simultaneous control over the global contexts and the local details in text-to-image generation without requiring training or fine-tuning.","It assigns multiple global and local prompts to corresponding layers and composes their noises to guide a denoising process using pre-trained diffusion models.","Our framework enables complex global-local compositions, conditioning objects in the global prompt with the local prompts while preserving other unspecified identities.","Our quantitative and qualitative evaluations demonstrate that GLoD effectively generates complex images that adhere to both user-provided object interactions and object details."],"url":"http://arxiv.org/abs/2404.15447v1"}
{"created":"2024-04-23 18:39:50","title":"OffRAMPS: An FPGA-based Intermediary for Analysis and Modification of Additive Manufacturing Control Systems","abstract":"Cybersecurity threats in Additive Manufacturing (AM) are an increasing concern as AM adoption continues to grow. AM is now being used for parts in the aerospace, transportation, and medical domains. Threat vectors which allow for part compromise are particularly concerning, as any failure in these domains would have life-threatening consequences. A major challenge to investigation of AM part-compromises comes from the difficulty in evaluating and benchmarking both identified threat vectors as well as methods for detecting adversarial actions. In this work, we introduce a generalized platform for systematic analysis of attacks against and defenses for 3D printers. Our \"OFFRAMPS\" platform is based on the open-source 3D printer control board \"RAMPS.\" OFFRAMPS allows analysis, recording, and modification of all control signals and I/O for a 3D printer. We show the efficacy of OFFRAMPS by presenting a series of case studies based on several Trojans, including ones identified in the literature, and show that OFFRAMPS can both emulate and detect these attacks, i.e., it can both change and detect arbitrary changes to the g-code print commands.","sentences":["Cybersecurity threats in Additive Manufacturing (AM) are an increasing concern as AM adoption continues to grow.","AM is now being used for parts in the aerospace, transportation, and medical domains.","Threat vectors which allow for part compromise are particularly concerning, as any failure in these domains would have life-threatening consequences.","A major challenge to investigation of AM part-compromises comes from the difficulty in evaluating and benchmarking both identified threat vectors as well as methods for detecting adversarial actions.","In this work, we introduce a generalized platform for systematic analysis of attacks against and defenses for 3D printers.","Our \"OFFRAMPS\" platform is based on the open-source 3D printer control board \"RAMPS.\"","OFFRAMPS allows analysis, recording, and modification of all control signals and I/O for a 3D printer.","We show the efficacy of OFFRAMPS by presenting a series of case studies based on several Trojans, including ones identified in the literature, and show that OFFRAMPS can both emulate and detect these attacks, i.e., it can both change and detect arbitrary changes to the g-code print commands."],"url":"http://arxiv.org/abs/2404.15446v1"}
{"created":"2024-04-23 18:37:37","title":"Deep multi-prototype capsule networks","abstract":"Capsule networks are a type of neural network that identify image parts and form the instantiation parameters of a whole hierarchically. The goal behind the network is to perform an inverse computer graphics task, and the network parameters are the mapping weights that transform parts into a whole. The trainability of capsule networks in complex data with high intra-class or intra-part variation is challenging. This paper presents a multi-prototype architecture for guiding capsule networks to represent the variations in the image parts. To this end, instead of considering a single capsule for each class and part, the proposed method employs several capsules (co-group capsules), capturing multiple prototypes of an object. In the final layer, co-group capsules compete, and their soft output is considered the target for a competitive cross-entropy loss. Moreover, in the middle layers, the most active capsules map to the next layer with a shared weight among the co-groups. Consequently, due to the reduction in parameters, implicit weight-sharing makes it possible to have more deep capsule network layers. The experimental results on MNIST, SVHN, C-Cube, CEDAR, MCYT, and UTSig datasets reveal that the proposed model outperforms others regarding image classification accuracy.","sentences":["Capsule networks are a type of neural network that identify image parts and form the instantiation parameters of a whole hierarchically.","The goal behind the network is to perform an inverse computer graphics task, and the network parameters are the mapping weights that transform parts into a whole.","The trainability of capsule networks in complex data with high intra-class or intra-part variation is challenging.","This paper presents a multi-prototype architecture for guiding capsule networks to represent the variations in the image parts.","To this end, instead of considering a single capsule for each class and part, the proposed method employs several capsules (co-group capsules), capturing multiple prototypes of an object.","In the final layer, co-group capsules compete, and their soft output is considered the target for a competitive cross-entropy loss.","Moreover, in the middle layers, the most active capsules map to the next layer with a shared weight among the co-groups.","Consequently, due to the reduction in parameters, implicit weight-sharing makes it possible to have more deep capsule network layers.","The experimental results on MNIST, SVHN, C-Cube, CEDAR, MCYT, and UTSig datasets reveal that the proposed model outperforms others regarding image classification accuracy."],"url":"http://arxiv.org/abs/2404.15445v1"}
{"created":"2024-04-23 18:37:36","title":"Renting Servers for Multi-Parameter Jobs in the Cloud","abstract":"We study the Renting Servers in the Cloud problem (RSiC) in multiple dimensions. In this problem, a sequence of multi-parameter jobs must be scheduled on servers that can be rented on-demand. Each job has an arrival time, a finishing time, and a multi-dimensional size vector that specifies its resource demands. Each server has a multi-dimensional capacity and jobs can be scheduled on a server as long as in each dimension the sum of sizes of jobs does not exceed the capacity of the server in that dimension. The goal is to minimize the total rental time of servers needed to process the job sequence. AF algorithms do not rent new servers to accommodate a job unless they have to. We introduce a sub-family of AF algorithms called monotone AF algorithms. We show this family have a tight competitive ratio of $Theta(d mu)$, where $d$ is the dimension of the problem and $mu$ is the ratio between the maximum and minimum duration of jobs in the input sequence. We also show that upper bounds for the RSiC problem obey the direct-sum property with respect to dimension $d$, that is we show how to transform $1$-dimensional algorithms for RSiC to work in the $d$-dimensional setting with competitive ratio scaling by a factor of $d$. As a corollary, we obtain an $O(d\\sqrt{log mu})$ upper bound for $d$-dimensional clairvoyant RSiC. We also establish a lower bound of $\\widetilde{Omega}(d mu)$ for both deterministic and randomized algorithms for $d$-dimensional non-clairvoyant RSiC, under the assumption that $mu \\le log d - 2$. Lastly, we propose a natural greedy algorithm called Greedy. Greedy, is a clairvoyant algorithm belongs to the monotone AF family, achieves a competitive ratio of $Theta(d mu)$. Our experimental results indicate that Greedy performs better or matches all other existing algorithms, for almost all the settings of arrival rates and values of mu and $d$ that we implemented.","sentences":["We study the Renting Servers in the Cloud problem (RSiC) in multiple dimensions.","In this problem, a sequence of multi-parameter jobs must be scheduled on servers that can be rented on-demand.","Each job has an arrival time, a finishing time, and a multi-dimensional size vector that specifies its resource demands.","Each server has a multi-dimensional capacity and jobs can be scheduled on a server as long as in each dimension the sum of sizes of jobs does not exceed the capacity of the server in that dimension.","The goal is to minimize the total rental time of servers needed to process the job sequence.","AF algorithms do not rent new servers to accommodate a job unless they have to.","We introduce a sub-family of AF algorithms called monotone AF algorithms.","We show this family have a tight competitive ratio of $Theta(d mu)$, where $d$ is the dimension of the problem and $mu$ is the ratio between the maximum and minimum duration of jobs in the input sequence.","We also show that upper bounds for the RSiC problem obey the direct-sum property with respect to dimension $d$, that is we show how to transform $1$-dimensional algorithms for RSiC to work in the $d$-dimensional setting with competitive ratio scaling by a factor of $d$. As a corollary, we obtain an $O(d\\sqrt{log mu})$ upper bound for $d$-dimensional clairvoyant RSiC.","We also establish a lower bound of $\\widetilde{Omega}(d mu)$ for both deterministic and randomized algorithms for $d$-dimensional non-clairvoyant RSiC, under the assumption that $mu \\le log d - 2$.","Lastly, we propose a natural greedy algorithm called Greedy.","Greedy, is a clairvoyant algorithm belongs to the monotone AF family, achieves a competitive ratio of $Theta(d mu)$. Our experimental results indicate that Greedy performs better or matches all other existing algorithms, for almost all the settings of arrival rates and values of mu and $d$ that we implemented."],"url":"http://arxiv.org/abs/2404.15444v1"}
{"created":"2024-04-23 18:31:03","title":"Exploring Convergence in Relation using Association Rules Mining: A Case Study in Collaborative Knowledge Production","abstract":"This study delves into the pivotal role played by non-experts in knowledge production on open collaboration platforms, with a particular focus on the intricate process of tag development that culminates in the proposal of new glitch classes. Leveraging the power of Association Rule Mining (ARM), this research endeavors to unravel the underlying dynamics of collaboration among citizen scientists. By meticulously quantifying tag associations and scrutinizing their temporal dynamics, the study provides a comprehensive and nuanced understanding of how non-experts collaborate to generate valuable scientific insights. Furthermore, this investigation extends its purview to examine the phenomenon of ideological convergence within online citizen science knowledge production. To accomplish this, a novel measurement algorithm, based on the Mann-Kendall Trend Test, is introduced. This innovative approach sheds illuminating light on the dynamics of collaborative knowledge production, revealing both the vast opportunities and daunting challenges inherent in leveraging non-expert contributions for scientific research endeavors. Notably, the study uncovers a robust pattern of convergence in ideology, employing both the newly proposed convergence testing method and the traditional approach based on the stationarity of time series data. This groundbreaking discovery holds significant implications for understanding the dynamics of online citizen science communities and underscores the crucial role played by non-experts in shaping the scientific landscape of the digital age. Ultimately, this study contributes significantly to our understanding of online citizen science communities, highlighting their potential to harness collective intelligence for tackling complex scientific tasks and enriching our comprehension of collaborative knowledge production processes in the digital age.","sentences":["This study delves into the pivotal role played by non-experts in knowledge production on open collaboration platforms, with a particular focus on the intricate process of tag development that culminates in the proposal of new glitch classes.","Leveraging the power of Association Rule Mining (ARM), this research endeavors to unravel the underlying dynamics of collaboration among citizen scientists.","By meticulously quantifying tag associations and scrutinizing their temporal dynamics, the study provides a comprehensive and nuanced understanding of how non-experts collaborate to generate valuable scientific insights.","Furthermore, this investigation extends its purview to examine the phenomenon of ideological convergence within online citizen science knowledge production.","To accomplish this, a novel measurement algorithm, based on the Mann-Kendall Trend Test, is introduced.","This innovative approach sheds illuminating light on the dynamics of collaborative knowledge production, revealing both the vast opportunities and daunting challenges inherent in leveraging non-expert contributions for scientific research endeavors.","Notably, the study uncovers a robust pattern of convergence in ideology, employing both the newly proposed convergence testing method and the traditional approach based on the stationarity of time series data.","This groundbreaking discovery holds significant implications for understanding the dynamics of online citizen science communities and underscores the crucial role played by non-experts in shaping the scientific landscape of the digital age.","Ultimately, this study contributes significantly to our understanding of online citizen science communities, highlighting their potential to harness collective intelligence for tackling complex scientific tasks and enriching our comprehension of collaborative knowledge production processes in the digital age."],"url":"http://arxiv.org/abs/2404.15440v1"}
{"created":"2024-04-23 18:26:11","title":"Iterative Cluster Harvesting for Wafer Map Defect Patterns","abstract":"Unsupervised clustering of wafer map defect patterns is challenging because the appearance of certain defect patterns varies significantly. This includes changing shape, location, density, and rotation of the defect area on the wafer. We present a harvesting approach, which can cluster even challenging defect patterns of wafer maps well. Our approach makes use of a well-known, three-step procedure: feature extraction, dimension reduction, and clustering. The novelty in our approach lies in repeating dimensionality reduction and clustering iteratively while filtering out one cluster per iteration according to its silhouette score. This method leads to an improvement of clustering performance in general and is especially useful for difficult defect patterns. The low computational effort allows for a quick assessment of large datasets and can be used to support manual labeling efforts. We benchmark against related approaches from the literature and show improved results on a real-world industrial dataset.","sentences":["Unsupervised clustering of wafer map defect patterns is challenging because the appearance of certain defect patterns varies significantly.","This includes changing shape, location, density, and rotation of the defect area on the wafer.","We present a harvesting approach, which can cluster even challenging defect patterns of wafer maps well.","Our approach makes use of a well-known, three-step procedure: feature extraction, dimension reduction, and clustering.","The novelty in our approach lies in repeating dimensionality reduction and clustering iteratively while filtering out one cluster per iteration according to its silhouette score.","This method leads to an improvement of clustering performance in general and is especially useful for difficult defect patterns.","The low computational effort allows for a quick assessment of large datasets and can be used to support manual labeling efforts.","We benchmark against related approaches from the literature and show improved results on a real-world industrial dataset."],"url":"http://arxiv.org/abs/2404.15436v1"}
{"created":"2024-04-23 18:25:05","title":"Introduction to Eye Tracking: A Hands-On Tutorial for Students and Practitioners","abstract":"Eye-tracking technology is widely used in various application areas such as psychology, neuroscience, marketing, and human-computer interaction, as it is a valuable tool for understanding how people process information and interact with their environment. This tutorial provides a comprehensive introduction to eye tracking, from the basics of eye anatomy and physiology to the principles and applications of different eye-tracking systems. The guide is designed to provide a hands-on learning experience for everyone interested in working with eye-tracking technology. Therefore, we include practical case studies to teach students and professionals how to effectively set up and operate an eye-tracking system. The tutorial covers a variety of eye-tracking systems, calibration techniques, data collection, and analysis methods, including fixations, saccades, pupil diameter, and visual scan path analysis. In addition, we emphasize the importance of considering ethical aspects when conducting eye-tracking research and experiments, especially informed consent and participant privacy. We aim to give the reader a solid understanding of basic eye-tracking principles and the practical skills needed to conduct their experiments. Python-based code snippets and illustrative examples are included in the tutorials and can be downloaded at: https://gitlab.lrz.de/hctl/Eye-Tracking-Tutorial.","sentences":["Eye-tracking technology is widely used in various application areas such as psychology, neuroscience, marketing, and human-computer interaction, as it is a valuable tool for understanding how people process information and interact with their environment.","This tutorial provides a comprehensive introduction to eye tracking, from the basics of eye anatomy and physiology to the principles and applications of different eye-tracking systems.","The guide is designed to provide a hands-on learning experience for everyone interested in working with eye-tracking technology.","Therefore, we include practical case studies to teach students and professionals how to effectively set up and operate an eye-tracking system.","The tutorial covers a variety of eye-tracking systems, calibration techniques, data collection, and analysis methods, including fixations, saccades, pupil diameter, and visual scan path analysis.","In addition, we emphasize the importance of considering ethical aspects when conducting eye-tracking research and experiments, especially informed consent and participant privacy.","We aim to give the reader a solid understanding of basic eye-tracking principles and the practical skills needed to conduct their experiments.","Python-based code snippets and illustrative examples are included in the tutorials and can be downloaded at: https://gitlab.lrz.de/hctl/Eye-Tracking-Tutorial."],"url":"http://arxiv.org/abs/2404.15435v1"}
