{"created":"2024-03-07 18:58:40","title":"Efficient LoFTR: Semi-Dense Local Feature Matching with Sparse-Like Speed","abstract":"We present a novel method for efficiently producing semi-dense matches across images. Previous detector-free matcher LoFTR has shown remarkable matching capability in handling large-viewpoint change and texture-poor scenarios but suffers from low efficiency. We revisit its design choices and derive multiple improvements for both efficiency and accuracy. One key observation is that performing the transformer over the entire feature map is redundant due to shared local information, therefore we propose an aggregated attention mechanism with adaptive token selection for efficiency. Furthermore, we find spatial variance exists in LoFTR's fine correlation module, which is adverse to matching accuracy. A novel two-stage correlation layer is proposed to achieve accurate subpixel correspondences for accuracy improvement. Our efficiency optimized model is $\\sim 2.5\\times$ faster than LoFTR which can even surpass state-of-the-art efficient sparse matching pipeline SuperPoint + LightGlue. Moreover, extensive experiments show that our method can achieve higher accuracy compared with competitive semi-dense matchers, with considerable efficiency benefits. This opens up exciting prospects for large-scale or latency-sensitive applications such as image retrieval and 3D reconstruction. Project page: https://zju3dv.github.io/efficientloftr.","sentences":["We present a novel method for efficiently producing semi-dense matches across images.","Previous detector-free matcher LoFTR has shown remarkable matching capability in handling large-viewpoint change and texture-poor scenarios but suffers from low efficiency.","We revisit its design choices and derive multiple improvements for both efficiency and accuracy.","One key observation is that performing the transformer over the entire feature map is redundant due to shared local information, therefore we propose an aggregated attention mechanism with adaptive token selection for efficiency.","Furthermore, we find spatial variance exists in LoFTR's fine correlation module, which is adverse to matching accuracy.","A novel two-stage correlation layer is proposed to achieve accurate subpixel correspondences for accuracy improvement.","Our efficiency optimized model is $\\sim 2.5\\times$ faster than LoFTR which can even surpass state-of-the-art efficient sparse matching pipeline SuperPoint + LightGlue.","Moreover, extensive experiments show that our method can achieve higher accuracy compared with competitive semi-dense matchers, with considerable efficiency benefits.","This opens up exciting prospects for large-scale or latency-sensitive applications such as image retrieval and 3D reconstruction.","Project page: https://zju3dv.github.io/efficientloftr."],"url":"http://arxiv.org/abs/2403.04765v1"}
{"created":"2024-03-07 18:58:26","title":"Minimizing the Thompson Sampling Regret-to-Sigma Ratio (TS-RSR): a provably efficient algorithm for batch Bayesian Optimization","abstract":"This paper presents a new approach for batch Bayesian Optimization (BO), where the sampling takes place by minimizing a Thompson Sampling approximation of a regret to uncertainty ratio. Our objective is able to coordinate the actions chosen in each batch in a way that minimizes redundancy between points whilst focusing on points with high predictive means or high uncertainty. We provide high-probability theoretical guarantees on the regret of our algorithm. Finally, numerically, we demonstrate that our method attains state-of-the-art performance on a range of nonconvex test functions, where it outperforms several competitive benchmark batch BO algorithms by an order of magnitude on average.","sentences":["This paper presents a new approach for batch Bayesian Optimization (BO), where the sampling takes place by minimizing a Thompson Sampling approximation of a regret to uncertainty ratio.","Our objective is able to coordinate the actions chosen in each batch in a way that minimizes redundancy between points whilst focusing on points with high predictive means or high uncertainty.","We provide high-probability theoretical guarantees on the regret of our algorithm.","Finally, numerically, we demonstrate that our method attains state-of-the-art performance on a range of nonconvex test functions, where it outperforms several competitive benchmark batch BO algorithms by an order of magnitude on average."],"url":"http://arxiv.org/abs/2403.04764v1"}
{"created":"2024-03-07 18:57:46","title":"BloomGML: Graph Machine Learning through the Lens of Bilevel Optimization","abstract":"Bilevel optimization refers to scenarios whereby the optimal solution of a lower-level energy function serves as input features to an upper-level objective of interest. These optimal features typically depend on tunable parameters of the lower-level energy in such a way that the entire bilevel pipeline can be trained end-to-end. Although not generally presented as such, this paper demonstrates how a variety of graph learning techniques can be recast as special cases of bilevel optimization or simplifications thereof. In brief, building on prior work we first derive a more flexible class of energy functions that, when paired with various descent steps (e.g., gradient descent, proximal methods, momentum, etc.), form graph neural network (GNN) message-passing layers; critically, we also carefully unpack where any residual approximation error lies with respect to the underlying constituent message-passing functions. We then probe several simplifications of this framework to derive close connections with non-GNN-based graph learning approaches, including knowledge graph embeddings, various forms of label propagation, and efficient graph-regularized MLP models. And finally, we present supporting empirical results that demonstrate the versatility of the proposed bilevel lens, which we refer to as BloomGML, referencing that BiLevel Optimization Offers More Graph Machine Learning. Our code is available at https://github.com/amberyzheng/BloomGML. Let graph ML bloom.","sentences":["Bilevel optimization refers to scenarios whereby the optimal solution of a lower-level energy function serves as input features to an upper-level objective of interest.","These optimal features typically depend on tunable parameters of the lower-level energy in such a way that the entire bilevel pipeline can be trained end-to-end.","Although not generally presented as such, this paper demonstrates how a variety of graph learning techniques can be recast as special cases of bilevel optimization or simplifications thereof.","In brief, building on prior work we first derive a more flexible class of energy functions that, when paired with various descent steps (e.g., gradient descent, proximal methods, momentum, etc.), form graph neural network (GNN) message-passing layers; critically, we also carefully unpack where any residual approximation error lies with respect to the underlying constituent message-passing functions.","We then probe several simplifications of this framework to derive close connections with non-GNN-based graph learning approaches, including knowledge graph embeddings, various forms of label propagation, and efficient graph-regularized MLP models.","And finally, we present supporting empirical results that demonstrate the versatility of the proposed bilevel lens, which we refer to as BloomGML, referencing that BiLevel Optimization Offers More Graph Machine Learning.","Our code is available at https://github.com/amberyzheng/BloomGML.","Let graph ML bloom."],"url":"http://arxiv.org/abs/2403.04763v1"}
{"created":"2024-03-07 18:56:47","title":"DeepSee: Multidimensional Visualizations of Seabed Ecosystems","abstract":"Scientists studying deep ocean microbial ecosystems use limited numbers of sediment samples collected from the seafloor to characterize important life-sustaining biogeochemical cycles in the environment. Yet conducting fieldwork to sample these extreme remote environments is both expensive and time consuming, requiring tools that enable scientists to explore the sampling history of field sites and predict where taking new samples is likely to maximize scientific return. We conducted a collaborative, user-centered design study with a team of scientific researchers to develop DeepSee, an interactive data workspace that visualizes 2D and 3D interpolations of biogeochemical and microbial processes in context together with sediment sampling history overlaid on 2D seafloor maps. Based on a field deployment and qualitative interviews, we found that DeepSee increased the scientific return from limited sample sizes, catalyzed new research workflows, reduced long-term costs of sharing data, and supported teamwork and communication between team members with diverse research goals.","sentences":["Scientists studying deep ocean microbial ecosystems use limited numbers of sediment samples collected from the seafloor to characterize important life-sustaining biogeochemical cycles in the environment.","Yet conducting fieldwork to sample these extreme remote environments is both expensive and time consuming, requiring tools that enable scientists to explore the sampling history of field sites and predict where taking new samples is likely to maximize scientific return.","We conducted a collaborative, user-centered design study with a team of scientific researchers to develop DeepSee, an interactive data workspace that visualizes 2D and 3D interpolations of biogeochemical and microbial processes in context together with sediment sampling history overlaid on 2D seafloor maps.","Based on a field deployment and qualitative interviews, we found that DeepSee increased the scientific return from limited sample sizes, catalyzed new research workflows, reduced long-term costs of sharing data, and supported teamwork and communication between team members with diverse research goals."],"url":"http://arxiv.org/abs/2403.04761v1"}
{"created":"2024-03-07 18:56:39","title":"iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries","abstract":"The recent explosion in popularity of large language models (LLMs) has inspired learning engineers to incorporate them into adaptive educational tools that automatically score summary writing. Understanding and evaluating LLMs is vital before deploying them in critical learning environments, yet their unprecedented size and expanding number of parameters inhibits transparency and impedes trust when they underperform. Through a collaborative user-centered design process with several learning engineers building and deploying summary scoring LLMs, we characterized fundamental design challenges and goals around interpreting their models, including aggregating large text inputs, tracking score provenance, and scaling LLM interpretability methods. To address their concerns, we developed iScore, an interactive visual analytics tool for learning engineers to upload, score, and compare multiple summaries simultaneously. Tightly integrated views allow users to iteratively revise the language in summaries, track changes in the resulting LLM scores, and visualize model weights at multiple levels of abstraction. To validate our approach, we deployed iScore with three learning engineers over the course of a month. We present a case study where interacting with iScore led a learning engineer to improve their LLM's score accuracy by three percentage points. Finally, we conducted qualitative interviews with the learning engineers that revealed how iScore enabled them to understand, evaluate, and build trust in their LLMs during deployment.","sentences":["The recent explosion in popularity of large language models (LLMs) has inspired learning engineers to incorporate them into adaptive educational tools that automatically score summary writing.","Understanding and evaluating LLMs is vital before deploying them in critical learning environments, yet their unprecedented size and expanding number of parameters inhibits transparency and impedes trust when they underperform.","Through a collaborative user-centered design process with several learning engineers building and deploying summary scoring LLMs, we characterized fundamental design challenges and goals around interpreting their models, including aggregating large text inputs, tracking score provenance, and scaling LLM interpretability methods.","To address their concerns, we developed iScore, an interactive visual analytics tool for learning engineers to upload, score, and compare multiple summaries simultaneously.","Tightly integrated views allow users to iteratively revise the language in summaries, track changes in the resulting LLM scores, and visualize model weights at multiple levels of abstraction.","To validate our approach, we deployed iScore with three learning engineers over the course of a month.","We present a case study where interacting with iScore led a learning engineer to improve their LLM's score accuracy by three percentage points.","Finally, we conducted qualitative interviews with the learning engineers that revealed how iScore enabled them to understand, evaluate, and build trust in their LLMs during deployment."],"url":"http://arxiv.org/abs/2403.04760v1"}
{"created":"2024-03-07 18:56:33","title":"Lifelong Intelligence Beyond the Edge using Hyperdimensional Computing","abstract":"On-device learning has emerged as a prevailing trend that avoids the slow response time and costly communication of cloud-based learning. The ability to learn continuously and indefinitely in a changing environment, and with resource constraints, is critical for real sensor deployments. However, existing designs are inadequate for practical scenarios with (i) streaming data input, (ii) lack of supervision and (iii) limited on-board resources. In this paper, we design and deploy the first on-device lifelong learning system called LifeHD for general IoT applications with limited supervision. LifeHD is designed based on a novel neurally-inspired and lightweight learning paradigm called Hyperdimensional Computing (HDC). We utilize a two-tier associative memory organization to intelligently store and manage high-dimensional, low-precision vectors, which represent the historical patterns as cluster centroids. We additionally propose two variants of LifeHD to cope with scarce labeled inputs and power constraints. We implement LifeHD on off-the-shelf edge platforms and perform extensive evaluations across three scenarios. Our measurements show that LifeHD improves the unsupervised clustering accuracy by up to 74.8% compared to the state-of-the-art NN-based unsupervised lifelong learning baselines with as much as 34.3x better energy efficiency. Our code is available at https://github.com/Orienfish/LifeHD.","sentences":["On-device learning has emerged as a prevailing trend that avoids the slow response time and costly communication of cloud-based learning.","The ability to learn continuously and indefinitely in a changing environment, and with resource constraints, is critical for real sensor deployments.","However, existing designs are inadequate for practical scenarios with (i) streaming data input, (ii) lack of supervision and (iii) limited on-board resources.","In this paper, we design and deploy the first on-device lifelong learning system called LifeHD for general IoT applications with limited supervision.","LifeHD is designed based on a novel neurally-inspired and lightweight learning paradigm called Hyperdimensional Computing (HDC).","We utilize a two-tier associative memory organization to intelligently store and manage high-dimensional, low-precision vectors, which represent the historical patterns as cluster centroids.","We additionally propose two variants of LifeHD to cope with scarce labeled inputs and power constraints.","We implement LifeHD on off-the-shelf edge platforms and perform extensive evaluations across three scenarios.","Our measurements show that LifeHD improves the unsupervised clustering accuracy by up to 74.8% compared to the state-of-the-art NN-based unsupervised lifelong learning baselines with as much as 34.3x better energy efficiency.","Our code is available at https://github.com/Orienfish/LifeHD."],"url":"http://arxiv.org/abs/2403.04759v1"}
{"created":"2024-03-07 18:56:31","title":"KnowledgeVIS: Interpreting Language Models by Comparing Fill-in-the-Blank Prompts","abstract":"Recent growth in the popularity of large language models has led to their increased usage for summarizing, predicting, and generating text, making it vital to help researchers and engineers understand how and why they work. We present KnowledgeVis, a human-in-the-loop visual analytics system for interpreting language models using fill-in-the-blank sentences as prompts. By comparing predictions between sentences, KnowledgeVis reveals learned associations that intuitively connect what language models learn during training to natural language tasks downstream, helping users create and test multiple prompt variations, analyze predicted words using a novel semantic clustering technique, and discover insights using interactive visualizations. Collectively, these visualizations help users identify the likelihood and uniqueness of individual predictions, compare sets of predictions between prompts, and summarize patterns and relationships between predictions across all prompts. We demonstrate the capabilities of KnowledgeVis with feedback from six NLP experts as well as three different use cases: (1) probing biomedical knowledge in two domain-adapted models; and (2) evaluating harmful identity stereotypes and (3) discovering facts and relationships between three general-purpose models.","sentences":["Recent growth in the popularity of large language models has led to their increased usage for summarizing, predicting, and generating text, making it vital to help researchers and engineers understand how and why they work.","We present KnowledgeVis, a human-in-the-loop visual analytics system for interpreting language models using fill-in-the-blank sentences as prompts.","By comparing predictions between sentences, KnowledgeVis reveals learned associations that intuitively connect what language models learn during training to natural language tasks downstream, helping users create and test multiple prompt variations, analyze predicted words using a novel semantic clustering technique, and discover insights using interactive visualizations.","Collectively, these visualizations help users identify the likelihood and uniqueness of individual predictions, compare sets of predictions between prompts, and summarize patterns and relationships between predictions across all prompts.","We demonstrate the capabilities of KnowledgeVis with feedback from six NLP experts as well as three different use cases: (1) probing biomedical knowledge in two domain-adapted models; and (2) evaluating harmful identity stereotypes and (3) discovering facts and relationships between three general-purpose models."],"url":"http://arxiv.org/abs/2403.04758v1"}
{"created":"2024-03-07 18:56:16","title":"Preliminary Guidelines For Combining Data Integration and Visual Data Analysis","abstract":"Data integration is often performed to consolidate information from multiple disparate data sources during visual data analysis. However, integration operations are usually separate from visual analytics operations such as encode and filter in both interface design and empirical research. We conducted a preliminary user study to investigate whether and how data integration should be incorporated directly into the visual analytics process. We used two interface alternatives featuring contrasting approaches to the data preparation and analysis workflow: manual file-based ex-situ integration as a separate step from visual analytics operations; and automatic UI-based in-situ integration merged with visual analytics operations. Participants were asked to complete specific and free-form tasks with each interface, browsing for patterns, generating insights, and summarizing relationships between attributes distributed across multiple files. Analyzing participants' interactions and feedback, we found both task completion time and total interactions to be similar across interfaces and tasks, as well as unique integration strategies between interfaces and emergent behaviors related to satisficing and cognitive bias. Participants' time spent and interactions revealed that in-situ integration enabled users to spend more time on analysis tasks compared with ex-situ integration. Participants' integration strategies and analytical behaviors revealed differences in interface usage for generating and tracking hypotheses and insights. With these results, we synthesized preliminary guidelines for designing future visual analytics interfaces that can support integrating attributes throughout an active analysis process.","sentences":["Data integration is often performed to consolidate information from multiple disparate data sources during visual data analysis.","However, integration operations are usually separate from visual analytics operations such as encode and filter in both interface design and empirical research.","We conducted a preliminary user study to investigate whether and how data integration should be incorporated directly into the visual analytics process.","We used two interface alternatives featuring contrasting approaches to the data preparation and analysis workflow: manual file-based ex-situ integration as a separate step from visual analytics operations; and automatic UI-based in-situ integration merged with visual analytics operations.","Participants were asked to complete specific and free-form tasks with each interface, browsing for patterns, generating insights, and summarizing relationships between attributes distributed across multiple files.","Analyzing participants' interactions and feedback, we found both task completion time and total interactions to be similar across interfaces and tasks, as well as unique integration strategies between interfaces and emergent behaviors related to satisficing and cognitive bias.","Participants' time spent and interactions revealed that in-situ integration enabled users to spend more time on analysis tasks compared with ex-situ integration.","Participants' integration strategies and analytical behaviors revealed differences in interface usage for generating and tracking hypotheses and insights.","With these results, we synthesized preliminary guidelines for designing future visual analytics interfaces that can support integrating attributes throughout an active analysis process."],"url":"http://arxiv.org/abs/2403.04757v1"}
{"created":"2024-03-07 18:55:30","title":"That's My Point: Compact Object-centric LiDAR Pose Estimation for Large-scale Outdoor Localisation","abstract":"This paper is about 3D pose estimation on LiDAR scans with extremely minimal storage requirements to enable scalable mapping and localisation. We achieve this by clustering all points of segmented scans into semantic objects and representing them only with their respective centroid and semantic class. In this way, each LiDAR scan is reduced to a compact collection of four-number vectors. This abstracts away important structural information from the scenes, which is crucial for traditional registration approaches. To mitigate this, we introduce an object-matching network based on self- and cross-correlation that captures geometric and semantic relationships between entities. The respective matches allow us to recover the relative transformation between scans through weighted Singular Value Decomposition (SVD) and RANdom SAmple Consensus (RANSAC). We demonstrate that such representation is sufficient for metric localisation by registering point clouds taken under different viewpoints on the KITTI dataset, and at different periods of time localising between KITTI and KITTI-360. We achieve accurate metric estimates comparable with state-of-the-art methods with almost half the representation size, specifically 1.33 kB on average.","sentences":["This paper is about 3D pose estimation on LiDAR scans with extremely minimal storage requirements to enable scalable mapping and localisation.","We achieve this by clustering all points of segmented scans into semantic objects and representing them only with their respective centroid and semantic class.","In this way, each LiDAR scan is reduced to a compact collection of four-number vectors.","This abstracts away important structural information from the scenes, which is crucial for traditional registration approaches.","To mitigate this, we introduce an object-matching network based on self- and cross-correlation that captures geometric and semantic relationships between entities.","The respective matches allow us to recover the relative transformation between scans through weighted Singular Value Decomposition (SVD) and RANdom SAmple Consensus (RANSAC).","We demonstrate that such representation is sufficient for metric localisation by registering point clouds taken under different viewpoints on the KITTI dataset, and at different periods of time localising between KITTI and KITTI-360.","We achieve accurate metric estimates comparable with state-of-the-art methods with almost half the representation size, specifically 1.33 kB on average."],"url":"http://arxiv.org/abs/2403.04755v1"}
{"created":"2024-03-07 18:54:59","title":"Mechanism for Decision-aware Collaborative Federated Learning: A Pitfall of Shapley Values","abstract":"This paper investigates mechanism design for decision-aware collaboration via federated learning (FL) platforms. Our framework consists of a digital platform and multiple decision-aware agents, each endowed with proprietary data sets. The platform offers an infrastructure that enables access to the data, creates incentives for collaborative learning aimed at operational decision-making, and conducts FL to avoid direct raw data sharing. The computation and communication efficiency of the FL process is inherently influenced by the agent participation equilibrium induced by the mechanism. Therefore, assessing the system's efficiency involves two critical factors: the surplus created by coalition formation and the communication costs incurred across the coalition during FL. To evaluate the system efficiency under the intricate interplay between mechanism design, agent participation, operational decision-making, and the performance of FL algorithms, we introduce a multi-action collaborative federated learning (MCFL) framework for decision-aware agents. Under this framework, we further analyze the equilibrium for the renowned Shapley value based mechanisms. Specifically, we examine the issue of false-name manipulation, a form of dishonest behavior where participating agents create duplicate fake identities to split their original data among these identities. By solving the agent participation equilibrium, we demonstrate that while Shapley value effectively maximizes coalition-generated surplus by encouraging full participation, it inadvertently promotes false-name manipulation. This further significantly increases the communication costs when the platform conducts FL. Thus, we highlight a significant pitfall of Shapley value based mechanisms, which implicitly incentivizes data splitting and identity duplication, ultimately impairing the overall efficiency in FL systems.","sentences":["This paper investigates mechanism design for decision-aware collaboration via federated learning (FL) platforms.","Our framework consists of a digital platform and multiple decision-aware agents, each endowed with proprietary data sets.","The platform offers an infrastructure that enables access to the data, creates incentives for collaborative learning aimed at operational decision-making, and conducts FL to avoid direct raw data sharing.","The computation and communication efficiency of the FL process is inherently influenced by the agent participation equilibrium induced by the mechanism.","Therefore, assessing the system's efficiency involves two critical factors: the surplus created by coalition formation and the communication costs incurred across the coalition during FL.","To evaluate the system efficiency under the intricate interplay between mechanism design, agent participation, operational decision-making, and the performance of FL algorithms, we introduce a multi-action collaborative federated learning (MCFL) framework for decision-aware agents.","Under this framework, we further analyze the equilibrium for the renowned Shapley value based mechanisms.","Specifically, we examine the issue of false-name manipulation, a form of dishonest behavior where participating agents create duplicate fake identities to split their original data among these identities.","By solving the agent participation equilibrium, we demonstrate that while Shapley value effectively maximizes coalition-generated surplus by encouraging full participation, it inadvertently promotes false-name manipulation.","This further significantly increases the communication costs when the platform conducts FL.","Thus, we highlight a significant pitfall of Shapley value based mechanisms, which implicitly incentivizes data splitting and identity duplication, ultimately impairing the overall efficiency in FL systems."],"url":"http://arxiv.org/abs/2403.04753v1"}
{"created":"2024-03-07 18:52:27","title":"GNN-VPA: A Variance-Preserving Aggregation Strategy for Graph Neural Networks","abstract":"Graph neural networks (GNNs), and especially message-passing neural networks, excel in various domains such as physics, drug discovery, and molecular modeling. The expressivity of GNNs with respect to their ability to discriminate non-isomorphic graphs critically depends on the functions employed for message aggregation and graph-level readout. By applying signal propagation theory, we propose a variance-preserving aggregation function (VPA) that maintains expressivity, but yields improved forward and backward dynamics. Experiments demonstrate that VPA leads to increased predictive performance for popular GNN architectures as well as improved learning dynamics. Our results could pave the way towards normalizer-free or self-normalizing GNNs.","sentences":["Graph neural networks (GNNs), and especially message-passing neural networks, excel in various domains such as physics, drug discovery, and molecular modeling.","The expressivity of GNNs with respect to their ability to discriminate non-isomorphic graphs critically depends on the functions employed for message aggregation and graph-level readout.","By applying signal propagation theory, we propose a variance-preserving aggregation function (VPA) that maintains expressivity, but yields improved forward and backward dynamics.","Experiments demonstrate that VPA leads to increased predictive performance for popular GNN architectures as well as improved learning dynamics.","Our results could pave the way towards normalizer-free or self-normalizing GNNs."],"url":"http://arxiv.org/abs/2403.04747v1"}
{"created":"2024-03-07 18:50:51","title":"LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error","abstract":"Tools are essential for large language models (LLMs) to acquire up-to-date information and take consequential actions in external environments. Existing work on tool-augmented LLMs primarily focuses on the broad coverage of tools and the flexibility of adding new tools. However, a critical aspect that has surprisingly been understudied is simply how accurately an LLM uses tools for which it has been trained. We find that existing LLMs, including GPT-4 and open-source LLMs specifically fine-tuned for tool use, only reach a correctness rate in the range of 30% to 60%, far from reliable use in practice. We propose a biologically inspired method for tool-augmented LLMs, simulated trial and error (STE), that orchestrates three key mechanisms for successful tool use behaviors in the biological system: trial and error, imagination, and memory. Specifically, STE leverages an LLM's 'imagination' to simulate plausible scenarios for using a tool, after which the LLM interacts with the tool to learn from its execution feedback. Both short-term and long-term memory are employed to improve the depth and breadth of the exploration, respectively. Comprehensive experiments on ToolBench show that STE substantially improves tool learning for LLMs under both in-context learning and fine-tuning settings, bringing a boost of 46.7% to Mistral-Instruct-7B and enabling it to outperform GPT-4. We also show effective continual learning of tools via a simple experience replay strategy.","sentences":["Tools are essential for large language models (LLMs) to acquire up-to-date information and take consequential actions in external environments.","Existing work on tool-augmented LLMs primarily focuses on the broad coverage of tools and the flexibility of adding new tools.","However, a critical aspect that has surprisingly been understudied is simply how accurately an LLM uses tools for which it has been trained.","We find that existing LLMs, including GPT-4 and open-source LLMs specifically fine-tuned for tool use, only reach a correctness rate in the range of 30% to 60%, far from reliable use in practice.","We propose a biologically inspired method for tool-augmented LLMs, simulated trial and error (STE), that orchestrates three key mechanisms for successful tool use behaviors in the biological system: trial and error, imagination, and memory.","Specifically, STE leverages an LLM's 'imagination' to simulate plausible scenarios for using a tool, after which the LLM interacts with the tool to learn from its execution feedback.","Both short-term and long-term memory are employed to improve the depth and breadth of the exploration, respectively.","Comprehensive experiments on ToolBench show that STE substantially improves tool learning for LLMs under both in-context learning and fine-tuning settings, bringing a boost of 46.7% to Mistral-Instruct-7B and enabling it to outperform GPT-4.","We also show effective continual learning of tools via a simple experience replay strategy."],"url":"http://arxiv.org/abs/2403.04746v1"}
{"created":"2024-03-07 18:49:36","title":"A General Calibrated Regret Metric for Detecting and Mitigating Human-Robot Interaction Failures","abstract":"Robot decision-making increasingly relies on expressive data-driven human prediction models when operating around people. While these models are known to suffer from prediction errors in out-of-distribution interactions, not all prediction errors equally impact downstream robot performance. We identify that the mathematical notion of regret precisely characterizes the degree to which incorrect predictions of future interaction outcomes degraded closed-loop robot performance. However, canonical regret measures are poorly calibrated across diverse deployment interactions. We extend the canonical notion of regret by deriving a calibrated regret metric that generalizes from absolute reward space to probability space. With this transformation, our metric removes the need for explicit reward functions to calculate the robot's regret, enables fairer comparison of interaction anomalies across disparate deployment contexts, and facilitates targetted dataset construction of \"system- level\" prediction failures. We experimentally quantify the value of this high-regret interaction data for aiding the robot in improving its downstream decision-making. In a suite of closed- loop autonomous driving simulations, we find that fine-tuning ego-conditioned behavior predictors exclusively on high-regret human-robot interaction data can improve the robot's overall re-deployment performance with significantly (77%) less data.","sentences":["Robot decision-making increasingly relies on expressive data-driven human prediction models when operating around people.","While these models are known to suffer from prediction errors in out-of-distribution interactions, not all prediction errors equally impact downstream robot performance.","We identify that the mathematical notion of regret precisely characterizes the degree to which incorrect predictions of future interaction outcomes degraded closed-loop robot performance.","However, canonical regret measures are poorly calibrated across diverse deployment interactions.","We extend the canonical notion of regret by deriving a calibrated regret metric that generalizes from absolute reward space to probability space.","With this transformation, our metric removes the need for explicit reward functions to calculate the robot's regret, enables fairer comparison of interaction anomalies across disparate deployment contexts, and facilitates targetted dataset construction of \"system- level\" prediction failures.","We experimentally quantify the value of this high-regret interaction data for aiding the robot in improving its downstream decision-making.","In a suite of closed- loop autonomous driving simulations, we find that fine-tuning ego-conditioned behavior predictors exclusively on high-regret human-robot interaction data can improve the robot's overall re-deployment performance with significantly (77%) less data."],"url":"http://arxiv.org/abs/2403.04745v1"}
{"created":"2024-03-07 18:49:32","title":"SQ Lower Bounds for Non-Gaussian Component Analysis with Weaker Assumptions","abstract":"We study the complexity of Non-Gaussian Component Analysis (NGCA) in the Statistical Query (SQ) model. Prior work developed a general methodology to prove SQ lower bounds for this task that have been applicable to a wide range of contexts. In particular, it was known that for any univariate distribution $A$ satisfying certain conditions, distinguishing between a standard multivariate Gaussian and a distribution that behaves like $A$ in a random hidden direction and like a standard Gaussian in the orthogonal complement, is SQ-hard. The required conditions were that (1) $A$ matches many low-order moments with the standard univariate Gaussian, and (2) the chi-squared norm of $A$ with respect to the standard Gaussian is finite. While the moment-matching condition is necessary for hardness, the chi-squared condition was only required for technical reasons. In this work, we establish that the latter condition is indeed not necessary. In particular, we prove near-optimal SQ lower bounds for NGCA under the moment-matching condition only. Our result naturally generalizes to the setting of a hidden subspace. Leveraging our general SQ lower bound, we obtain near-optimal SQ lower bounds for a range of concrete estimation tasks where existing techniques provide sub-optimal or even vacuous guarantees.","sentences":["We study the complexity of Non-Gaussian Component Analysis (NGCA) in the Statistical Query (SQ) model.","Prior work developed a general methodology to prove SQ lower bounds for this task that have been applicable to a wide range of contexts.","In particular, it was known that for any univariate distribution $A$ satisfying certain conditions, distinguishing between a standard multivariate Gaussian and a distribution that behaves like $A$ in a random hidden direction and like a standard Gaussian in the orthogonal complement, is SQ-hard.","The required conditions were that (1) $A$ matches many low-order moments with the standard univariate Gaussian, and (2) the chi-squared norm of $A$ with respect to the standard Gaussian is finite.","While the moment-matching condition is necessary for hardness, the chi-squared condition was only required for technical reasons.","In this work, we establish that the latter condition is indeed not necessary.","In particular, we prove near-optimal SQ lower bounds for NGCA under the moment-matching condition only.","Our result naturally generalizes to the setting of a hidden subspace.","Leveraging our general SQ lower bound, we obtain near-optimal SQ lower bounds for a range of concrete estimation tasks where existing techniques provide sub-optimal or even vacuous guarantees."],"url":"http://arxiv.org/abs/2403.04744v1"}
{"created":"2024-03-07 18:46:01","title":"I Can't Believe It's Not Scene Flow!","abstract":"Current scene flow methods broadly fail to describe motion on small objects, and current scene flow evaluation protocols hide this failure by averaging over many points, with most drawn larger objects. To fix this evaluation failure, we propose a new evaluation protocol, Bucket Normalized EPE, which is class-aware and speed-normalized, enabling contextualized error comparisons between object types that move at vastly different speeds. To highlight current method failures, we propose a frustratingly simple supervised scene flow baseline, TrackFlow, built by bolting a high-quality pretrained detector (trained using many class rebalancing techniques) onto a simple tracker, that produces state-of-the-art performance on current standard evaluations and large improvements over prior art on our new evaluation. Our results make it clear that all scene flow evaluations must be class and speed aware, and supervised scene flow methods must address point class imbalances. We release the evaluation code publicly at https://github.com/kylevedder/BucketedSceneFlowEval.","sentences":["Current scene flow methods broadly fail to describe motion on small objects, and current scene flow evaluation protocols hide this failure by averaging over many points, with most drawn larger objects.","To fix this evaluation failure, we propose a new evaluation protocol, Bucket Normalized EPE, which is class-aware and speed-normalized, enabling contextualized error comparisons between object types that move at vastly different speeds.","To highlight current method failures, we propose a frustratingly simple supervised scene flow baseline, TrackFlow, built by bolting a high-quality pretrained detector (trained using many class rebalancing techniques) onto a simple tracker, that produces state-of-the-art performance on current standard evaluations and large improvements over prior art on our new evaluation.","Our results make it clear that all scene flow evaluations must be class and speed aware, and supervised scene flow methods must address point class imbalances.","We release the evaluation code publicly at https://github.com/kylevedder/BucketedSceneFlowEval."],"url":"http://arxiv.org/abs/2403.04739v1"}
{"created":"2024-03-07 18:38:47","title":"Benchmarking News Recommendation in the Era of Green AI","abstract":"Over recent years, news recommender systems have gained significant attention in both academia and industry, emphasizing the need for a standardized benchmark to evaluate and compare the performance of these systems. Concurrently, Green AI advocates for reducing the energy consumption and environmental impact of machine learning. To address these concerns, we introduce the first Green AI benchmarking framework for news recommendation, known as GreenRec, and propose a metric for assessing the tradeoff between recommendation accuracy and efficiency. Our benchmark encompasses 30 base models and their variants, covering traditional end-to-end training paradigms as well as our proposed efficient only-encode-once (OLEO) paradigm. Through experiments consuming 2000 GPU hours, we observe that the OLEO paradigm achieves competitive accuracy compared to state-of-the-art end-to-end paradigms and delivers up to a 2992\\% improvement in sustainability metrics.","sentences":["Over recent years, news recommender systems have gained significant attention in both academia and industry, emphasizing the need for a standardized benchmark to evaluate and compare the performance of these systems.","Concurrently, Green AI advocates for reducing the energy consumption and environmental impact of machine learning.","To address these concerns, we introduce the first Green AI benchmarking framework for news recommendation, known as GreenRec, and propose a metric for assessing the tradeoff between recommendation accuracy and efficiency.","Our benchmark encompasses 30 base models and their variants, covering traditional end-to-end training paradigms as well as our proposed efficient only-encode-once (OLEO) paradigm.","Through experiments consuming 2000 GPU hours, we observe that the OLEO paradigm achieves competitive accuracy compared to state-of-the-art end-to-end paradigms and delivers up to a 2992\\% improvement in sustainability metrics."],"url":"http://arxiv.org/abs/2403.04736v1"}
{"created":"2024-03-07 18:38:17","title":"SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM","abstract":"Vision-extended LLMs have made significant strides in Visual Question Answering (VQA). Despite these advancements, VLLMs still encounter substantial difficulties in handling queries involving long-tail entities, with a tendency to produce erroneous or hallucinated responses. In this work, we introduce a novel evaluative benchmark named \\textbf{SnapNTell}, specifically tailored for entity-centric VQA. This task aims to test the models' capabilities in identifying entities and providing detailed, entity-specific knowledge. We have developed the \\textbf{SnapNTell Dataset}, distinct from traditional VQA datasets: (1) It encompasses a wide range of categorized entities, each represented by images and explicitly named in the answers; (2) It features QA pairs that require extensive knowledge for accurate responses. The dataset is organized into 22 major categories, containing 7,568 unique entities in total. For each entity, we curated 10 illustrative images and crafted 10 knowledge-intensive QA pairs. To address this novel task, we devised a scalable, efficient, and transparent retrieval-augmented multimodal LLM. Our approach markedly outperforms existing methods on the SnapNTell dataset, achieving a 66.5\\% improvement in the BELURT score. We will soon make the dataset and the source code publicly accessible.","sentences":["Vision-extended LLMs have made significant strides in Visual Question Answering (VQA).","Despite these advancements, VLLMs still encounter substantial difficulties in handling queries involving long-tail entities, with a tendency to produce erroneous or hallucinated responses.","In this work, we introduce a novel evaluative benchmark named \\textbf{SnapNTell}, specifically tailored for entity-centric VQA.","This task aims to test the models' capabilities in identifying entities and providing detailed, entity-specific knowledge.","We have developed the \\textbf{SnapNTell Dataset}, distinct from traditional VQA datasets: (1) It encompasses a wide range of categorized entities, each represented by images and explicitly named in the answers; (2) It features QA pairs that require extensive knowledge for accurate responses.","The dataset is organized into 22 major categories, containing 7,568 unique entities in total.","For each entity, we curated 10 illustrative images and crafted 10 knowledge-intensive QA pairs.","To address this novel task, we devised a scalable, efficient, and transparent retrieval-augmented multimodal LLM.","Our approach markedly outperforms existing methods on the SnapNTell dataset, achieving a 66.5\\% improvement in the BELURT score.","We will soon make the dataset and the source code publicly accessible."],"url":"http://arxiv.org/abs/2403.04735v1"}
{"created":"2024-03-07 18:35:54","title":"How Far Are We from Intelligent Visual Deductive Reasoning?","abstract":"Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated incredible strides on diverse vision language tasks. We dig into vision-based deductive reasoning, a more sophisticated but less explored realm, and find previously unexposed blindspots in the current SOTA VLMs. Specifically, we leverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to perform multi-hop relational and deductive reasoning relying solely on visual clues. We perform comprehensive evaluations of several popular VLMs employing standard strategies such as in-context learning, self-consistency, and Chain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test, IntelligenceTest, and RAVEN. The results reveal that despite the impressive capabilities of LLMs in text-based reasoning, we are still far from achieving comparable proficiency in visual deductive reasoning. We found that certain standard strategies that are effective when applied to LLMs do not seamlessly translate to the challenges presented by visual reasoning tasks. Moreover, a detailed analysis reveals that VLMs struggle to solve these tasks mainly because they are unable to perceive and comprehend multiple, confounding abstract patterns in RPM examples.","sentences":["Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated incredible strides on diverse vision language tasks.","We dig into vision-based deductive reasoning, a more sophisticated but less explored realm, and find previously unexposed blindspots in the current SOTA VLMs.","Specifically, we leverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to perform multi-hop relational and deductive reasoning relying solely on visual clues.","We perform comprehensive evaluations of several popular VLMs employing standard strategies such as in-context learning, self-consistency, and Chain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test, IntelligenceTest, and RAVEN.","The results reveal that despite the impressive capabilities of LLMs in text-based reasoning, we are still far from achieving comparable proficiency in visual deductive reasoning.","We found that certain standard strategies that are effective when applied to LLMs do not seamlessly translate to the challenges presented by visual reasoning tasks.","Moreover, a detailed analysis reveals that VLMs struggle to solve these tasks mainly because they are unable to perceive and comprehend multiple, confounding abstract patterns in RPM examples."],"url":"http://arxiv.org/abs/2403.04732v1"}
{"created":"2024-03-07 18:31:32","title":"Stretchable Pneumatic Sleeve for Adaptable, Low-Displacement Anchoring in Exosuits","abstract":"Despite recent advances in wearable technology, interfacing movement assistance devices with the human body remains challenging. We present a stretchable pneumatic sleeve that can anchor an exosuit actuator to the human arm with a low displacement of the actuator's mounting point relative to the body during operation. Our sleeve has the potential to serve as an adaptable attachment mechanism for exosuits, since it can adjust its pressure to only compress the arm as much as needed to transmit the applied exosuit forces without a large displacement. We discuss the design of our sleeve, which is made of fabric pneumatic artificial muscle (fPAM) actuators formed into bands. We quantify the performance of nine fPAM bands of various lengths and widths, as well as three sleeves (an fPAM sleeve, a series pouch motor (SPM) sleeve as in previous literature, and an off the shelf hook and loop sleeve), through the measurement of the compressing force as a function of pressure and the localized pulling force that can be resisted as a function of both pressure and mounting point displacement. Our experimental results show that fPAM bands with smaller resting length and/or larger resting width produce higher forces. Also, when inflated, an fPAM sleeve that has equivalent dimensions to the SPM sleeve while fully stretched has similar performance to the SPM sleeve. While inflated, both pneumatic sleeves decrease the mounting point displacement compared to the hook and loop sleeve. Compared to the SPM sleeve, the fPAM sleeve is able to hold larger internal pressure before bursting, increasing its possible force range. Also, when not inflated, the fPAM sleeve resists the pulling force well, indicating its ability to provide anchoring when not actuated.","sentences":["Despite recent advances in wearable technology, interfacing movement assistance devices with the human body remains challenging.","We present a stretchable pneumatic sleeve that can anchor an exosuit actuator to the human arm with a low displacement of the actuator's mounting point relative to the body during operation.","Our sleeve has the potential to serve as an adaptable attachment mechanism for exosuits, since it can adjust its pressure to only compress the arm as much as needed to transmit the applied exosuit forces without a large displacement.","We discuss the design of our sleeve, which is made of fabric pneumatic artificial muscle (fPAM) actuators formed into bands.","We quantify the performance of nine fPAM bands of various lengths and widths, as well as three sleeves (an fPAM sleeve, a series pouch motor (SPM) sleeve as in previous literature, and an off the shelf hook and loop sleeve), through the measurement of the compressing force as a function of pressure and the localized pulling force that can be resisted as a function of both pressure and mounting point displacement.","Our experimental results show that fPAM bands with smaller resting length and/or larger resting width produce higher forces.","Also, when inflated, an fPAM sleeve that has equivalent dimensions to the SPM sleeve while fully stretched has similar performance to the SPM sleeve.","While inflated, both pneumatic sleeves decrease the mounting point displacement compared to the hook and loop sleeve.","Compared to the SPM sleeve, the fPAM sleeve is able to hold larger internal pressure before bursting, increasing its possible force range.","Also, when not inflated, the fPAM sleeve resists the pulling force well, indicating its ability to provide anchoring when not actuated."],"url":"http://arxiv.org/abs/2403.04729v1"}
{"created":"2024-03-07 18:23:51","title":"A Sub-Quadratic Time Algorithm for Robust Sparse Mean Estimation","abstract":"We study the algorithmic problem of sparse mean estimation in the presence of adversarial outliers. Specifically, the algorithm observes a \\emph{corrupted} set of samples from $\\mathcal{N}(\\mu,\\mathbf{I}_d)$, where the unknown mean $\\mu \\in \\mathbb{R}^d$ is constrained to be $k$-sparse. A series of prior works has developed efficient algorithms for robust sparse mean estimation with sample complexity $\\mathrm{poly}(k,\\log d, 1/\\epsilon)$ and runtime $d^2 \\mathrm{poly}(k,\\log d,1/\\epsilon)$, where $\\epsilon$ is the fraction of contamination. In particular, the fastest runtime of existing algorithms is quadratic ($\\Omega(d^2)$), which can be prohibitive in high dimensions. This quadratic barrier in the runtime stems from the reliance of these algorithms on the sample covariance matrix, which is of size $d^2$. Our main contribution is an algorithm for robust sparse mean estimation which runs in \\emph{subquadratic} time using $\\mathrm{poly}(k,\\log d,1/\\epsilon)$ samples. We also provide analogous results for robust sparse PCA. Our results build on algorithmic advances in detecting weak correlations, a generalized version of the light-bulb problem by Valiant.","sentences":["We study the algorithmic problem of sparse mean estimation in the presence of adversarial outliers.","Specifically, the algorithm observes a \\emph{corrupted} set of samples from $\\mathcal{N}(\\mu,\\mathbf{I}_d)$, where the unknown mean $\\mu \\in \\mathbb{R}^d$ is constrained to be $k$-sparse.","A series of prior works has developed efficient algorithms for robust sparse mean estimation with sample complexity $\\mathrm{poly}(k,\\log d, 1/\\epsilon)$ and runtime $d^2 \\mathrm{poly}(k,\\log d,1/\\epsilon)$, where $\\epsilon$ is the fraction of contamination.","In particular, the fastest runtime of existing algorithms is quadratic ($\\Omega(d^2)$), which can be prohibitive in high dimensions.","This quadratic barrier in the runtime stems from the reliance of these algorithms on the sample covariance matrix, which is of size $d^2$. Our main contribution is an algorithm for robust sparse mean estimation which runs in \\emph{subquadratic} time using $\\mathrm{poly}(k,\\log d,1/\\epsilon)$ samples.","We also provide analogous results for robust sparse PCA.","Our results build on algorithmic advances in detecting weak correlations, a generalized version of the light-bulb problem by Valiant."],"url":"http://arxiv.org/abs/2403.04726v1"}
{"created":"2024-03-07 18:22:03","title":"Masked Capsule Autoencoders","abstract":"We propose Masked Capsule Autoencoders (MCAE), the first Capsule Network that utilises pretraining in a self-supervised manner. Capsule Networks have emerged as a powerful alternative to Convolutional Neural Networks (CNNs), and have shown favourable properties when compared to Vision Transformers (ViT), but have struggled to effectively learn when presented with more complex data, leading to Capsule Network models that do not scale to modern tasks. Our proposed MCAE model alleviates this issue by reformulating the Capsule Network to use masked image modelling as a pretraining stage before finetuning in a supervised manner. Across several experiments and ablations studies we demonstrate that similarly to CNNs and ViTs, Capsule Networks can also benefit from self-supervised pretraining, paving the way for further advancements in this neural network domain. For instance, pretraining on the Imagenette dataset, a dataset of 10 classes of Imagenet-sized images, we achieve not only state-of-the-art results for Capsule Networks but also a 9% improvement compared to purely supervised training. Thus we propose that Capsule Networks benefit from and should be trained within a masked image modelling framework, with a novel capsule decoder, to improve a Capsule Network's performance on realistic-sized images.","sentences":["We propose Masked Capsule Autoencoders (MCAE), the first Capsule Network that utilises pretraining in a self-supervised manner.","Capsule Networks have emerged as a powerful alternative to Convolutional Neural Networks (CNNs), and have shown favourable properties when compared to Vision Transformers (ViT), but have struggled to effectively learn when presented with more complex data, leading to Capsule Network models that do not scale to modern tasks.","Our proposed MCAE model alleviates this issue by reformulating the Capsule Network to use masked image modelling as a pretraining stage before finetuning in a supervised manner.","Across several experiments and ablations studies we demonstrate that similarly to CNNs and ViTs, Capsule Networks can also benefit from self-supervised pretraining, paving the way for further advancements in this neural network domain.","For instance, pretraining on the Imagenette dataset, a dataset of 10 classes of Imagenet-sized images, we achieve not only state-of-the-art results for Capsule Networks but also a 9% improvement compared to purely supervised training.","Thus we propose that Capsule Networks benefit from and should be trained within a masked image modelling framework, with a novel capsule decoder, to improve a Capsule Network's performance on realistic-sized images."],"url":"http://arxiv.org/abs/2403.04724v1"}
{"created":"2024-03-07 18:16:29","title":"Rethinking of Encoder-based Warm-start Methods in Hyperparameter Optimization","abstract":"Effectively representing heterogeneous tabular datasets for meta-learning remains an open problem. Previous approaches rely on predefined meta-features, for example, statistical measures or landmarkers. Encoder-based models, such as Dataset2Vec, allow us to extract significant meta-features automatically without human intervention. This research introduces a novel encoder-based representation of tabular datasets implemented within the liltab package available on GitHub https://github.com/azoz01/liltab. Our package is based on an established model for heterogeneous tabular data proposed in [Iwata and Kumagai, 2020]. The proposed approach employs a different model for encoding feature relationships, generating alternative representations compared to existing methods like Dataset2Vec. Both of them leverage the fundamental assumption of dataset similarity learning. In this work, we evaluate Dataset2Vec and liltab on two common meta-tasks - representing entire datasets and hyperparameter optimization warm-start. However, validation on an independent metaMIMIC dataset highlights the nuanced challenges in representation learning. We show that general representations may not suffice for some meta-tasks where requirements are not explicitly considered during extraction.   [Iwata and Kumagai, 2020] Tomoharu Iwata and Atsutoshi Kumagai. Meta-learning from Tasks with Heterogeneous Attribute Spaces. In Advances in Neural Information Processing Systems, 2020.","sentences":["Effectively representing heterogeneous tabular datasets for meta-learning remains an open problem.","Previous approaches rely on predefined meta-features, for example, statistical measures or landmarkers.","Encoder-based models, such as Dataset2Vec, allow us to extract significant meta-features automatically without human intervention.","This research introduces a novel encoder-based representation of tabular datasets implemented within the liltab package available on GitHub https://github.com/azoz01/liltab.","Our package is based on an established model for heterogeneous tabular data proposed in [Iwata and Kumagai, 2020].","The proposed approach employs a different model for encoding feature relationships, generating alternative representations compared to existing methods like Dataset2Vec.","Both of them leverage the fundamental assumption of dataset similarity learning.","In this work, we evaluate Dataset2Vec and liltab on two common meta-tasks - representing entire datasets and hyperparameter optimization warm-start.","However, validation on an independent metaMIMIC dataset highlights the nuanced challenges in representation learning.","We show that general representations may not suffice for some meta-tasks where requirements are not explicitly considered during extraction.   ","[Iwata and Kumagai, 2020]","Tomoharu Iwata and Atsutoshi Kumagai.","Meta-learning from Tasks with Heterogeneous Attribute Spaces.","In Advances in Neural Information Processing Systems, 2020."],"url":"http://arxiv.org/abs/2403.04720v1"}
{"created":"2024-03-07 18:14:52","title":"Literature Review of Current Sustainability Assessment Frameworks and Approaches for Organizations","abstract":"This systematic literature review explores sustainability assessment frameworks (SAFs) across diverse industries. The review focuses on SAF design approaches including the methods used for Sustainability Indicator (SI) selection, relative importance assessment, and interdependency analysis. Various methods, including literature reviews, stakeholder interviews, questionnaires, Pareto analysis, SMART approach, and adherence to sustainability standards, contribute to the complex SI selection process. Fuzzy-AHP stands out as a robust technique for assessing relative SI importance. While dynamic sustainability and performance indices are essential, methods like DEMATEL, VIKOR, correlation analysis, and causal models for interdependency assessment exhibit static limitations. The review presents strengths and limitations of SAFs, addressing gaps in design approaches and contributing to a comprehensive understanding. The insights of this review aim to benefit policymakers, administrators, leaders, and researchers, fostering sustainability practices. Future research recommendations include exploring multi-criteria decision-making models and hybrid approaches, extending sustainability evaluation across organizational levels and supply chains. Emphasizing adaptability to industry specifics and dynamic global adjustments is proposed for holistic sustainability practices, further enhancing organizational sustainability.","sentences":["This systematic literature review explores sustainability assessment frameworks (SAFs) across diverse industries.","The review focuses on SAF design approaches including the methods used for Sustainability Indicator (SI) selection, relative importance assessment, and interdependency analysis.","Various methods, including literature reviews, stakeholder interviews, questionnaires, Pareto analysis, SMART approach, and adherence to sustainability standards, contribute to the complex SI selection process.","Fuzzy-AHP stands out as a robust technique for assessing relative SI importance.","While dynamic sustainability and performance indices are essential, methods like DEMATEL, VIKOR, correlation analysis, and causal models for interdependency assessment exhibit static limitations.","The review presents strengths and limitations of SAFs, addressing gaps in design approaches and contributing to a comprehensive understanding.","The insights of this review aim to benefit policymakers, administrators, leaders, and researchers, fostering sustainability practices.","Future research recommendations include exploring multi-criteria decision-making models and hybrid approaches, extending sustainability evaluation across organizational levels and supply chains.","Emphasizing adaptability to industry specifics and dynamic global adjustments is proposed for holistic sustainability practices, further enhancing organizational sustainability."],"url":"http://arxiv.org/abs/2403.04717v1"}
{"created":"2024-03-07 18:14:02","title":"QRtree - Decision Tree dialect specification of QRscript","abstract":"This specification document specifies the syntax and semantics of QRtree, which is a specific dialect of QRscript particularly suited to represent decision trees without chance nodes. The term dialect identifies one of the possible sub-languages that can be encoded inside of an eQR code via QRscript. This specification will describe an intermediate representation of QRtree, made through a language derived by the three-address code. It will then define the transformation rules from the intermediate representation to a binary code. The latter is a binary representation called eQRtreebytecode. These rules can also be applied inversely to transform the eQRtreeBytecode into the intermediate representation. This specification document will pay particular attention to the creation of a compact eQRtreebytecode, as the maximum number of bits that can be stored in a QR code is, at the time of writing, equal to 2953 bytes (in the case of QR code version 40 with a \"low\" error correction level).","sentences":["This specification document specifies the syntax and semantics of QRtree, which is a specific dialect of QRscript particularly suited to represent decision trees without chance nodes.","The term dialect identifies one of the possible sub-languages that can be encoded inside of an eQR code via QRscript.","This specification will describe an intermediate representation of QRtree, made through a language derived by the three-address code.","It will then define the transformation rules from the intermediate representation to a binary code.","The latter is a binary representation called eQRtreebytecode.","These rules can also be applied inversely to transform the eQRtreeBytecode into the intermediate representation.","This specification document will pay particular attention to the creation of a compact eQRtreebytecode, as the maximum number of bits that can be stored in a QR code is, at the time of writing, equal to 2953 bytes (in the case of QR code version 40 with a \"low\" error correction level)."],"url":"http://arxiv.org/abs/2403.04716v1"}
{"created":"2024-03-07 18:09:59","title":"Parendi: Thousand-Way Parallel RTL Simulation","abstract":"Hardware development relies on simulations, particularly cycle-accurate RTL (Register Transfer Level) simulations, which consume significant time. As single-processor performance grows only slowly, conventional, single-threaded RTL simulation is becoming less practical for increasingly complex chips and systems. A solution is parallel RTL simulation, where ideally, simulators could run on thousands of parallel cores. However, existing simulators can only exploit tens of cores.   This paper studies the challenges inherent in running parallel RTL simulation on a multi-thousand-core machine (the Graphcore IPU, a 1472-core machine). Simulation performance requires balancing three factors: synchronization, communication, and computation. We experimentally evaluate each metric and analyze how it affects parallel simulation speed, drawing on contrasts between the large-scale IPU and smaller but faster x86 systems.   Using this analysis, we build Parendi, an RTL simulator for the IPU. It distributes RTL simulation across 5888 cores on 4 IPU sockets. Parendi runs large RTL designs up to 4x faster than a powerful, state-of-the-art x86 multicore system.","sentences":["Hardware development relies on simulations, particularly cycle-accurate RTL (Register Transfer Level) simulations, which consume significant time.","As single-processor performance grows only slowly, conventional, single-threaded RTL simulation is becoming less practical for increasingly complex chips and systems.","A solution is parallel RTL simulation, where ideally, simulators could run on thousands of parallel cores.","However, existing simulators can only exploit tens of cores.   ","This paper studies the challenges inherent in running parallel RTL simulation on a multi-thousand-core machine (the Graphcore IPU, a 1472-core machine).","Simulation performance requires balancing three factors: synchronization, communication, and computation.","We experimentally evaluate each metric and analyze how it affects parallel simulation speed, drawing on contrasts between the large-scale IPU and smaller but faster x86 systems.   ","Using this analysis, we build Parendi, an RTL simulator for the IPU.","It distributes RTL simulation across 5888 cores on 4 IPU sockets.","Parendi runs large RTL designs up to 4x faster than a powerful, state-of-the-art x86 multicore system."],"url":"http://arxiv.org/abs/2403.04714v1"}
{"created":"2024-03-07 18:07:41","title":"GMKF: Generalized Moment Kalman Filter for Polynomial Systems with Arbitrary Noise","abstract":"This paper develops a new filtering approach for state estimation in polynomial systems corrupted by arbitrary noise, which commonly arise in robotics. We first consider a batch setup where we perform state estimation using all data collected from the initial to the current time. We formulate the batch state estimation problem as a Polynomial Optimization Problem (POP) and relax the assumption of Gaussian noise by specifying a finite number of moments of the noise. We solve the resulting POP using a moment relaxation and prove that under suitable conditions on the rank of the relaxation, (i) we can extract a provably optimal estimate from the moment relaxation, and (ii) we can obtain a belief representation from the dual (sum-of-squares) relaxation. We then turn our attention to the filtering setup and apply similar insights to develop a GMKF for recursive state estimation in polynomial systems with arbitrary noise. The GMKF formulates the prediction and update steps as POPs and solves them using moment relaxations, carrying over a possibly non-Gaussian belief. In the linear-Gaussian case, GMKF reduces to the standard Kalman Filter. We demonstrate that GMKF performs well under highly non-Gaussian noise and outperforms common alternatives, including the Extended and Unscented Kalman Filter, and their variants on matrix Lie group.","sentences":["This paper develops a new filtering approach for state estimation in polynomial systems corrupted by arbitrary noise, which commonly arise in robotics.","We first consider a batch setup where we perform state estimation using all data collected from the initial to the current time.","We formulate the batch state estimation problem as a Polynomial Optimization Problem (POP) and relax the assumption of Gaussian noise by specifying a finite number of moments of the noise.","We solve the resulting POP using a moment relaxation and prove that under suitable conditions on the rank of the relaxation, (i) we can extract a provably optimal estimate from the moment relaxation, and (ii) we can obtain a belief representation from the dual (sum-of-squares) relaxation.","We then turn our attention to the filtering setup and apply similar insights to develop a GMKF for recursive state estimation in polynomial systems with arbitrary noise.","The GMKF formulates the prediction and update steps as POPs and solves them using moment relaxations, carrying over a possibly non-Gaussian belief.","In the linear-Gaussian case, GMKF reduces to the standard Kalman Filter.","We demonstrate that GMKF performs well under highly non-Gaussian noise and outperforms common alternatives, including the Extended and Unscented Kalman Filter, and their variants on matrix Lie group."],"url":"http://arxiv.org/abs/2403.04712v1"}
{"created":"2024-03-07 18:02:27","title":"QRscript specification","abstract":"This specification document specifies the syntax and semantics of QRscript. The current document only shows the part related to the QRscript header, i.e., the first part of the binary code that must be inserted into the QR code. A QR code containing an executable code is called an executable QR code (eQR code). QRscript supports different dialects, i.e., sublanguages with implementation characteristics specific to the application field. The specifications of the individual dialects will be described in separate documents.","sentences":["This specification document specifies the syntax and semantics of QRscript.","The current document only shows the part related to the QRscript header, i.e., the first part of the binary code that must be inserted into the QR code.","A QR code containing an executable code is called an executable QR code (eQR code).","QRscript supports different dialects, i.e., sublanguages with implementation characteristics specific to the application field.","The specifications of the individual dialects will be described in separate documents."],"url":"http://arxiv.org/abs/2403.04708v1"}
{"created":"2024-03-07 18:00:40","title":"Common 7B Language Models Already Possess Strong Math Capabilities","abstract":"Mathematical capabilities were previously believed to emerge in common language models only at a very large scale or require extensive math-related pre-training. This paper shows that the LLaMA-2 7B model with common pre-training already exhibits strong mathematical abilities, as evidenced by its impressive accuracy of 97.7% and 72.0% on the GSM8K and MATH benchmarks, respectively, when selecting the best response from 256 random generations. The primary issue with the current base model is the difficulty in consistently eliciting its inherent mathematical capabilities. Notably, the accuracy for the first answer drops to 49.5% and 7.9% on the GSM8K and MATH benchmarks, respectively. We find that simply scaling up the SFT data can significantly enhance the reliability of generating correct answers. However, the potential for extensive scaling is constrained by the scarcity of publicly available math questions. To overcome this limitation, we employ synthetic data, which proves to be nearly as effective as real data and shows no clear saturation when scaled up to approximately one million samples. This straightforward approach achieves an accuracy of 82.6% on GSM8K and 40.6% on MATH using LLaMA-2 7B models, surpassing previous models by 14.2% and 20.8%, respectively. We also provide insights into scaling behaviors across different reasoning complexities and error types.","sentences":["Mathematical capabilities were previously believed to emerge in common language models only at a very large scale or require extensive math-related pre-training.","This paper shows that the LLaMA-2 7B model with common pre-training already exhibits strong mathematical abilities, as evidenced by its impressive accuracy of 97.7% and 72.0% on the GSM8K and MATH benchmarks, respectively, when selecting the best response from 256 random generations.","The primary issue with the current base model is the difficulty in consistently eliciting its inherent mathematical capabilities.","Notably, the accuracy for the first answer drops to 49.5% and 7.9% on the GSM8K and MATH benchmarks, respectively.","We find that simply scaling up the SFT data can significantly enhance the reliability of generating correct answers.","However, the potential for extensive scaling is constrained by the scarcity of publicly available math questions.","To overcome this limitation, we employ synthetic data, which proves to be nearly as effective as real data and shows no clear saturation when scaled up to approximately one million samples.","This straightforward approach achieves an accuracy of 82.6% on GSM8K and 40.6% on MATH using LLaMA-2 7B models, surpassing previous models by 14.2% and 20.8%, respectively.","We also provide insights into scaling behaviors across different reasoning complexities and error types."],"url":"http://arxiv.org/abs/2403.04706v1"}
{"created":"2024-03-07 17:53:37","title":"mmPlace: Robust Place Recognition with Intermediate Frequency Signal of Low-cost Single-chip Millimeter Wave Radar","abstract":"Place recognition is crucial for tasks like loop-closure detection and re-localization. Single-chip millimeter wave radar (single-chip radar in short) emerges as a low-cost sensor option for place recognition, with the advantage of insensitivity to degraded visual environments. However, it encounters two challenges. Firstly, sparse point cloud from single-chip radar leads to poor performance when using current place recognition methods, which assume much denser data. Secondly, its performance significantly declines in scenarios involving rotational and lateral variations, due to limited overlap in its field of view (FOV). We propose mmPlace, a robust place recognition system to address these challenges. Specifically, mmPlace transforms intermediate frequency (IF) signal into range azimuth heatmap and employs a spatial encoder to extract features. Additionally, to improve the performance in scenarios involving rotational and lateral variations, mmPlace employs a rotating platform and concatenates heatmaps in a rotation cycle, effectively expanding the system's FOV. We evaluate mmPlace's performance on the milliSonic dataset, which is collected on the University of Science and Technology of China (USTC) campus, the city roads surrounding the campus, and an underground parking garage. The results demonstrate that mmPlace outperforms point cloud-based methods and achieves 87.37% recall@1 in scenarios involving rotational and lateral variations.","sentences":["Place recognition is crucial for tasks like loop-closure detection and re-localization.","Single-chip millimeter wave radar (single-chip radar in short) emerges as a low-cost sensor option for place recognition, with the advantage of insensitivity to degraded visual environments.","However, it encounters two challenges.","Firstly, sparse point cloud from single-chip radar leads to poor performance when using current place recognition methods, which assume much denser data.","Secondly, its performance significantly declines in scenarios involving rotational and lateral variations, due to limited overlap in its field of view (FOV).","We propose mmPlace, a robust place recognition system to address these challenges.","Specifically, mmPlace transforms intermediate frequency (IF) signal into range azimuth heatmap and employs a spatial encoder to extract features.","Additionally, to improve the performance in scenarios involving rotational and lateral variations, mmPlace employs a rotating platform and concatenates heatmaps in a rotation cycle, effectively expanding the system's FOV.","We evaluate mmPlace's performance on the milliSonic dataset, which is collected on the University of Science and Technology of China (USTC) campus, the city roads surrounding the campus, and an underground parking garage.","The results demonstrate that mmPlace outperforms point cloud-based methods and achieves 87.37% recall@1 in scenarios involving rotational and lateral variations."],"url":"http://arxiv.org/abs/2403.04703v1"}
{"created":"2024-03-07 17:48:48","title":"ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes","abstract":"Given the large-scale multi-modal training of recent vision-based models and their generalization capabilities, understanding the extent of their robustness is critical for their real-world deployment. In this work, we evaluate the resilience of current vision-based models against diverse object-to-background context variations. The majority of robustness evaluation methods have introduced synthetic datasets to induce changes to object characteristics (viewpoints, scale, color) or utilized image transformation techniques (adversarial changes, common corruptions) on real images to simulate shifts in distributions. Recent works have explored leveraging large language models and diffusion models to generate changes in the background. However, these methods either lack in offering control over the changes to be made or distort the object semantics, making them unsuitable for the task. Our method, on the other hand, can induce diverse object-to-background changes while preserving the original semantics and appearance of the object. To achieve this goal, we harness the generative capabilities of text-to-image, image-to-text, and image-to-segment models to automatically generate a broad spectrum of object-to-background changes. We induce both natural and adversarial background changes by either modifying the textual prompts or optimizing the latents and textual embedding of text-to-image models. This allows us to quantify the role of background context in understanding the robustness and generalization of deep neural networks. We produce various versions of standard vision datasets (ImageNet, COCO), incorporating either diverse and realistic backgrounds into the images or introducing color, texture, and adversarial changes in the background. We conduct extensive experiment to analyze the robustness of vision-based models against object-to-background context variations across diverse tasks.","sentences":["Given the large-scale multi-modal training of recent vision-based models and their generalization capabilities, understanding the extent of their robustness is critical for their real-world deployment.","In this work, we evaluate the resilience of current vision-based models against diverse object-to-background context variations.","The majority of robustness evaluation methods have introduced synthetic datasets to induce changes to object characteristics (viewpoints, scale, color) or utilized image transformation techniques (adversarial changes, common corruptions) on real images to simulate shifts in distributions.","Recent works have explored leveraging large language models and diffusion models to generate changes in the background.","However, these methods either lack in offering control over the changes to be made or distort the object semantics, making them unsuitable for the task.","Our method, on the other hand, can induce diverse object-to-background changes while preserving the original semantics and appearance of the object.","To achieve this goal, we harness the generative capabilities of text-to-image, image-to-text, and image-to-segment models to automatically generate a broad spectrum of object-to-background changes.","We induce both natural and adversarial background changes by either modifying the textual prompts or optimizing the latents and textual embedding of text-to-image models.","This allows us to quantify the role of background context in understanding the robustness and generalization of deep neural networks.","We produce various versions of standard vision datasets (ImageNet, COCO), incorporating either diverse and realistic backgrounds into the images or introducing color, texture, and adversarial changes in the background.","We conduct extensive experiment to analyze the robustness of vision-based models against object-to-background context variations across diverse tasks."],"url":"http://arxiv.org/abs/2403.04701v1"}
{"created":"2024-03-07 17:48:47","title":"Delving into the Trajectory Long-tail Distribution for Muti-object Tracking","abstract":"Multiple Object Tracking (MOT) is a critical area within computer vision, with a broad spectrum of practical implementations. Current research has primarily focused on the development of tracking algorithms and enhancement of post-processing techniques. Yet, there has been a lack of thorough examination concerning the nature of tracking data it self. In this study, we pioneer an exploration into the distribution patterns of tracking data and identify a pronounced long-tail distribution issue within existing MOT datasets. We note a significant imbalance in the distribution of trajectory lengths across different pedestrians, a phenomenon we refer to as \"pedestrians trajectory long-tail distribution\". Addressing this challenge, we introduce a bespoke strategy designed to mitigate the effects of this skewed distribution. Specifically, we propose two data augmentation strategies, including Stationary Camera View Data Augmentation (SVA) and Dynamic Camera View Data Augmentation (DVA) , designed for viewpoint states and the Group Softmax (GS) module for Re-ID. SVA is to backtrack and predict the pedestrian trajectory of tail classes, and DVA is to use diffusion model to change the background of the scene. GS divides the pedestrians into unrelated groups and performs softmax operation on each group individually. Our proposed strategies can be integrated into numerous existing tracking systems, and extensive experimentation validates the efficacy of our method in reducing the influence of long-tail distribution on multi-object tracking performance. The code is available at https://github.com/chen-si-jia/Trajectory-Long-tail-Distribution-for-MOT.","sentences":["Multiple Object Tracking (MOT) is a critical area within computer vision, with a broad spectrum of practical implementations.","Current research has primarily focused on the development of tracking algorithms and enhancement of post-processing techniques.","Yet, there has been a lack of thorough examination concerning the nature of tracking data it self.","In this study, we pioneer an exploration into the distribution patterns of tracking data and identify a pronounced long-tail distribution issue within existing MOT datasets.","We note a significant imbalance in the distribution of trajectory lengths across different pedestrians, a phenomenon we refer to as \"pedestrians trajectory long-tail distribution\".","Addressing this challenge, we introduce a bespoke strategy designed to mitigate the effects of this skewed distribution.","Specifically, we propose two data augmentation strategies, including Stationary Camera View Data Augmentation (SVA) and Dynamic Camera View Data Augmentation (DVA) , designed for viewpoint states and the Group Softmax (GS) module for Re-ID.","SVA is to backtrack and predict the pedestrian trajectory of tail classes, and DVA is to use diffusion model to change the background of the scene.","GS divides the pedestrians into unrelated groups and performs softmax operation on each group individually.","Our proposed strategies can be integrated into numerous existing tracking systems, and extensive experimentation validates the efficacy of our method in reducing the influence of long-tail distribution on multi-object tracking performance.","The code is available at https://github.com/chen-si-jia/Trajectory-Long-tail-Distribution-for-MOT."],"url":"http://arxiv.org/abs/2403.04700v1"}
{"created":"2024-03-07 17:46:50","title":"AUFormer: Vision Transformers are Parameter-Efficient Facial Action Unit Detectors","abstract":"Facial Action Units (AU) is a vital concept in the realm of affective computing, and AU detection has always been a hot research topic. Existing methods suffer from overfitting issues due to the utilization of a large number of learnable parameters on scarce AU-annotated datasets or heavy reliance on substantial additional relevant data. Parameter-Efficient Transfer Learning (PETL) provides a promising paradigm to address these challenges, whereas its existing methods lack design for AU characteristics. Therefore, we innovatively investigate PETL paradigm to AU detection, introducing AUFormer and proposing a novel Mixture-of-Knowledge Expert (MoKE) collaboration mechanism. An individual MoKE specific to a certain AU with minimal learnable parameters first integrates personalized multi-scale and correlation knowledge. Then the MoKE collaborates with other MoKEs in the expert group to obtain aggregated information and inject it into the frozen Vision Transformer (ViT) to achieve parameter-efficient AU detection. Additionally, we design a Margin-truncated Difficulty-aware Weighted Asymmetric Loss (MDWA-Loss), which can encourage the model to focus more on activated AUs, differentiate the difficulty of unactivated AUs, and discard potential mislabeled samples. Extensive experiments from various perspectives, including within-domain, cross-domain, data efficiency, and micro-expression domain, demonstrate AUFormer's state-of-the-art performance and robust generalization abilities without relying on additional relevant data. The code for AUFormer is available at https://github.com/yuankaishen2001/AUFormer.","sentences":["Facial Action Units (AU) is a vital concept in the realm of affective computing, and AU detection has always been a hot research topic.","Existing methods suffer from overfitting issues due to the utilization of a large number of learnable parameters on scarce AU-annotated datasets or heavy reliance on substantial additional relevant data.","Parameter-Efficient Transfer Learning (PETL) provides a promising paradigm to address these challenges, whereas its existing methods lack design for AU characteristics.","Therefore, we innovatively investigate PETL paradigm to AU detection, introducing AUFormer and proposing a novel Mixture-of-Knowledge Expert (MoKE) collaboration mechanism.","An individual MoKE specific to a certain AU with minimal learnable parameters first integrates personalized multi-scale and correlation knowledge.","Then the MoKE collaborates with other MoKEs","in the expert group to obtain aggregated information and inject it into the frozen Vision Transformer (ViT) to achieve parameter-efficient AU detection.","Additionally, we design a Margin-truncated Difficulty-aware Weighted Asymmetric Loss (MDWA-Loss), which can encourage the model to focus more on activated AUs, differentiate the difficulty of unactivated AUs, and discard potential mislabeled samples.","Extensive experiments from various perspectives, including within-domain, cross-domain, data efficiency, and micro-expression domain, demonstrate AUFormer's state-of-the-art performance and robust generalization abilities without relying on additional relevant data.","The code for AUFormer is available at https://github.com/yuankaishen2001/AUFormer."],"url":"http://arxiv.org/abs/2403.04697v1"}
{"created":"2024-03-07 17:44:17","title":"Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification","abstract":"Large language models (LLMs) are notorious for hallucinating, i.e., producing erroneous claims in their output. Such hallucinations can be dangerous, as occasional factual inaccuracies in the generated text might be obscured by the rest of the output being generally factual, making it extremely hard for the users to spot them. Current services that leverage LLMs usually do not provide any means for detecting unreliable generations. Here, we aim to bridge this gap. In particular, we propose a novel fact-checking and hallucination detection pipeline based on token-level uncertainty quantification. Uncertainty scores leverage information encapsulated in the output of a neural network or its layers to detect unreliable predictions, and we show that they can be used to fact-check the atomic claims in the LLM output. Moreover, we present a novel token-level uncertainty quantification method that removes the impact of uncertainty about what claim to generate on the current step and what surface form to use. Our method Claim Conditioned Probability (CCP) measures only the uncertainty of particular claim value expressed by the model. Experiments on the task of biography generation demonstrate strong improvements for CCP compared to the baselines for six different LLMs and three languages. Human evaluation reveals that the fact-checking pipeline based on uncertainty quantification is competitive with a fact-checking tool that leverages external knowledge.","sentences":["Large language models (LLMs) are notorious for hallucinating, i.e., producing erroneous claims in their output.","Such hallucinations can be dangerous, as occasional factual inaccuracies in the generated text might be obscured by the rest of the output being generally factual, making it extremely hard for the users to spot them.","Current services that leverage LLMs usually do not provide any means for detecting unreliable generations.","Here, we aim to bridge this gap.","In particular, we propose a novel fact-checking and hallucination detection pipeline based on token-level uncertainty quantification.","Uncertainty scores leverage information encapsulated in the output of a neural network or its layers to detect unreliable predictions, and we show that they can be used to fact-check the atomic claims in the LLM output.","Moreover, we present a novel token-level uncertainty quantification method that removes the impact of uncertainty about what claim to generate on the current step and what surface form to use.","Our method Claim Conditioned Probability (CCP) measures only the uncertainty of particular claim value expressed by the model.","Experiments on the task of biography generation demonstrate strong improvements for CCP compared to the baselines for six different LLMs and three languages.","Human evaluation reveals that the fact-checking pipeline based on uncertainty quantification is competitive with a fact-checking tool that leverages external knowledge."],"url":"http://arxiv.org/abs/2403.04696v1"}
{"created":"2024-03-07 17:43:21","title":"On $[1,2]$-Domination in Interval and Circle Graphs","abstract":"A subset $S$ of vertices in a graph $G=(V, E)$ is Dominating Set if each vertex in $V(G)\\setminus S$ is adjacent to at least one vertex in $S$. Chellali et al. in 2013, by restricting the number of neighbors in $S$ of a vertex outside $S$, introduced the concept of $[1,j]$-dominating set. A set $D \\subseteq V$ of a graph $G = (V, E)$ is called $[1,j]$-Dominating Set of $G$ if every vertex not in $D$ has at least one neighbor and at most $j$ neighbors in $D$. The Minimum $[1,j]$-Domination problem is the problem of finding the minimum set $D$. Given a positive integer $k$ and a graph $G = (V, E)$, the $[1,j]$-Domination Decision problem is to decide whether $G$ has $[1,j]$-dominating set of cardinality at most $k$. A polynomial-time algorithm was obtained in split graphs for a constant $j$ in contrast to the classic Dominating Set problem which is NP-hard in split graphs. This result motivates us to investigate the effect of restriction $j$ on the complexity of $[1,j]$-domination problem on various classes of graphs. Although for $j\\geq 3$, it has been proved that the minimum of classical domination is equal to minimum $[1,j]$-domination in interval graphs, the complexity of finding the minimum $[1,2]$-domination in interval graphs is still outstanding. In this paper, we propose a polynomial-time algorithm for computing a minimum $[1,2]$ on non-proper interval graphs by a dynamic programming technique. Next, on the negative side, we show that the minimum $[1,2]$-dominating set problem on circle graphs is $NP$-complete.","sentences":["A subset $S$ of vertices in a graph $G=(V, E)$ is Dominating Set if each vertex in $V(G)\\setminus S$ is adjacent to at least one vertex in $S$. Chellali et al.","in 2013, by restricting the number of neighbors in $S$ of a vertex outside $S$, introduced the concept of $[1,j]$-dominating set.","A set $D \\subseteq V$ of a graph $G = (V, E)$ is called $[1,j]$-Dominating Set of $G$ if every vertex not in $D$ has at least one neighbor and at most $j$ neighbors in $D$. The Minimum $[1,j]$-Domination problem is the problem of finding the minimum set $D$. Given a positive integer $k$ and a graph $G = (V, E)$, the $[1,j]$-Domination Decision problem is to decide whether $G$ has $[1,j]$-dominating set of cardinality at most $k$. A polynomial-time algorithm was obtained in split graphs for a constant $j$ in contrast to the classic Dominating Set problem which is NP-hard in split graphs.","This result motivates us to investigate the effect of restriction $j$ on the complexity of $[1,j]$-domination problem on various classes of graphs.","Although for $j\\geq 3$, it has been proved that the minimum of classical domination is equal to minimum $[1,j]$-domination in interval graphs, the complexity of finding the minimum $[1,2]$-domination in interval graphs is still outstanding.","In this paper, we propose a polynomial-time algorithm for computing a minimum $[1,2]$ on non-proper interval graphs by a dynamic programming technique.","Next, on the negative side, we show that the minimum $[1,2]$-dominating set problem on circle graphs is $NP$-complete."],"url":"http://arxiv.org/abs/2403.04694v1"}
{"created":"2024-03-07 17:42:40","title":"Analysis of Systems' Performance in Natural Language Processing Competitions","abstract":"Collaborative competitions have gained popularity in the scientific and technological fields. These competitions involve defining tasks, selecting evaluation scores, and devising result verification methods. In the standard scenario, participants receive a training set and are expected to provide a solution for a held-out dataset kept by organizers. An essential challenge for organizers arises when comparing algorithms' performance, assessing multiple participants, and ranking them. Statistical tools are often used for this purpose; however, traditional statistical methods often fail to capture decisive differences between systems' performance. This manuscript describes an evaluation methodology for statistically analyzing competition results and competition. The methodology is designed to be universally applicable; however, it is illustrated using eight natural language competitions as case studies involving classification and regression problems. The proposed methodology offers several advantages, including off-the-shell comparisons with correction mechanisms and the inclusion of confidence intervals. Furthermore, we introduce metrics that allow organizers to assess the difficulty of competitions. Our analysis shows the potential usefulness of our methodology for effectively evaluating competition results.","sentences":["Collaborative competitions have gained popularity in the scientific and technological fields.","These competitions involve defining tasks, selecting evaluation scores, and devising result verification methods.","In the standard scenario, participants receive a training set and are expected to provide a solution for a held-out dataset kept by organizers.","An essential challenge for organizers arises when comparing algorithms' performance, assessing multiple participants, and ranking them.","Statistical tools are often used for this purpose; however, traditional statistical methods often fail to capture decisive differences between systems' performance.","This manuscript describes an evaluation methodology for statistically analyzing competition results and competition.","The methodology is designed to be universally applicable; however, it is illustrated using eight natural language competitions as case studies involving classification and regression problems.","The proposed methodology offers several advantages, including off-the-shell comparisons with correction mechanisms and the inclusion of confidence intervals.","Furthermore, we introduce metrics that allow organizers to assess the difficulty of competitions.","Our analysis shows the potential usefulness of our methodology for effectively evaluating competition results."],"url":"http://arxiv.org/abs/2403.04693v1"}
{"created":"2024-03-07 17:41:37","title":"PixArt-\u03a3: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation","abstract":"In this paper, we introduce PixArt-\\Sigma, a Diffusion Transformer model~(DiT) capable of directly generating images at 4K resolution. PixArt-\\Sigma represents a significant advancement over its predecessor, PixArt-\\alpha, offering images of markedly higher fidelity and improved alignment with text prompts. A key feature of PixArt-\\Sigma is its training efficiency. Leveraging the foundational pre-training of PixArt-\\alpha, it evolves from the `weaker' baseline to a `stronger' model via incorporating higher quality data, a process we term \"weak-to-strong training\". The advancements in PixArt-\\Sigma are twofold: (1) High-Quality Training Data: PixArt-\\Sigma incorporates superior-quality image data, paired with more precise and detailed image captions. (2) Efficient Token Compression: we propose a novel attention module within the DiT framework that compresses both keys and values, significantly improving efficiency and facilitating ultra-high-resolution image generation. Thanks to these improvements, PixArt-\\Sigma achieves superior image quality and user prompt adherence capabilities with significantly smaller model size (0.6B parameters) than existing text-to-image diffusion models, such as SDXL (2.6B parameters) and SD Cascade (5.1B parameters). Moreover, PixArt-\\Sigma's capability to generate 4K images supports the creation of high-resolution posters and wallpapers, efficiently bolstering the production of high-quality visual content in industries such as film and gaming.","sentences":["In this paper, we introduce PixArt-\\Sigma, a Diffusion Transformer model~(DiT) capable of directly generating images at 4K resolution.","PixArt-\\Sigma represents a significant advancement over its predecessor, PixArt-\\alpha, offering images of markedly higher fidelity and improved alignment with text prompts.","A key feature of PixArt-\\Sigma is its training efficiency.","Leveraging the foundational pre-training of PixArt-\\alpha, it evolves from the `weaker' baseline to a `stronger' model via incorporating higher quality data, a process we term \"weak-to-strong training\".","The advancements in PixArt-\\Sigma are twofold: (1) High-Quality Training Data: PixArt-\\Sigma incorporates superior-quality image data, paired with more precise and detailed image captions.","(2) Efficient Token Compression: we propose a novel attention module within the DiT framework that compresses both keys and values, significantly improving efficiency and facilitating ultra-high-resolution image generation.","Thanks to these improvements, PixArt-\\Sigma achieves superior image quality and user prompt adherence capabilities with significantly smaller model size (0.6B parameters) than existing text-to-image diffusion models, such as SDXL (2.6B parameters) and SD Cascade (5.1B parameters).","Moreover, PixArt-\\Sigma's capability to generate 4K images supports the creation of high-resolution posters and wallpapers, efficiently bolstering the production of high-quality visual content in industries such as film and gaming."],"url":"http://arxiv.org/abs/2403.04692v1"}
{"created":"2024-03-07 17:35:58","title":"Faster Neighborhood Attention: Reducing the O(n^2) Cost of Self Attention at the Threadblock Level","abstract":"Neighborhood attention reduces the cost of self attention by restricting each token's attention span to its nearest neighbors. This restriction, parameterized by a window size and dilation factor, draws a spectrum of possible attention patterns between linear projection and self attention. Neighborhood attention, and more generally sliding window attention patterns, have long been bounded by infrastructure, particularly in higher-rank spaces (2-D and 3-D), calling for the development of custom kernels, which have been limited in either functionality, or performance, if not both. In this work, we first show that neighborhood attention can be represented as a batched GEMM problem, similar to standard attention, and implement it for 1-D and 2-D neighborhood attention. These kernels on average provide 895% and 272% improvement in full precision latency compared to existing naive kernels for 1-D and 2-D neighborhood attention respectively. We find certain inherent inefficiencies in all unfused neighborhood attention kernels that bound their performance and lower-precision scalability. We also developed fused neighborhood attention; an adaptation of fused dot-product attention kernels that allow fine-grained control over attention across different spatial axes. Known for reducing the quadratic time complexity of self attention to a linear complexity, neighborhood attention can now enjoy a reduced and constant memory footprint, and record-breaking half precision latency. We observe that our fused kernels successfully circumvent some of the unavoidable inefficiencies in unfused implementations. While our unfused GEMM-based kernels only improve half precision performance compared to naive kernels by an average of 496% and 113% in 1-D and 2-D problems respectively, our fused kernels improve naive kernels by an average of 1607% and 581% in 1-D and 2-D problems respectively.","sentences":["Neighborhood attention reduces the cost of self attention by restricting each token's attention span to its nearest neighbors.","This restriction, parameterized by a window size and dilation factor, draws a spectrum of possible attention patterns between linear projection and self attention.","Neighborhood attention, and more generally sliding window attention patterns, have long been bounded by infrastructure, particularly in higher-rank spaces (2-D and 3-D), calling for the development of custom kernels, which have been limited in either functionality, or performance, if not both.","In this work, we first show that neighborhood attention can be represented as a batched GEMM problem, similar to standard attention, and implement it for 1-D and 2-D neighborhood attention.","These kernels on average provide 895% and 272% improvement in full precision latency compared to existing naive kernels for 1-D and 2-D neighborhood attention respectively.","We find certain inherent inefficiencies in all unfused neighborhood attention kernels that bound their performance and lower-precision scalability.","We also developed fused neighborhood attention; an adaptation of fused dot-product attention kernels that allow fine-grained control over attention across different spatial axes.","Known for reducing the quadratic time complexity of self attention to a linear complexity, neighborhood attention can now enjoy a reduced and constant memory footprint, and record-breaking half precision latency.","We observe that our fused kernels successfully circumvent some of the unavoidable inefficiencies in unfused implementations.","While our unfused GEMM-based kernels only improve half precision performance compared to naive kernels by an average of 496% and 113% in 1-D and 2-D problems respectively, our fused kernels improve naive kernels by an average of 1607% and 581% in 1-D and 2-D problems respectively."],"url":"http://arxiv.org/abs/2403.04690v1"}
{"created":"2024-03-07 17:24:50","title":"Extensive-Form Game Solving via Blackwell Approachability on Treeplexes","abstract":"In this paper, we introduce the first algorithmic framework for Blackwell approachability on the sequence-form polytope, the class of convex polytopes capturing the strategies of players in extensive-form games (EFGs). This leads to a new class of regret-minimization algorithms that are stepsize-invariant, in the same sense as the Regret Matching and Regret Matching$^+$ algorithms for the simplex. Our modular framework can be combined with any existing regret minimizer over cones to compute a Nash equilibrium in two-player zero-sum EFGs with perfect recall, through the self-play framework. Leveraging predictive online mirror descent, we introduce Predictive Treeplex Blackwell$^+$ (PTB$^+$), and show a $O(1/\\sqrt{T})$ convergence rate to Nash equilibrium in self-play. We then show how to stabilize PTB$^+$ with a stepsize, resulting in an algorithm with a state-of-the-art $O(1/T)$ convergence rate. We provide an extensive set of experiments to compare our framework with several algorithmic benchmarks, including CFR$^+$ and its predictive variant, and we highlight interesting connections between practical performance and the stepsize-dependence or stepsize-invariance properties of classical algorithms.","sentences":["In this paper, we introduce the first algorithmic framework for Blackwell approachability on the sequence-form polytope, the class of convex polytopes capturing the strategies of players in extensive-form games (EFGs).","This leads to a new class of regret-minimization algorithms that are stepsize-invariant, in the same sense as the Regret Matching and Regret Matching$^+$ algorithms for the simplex.","Our modular framework can be combined with any existing regret minimizer over cones to compute a Nash equilibrium in two-player zero-sum EFGs with perfect recall, through the self-play framework.","Leveraging predictive online mirror descent, we introduce Predictive Treeplex Blackwell$^+$ (PTB$^+$), and show a $O(1/\\sqrt{T})$ convergence rate to Nash equilibrium in self-play.","We then show how to stabilize PTB$^+$ with a stepsize, resulting in an algorithm with a state-of-the-art $O(1/T)$ convergence rate.","We provide an extensive set of experiments to compare our framework with several algorithmic benchmarks, including CFR$^+$ and its predictive variant, and we highlight interesting connections between practical performance and the stepsize-dependence or stepsize-invariance properties of classical algorithms."],"url":"http://arxiv.org/abs/2403.04680v1"}
{"created":"2024-03-07 17:18:32","title":"Molecular Arithmetic Coding (MAC) for Internet of Bio-Nano Things (IoBNT)","abstract":"Molecular Communication (MC) has emerged as a promising paradigm employing molecules to transfer information at the nano-scale. Unlike MC channel coding, MC source coding has remained mostly an unexplored area of research. In a recent paper, prefix source coding was introduced into the field, through an MC-adapted version of the Huffman Coding. In the context of MC source coding, this paper proposes the Molecular Arithmetic Coding (MAC) whose algorithmic implementation and code-structure is non-arbitrarily different than that of the widely-known classical arithmetic coding. MAC is designed to mitigate Inter-Symbol Interference (ISI) for alphabets with known symbol probabilities through, in a highly efficient way, avoiding consecutive 1-bits. However, due to bit precision limitations any arithmetic coding method faces, without any assumption made on the structure of the symbol alphabet, unique-decodability of MAC is not guaranteed. Accordingly, a uniquely-decodable new coding scheme named Molecular Arithmetic with Prefix Coding (MAPC) is also introduced. Across multiple alphabets, we show that MAPC provides a better compression performance compared to the optimal MC-adapted prefix coding. Simulation results of an exemplary alphabet demonstrates the superior symbol and word error rate performance of MAPC compared to the optimal MC-adapted prefix coding and to the uncoded BCSK schemes.","sentences":["Molecular Communication (MC) has emerged as a promising paradigm employing molecules to transfer information at the nano-scale.","Unlike MC channel coding, MC source coding has remained mostly an unexplored area of research.","In a recent paper, prefix source coding was introduced into the field, through an MC-adapted version of the Huffman Coding.","In the context of MC source coding, this paper proposes the Molecular Arithmetic Coding (MAC) whose algorithmic implementation and code-structure is non-arbitrarily different than that of the widely-known classical arithmetic coding.","MAC is designed to mitigate Inter-Symbol Interference (ISI) for alphabets with known symbol probabilities through, in a highly efficient way, avoiding consecutive 1-bits.","However, due to bit precision limitations any arithmetic coding method faces, without any assumption made on the structure of the symbol alphabet, unique-decodability of MAC is not guaranteed.","Accordingly, a uniquely-decodable new coding scheme named Molecular Arithmetic with Prefix Coding (MAPC) is also introduced.","Across multiple alphabets, we show that MAPC provides a better compression performance compared to the optimal MC-adapted prefix coding.","Simulation results of an exemplary alphabet demonstrates the superior symbol and word error rate performance of MAPC compared to the optimal MC-adapted prefix coding and to the uncoded BCSK schemes."],"url":"http://arxiv.org/abs/2403.04672v1"}
{"created":"2024-03-07 17:17:20","title":"Greater than the sum of its parts: The role of minority and majority status in collaborative problem-solving communication","abstract":"Collaborative problem-solving (CPS) is a vital skill used both in the workplace and in educational environments. CPS is useful in tackling increasingly complex global, economic, and political issues and is considered a central 21st century skill. The increasingly connected global community presents a fruitful opportunity for creative and collaborative problem-solving interactions and solutions that involve diverse perspectives. Unfortunately, women and underrepresented minorities (URMs) often face obstacles during collaborative interactions that hinder their key participation in these problem-solving conversations. Here, we explored the communication patterns of minority and non-minority individuals working together in a CPS task. Group Communication Analysis (GCA), a temporally-sensitive computational linguistic tool, was used to examine how URM status impacts individuals' sociocognitive linguistic patterns. Results show differences across racial/ethnic groups in key sociocognitive features that indicate fruitful collaborative interactions. We also investigated how the groups' racial/ethnic composition impacts both individual and group communication patterns. In general, individuals in more demographically diverse groups displayed more productive communication behaviors than individuals who were in majority-dominated groups. We discuss the implications of individual and group diversity on communication patterns that emerge during CPS and how these patterns can impact collaborative outcomes.","sentences":["Collaborative problem-solving (CPS) is a vital skill used both in the workplace and in educational environments.","CPS is useful in tackling increasingly complex global, economic, and political issues and is considered a central 21st century skill.","The increasingly connected global community presents a fruitful opportunity for creative and collaborative problem-solving interactions and solutions that involve diverse perspectives.","Unfortunately, women and underrepresented minorities (URMs) often face obstacles during collaborative interactions that hinder their key participation in these problem-solving conversations.","Here, we explored the communication patterns of minority and non-minority individuals working together in a CPS task.","Group Communication Analysis (GCA), a temporally-sensitive computational linguistic tool, was used to examine how URM status impacts individuals' sociocognitive linguistic patterns.","Results show differences across racial/ethnic groups in key sociocognitive features that indicate fruitful collaborative interactions.","We also investigated how the groups' racial/ethnic composition impacts both individual and group communication patterns.","In general, individuals in more demographically diverse groups displayed more productive communication behaviors than individuals who were in majority-dominated groups.","We discuss the implications of individual and group diversity on communication patterns that emerge during CPS and how these patterns can impact collaborative outcomes."],"url":"http://arxiv.org/abs/2403.04671v1"}
{"created":"2024-03-07 17:16:59","title":"End-to-end Conditional Robust Optimization","abstract":"The field of Contextual Optimization (CO) integrates machine learning and optimization to solve decision making problems under uncertainty. Recently, a risk sensitive variant of CO, known as Conditional Robust Optimization (CRO), combines uncertainty quantification with robust optimization in order to promote safety and reliability in high stake applications. Exploiting modern differentiable optimization methods, we propose a novel end-to-end approach to train a CRO model in a way that accounts for both the empirical risk of the prescribed decisions and the quality of conditional coverage of the contextual uncertainty set that supports them. While guarantees of success for the latter objective are impossible to obtain from the point of view of conformal prediction theory, high quality conditional coverage is achieved empirically by ingeniously employing a logistic regression differentiable layer within the calculation of coverage quality in our training loss. We show that the proposed training algorithms produce decisions that outperform the traditional estimate then optimize approaches.","sentences":["The field of Contextual Optimization (CO) integrates machine learning and optimization to solve decision making problems under uncertainty.","Recently, a risk sensitive variant of CO, known as Conditional Robust Optimization (CRO), combines uncertainty quantification with robust optimization in order to promote safety and reliability in high stake applications.","Exploiting modern differentiable optimization methods, we propose a novel end-to-end approach to train a CRO model in a way that accounts for both the empirical risk of the prescribed decisions and the quality of conditional coverage of the contextual uncertainty set that supports them.","While guarantees of success for the latter objective are impossible to obtain from the point of view of conformal prediction theory, high quality conditional coverage is achieved empirically by ingeniously employing a logistic regression differentiable layer within the calculation of coverage quality in our training loss.","We show that the proposed training algorithms produce decisions that outperform the traditional estimate then optimize approaches."],"url":"http://arxiv.org/abs/2403.04670v1"}
{"created":"2024-03-07 17:14:22","title":"The Social Impact of Generative AI: An Analysis on ChatGPT","abstract":"In recent months, the social impact of Artificial Intelligence (AI) has gained considerable public interest, driven by the emergence of Generative AI models, ChatGPT in particular. The rapid development of these models has sparked heated discussions regarding their benefits, limitations, and associated risks. Generative models hold immense promise across multiple domains, such as healthcare, finance, and education, to cite a few, presenting diverse practical applications. Nevertheless, concerns about potential adverse effects have elicited divergent perspectives, ranging from privacy risks to escalating social inequality. This paper adopts a methodology to delve into the societal implications of Generative AI tools, focusing primarily on the case of ChatGPT. It evaluates the potential impact on several social sectors and illustrates the findings of a comprehensive literature review of both positive and negative effects, emerging trends, and areas of opportunity of Generative AI models. This analysis aims to facilitate an in-depth discussion by providing insights that can inspire policy, regulation, and responsible development practices to foster a human-centered AI.","sentences":["In recent months, the social impact of Artificial Intelligence (AI) has gained considerable public interest, driven by the emergence of Generative AI models, ChatGPT in particular.","The rapid development of these models has sparked heated discussions regarding their benefits, limitations, and associated risks.","Generative models hold immense promise across multiple domains, such as healthcare, finance, and education, to cite a few, presenting diverse practical applications.","Nevertheless, concerns about potential adverse effects have elicited divergent perspectives, ranging from privacy risks to escalating social inequality.","This paper adopts a methodology to delve into the societal implications of Generative AI tools, focusing primarily on the case of ChatGPT.","It evaluates the potential impact on several social sectors and illustrates the findings of a comprehensive literature review of both positive and negative effects, emerging trends, and areas of opportunity of Generative AI models.","This analysis aims to facilitate an in-depth discussion by providing insights that can inspire policy, regulation, and responsible development practices to foster a human-centered AI."],"url":"http://arxiv.org/abs/2403.04667v1"}
{"created":"2024-03-07 17:13:12","title":"Telecom Language Models: Must They Be Large?","abstract":"The increasing interest in Large Language Models (LLMs) within the telecommunications sector underscores their potential to revolutionize operational efficiency. However, the deployment of these sophisticated models is often hampered by their substantial size and computational demands, raising concerns about their viability in resource-constrained environments. Addressing this challenge, recent advancements have seen the emergence of small language models that surprisingly exhibit performance comparable to their larger counterparts in many tasks, such as coding and common-sense reasoning. Phi-2, a compact yet powerful model, exemplifies this new wave of efficient small language models. This paper conducts a comprehensive evaluation of Phi-2's intrinsic understanding of the telecommunications domain. Recognizing the scale-related limitations, we enhance Phi-2's capabilities through a Retrieval-Augmented Generation approach, meticulously integrating an extensive knowledge base specifically curated with telecom standard specifications. The enhanced Phi-2 model demonstrates a profound improvement in accuracy, answering questions about telecom standards with a precision that closely rivals the more resource-intensive GPT-3.5. The paper further explores the refined capabilities of Phi-2 in addressing problem-solving scenarios within the telecom sector, highlighting its potential and limitations.","sentences":["The increasing interest in Large Language Models (LLMs) within the telecommunications sector underscores their potential to revolutionize operational efficiency.","However, the deployment of these sophisticated models is often hampered by their substantial size and computational demands, raising concerns about their viability in resource-constrained environments.","Addressing this challenge, recent advancements have seen the emergence of small language models that surprisingly exhibit performance comparable to their larger counterparts in many tasks, such as coding and common-sense reasoning.","Phi-2, a compact yet powerful model, exemplifies this new wave of efficient small language models.","This paper conducts a comprehensive evaluation of Phi-2's intrinsic understanding of the telecommunications domain.","Recognizing the scale-related limitations, we enhance Phi-2's capabilities through a Retrieval-Augmented Generation approach, meticulously integrating an extensive knowledge base specifically curated with telecom standard specifications.","The enhanced Phi-2 model demonstrates a profound improvement in accuracy, answering questions about telecom standards with a precision that closely rivals the more resource-intensive GPT-3.5.","The paper further explores the refined capabilities of Phi-2 in addressing problem-solving scenarios within the telecom sector, highlighting its potential and limitations."],"url":"http://arxiv.org/abs/2403.04666v1"}
{"created":"2024-03-07 17:12:12","title":"GreenBytes: Intelligent Energy Estimation for Edge-Cloud","abstract":"This study investigates the application of advanced machine learning models, specifically Long Short-Term Memory (LSTM) networks and Gradient Booster models, for accurate energy consumption estimation within a Kubernetes cluster environment. It aims to enhance sustainable computing practices by providing precise predictions of energy usage across various computing nodes. Through meticulous analysis of model performance on both master and worker nodes, the research reveals the strengths and potential applications of these models in promoting energy efficiency. The LSTM model demonstrates remarkable predictive accuracy, particularly in capturing dynamic computing workloads over time, evidenced by low mean squared error (MSE) rates and the ability to closely track actual energy consumption trends. Conversely, the Gradient Booster model showcases robustness and adaptability across different computational environments, despite slightly higher MSE values. The study underscores the complementary nature of these models in advancing sustainable computing practices, suggesting their integration into energy management systems could significantly enhance environmental sustainability in technology operations.","sentences":["This study investigates the application of advanced machine learning models, specifically Long Short-Term Memory (LSTM) networks and Gradient Booster models, for accurate energy consumption estimation within a Kubernetes cluster environment.","It aims to enhance sustainable computing practices by providing precise predictions of energy usage across various computing nodes.","Through meticulous analysis of model performance on both master and worker nodes, the research reveals the strengths and potential applications of these models in promoting energy efficiency.","The LSTM model demonstrates remarkable predictive accuracy, particularly in capturing dynamic computing workloads over time, evidenced by low mean squared error (MSE) rates and the ability to closely track actual energy consumption trends.","Conversely, the Gradient Booster model showcases robustness and adaptability across different computational environments, despite slightly higher MSE values.","The study underscores the complementary nature of these models in advancing sustainable computing practices, suggesting their integration into energy management systems could significantly enhance environmental sustainability in technology operations."],"url":"http://arxiv.org/abs/2403.04665v1"}
{"created":"2024-03-07 17:07:51","title":"Dynamic Cross Attention for Audio-Visual Person Verification","abstract":"Although person or identity verification has been predominantly explored using individual modalities such as face and voice, audio-visual fusion has recently shown immense potential to outperform unimodal approaches. Audio and visual modalities are often expected to pose strong complementary relationships, which plays a crucial role in effective audio-visual fusion. However, they may not always strongly complement each other, they may also exhibit weak complementary relationships, resulting in poor audio-visual feature representations. In this paper, we propose a Dynamic Cross-Attention (DCA) model that can dynamically select the cross-attended or unattended features on the fly based on the strong or weak complementary relationships, respectively, across audio and visual modalities. In particular, a conditional gating layer is designed to evaluate the contribution of the cross-attention mechanism and choose cross-attended features only when they exhibit strong complementary relationships, otherwise unattended features. Extensive experiments are conducted on the Voxceleb1 dataset to demonstrate the robustness of the proposed model. Results indicate that the proposed model consistently improves the performance on multiple variants of cross-attention while outperforming the state-of-the-art methods.","sentences":["Although person or identity verification has been predominantly explored using individual modalities such as face and voice, audio-visual fusion has recently shown immense potential to outperform unimodal approaches.","Audio and visual modalities are often expected to pose strong complementary relationships, which plays a crucial role in effective audio-visual fusion.","However, they may not always strongly complement each other, they may also exhibit weak complementary relationships, resulting in poor audio-visual feature representations.","In this paper, we propose a Dynamic Cross-Attention (DCA) model that can dynamically select the cross-attended or unattended features on the fly based on the strong or weak complementary relationships, respectively, across audio and visual modalities.","In particular, a conditional gating layer is designed to evaluate the contribution of the cross-attention mechanism and choose cross-attended features only when they exhibit strong complementary relationships, otherwise unattended features.","Extensive experiments are conducted on the Voxceleb1 dataset to demonstrate the robustness of the proposed model.","Results indicate that the proposed model consistently improves the performance on multiple variants of cross-attention while outperforming the state-of-the-art methods."],"url":"http://arxiv.org/abs/2403.04661v1"}
{"created":"2024-03-07 17:06:15","title":"Exploring the Design Space of Optical See-through AR Head-Mounted Displays to Support First Responders in the Field","abstract":"First responders (FRs) navigate hazardous, unfamiliar environments in the field (e.g., mass-casualty incidents), making life-changing decisions in a split second. AR head-mounted displays (HMDs) have shown promise in supporting them due to its capability of recognizing and augmenting the challenging environments in a hands-free manner. However, the design space have not been thoroughly explored by involving various FRs who serve different roles (e.g., firefighters, law enforcement) but collaborate closely in the field. We interviewed 26 first responders in the field who experienced a state-of-the-art optical-see-through AR HMD, as well as its interaction techniques and four types of AR cues (i.e., overview cues, directional cues, highlighting cues, and labeling cues), soliciting their first-hand experiences, design ideas, and concerns. Our study revealed both generic and role-specific preferences and needs for AR hardware, interactions, and feedback, as well as identifying desired AR designs tailored to urgent, risky scenarios (e.g., affordance augmentation to facilitate fast and safe action). While acknowledging the value of AR HMDs, concerns were also raised around trust, privacy, and proper integration with other equipment. Finally, we derived comprehensive and actionable design guidelines to inform future AR systems for in-field FRs.","sentences":["First responders (FRs) navigate hazardous, unfamiliar environments in the field (e.g., mass-casualty incidents), making life-changing decisions in a split second.","AR head-mounted displays (HMDs) have shown promise in supporting them due to its capability of recognizing and augmenting the challenging environments in a hands-free manner.","However, the design space have not been thoroughly explored by involving various FRs who serve different roles (e.g., firefighters, law enforcement) but collaborate closely in the field.","We interviewed 26 first responders in the field who experienced a state-of-the-art optical-see-through AR HMD, as well as its interaction techniques and four types of AR cues (i.e., overview cues, directional cues, highlighting cues, and labeling cues), soliciting their first-hand experiences, design ideas, and concerns.","Our study revealed both generic and role-specific preferences and needs for AR hardware, interactions, and feedback, as well as identifying desired AR designs tailored to urgent, risky scenarios (e.g., affordance augmentation to facilitate fast and safe action).","While acknowledging the value of AR HMDs, concerns were also raised around trust, privacy, and proper integration with other equipment.","Finally, we derived comprehensive and actionable design guidelines to inform future AR systems for in-field FRs."],"url":"http://arxiv.org/abs/2403.04660v1"}
{"created":"2024-03-07 17:04:55","title":"\"Did They Consent to That?\": Safer Digital Intimacy via Proactive Protection Against Image-Based Sexual Abuse","abstract":"As many as 8 in 10 adults share intimate content such as nude or lewd images. Sharing such content has significant benefits for relationship intimacy and body image, and can offer employment. However, stigmatizing attitudes and a lack of technological mitigations put those sharing such content at risk of sexual violence. An estimated 1 in 3 people have been subjected to image-based sexual abuse (IBSA), a spectrum of violence that includes the nonconsensual distribution or threat of distribution of consensually-created intimate content (also called NDII). In this work, we conducted a rigorous empirical interview study of 52 European creators of intimate content to examine the threats they face and how they defend against them, situated in the context of their different use cases for intimate content sharing and their choice of technologies for storing and sharing such content. Synthesizing our results with the limited body of prior work on technological prevention of NDII, we offer concrete next steps for both platforms and security & privacy researchers to work toward safer intimate content sharing through proactive protection.","sentences":["As many as 8 in 10 adults share intimate content such as nude or lewd images.","Sharing such content has significant benefits for relationship intimacy and body image, and can offer employment.","However, stigmatizing attitudes and a lack of technological mitigations put those sharing such content at risk of sexual violence.","An estimated 1 in 3 people have been subjected to image-based sexual abuse (IBSA), a spectrum of violence that includes the nonconsensual distribution or threat of distribution of consensually-created intimate content (also called NDII).","In this work, we conducted a rigorous empirical interview study of 52 European creators of intimate content to examine the threats they face and how they defend against them, situated in the context of their different use cases for intimate content sharing and their choice of technologies for storing and sharing such content.","Synthesizing our results with the limited body of prior work on technological prevention of NDII, we offer concrete next steps for both platforms and security & privacy researchers to work toward safer intimate content sharing through proactive protection."],"url":"http://arxiv.org/abs/2403.04659v1"}
{"created":"2024-03-07 16:59:55","title":"Chain of Thought Explanation for Dialogue State Tracking","abstract":"Dialogue state tracking (DST) aims to record user queries and goals during a conversational interaction achieved by maintaining a prede- fined set of slots and their corresponding values. Current approaches decide slot values opaquely, while humans usually adopt a more deliberate approach by collecting information from relevant dialogue turns and then reasoning the appropriate values. In this work, we focus on the steps needed to figure out slot values by proposing a model named Chain-of-Thought-Explanation (CoTE) for the DST task. CoTE, which is built on the generative DST framework, is designed to create detailed explanations step by step after determining the slot values. This process leads to more accurate and reliable slot values. More-over, to improve the reasoning ability of the CoTE, we further construct more fluent and high-quality explanations with automatic paraphrasing, leading the method CoTE-refined. Experimental results on three widely recognized DST benchmarks-MultiWOZ 2.2, WoZ 2.0, and M2M-demonstrate the remarkable effectiveness of the CoTE. Furthermore, through a meticulous fine-grained analysis, we observe significant benefits of our CoTE on samples characterized by longer dialogue turns, user responses, and reasoning steps.","sentences":["Dialogue state tracking (DST) aims to record user queries and goals during a conversational interaction achieved by maintaining a prede- fined set of slots and their corresponding values.","Current approaches decide slot values opaquely, while humans usually adopt a more deliberate approach by collecting information from relevant dialogue turns and then reasoning the appropriate values.","In this work, we focus on the steps needed to figure out slot values by proposing a model named Chain-of-Thought-Explanation (CoTE) for the DST task.","CoTE, which is built on the generative DST framework, is designed to create detailed explanations step by step after determining the slot values.","This process leads to more accurate and reliable slot values.","More-over, to improve the reasoning ability of the CoTE, we further construct more fluent and high-quality explanations with automatic paraphrasing, leading the method CoTE-refined.","Experimental results on three widely recognized DST benchmarks-MultiWOZ 2.2, WoZ 2.0, and M2M-demonstrate the remarkable effectiveness of the CoTE.","Furthermore, through a meticulous fine-grained analysis, we observe significant benefits of our CoTE on samples characterized by longer dialogue turns, user responses, and reasoning steps."],"url":"http://arxiv.org/abs/2403.04656v1"}
{"created":"2024-03-07 16:57:45","title":"Audio-Visual Person Verification based on Recursive Fusion of Joint Cross-Attention","abstract":"Person or identity verification has been recently gaining a lot of attention using audio-visual fusion as faces and voices share close associations with each other. Conventional approaches based on audio-visual fusion rely on score-level or early feature-level fusion techniques. Though existing approaches showed improvement over unimodal systems, the potential of audio-visual fusion for person verification is not fully exploited. In this paper, we have investigated the prospect of effectively capturing both the intra- and inter-modal relationships across audio and visual modalities, which can play a crucial role in significantly improving the fusion performance over unimodal systems. In particular, we introduce a recursive fusion of a joint cross-attentional model, where a joint audio-visual feature representation is employed in the cross-attention framework in a recursive fashion to progressively refine the feature representations that can efficiently capture the intra-and inter-modal relationships. To further enhance the audio-visual feature representations, we have also explored BLSTMs to improve the temporal modeling of audio-visual feature representations. Extensive experiments are conducted on the Voxceleb1 dataset to evaluate the proposed model. Results indicate that the proposed model shows promising improvement in fusion performance by adeptly capturing the intra-and inter-modal relationships across audio and visual modalities.","sentences":["Person or identity verification has been recently gaining a lot of attention using audio-visual fusion as faces and voices share close associations with each other.","Conventional approaches based on audio-visual fusion rely on score-level or early feature-level fusion techniques.","Though existing approaches showed improvement over unimodal systems, the potential of audio-visual fusion for person verification is not fully exploited.","In this paper, we have investigated the prospect of effectively capturing both the intra- and inter-modal relationships across audio and visual modalities, which can play a crucial role in significantly improving the fusion performance over unimodal systems.","In particular, we introduce a recursive fusion of a joint cross-attentional model, where a joint audio-visual feature representation is employed in the cross-attention framework in a recursive fashion to progressively refine the feature representations that can efficiently capture the intra-and inter-modal relationships.","To further enhance the audio-visual feature representations, we have also explored BLSTMs to improve the temporal modeling of audio-visual feature representations.","Extensive experiments are conducted on the Voxceleb1 dataset to evaluate the proposed model.","Results indicate that the proposed model shows promising improvement in fusion performance by adeptly capturing the intra-and inter-modal relationships across audio and visual modalities."],"url":"http://arxiv.org/abs/2403.04654v1"}
{"created":"2024-03-07 16:52:49","title":"Yi: Open Foundation Models by 01.AI","abstract":"We introduce the Yi model family, a series of language and multimodal models that demonstrate strong multi-dimensional capabilities. The Yi model family is based on 6B and 34B pretrained language models, then we extend them to chat models, 200K long context models, depth-upscaled models, and vision-language models. Our base models achieve strong performance on a wide range of benchmarks like MMLU, and our finetuned chat models deliver strong human preference rate on major evaluation platforms like AlpacaEval and Chatbot Arena. Building upon our scalable super-computing infrastructure and the classical transformer architecture, we attribute the performance of Yi models primarily to its data quality resulting from our data-engineering efforts. For pretraining, we construct 3.1 trillion tokens of English and Chinese corpora using a cascaded data deduplication and quality filtering pipeline. For finetuning, we polish a small scale (less than 10K) instruction dataset over multiple iterations such that every single instance has been verified directly by our machine learning engineers. For vision-language, we combine the chat language model with a vision transformer encoder and train the model to align visual representations to the semantic space of the language model. We further extend the context length to 200K through lightweight continual pretraining and demonstrate strong needle-in-a-haystack retrieval performance. We show that extending the depth of the pretrained checkpoint through continual pretraining further improves performance. We believe that given our current results, continuing to scale up model parameters using thoroughly optimized data will lead to even stronger frontier models.","sentences":["We introduce the Yi model family, a series of language and multimodal models that demonstrate strong multi-dimensional capabilities.","The Yi model family is based on 6B and 34B pretrained language models, then we extend them to chat models, 200K long context models, depth-upscaled models, and vision-language models.","Our base models achieve strong performance on a wide range of benchmarks like MMLU, and our finetuned chat models deliver strong human preference rate on major evaluation platforms like AlpacaEval and Chatbot Arena.","Building upon our scalable super-computing infrastructure and the classical transformer architecture, we attribute the performance of Yi models primarily to its data quality resulting from our data-engineering efforts.","For pretraining, we construct 3.1 trillion tokens of English and Chinese corpora using a cascaded data deduplication and quality filtering pipeline.","For finetuning, we polish a small scale (less than 10K) instruction dataset over multiple iterations such that every single instance has been verified directly by our machine learning engineers.","For vision-language, we combine the chat language model with a vision transformer encoder and train the model to align visual representations to the semantic space of the language model.","We further extend the context length to 200K through lightweight continual pretraining and demonstrate strong needle-in-a-haystack retrieval performance.","We show that extending the depth of the pretrained checkpoint through continual pretraining further improves performance.","We believe that given our current results, continuing to scale up model parameters using thoroughly optimized data will lead to even stronger frontier models."],"url":"http://arxiv.org/abs/2403.04652v1"}
{"created":"2024-03-07 16:51:15","title":"Cedar: A New Language for Expressive, Fast, Safe, and Analyzable Authorization (Extended Version)","abstract":"Cedar is a new authorization policy language designed to be ergonomic, fast, safe, and analyzable. Rather than embed authorization logic in an application's code, developers can write that logic as Cedar policies and delegate access decisions to Cedar's evaluation engine. Cedar's simple and intuitive syntax supports common authorization use-cases with readable policies, naturally leveraging concepts from role-based, attribute-based, and relation-based access control models. Cedar's policy structure enables access requests to be decided quickly. Cedar's policy validator leverages optional typing to help policy writers avoid mistakes, but not get in their way. Cedar's design has been finely balanced to allow for a sound and complete logical encoding, which enables precise policy analysis, e.g., to ensure that when refactoring a set of policies, the authorized permissions do not change. We have modeled Cedar in the Lean programming language, and used Lean's proof assistant to prove important properties of Cedar's design. We have implemented Cedar in Rust, and released it open-source. Comparing Cedar to two open-source languages, OpenFGA and Rego, we find (subjectively) that Cedar has equally or more readable policies, but (objectively) performs far better.","sentences":["Cedar is a new authorization policy language designed to be ergonomic, fast, safe, and analyzable.","Rather than embed authorization logic in an application's code, developers can write that logic as Cedar policies and delegate access decisions to Cedar's evaluation engine.","Cedar's simple and intuitive syntax supports common authorization use-cases with readable policies, naturally leveraging concepts from role-based, attribute-based, and relation-based access control models.","Cedar's policy structure enables access requests to be decided quickly.","Cedar's policy validator leverages optional typing to help policy writers avoid mistakes, but not get in their way.","Cedar's design has been finely balanced to allow for a sound and complete logical encoding, which enables precise policy analysis, e.g., to ensure that when refactoring a set of policies, the authorized permissions do not change.","We have modeled Cedar in the Lean programming language, and used Lean's proof assistant to prove important properties of Cedar's design.","We have implemented Cedar in Rust, and released it open-source.","Comparing Cedar to two open-source languages, OpenFGA and Rego, we find (subjectively) that Cedar has equally or more readable policies, but (objectively) performs far better."],"url":"http://arxiv.org/abs/2403.04651v1"}
{"created":"2024-03-07 16:50:25","title":"Context-Based Multimodal Fusion","abstract":"The fusion models, which effectively combine information from different sources, are widely used in solving multimodal tasks. However, they have significant limitations related to aligning data distributions across different modalities. This challenge can lead to inconsistencies and difficulties in learning robust representations. Alignment models, while specifically addressing this issue, often require training \"from scratch\" with large datasets to achieve optimal results, which can be costly in terms of resources and time. To overcome these limitations, we propose an innovative model called Context-Based Multimodal Fusion (CBMF), which combines both modality fusion and data distribution alignment. In CBMF, each modality is represented by a specific context vector, fused with the embedding of each modality. This enables the use of large pre-trained models that can be frozen, reducing the computational and training data requirements. Additionally, the network learns to differentiate embeddings of different modalities through fusion with context and aligns data distributions using a contrastive approach for self-supervised learning. Thus, CBMF offers an effective and economical solution for solving complex multimodal tasks.","sentences":["The fusion models, which effectively combine information from different sources, are widely used in solving multimodal tasks.","However, they have significant limitations related to aligning data distributions across different modalities.","This challenge can lead to inconsistencies and difficulties in learning robust representations.","Alignment models, while specifically addressing this issue, often require training \"from scratch\" with large datasets to achieve optimal results, which can be costly in terms of resources and time.","To overcome these limitations, we propose an innovative model called Context-Based Multimodal Fusion (CBMF), which combines both modality fusion and data distribution alignment.","In CBMF, each modality is represented by a specific context vector, fused with the embedding of each modality.","This enables the use of large pre-trained models that can be frozen, reducing the computational and training data requirements.","Additionally, the network learns to differentiate embeddings of different modalities through fusion with context and aligns data distributions using a contrastive approach for self-supervised learning.","Thus, CBMF offers an effective and economical solution for solving complex multimodal tasks."],"url":"http://arxiv.org/abs/2403.04650v1"}
{"created":"2024-03-07 16:42:37","title":"QAQ: Quality Adaptive Quantization for LLM KV Cache","abstract":"The emergence of LLMs has ignited a fresh surge of breakthroughs in NLP applications, particularly in domains such as question-answering systems and text generation. As the need for longer context grows, a significant bottleneck in model deployment emerges due to the linear expansion of the Key-Value (KV) cache with the context length. Existing methods primarily rely on various hypotheses, such as sorting the KV cache based on attention scores for replacement or eviction, to compress the KV cache and improve model throughput. However, heuristics used by these strategies may wrongly evict essential KV cache, which can significantly degrade model performance. In this paper, we propose QAQ, a Quality Adaptive Quantization scheme for the KV cache. We theoretically demonstrate that key cache and value cache exhibit distinct sensitivities to quantization, leading to the formulation of separate quantization strategies for their non-uniform quantization. Through the integration of dedicated outlier handling, as well as an improved attention-aware approach, QAQ achieves up to 10x the compression ratio of the KV cache size with a neglectable impact on model performance. QAQ significantly reduces the practical hurdles of deploying LLMs, opening up new possibilities for longer-context applications. The code is available at github.com/ClubieDong/KVCacheQuantization.","sentences":["The emergence of LLMs has ignited a fresh surge of breakthroughs in NLP applications, particularly in domains such as question-answering systems and text generation.","As the need for longer context grows, a significant bottleneck in model deployment emerges due to the linear expansion of the Key-Value (KV) cache with the context length.","Existing methods primarily rely on various hypotheses, such as sorting the KV cache based on attention scores for replacement or eviction, to compress the KV cache and improve model throughput.","However, heuristics used by these strategies may wrongly evict essential KV cache, which can significantly degrade model performance.","In this paper, we propose QAQ, a Quality Adaptive Quantization scheme for the KV cache.","We theoretically demonstrate that key cache and value cache exhibit distinct sensitivities to quantization, leading to the formulation of separate quantization strategies for their non-uniform quantization.","Through the integration of dedicated outlier handling, as well as an improved attention-aware approach, QAQ achieves up to 10x the compression ratio of the KV cache size with a neglectable impact on model performance.","QAQ significantly reduces the practical hurdles of deploying LLMs, opening up new possibilities for longer-context applications.","The code is available at github.com/ClubieDong/KVCacheQuantization."],"url":"http://arxiv.org/abs/2403.04643v1"}
{"created":"2024-03-07 16:36:29","title":"Teaching Large Language Models to Reason with Reinforcement Learning","abstract":"Reinforcement Learning from Human Feedback (\\textbf{RLHF}) has emerged as a dominant approach for aligning LLM outputs with human preferences. Inspired by the success of RLHF, we study the performance of multiple algorithms that learn from feedback (Expert Iteration, Proximal Policy Optimization (\\textbf{PPO}), Return-Conditioned RL) on improving LLM reasoning capabilities. We investigate both sparse and dense rewards provided to the LLM both heuristically and via a learned reward model. We additionally start from multiple model sizes and initializations both with and without supervised fine-tuning (\\textbf{SFT}) data. Overall, we find all algorithms perform comparably, with Expert Iteration performing best in most cases. Surprisingly, we find the sample complexity of Expert Iteration is similar to that of PPO, requiring at most on the order of $10^6$ samples to converge from a pretrained checkpoint. We investigate why this is the case, concluding that during RL training models fail to explore significantly beyond solutions already produced by SFT models. Additionally, we discuss a trade off between maj@1 and pass@96 metric performance during SFT training and how conversely RL training improves both simultaneously. We then conclude by discussing the implications of our findings for RLHF and the future role of RL in LLM fine-tuning.","sentences":["Reinforcement Learning from Human Feedback (\\textbf{RLHF}) has emerged as a dominant approach for aligning LLM outputs with human preferences.","Inspired by the success of RLHF, we study the performance of multiple algorithms that learn from feedback (Expert Iteration, Proximal Policy Optimization (\\textbf{PPO}), Return-Conditioned RL) on improving LLM reasoning capabilities.","We investigate both sparse and dense rewards provided to the LLM both heuristically and via a learned reward model.","We additionally start from multiple model sizes and initializations both with and without supervised fine-tuning (\\textbf{SFT}) data.","Overall, we find all algorithms perform comparably, with Expert Iteration performing best in most cases.","Surprisingly, we find the sample complexity of Expert Iteration is similar to that of PPO, requiring at most on the order of $10^6","$ samples to converge from a pretrained checkpoint.","We investigate why this is the case, concluding that during RL training models fail to explore significantly beyond solutions already produced by SFT models.","Additionally, we discuss a trade off between maj@1 and pass@96 metric performance during SFT training and how conversely RL training improves both simultaneously.","We then conclude by discussing the implications of our findings for RLHF and the future role of RL in LLM fine-tuning."],"url":"http://arxiv.org/abs/2403.04642v1"}
{"created":"2024-03-07 16:31:02","title":"CAT: Enhancing Multimodal Large Language Model to Answer Questions in Dynamic Audio-Visual Scenarios","abstract":"This paper focuses on the challenge of answering questions in scenarios that are composed of rich and complex dynamic audio-visual components. Although existing Multimodal Large Language Models (MLLMs) can respond to audio-visual content, these responses are sometimes ambiguous and fail to describe specific audio-visual events. To overcome this limitation, we introduce the CAT, which enhances MLLM in three ways: 1) besides straightforwardly bridging audio and video, we design a clue aggregator that aggregates question-related clues in dynamic audio-visual scenarios to enrich the detailed knowledge required for large language models. 2) CAT is trained on a mixed multimodal dataset, allowing direct application in audio-visual scenarios. Notably, we collect an audio-visual joint instruction dataset named AVinstruct, to further enhance the capacity of CAT to model cross-semantic correlations. 3) we propose AI-assisted ambiguity-aware direct preference optimization, a strategy specialized in retraining the model to favor the non-ambiguity response and improve the ability to localize specific audio-visual objects. Extensive experimental results demonstrate that CAT outperforms existing methods on multimodal tasks, especially in Audio-Visual Question Answering (AVQA) tasks. The codes and the collected instructions are released at https://github.com/rikeilong/Bay-CAT.","sentences":["This paper focuses on the challenge of answering questions in scenarios that are composed of rich and complex dynamic audio-visual components.","Although existing Multimodal Large Language Models (MLLMs) can respond to audio-visual content, these responses are sometimes ambiguous and fail to describe specific audio-visual events.","To overcome this limitation, we introduce the CAT, which enhances MLLM in three ways: 1) besides straightforwardly bridging audio and video, we design a clue aggregator that aggregates question-related clues in dynamic audio-visual scenarios to enrich the detailed knowledge required for large language models.","2) CAT is trained on a mixed multimodal dataset, allowing direct application in audio-visual scenarios.","Notably, we collect an audio-visual joint instruction dataset named AVinstruct, to further enhance the capacity of CAT to model cross-semantic correlations.","3) we propose AI-assisted ambiguity-aware direct preference optimization, a strategy specialized in retraining the model to favor the non-ambiguity response and improve the ability to localize specific audio-visual objects.","Extensive experimental results demonstrate that CAT outperforms existing methods on multimodal tasks, especially in Audio-Visual Question Answering (AVQA) tasks.","The codes and the collected instructions are released at https://github.com/rikeilong/Bay-CAT."],"url":"http://arxiv.org/abs/2403.04640v1"}
{"created":"2024-03-07 16:29:19","title":"MaCmS: Magahi Code-mixed Dataset for Sentiment Analysis","abstract":"The present paper introduces new sentiment data, MaCMS, for Magahi-Hindi-English (MHE) code-mixed language, where Magahi is a less-resourced minority language. This dataset is the first Magahi-Hindi-English code-mixed dataset for sentiment analysis tasks. Further, we also provide a linguistics analysis of the dataset to understand the structure of code-mixing and a statistical study to understand the language preferences of speakers with different polarities. With these analyses, we also train baseline models to evaluate the dataset's quality.","sentences":["The present paper introduces new sentiment data, MaCMS, for Magahi-Hindi-English (MHE) code-mixed language, where Magahi is a less-resourced minority language.","This dataset is the first Magahi-Hindi-English code-mixed dataset for sentiment analysis tasks.","Further, we also provide a linguistics analysis of the dataset to understand the structure of code-mixing and a statistical study to understand the language preferences of speakers with different polarities.","With these analyses, we also train baseline models to evaluate the dataset's quality."],"url":"http://arxiv.org/abs/2403.04639v1"}
{"created":"2024-03-07 16:29:12","title":"Scalable, Simulation-Guided Compliant Tactile Finger Design","abstract":"Compliant grippers enable robots to work with humans in unstructured environments. In general, these grippers can improve with tactile sensing to estimate the state of objects around them to precisely manipulate objects. However, co-designing compliant structures with high-resolution tactile sensing is a challenging task. We propose a simulation framework for the end-to-end forward design of GelSight Fin Ray sensors. Our simulation framework consists of mechanical simulation using the finite element method (FEM) and optical simulation including physically based rendering (PBR). To simulate the fluorescent paint used in these GelSight Fin Rays, we propose an efficient method that can be directly integrated in PBR. Using the simulation framework, we investigate design choices available in the compliant grippers, namely gel pad shapes, illumination conditions, Fin Ray gripper sizes, and Fin Ray stiffness. This infrastructure enables faster design and prototype time frames of new Fin Ray sensors that have various sensing areas, ranging from 48 mm $\\times$ \\18 mm to 70 mm $\\times$ 35 mm. Given the parameters we choose, we can thus optimize different Fin Ray designs and show their utility in grasping day-to-day objects.","sentences":["Compliant grippers enable robots to work with humans in unstructured environments.","In general, these grippers can improve with tactile sensing to estimate the state of objects around them to precisely manipulate objects.","However, co-designing compliant structures with high-resolution tactile sensing is a challenging task.","We propose a simulation framework for the end-to-end forward design of GelSight Fin Ray sensors.","Our simulation framework consists of mechanical simulation using the finite element method (FEM) and optical simulation including physically based rendering (PBR).","To simulate the fluorescent paint used in these GelSight Fin Rays, we propose an efficient method that can be directly integrated in PBR.","Using the simulation framework, we investigate design choices available in the compliant grippers, namely gel pad shapes, illumination conditions, Fin Ray gripper sizes, and Fin Ray stiffness.","This infrastructure enables faster design and prototype time frames of new Fin Ray sensors that have various sensing areas, ranging from 48 mm $\\times$ \\18","mm to 70 mm $\\times$ 35 mm.","Given the parameters we choose, we can thus optimize different Fin Ray designs and show their utility in grasping day-to-day objects."],"url":"http://arxiv.org/abs/2403.04638v1"}
{"created":"2024-03-07 16:21:02","title":"Virtuoso: An Open-Source, Comprehensive and Modular Simulation Framework for Virtual Memory Research","abstract":"Virtual memory is a cornerstone of modern computing systems.Introduced as one of the earliest instances of hardware-software co-design, VM facilitates programmer-transparent memory man agement, data sharing, process isolation and memory protection. Evaluating the efficiency of various virtual memory (VM) designs is crucial (i) given their significant impact on the system, including the CPU caches, the main memory, and the storage device and (ii) given that different system architectures might benefit from various VM techniques. Such an evaluation is not straightforward, as it heavily hinges on modeling the interplay between different VM techniques and the interactions of VM with the system architecture. Modern simulators, however, struggle to keep up with the rapid VM research developments, lacking the capability to model a wide range of contemporary VM techniques and their interactions. To this end, we present Virtuoso, an open-source, comprehensive and modular simulation framework that models various VM designs to establish a common ground for virtual memory research. We demonstrate the versatility and the potential of Virtuoso with four new case studies. Virtuoso is freely open-source and can be found at https://github.com/CMU-SAFARI/Virtuoso.","sentences":["Virtual memory is a cornerstone of modern computing systems.","Introduced as one of the earliest instances of hardware-software co-design, VM facilitates programmer-transparent memory man agement, data sharing, process isolation and memory protection.","Evaluating the efficiency of various virtual memory (VM) designs is crucial (i) given their significant impact on the system, including the CPU caches, the main memory, and the storage device and (ii) given that different system architectures might benefit from various VM techniques.","Such an evaluation is not straightforward, as it heavily hinges on modeling the interplay between different VM techniques and the interactions of VM with the system architecture.","Modern simulators, however, struggle to keep up with the rapid VM research developments, lacking the capability to model a wide range of contemporary VM techniques and their interactions.","To this end, we present Virtuoso, an open-source, comprehensive and modular simulation framework that models various VM designs to establish a common ground for virtual memory research.","We demonstrate the versatility and the potential of Virtuoso with four new case studies.","Virtuoso is freely open-source and can be found at https://github.com/CMU-SAFARI/Virtuoso."],"url":"http://arxiv.org/abs/2403.04635v1"}
{"created":"2024-03-07 16:18:28","title":"Pix2Gif: Motion-Guided Diffusion for GIF Generation","abstract":"We present Pix2Gif, a motion-guided diffusion model for image-to-GIF (video) generation. We tackle this problem differently by formulating the task as an image translation problem steered by text and motion magnitude prompts, as shown in teaser fig. To ensure that the model adheres to motion guidance, we propose a new motion-guided warping module to spatially transform the features of the source image conditioned on the two types of prompts. Furthermore, we introduce a perceptual loss to ensure the transformed feature map remains within the same space as the target image, ensuring content consistency and coherence. In preparation for the model training, we meticulously curated data by extracting coherent image frames from the TGIF video-caption dataset, which provides rich information about the temporal changes of subjects. After pretraining, we apply our model in a zero-shot manner to a number of video datasets. Extensive qualitative and quantitative experiments demonstrate the effectiveness of our model -- it not only captures the semantic prompt from text but also the spatial ones from motion guidance. We train all our models using a single node of 16xV100 GPUs. Code, dataset and models are made public at: https://hiteshk03.github.io/Pix2Gif/.","sentences":["We present Pix2Gif, a motion-guided diffusion model for image-to-GIF (video) generation.","We tackle this problem differently by formulating the task as an image translation problem steered by text and motion magnitude prompts, as shown in teaser fig.","To ensure that the model adheres to motion guidance, we propose a new motion-guided warping module to spatially transform the features of the source image conditioned on the two types of prompts.","Furthermore, we introduce a perceptual loss to ensure the transformed feature map remains within the same space as the target image, ensuring content consistency and coherence.","In preparation for the model training, we meticulously curated data by extracting coherent image frames from the TGIF video-caption dataset, which provides rich information about the temporal changes of subjects.","After pretraining, we apply our model in a zero-shot manner to a number of video datasets.","Extensive qualitative and quantitative experiments demonstrate the effectiveness of our model -- it not only captures the semantic prompt from text but also the spatial ones from motion guidance.","We train all our models using a single node of 16xV100 GPUs.","Code, dataset and models are made public at: https://hiteshk03.github.io/Pix2Gif/."],"url":"http://arxiv.org/abs/2403.04634v1"}
{"created":"2024-03-07 16:16:39","title":"Message-Observing Sessions","abstract":"We present Most, a process language with message-observing session types. Message-observing session types extend binary session types with type-level computation to specify communication protocols that vary based on messages observed on other channels. Hence, Most allows us to express global invariants about processes, rather than just local invariants, in a bottom-up, compositional way. We give Most a semantic foundation using traces with binding, a semantic approach for compositionally reasoning about traces in the presence of name generation. We use this semantics to prove type soundness and compositionality for Most processes. We see this as a significant step towards capturing message-dependencies and providing more precise guarantees about processes.","sentences":["We present Most, a process language with message-observing session types.","Message-observing session types extend binary session types with type-level computation to specify communication protocols that vary based on messages observed on other channels.","Hence, Most allows us to express global invariants about processes, rather than just local invariants, in a bottom-up, compositional way.","We give Most a semantic foundation using traces with binding, a semantic approach for compositionally reasoning about traces in the presence of name generation.","We use this semantics to prove type soundness and compositionality for Most processes.","We see this as a significant step towards capturing message-dependencies and providing more precise guarantees about processes."],"url":"http://arxiv.org/abs/2403.04633v1"}
{"created":"2024-03-07 16:14:08","title":"Time-Aware Projections: Truly Node-Private Graph Statistics under Continual Observation","abstract":"We describe the first algorithms that satisfy the standard notion of node-differential privacy in the continual release setting (i.e., without an assumed promise on input streams). Previous work addresses node-private continual release by assuming an unenforced promise on the maximum degree in a graph; indeed, the algorithms from these works exhibit blatant privacy violations when the degree bound is not met. Our algorithms are accurate on sparse graphs, for several fundamental graph problems: counting edges, triangles, other subgraphs, and connected components; and releasing degree histograms. Our unconditionally private algorithms generally have optimal error, up to polylogarithmic factors and lower-order terms.   We provide general transformations that take a base algorithm for the continual release setting, which need only be private for streams satisfying a promised degree bound, and produce an algorithm that is unconditionally private yet mimics the base algorithm when the stream meets the degree bound (and adds only linear overhead to the time and space complexity of the base algorithm). To do so, we design new projection algorithms for graph streams, based on the batch-model techniques of Day et al. 2016 and Blocki et al. 2013, which modify the stream to limit its degree. Our main technical innovation is to show that the projections are stable -- meaning that similar input graphs have similar projections -- when the input stream satisfies a privately testable safety condition. Our transformation then follows a novel online variant of the Propose-Test-Release framework (Dwork and Lei, 2009), privately testing the safety condition before releasing output at each step.","sentences":["We describe the first algorithms that satisfy the standard notion of node-differential privacy in the continual release setting (i.e., without an assumed promise on input streams).","Previous work addresses node-private continual release by assuming an unenforced promise on the maximum degree in a graph; indeed, the algorithms from these works exhibit blatant privacy violations when the degree bound is not met.","Our algorithms are accurate on sparse graphs, for several fundamental graph problems: counting edges, triangles, other subgraphs, and connected components; and releasing degree histograms.","Our unconditionally private algorithms generally have optimal error, up to polylogarithmic factors and lower-order terms.   ","We provide general transformations that take a base algorithm for the continual release setting, which need only be private for streams satisfying a promised degree bound, and produce an algorithm that is unconditionally private yet mimics the base algorithm when the stream meets the degree bound (and adds only linear overhead to the time and space complexity of the base algorithm).","To do so, we design new projection algorithms for graph streams, based on the batch-model techniques of Day et al. 2016 and Blocki et al. 2013, which modify the stream to limit its degree.","Our main technical innovation is to show that the projections are stable -- meaning that similar input graphs have similar projections -- when the input stream satisfies a privately testable safety condition.","Our transformation then follows a novel online variant of the Propose-Test-Release framework (Dwork and Lei, 2009), privately testing the safety condition before releasing output at each step."],"url":"http://arxiv.org/abs/2403.04630v1"}
{"created":"2024-03-07 16:13:32","title":"Explaining Bayesian Optimization by Shapley Values Facilitates Human-AI Collaboration","abstract":"Bayesian optimization (BO) with Gaussian processes (GP) has become an indispensable algorithm for black box optimization problems. Not without a dash of irony, BO is often considered a black box itself, lacking ways to provide reasons as to why certain parameters are proposed to be evaluated. This is particularly relevant in human-in-the-loop applications of BO, such as in robotics. We address this issue by proposing ShapleyBO, a framework for interpreting BO's proposals by game-theoretic Shapley values.They quantify each parameter's contribution to BO's acquisition function. Exploiting the linearity of Shapley values, we are further able to identify how strongly each parameter drives BO's exploration and exploitation for additive acquisition functions like the confidence bound. We also show that ShapleyBO can disentangle the contributions to exploration into those that explore aleatoric and epistemic uncertainty. Moreover, our method gives rise to a ShapleyBO-assisted human machine interface (HMI), allowing users to interfere with BO in case proposals do not align with human reasoning. We demonstrate this HMI's benefits for the use case of personalizing wearable robotic devices (assistive back exosuits) by human-in-the-loop BO. Results suggest human-BO teams with access to ShapleyBO can achieve lower regret than teams without.","sentences":["Bayesian optimization (BO) with Gaussian processes (GP) has become an indispensable algorithm for black box optimization problems.","Not without a dash of irony, BO is often considered a black box itself, lacking ways to provide reasons as to why certain parameters are proposed to be evaluated.","This is particularly relevant in human-in-the-loop applications of BO, such as in robotics.","We address this issue by proposing ShapleyBO, a framework for interpreting BO's proposals by game-theoretic Shapley values.","They quantify each parameter's contribution to BO's acquisition function.","Exploiting the linearity of Shapley values, we are further able to identify how strongly each parameter drives BO's exploration and exploitation for additive acquisition functions like the confidence bound.","We also show that ShapleyBO can disentangle the contributions to exploration into those that explore aleatoric and epistemic uncertainty.","Moreover, our method gives rise to a ShapleyBO-assisted human machine interface (HMI), allowing users to interfere with BO in case proposals do not align with human reasoning.","We demonstrate this HMI's benefits for the use case of personalizing wearable robotic devices (assistive back exosuits) by human-in-the-loop BO.","Results suggest human-BO teams with access to ShapleyBO can achieve lower regret than teams without."],"url":"http://arxiv.org/abs/2403.04629v1"}
{"created":"2024-03-07 16:12:54","title":"Distributed Multi-objective Optimization in Cyber-Physical Energy Systems","abstract":"Managing complex Cyber-Physical Energy Systems (CPES) requires solving various optimization problems with multiple objectives and constraints. As distributed control architectures are becoming more popular in CPES for certain tasks due to their flexibility, robustness, and privacy protection, multi-objective optimization must also be distributed. For this purpose, we present MO-COHDA, a fully distributed, agent-based algorithm, for solving multi-objective optimization problems of CPES. MO-COHDA allows an easy and flexible adaptation to different use cases and integration of custom functionality. To evaluate the effectiveness of MO-COHDA, we compare it to a central NSGA-2 algorithm using multi-objective benchmark functions from the ZDT problem suite. The results show that MO-COHDA can approximate the reference front of the benchmark problems well and is suitable for solving multi-objective optimization problems. In addition, an example use case of scheduling a group of generation units while optimizing three different objectives was evaluated to show how MO-COHDA can be easily applied to real-world optimization problems in CPES.","sentences":["Managing complex Cyber-Physical Energy Systems (CPES) requires solving various optimization problems with multiple objectives and constraints.","As distributed control architectures are becoming more popular in CPES for certain tasks due to their flexibility, robustness, and privacy protection, multi-objective optimization must also be distributed.","For this purpose, we present MO-COHDA, a fully distributed, agent-based algorithm, for solving multi-objective optimization problems of CPES.","MO-COHDA allows an easy and flexible adaptation to different use cases and integration of custom functionality.","To evaluate the effectiveness of MO-COHDA, we compare it to a central NSGA-2 algorithm using multi-objective benchmark functions from the ZDT problem suite.","The results show that MO-COHDA can approximate the reference front of the benchmark problems well and is suitable for solving multi-objective optimization problems.","In addition, an example use case of scheduling a group of generation units while optimizing three different objectives was evaluated to show how MO-COHDA can be easily applied to real-world optimization problems in CPES."],"url":"http://arxiv.org/abs/2403.04627v1"}
{"created":"2024-03-07 16:02:31","title":"Strong Priority and Determinacy in Timed CCS","abstract":"Building on the classical theory of process algebra with priorities, we identify a new scheduling mechanism, called \"sequentially constructive reduction\" which is designed to capture the essence of synchronous programming. The distinctive property of this evaluation strategy is to achieve determinism-by-construction for multi-cast concurrent communication. In particular, it permits us to model shared memory multi-threading with reaction to absence as it lies at the core of the programming language Esterel. In the technical setting of CCS extended by clocks and priorities, we prove for a large class of processes, which we call \"structurally coherent\" the confluence property for constructive reductions. We further show that under some syntactic restrictions, called \"pivotable\" the operators of prefix, summation, parallel composition, restriction and hiding preserve structural coherence. This covers a strictly larger class of processes compared to those that are confluent in Milner's classical theory of CCS without priorities.","sentences":["Building on the classical theory of process algebra with priorities, we identify a new scheduling mechanism, called \"sequentially constructive reduction\" which is designed to capture the essence of synchronous programming.","The distinctive property of this evaluation strategy is to achieve determinism-by-construction for multi-cast concurrent communication.","In particular, it permits us to model shared memory multi-threading with reaction to absence as it lies at the core of the programming language Esterel.","In the technical setting of CCS extended by clocks and priorities, we prove for a large class of processes, which we call \"structurally coherent\" the confluence property for constructive reductions.","We further show that under some syntactic restrictions, called \"pivotable\" the operators of prefix, summation, parallel composition, restriction and hiding preserve structural coherence.","This covers a strictly larger class of processes compared to those that are confluent in Milner's classical theory of CCS without priorities."],"url":"http://arxiv.org/abs/2403.04618v1"}
{"created":"2024-03-07 16:01:08","title":"Modeling reputation-based behavioral biases in school choice","abstract":"A fundamental component in the theoretical school choice literature is the problem a student faces in deciding which schools to apply to. Recent models have considered a set of schools of different selectiveness and a student who is unsure of their strength and can apply to at most $k$ schools. Such models assume that the student cares solely about maximizing the quality of the school that they attend, but experience suggests that students' decisions are also influenced by a set of behavioral biases based on reputational effects: a subjective reputational benefit when admitted to a selective school, whether or not they attend; and a subjective loss based on disappointment when rejected. Guided by these observations, and inspired by recent behavioral economics work on loss aversion relative to expectations, we propose a behavioral model by which a student chooses schools to balance these behavioral effects with the quality of the school they attend.   Our main results show that a student's choices change in dramatic ways when these reputation-based behavioral biases are taken into account. In particular, where a rational applicant spreads their applications evenly, a biased student applies very sparsely to highly selective schools, such that above a certain threshold they apply to only an absolute constant number of schools even as their budget of applications grows to infinity. Consequently, a biased student underperforms a rational student even when the rational student is restricted to a sufficiently large upper bound on applications and the biased student can apply to arbitrarily many. Our analysis shows that the reputation-based model is rich enough to cover a range of different ways that biased students cope with fear of rejection, including not just targeting less selective schools, but also occasionally applying to schools that are too selective, compared to rational students.","sentences":["A fundamental component in the theoretical school choice literature is the problem a student faces in deciding which schools to apply to.","Recent models have considered a set of schools of different selectiveness and a student who is unsure of their strength and can apply to at most $k$ schools.","Such models assume that the student cares solely about maximizing the quality of the school that they attend, but experience suggests that students' decisions are also influenced by a set of behavioral biases based on reputational effects: a subjective reputational benefit when admitted to a selective school, whether or not they attend; and a subjective loss based on disappointment when rejected.","Guided by these observations, and inspired by recent behavioral economics work on loss aversion relative to expectations, we propose a behavioral model by which a student chooses schools to balance these behavioral effects with the quality of the school they attend.   ","Our main results show that a student's choices change in dramatic ways when these reputation-based behavioral biases are taken into account.","In particular, where a rational applicant spreads their applications evenly, a biased student applies very sparsely to highly selective schools, such that above a certain threshold they apply to only an absolute constant number of schools even as their budget of applications grows to infinity.","Consequently, a biased student underperforms a rational student even when the rational student is restricted to a sufficiently large upper bound on applications and the biased student can apply to arbitrarily many.","Our analysis shows that the reputation-based model is rich enough to cover a range of different ways that biased students cope with fear of rejection, including not just targeting less selective schools, but also occasionally applying to schools that are too selective, compared to rational students."],"url":"http://arxiv.org/abs/2403.04616v1"}
{"created":"2024-03-07 15:59:35","title":"Rectangular Rotational Invariant Estimator for High-Rank Matrix Estimation","abstract":"We consider estimating a matrix from noisy observations coming from an arbitrary additive bi- rotational invariant perturbation. We propose an estimator which is optimal among the class of rectangular rotational invariant estimators and can be applied irrespective of the prior on the signal. For the particular case of Gaussian noise, we prove the optimality of the proposed estimator, and we find an explicit expression for the MMSE in terms of the limiting singular value distribution of the observation matrix. Moreover, we prove a formula linking the asymptotic mutual information and the limit of a log-spherical integral of rectangular matrices. We also provide numerical checks for our results for general bi-rotational invariant noise, as well as Gaussian noise, which match our theoretical predictions.","sentences":["We consider estimating a matrix from noisy observations coming from an arbitrary additive bi- rotational invariant perturbation.","We propose an estimator which is optimal among the class of rectangular rotational invariant estimators and can be applied irrespective of the prior on the signal.","For the particular case of Gaussian noise, we prove the optimality of the proposed estimator, and we find an explicit expression for the MMSE in terms of the limiting singular value distribution of the observation matrix.","Moreover, we prove a formula linking the asymptotic mutual information and the limit of a log-spherical integral of rectangular matrices.","We also provide numerical checks for our results for general bi-rotational invariant noise, as well as Gaussian noise, which match our theoretical predictions."],"url":"http://arxiv.org/abs/2403.04615v1"}
{"created":"2024-03-07 15:55:05","title":"Standardization of Cloth Objects and its Relevance in Robotic Manipulation","abstract":"The field of robotics faces inherent challenges in manipulating deformable objects, particularly in understanding and standardising fabric properties like elasticity, stiffness, and friction. While the significance of these properties is evident in the realm of cloth manipulation, accurately categorising and comprehending them in real-world applications remains elusive. This study sets out to address two primary objectives: (1) to provide a framework suitable for robotics applications to characterise cloth objects, and (2) to study how these properties influence robotic manipulation tasks. Our preliminary results validate the framework's ability to characterise cloth properties and compare cloth sets, and reveal the influence that different properties have on the outcome of five manipulation primitives. We believe that, in general, results on the manipulation of clothes should be reported along with a better description of the garments used in the evaluation. This paper proposes a set of these measures.","sentences":["The field of robotics faces inherent challenges in manipulating deformable objects, particularly in understanding and standardising fabric properties like elasticity, stiffness, and friction.","While the significance of these properties is evident in the realm of cloth manipulation, accurately categorising and comprehending them in real-world applications remains elusive.","This study sets out to address two primary objectives: (1) to provide a framework suitable for robotics applications to characterise cloth objects, and (2) to study how these properties influence robotic manipulation tasks.","Our preliminary results validate the framework's ability to characterise cloth properties and compare cloth sets, and reveal the influence that different properties have on the outcome of five manipulation primitives.","We believe that, in general, results on the manipulation of clothes should be reported along with a better description of the garments used in the evaluation.","This paper proposes a set of these measures."],"url":"http://arxiv.org/abs/2403.04608v1"}
{"created":"2024-03-07 15:54:46","title":"In-n-Out: Calibrating Graph Neural Networks for Link Prediction","abstract":"Deep neural networks are notoriously miscalibrated, i.e., their outputs do not reflect the true probability of the event we aim to predict. While networks for tabular or image data are usually overconfident, recent works have shown that graph neural networks (GNNs) show the opposite behavior for node-level classification. But what happens when we are predicting links? We show that, in this case, GNNs often exhibit a mixed behavior. More specifically, they may be overconfident in negative predictions while being underconfident in positive ones. Based on this observation, we propose IN-N-OUT, the first-ever method to calibrate GNNs for link prediction. IN-N-OUT is based on two simple intuitions: i) attributing true/false labels to an edge while respecting a GNNs prediction should cause but small fluctuations in that edge's embedding; and, conversely, ii) if we label that same edge contradicting our GNN, embeddings should change more substantially. An extensive experimental campaign shows that IN-N-OUT significantly improves the calibration of GNNs in link prediction, consistently outperforming the baselines available -- which are not designed for this specific task.","sentences":["Deep neural networks are notoriously miscalibrated, i.e., their outputs do not reflect the true probability of the event we aim to predict.","While networks for tabular or image data are usually overconfident, recent works have shown that graph neural networks (GNNs) show the opposite behavior for node-level classification.","But what happens when we are predicting links?","We show that, in this case, GNNs often exhibit a mixed behavior.","More specifically, they may be overconfident in negative predictions while being underconfident in positive ones.","Based on this observation, we propose IN-N-OUT, the first-ever method to calibrate GNNs for link prediction.","IN-N-OUT is based on two simple intuitions: i) attributing true/false labels to an edge while respecting a GNNs prediction should cause but small fluctuations in that edge's embedding; and, conversely, ii) if we label that same edge contradicting our GNN, embeddings should change more substantially.","An extensive experimental campaign shows that IN-N-OUT significantly improves the calibration of GNNs in link prediction, consistently outperforming the baselines available -- which are not designed for this specific task."],"url":"http://arxiv.org/abs/2403.04605v1"}
{"created":"2024-03-07 15:52:32","title":"Minimum-Time Planar Paths with up to Two Constant Acceleration Inputs and $L_2$ Velocity and Acceleration Constraints","abstract":"Given starting and ending positions and velocities, $L_2$ bounds on the acceleration and velocity, and the restriction to no more than two constant control inputs, this paper provides routines to compute the minimal-time path. Closed form solutions are provided for reaching a position in minimum time with and without a velocity bound, and for stopping at the goal position.   A numeric solver is used to reach a goal position and velocity with no more than two constant control inputs. If a cruising phase at the terminal velocity is needed, this requires solving a non-linear equation with a single parameter. Code is provided on GitHub at https://github.com/RoboticSwarmControl/MinTimeL2pathsConstraints.","sentences":["Given starting and ending positions and velocities, $L_2$ bounds on the acceleration and velocity, and the restriction to no more than two constant control inputs, this paper provides routines to compute the minimal-time path.","Closed form solutions are provided for reaching a position in minimum time with and without a velocity bound, and for stopping at the goal position.   ","A numeric solver is used to reach a goal position and velocity with no more than two constant control inputs.","If a cruising phase at the terminal velocity is needed, this requires solving a non-linear equation with a single parameter.","Code is provided on GitHub at https://github.com/RoboticSwarmControl/MinTimeL2pathsConstraints."],"url":"http://arxiv.org/abs/2403.04602v1"}
{"created":"2024-03-07 15:48:19","title":"Equivalence of constacyclic codes with shift constants of different orders","abstract":"Let $a$ and $b$ be two non-zero elements of a finite field $\\mathbb{F}_q$, where $q>2$. It has been shown that if $a$ and $b$ have the same multiplicative order in $\\mathbb{F}_q$, then the families of $a$-constacyclic and $b$-constacyclic codes over $\\mathbb{F}_q$ are monomially equivalent. In this paper, we investigate the monomial equivalence of $a$-constacyclic and $b$-constacyclic codes when $a$ and $b$ have distinct multiplicative orders. We present novel conditions for establishing monomial equivalence in such constacyclic codes, surpassing previous methods of determining monomially equivalent constacyclic and cyclic codes. As an application, we use these results to search for new linear codes more systematically. In particular, we present more than $70$ new record-breaking linear codes over various finite fields, as well as new binary quantum codes.","sentences":["Let $a$ and $b$ be two non-zero elements of a finite field $\\mathbb{F}_q$, where $q>2$. It has been shown that if $a$ and $b$ have the same multiplicative order in $\\mathbb{F}_q$, then the families of $a$-constacyclic and $b$-constacyclic codes over $\\mathbb{F}_q$ are monomially equivalent.","In this paper, we investigate the monomial equivalence of $a$-constacyclic and $b$-constacyclic codes when $a$ and $b$ have distinct multiplicative orders.","We present novel conditions for establishing monomial equivalence in such constacyclic codes, surpassing previous methods of determining monomially equivalent constacyclic and cyclic codes.","As an application, we use these results to search for new linear codes more systematically.","In particular, we present more than $70$ new record-breaking linear codes over various finite fields, as well as new binary quantum codes."],"url":"http://arxiv.org/abs/2403.04600v1"}
{"created":"2024-03-07 15:47:52","title":"Contrastive Continual Learning with Importance Sampling and Prototype-Instance Relation Distillation","abstract":"Recently, because of the high-quality representations of contrastive learning methods, rehearsal-based contrastive continual learning has been proposed to explore how to continually learn transferable representation embeddings to avoid the catastrophic forgetting issue in traditional continual settings. Based on this framework, we propose Contrastive Continual Learning via Importance Sampling (CCLIS) to preserve knowledge by recovering previous data distributions with a new strategy for Replay Buffer Selection (RBS), which minimize estimated variance to save hard negative samples for representation learning with high quality. Furthermore, we present the Prototype-instance Relation Distillation (PRD) loss, a technique designed to maintain the relationship between prototypes and sample representations using a self-distillation process. Experiments on standard continual learning benchmarks reveal that our method notably outperforms existing baselines in terms of knowledge preservation and thereby effectively counteracts catastrophic forgetting in online contexts. The code is available at https://github.com/lijy373/CCLIS.","sentences":["Recently, because of the high-quality representations of contrastive learning methods, rehearsal-based contrastive continual learning has been proposed to explore how to continually learn transferable representation embeddings to avoid the catastrophic forgetting issue in traditional continual settings.","Based on this framework, we propose Contrastive Continual Learning via Importance Sampling (CCLIS) to preserve knowledge by recovering previous data distributions with a new strategy for Replay Buffer Selection (RBS), which minimize estimated variance to save hard negative samples for representation learning with high quality.","Furthermore, we present the Prototype-instance Relation Distillation (PRD) loss, a technique designed to maintain the relationship between prototypes and sample representations using a self-distillation process.","Experiments on standard continual learning benchmarks reveal that our method notably outperforms existing baselines in terms of knowledge preservation and thereby effectively counteracts catastrophic forgetting in online contexts.","The code is available at https://github.com/lijy373/CCLIS."],"url":"http://arxiv.org/abs/2403.04599v1"}
{"created":"2024-03-07 15:46:19","title":"Optimizing Inventory Placement for a Downstream Online Matching Problem","abstract":"We study the inventory placement problem of splitting $Q$ units of a single item across warehouses, in advance of a downstream online matching problem that represents the dynamic fulfillment decisions of an e-commerce retailer. This is a challenging problem both in theory, because the downstream matching problem itself is computationally hard, and in practice, because the fulfillment team is constantly updating its algorithm and the placement team cannot directly evaluate how a placement decision would perform.   We compare the performance of three placement procedures based on optimizing surrogate functions that have been studied and applied: Offline, Myopic, and Fluid placement. On the theory side, we show that optimizing inventory placement for the Offline surrogate leads to a $(1-(1-1/d)^d)/2$-approximation for the joint placement and fulfillment problem. We assume $d$ is an upper bound on how many warehouses can serve any demand location and that stochastic arrivals satisfy either temporal or spatial independence. The crux of our theoretical contribution is to use randomized rounding to derive a tight $(1-(1-1/d)^d)$-approximation for the integer programming problem of optimizing the Offline surrogate. We use statistical learning to show that rounding after optimizing a sample-average Offline surrogate, which is necessary due to the exponentially-sized support, does indeed have vanishing loss.   On the experimental side, we extract real-world sequences of customer orders from publicly-available JD.com data and evaluate different combinations of placement and fulfillment procedures. Optimizing the Offline surrogate performs best overall, even compared to simulation procedures, corroborating our theory.","sentences":["We study the inventory placement problem of splitting $Q$ units of a single item across warehouses, in advance of a downstream online matching problem that represents the dynamic fulfillment decisions of an e-commerce retailer.","This is a challenging problem both in theory, because the downstream matching problem itself is computationally hard, and in practice, because the fulfillment team is constantly updating its algorithm and the placement team cannot directly evaluate how a placement decision would perform.   ","We compare the performance of three placement procedures based on optimizing surrogate functions that have been studied and applied: Offline, Myopic, and Fluid placement.","On the theory side, we show that optimizing inventory placement for the Offline surrogate leads to a $(1-(1-1/d)^d)/2$-approximation for the joint placement and fulfillment problem.","We assume $d$ is an upper bound on how many warehouses can serve any demand location and that stochastic arrivals satisfy either temporal or spatial independence.","The crux of our theoretical contribution is to use randomized rounding to derive a tight $(1-(1-1/d)^d)$-approximation for the integer programming problem of optimizing the Offline surrogate.","We use statistical learning to show that rounding after optimizing a sample-average Offline surrogate, which is necessary due to the exponentially-sized support, does indeed have vanishing loss.   ","On the experimental side, we extract real-world sequences of customer orders from publicly-available JD.com data and evaluate different combinations of placement and fulfillment procedures.","Optimizing the Offline surrogate performs best overall, even compared to simulation procedures, corroborating our theory."],"url":"http://arxiv.org/abs/2403.04598v1"}
{"created":"2024-03-07 15:40:01","title":"A Detailed Audio-Text Data Simulation Pipeline using Single-Event Sounds","abstract":"Recently, there has been an increasing focus on audio-text cross-modal learning. However, most of the existing audio-text datasets contain only simple descriptions of sound events. Compared with classification labels, the advantages of such descriptions are significantly limited. In this paper, we first analyze the detailed information that human descriptions of audio may contain beyond sound event labels. Based on the analysis, we propose an automatic pipeline for curating audio-text pairs with rich details. Leveraging the property that sounds can be mixed and concatenated in the time domain, we control details in four aspects: temporal relationship, loudness, speaker identity, and occurrence number, in simulating audio mixtures. Corresponding details are transformed into captions by large language models. Audio-text pairs with rich details in text descriptions are thereby obtained. We validate the effectiveness of our pipeline with a small amount of simulated data, demonstrating that the simulated data enables models to learn detailed audio captioning.","sentences":["Recently, there has been an increasing focus on audio-text cross-modal learning.","However, most of the existing audio-text datasets contain only simple descriptions of sound events.","Compared with classification labels, the advantages of such descriptions are significantly limited.","In this paper, we first analyze the detailed information that human descriptions of audio may contain beyond sound event labels.","Based on the analysis, we propose an automatic pipeline for curating audio-text pairs with rich details.","Leveraging the property that sounds can be mixed and concatenated in the time domain, we control details in four aspects: temporal relationship, loudness, speaker identity, and occurrence number, in simulating audio mixtures.","Corresponding details are transformed into captions by large language models.","Audio-text pairs with rich details in text descriptions are thereby obtained.","We validate the effectiveness of our pipeline with a small amount of simulated data, demonstrating that the simulated data enables models to learn detailed audio captioning."],"url":"http://arxiv.org/abs/2403.04594v1"}
{"created":"2024-03-07 15:39:18","title":"Embodied Understanding of Driving Scenarios","abstract":"Embodied scene understanding serves as the cornerstone for autonomous agents to perceive, interpret, and respond to open driving scenarios. Such understanding is typically founded upon Vision-Language Models (VLMs). Nevertheless, existing VLMs are restricted to the 2D domain, devoid of spatial awareness and long-horizon extrapolation proficiencies. We revisit the key aspects of autonomous driving and formulate appropriate rubrics. Hereby, we introduce the Embodied Language Model (ELM), a comprehensive framework tailored for agents' understanding of driving scenes with large spatial and temporal spans. ELM incorporates space-aware pre-training to endow the agent with robust spatial localization capabilities. Besides, the model employs time-aware token selection to accurately inquire about temporal cues. We instantiate ELM on the reformulated multi-faced benchmark, and it surpasses previous state-of-the-art approaches in all aspects. All code, data, and models will be publicly shared.","sentences":["Embodied scene understanding serves as the cornerstone for autonomous agents to perceive, interpret, and respond to open driving scenarios.","Such understanding is typically founded upon Vision-Language Models (VLMs).","Nevertheless, existing VLMs are restricted to the 2D domain, devoid of spatial awareness and long-horizon extrapolation proficiencies.","We revisit the key aspects of autonomous driving and formulate appropriate rubrics.","Hereby, we introduce the Embodied Language Model (ELM), a comprehensive framework tailored for agents' understanding of driving scenes with large spatial and temporal spans.","ELM incorporates space-aware pre-training to endow the agent with robust spatial localization capabilities.","Besides, the model employs time-aware token selection to accurately inquire about temporal cues.","We instantiate ELM on the reformulated multi-faced benchmark, and it surpasses previous state-of-the-art approaches in all aspects.","All code, data, and models will be publicly shared."],"url":"http://arxiv.org/abs/2403.04593v1"}
{"created":"2024-03-07 15:35:36","title":"Algorithms and complexity for path covers of temporal DAGs: when is Dilworth dynamic?","abstract":"In this paper, we study a dynamic analogue of the Path Cover problem, which can be solved in polynomial-time in directed acyclic graphs. A temporal digraph has an arc set that changes over discrete time-steps, if the underlying digraph (the union of all the arc sets) is acyclic, then we have a temporal DAG. A temporal path is a directed path in the underlying digraph, such that the time-steps of arcs are strictly increasing along the path. Two temporal paths are temporally disjoint if they do not occupy any vertex at the same time. A temporal (resp. temporally disjoint) path cover is a collection of (resp. temporally disjoint) temporal paths that covers all vertices. In this paper, we study the computational complexities of the problems of finding a temporal (disjoint) path cover with minimum cardinality, denoted as Temporal Path Cover (TPC) and Temporally Disjoint Path Cover (TD-PC). We show that both problems are NP-hard even when the underlying DAG is planar, bipartite, subcubic, and there are only two arc-disjoint time-steps. Moreover, TD-PC remains NP-hard even on temporal oriented trees. In contrast, we show that TPC is polynomial-time solvable on temporal oriented trees by a reduction to Clique Cover for (static undirected) weakly chordal graphs (a subclass of perfect graphs for which Clique Cover admits an efficient algorithm). This highlights an interesting algorithmic difference between the two problems. Although it is NP-hard on temporal oriented trees, TD-PC becomes polynomial-time solvable on temporal oriented lines and temporal rooted directed trees. We also show that TPC (resp. TD-PC) admits an XP (resp. FPT) time algorithm with respect to parameter tmax + tw, where tmax is the maximum time-step, and tw is the treewidth of the underlying static undirected graph.","sentences":["In this paper, we study a dynamic analogue of the Path Cover problem, which can be solved in polynomial-time in directed acyclic graphs.","A temporal digraph has an arc set that changes over discrete time-steps, if the underlying digraph (the union of all the arc sets) is acyclic, then we have a temporal DAG.","A temporal path is a directed path in the underlying digraph, such that the time-steps of arcs are strictly increasing along the path.","Two temporal paths are temporally disjoint if they do not occupy any vertex at the same time.","A temporal (resp.","temporally disjoint) path cover is a collection of (resp.","temporally disjoint) temporal paths that covers all vertices.","In this paper, we study the computational complexities of the problems of finding a temporal (disjoint) path cover with minimum cardinality, denoted as Temporal Path Cover (TPC) and Temporally Disjoint Path Cover (TD-PC).","We show that both problems are NP-hard even when the underlying DAG is planar, bipartite, subcubic, and there are only two arc-disjoint time-steps.","Moreover, TD-PC remains NP-hard even on temporal oriented trees.","In contrast, we show that TPC is polynomial-time solvable on temporal oriented trees by a reduction to Clique Cover for (static undirected) weakly chordal graphs (a subclass of perfect graphs for which Clique Cover admits an efficient algorithm).","This highlights an interesting algorithmic difference between the two problems.","Although it is NP-hard on temporal oriented trees, TD-PC becomes polynomial-time solvable on temporal oriented lines and temporal rooted directed trees.","We also show that TPC (resp.","TD-PC) admits an XP (resp.","FPT) time algorithm with respect to parameter tmax + tw, where tmax is the maximum time-step, and tw is the treewidth of the underlying static undirected graph."],"url":"http://arxiv.org/abs/2403.04589v1"}
{"created":"2024-03-07 15:35:29","title":"Zero-shot cross-modal transfer of Reinforcement Learning policies through a Global Workspace","abstract":"Humans perceive the world through multiple senses, enabling them to create a comprehensive representation of their surroundings and to generalize information across domains. For instance, when a textual description of a scene is given, humans can mentally visualize it. In fields like robotics and Reinforcement Learning (RL), agents can also access information about the environment through multiple sensors; yet redundancy and complementarity between sensors is difficult to exploit as a source of robustness (e.g. against sensor failure) or generalization (e.g. transfer across domains). Prior research demonstrated that a robust and flexible multimodal representation can be efficiently constructed based on the cognitive science notion of a 'Global Workspace': a unique representation trained to combine information across modalities, and to broadcast its signal back to each modality. Here, we explore whether such a brain-inspired multimodal representation could be advantageous for RL agents. First, we train a 'Global Workspace' to exploit information collected about the environment via two input modalities (a visual input, or an attribute vector representing the state of the agent and/or its environment). Then, we train a RL agent policy using this frozen Global Workspace. In two distinct environments and tasks, our results reveal the model's ability to perform zero-shot cross-modal transfer between input modalities, i.e. to apply to image inputs a policy previously trained on attribute vectors (and vice-versa), without additional training or fine-tuning. Variants and ablations of the full Global Workspace (including a CLIP-like multimodal representation trained via contrastive learning) did not display the same generalization abilities.","sentences":["Humans perceive the world through multiple senses, enabling them to create a comprehensive representation of their surroundings and to generalize information across domains.","For instance, when a textual description of a scene is given, humans can mentally visualize it.","In fields like robotics and Reinforcement Learning (RL), agents can also access information about the environment through multiple sensors; yet redundancy and complementarity between sensors is difficult to exploit as a source of robustness (e.g. against sensor failure) or generalization (e.g. transfer across domains).","Prior research demonstrated that a robust and flexible multimodal representation can be efficiently constructed based on the cognitive science notion of a 'Global Workspace': a unique representation trained to combine information across modalities, and to broadcast its signal back to each modality.","Here, we explore whether such a brain-inspired multimodal representation could be advantageous for RL agents.","First, we train a 'Global Workspace' to exploit information collected about the environment via two input modalities (a visual input, or an attribute vector representing the state of the agent and/or its environment).","Then, we train a RL agent policy using this frozen Global Workspace.","In two distinct environments and tasks, our results reveal the model's ability to perform zero-shot cross-modal transfer between input modalities, i.e. to apply to image inputs a policy previously trained on attribute vectors (and vice-versa), without additional training or fine-tuning.","Variants and ablations of the full Global Workspace (including a CLIP-like multimodal representation trained via contrastive learning) did not display the same generalization abilities."],"url":"http://arxiv.org/abs/2403.04588v1"}
{"created":"2024-03-07 15:30:54","title":"Learning Agility Adaptation for Flight in Clutter","abstract":"Animals learn to adapt agility of their movements to their capabilities and the environment they operate in. Mobile robots should also demonstrate this ability to combine agility and safety. The aim of this work is to endow flight vehicles with the ability of agility adaptation in prior unknown and partially observable cluttered environments. We propose a hierarchical learning and planning framework where we utilize both trial and error to comprehensively learn an agility policy with the vehicle's observation as the input, and well-established methods of model-based trajectory generation. Technically, we use online model-free reinforcement learning and a pre-training-fine-tuning reward scheme to obtain the deployable policy. The statistical results in simulation demonstrate the advantages of our method over the constant agility baselines and an alternative method in terms of flight efficiency and safety. In particular, the policy leads to intelligent behaviors, such as perception awareness, which distinguish it from other approaches. By deploying the policy to hardware, we verify that these advantages can be brought to the real world.","sentences":["Animals learn to adapt agility of their movements to their capabilities and the environment they operate in.","Mobile robots should also demonstrate this ability to combine agility and safety.","The aim of this work is to endow flight vehicles with the ability of agility adaptation in prior unknown and partially observable cluttered environments.","We propose a hierarchical learning and planning framework where we utilize both trial and error to comprehensively learn an agility policy with the vehicle's observation as the input, and well-established methods of model-based trajectory generation.","Technically, we use online model-free reinforcement learning and a pre-training-fine-tuning reward scheme to obtain the deployable policy.","The statistical results in simulation demonstrate the advantages of our method over the constant agility baselines and an alternative method in terms of flight efficiency and safety.","In particular, the policy leads to intelligent behaviors, such as perception awareness, which distinguish it from other approaches.","By deploying the policy to hardware, we verify that these advantages can be brought to the real world."],"url":"http://arxiv.org/abs/2403.04586v1"}
{"created":"2024-03-07 15:29:11","title":"Unbiased Estimator for Distorted Conics in Camera Calibration","abstract":"In the literature, points and conics have been major features for camera geometric calibration. Although conics are more informative features than points, the loss of the conic property under distortion has critically limited the utility of conic features in camera calibration. Many existing approaches addressed conic-based calibration by ignoring distortion or introducing 3D spherical targets to circumvent this limitation. In this paper, we present a novel formulation for conic-based calibration using moments. Our derivation is based on the mathematical finding that the first moment can be estimated without bias even under distortion. This allows us to track moment changes during projection and distortion, ensuring the preservation of the first moment of the distorted conic. With an unbiased estimator, the circular patterns can be accurately detected at the sub-pixel level and can now be fully exploited for an entire calibration pipeline, resulting in significantly improved calibration. The entire code is readily available from github.com/ChaehyeonSong/discocal.","sentences":["In the literature, points and conics have been major features for camera geometric calibration.","Although conics are more informative features than points, the loss of the conic property under distortion has critically limited the utility of conic features in camera calibration.","Many existing approaches addressed conic-based calibration by ignoring distortion or introducing 3D spherical targets to circumvent this limitation.","In this paper, we present a novel formulation for conic-based calibration using moments.","Our derivation is based on the mathematical finding that the first moment can be estimated without bias even under distortion.","This allows us to track moment changes during projection and distortion, ensuring the preservation of the first moment of the distorted conic.","With an unbiased estimator, the circular patterns can be accurately detected at the sub-pixel level and can now be fully exploited for an entire calibration pipeline, resulting in significantly improved calibration.","The entire code is readily available from github.com/ChaehyeonSong/discocal."],"url":"http://arxiv.org/abs/2403.04583v1"}
{"created":"2024-03-07 15:29:04","title":"What Cannot be Skipped About the Skiplist: A Survey of Skiplists and Their Applications in Big Data Systems","abstract":"Skiplists have become prevalent in systems. The main advantages of skiplists are their simplicity and ease of implementation, and the ability to support operations in the same asymptotic complexities as their tree-based counterparts. In this survey, we explore skiplists and their many variants. We highlight many scenarios of how skiplists are useful and fit well in these usage scenarios. We study several extensions to skiplists to make them fit for more applications, e.g., their use in the multi-dimensional space, network overlaying algorithms, as well as serving as indexes in database systems. Besides, we also discuss systems that adopt the idea of skiplists and apply the probabilistic skip pattern into their designs.","sentences":["Skiplists have become prevalent in systems.","The main advantages of skiplists are their simplicity and ease of implementation, and the ability to support operations in the same asymptotic complexities as their tree-based counterparts.","In this survey, we explore skiplists and their many variants.","We highlight many scenarios of how skiplists are useful and fit well in these usage scenarios.","We study several extensions to skiplists to make them fit for more applications, e.g., their use in the multi-dimensional space, network overlaying algorithms, as well as serving as indexes in database systems.","Besides, we also discuss systems that adopt the idea of skiplists and apply the probabilistic skip pattern into their designs."],"url":"http://arxiv.org/abs/2403.04582v1"}
{"created":"2024-03-07 15:26:23","title":"Beyond Major Product Prediction: Reproducing Reaction Mechanisms with Machine Learning Models Trained on a Large-Scale Mechanistic Dataset","abstract":"Mechanistic understanding of organic reactions can facilitate reaction development, impurity prediction, and in principle, reaction discovery. While several machine learning models have sought to address the task of predicting reaction products, their extension to predicting reaction mechanisms has been impeded by the lack of a corresponding mechanistic dataset. In this study, we construct such a dataset by imputing intermediates between experimentally reported reactants and products using expert reaction templates and train several machine learning models on the resulting dataset of 5,184,184 elementary steps. We explore the performance and capabilities of these models, focusing on their ability to predict reaction pathways and recapitulate the roles of catalysts and reagents. Additionally, we demonstrate the potential of mechanistic models in predicting impurities, often overlooked by conventional models. We conclude by evaluating the generalizability of mechanistic models to new reaction types, revealing challenges related to dataset diversity, consecutive predictions, and violations of atom conservation.","sentences":["Mechanistic understanding of organic reactions can facilitate reaction development, impurity prediction, and in principle, reaction discovery.","While several machine learning models have sought to address the task of predicting reaction products, their extension to predicting reaction mechanisms has been impeded by the lack of a corresponding mechanistic dataset.","In this study, we construct such a dataset by imputing intermediates between experimentally reported reactants and products using expert reaction templates and train several machine learning models on the resulting dataset of 5,184,184 elementary steps.","We explore the performance and capabilities of these models, focusing on their ability to predict reaction pathways and recapitulate the roles of catalysts and reagents.","Additionally, we demonstrate the potential of mechanistic models in predicting impurities, often overlooked by conventional models.","We conclude by evaluating the generalizability of mechanistic models to new reaction types, revealing challenges related to dataset diversity, consecutive predictions, and violations of atom conservation."],"url":"http://arxiv.org/abs/2403.04580v1"}
{"created":"2024-03-07 15:22:07","title":"Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition","abstract":"Web tables contain a large amount of valuable knowledge and have inspired tabular language models aimed at tackling table interpretation (TI) tasks. In this paper, we analyse a widely used benchmark dataset for evaluation of TI tasks, particularly focusing on the entity linking task. Our analysis reveals that this dataset is overly simplified, potentially reducing its effectiveness for thorough evaluation and failing to accurately represent tables as they appear in the real-world. To overcome this drawback, we construct and annotate a new more challenging dataset. In addition to introducing the new dataset, we also introduce a novel problem aimed at addressing the entity linking task: named entity recognition within cells. Finally, we propose a prompting framework for evaluating the newly developed large language models (LLMs) on this novel TI task. We conduct experiments on prompting LLMs under various settings, where we use both random and similarity-based selection to choose the examples presented to the models. Our ablation study helps us gain insights into the impact of the few-shot examples. Additionally, we perform qualitative analysis to gain insights into the challenges encountered by the models and to understand the limitations of the proposed dataset.","sentences":["Web tables contain a large amount of valuable knowledge and have inspired tabular language models aimed at tackling table interpretation (TI) tasks.","In this paper, we analyse a widely used benchmark dataset for evaluation of TI tasks, particularly focusing on the entity linking task.","Our analysis reveals that this dataset is overly simplified, potentially reducing its effectiveness for thorough evaluation and failing to accurately represent tables as they appear in the real-world.","To overcome this drawback, we construct and annotate a new more challenging dataset.","In addition to introducing the new dataset, we also introduce a novel problem aimed at addressing the entity linking task: named entity recognition within cells.","Finally, we propose a prompting framework for evaluating the newly developed large language models (LLMs) on this novel TI task.","We conduct experiments on prompting LLMs under various settings, where we use both random and similarity-based selection to choose the examples presented to the models.","Our ablation study helps us gain insights into the impact of the few-shot examples.","Additionally, we perform qualitative analysis to gain insights into the challenges encountered by the models and to understand the limitations of the proposed dataset."],"url":"http://arxiv.org/abs/2403.04577v1"}
{"created":"2024-03-07 15:21:53","title":"A Model Hierarchy for Predicting the Flow in Stirred Tanks with Physics-Informed Neural Networks","abstract":"This paper explores the potential of Physics-Informed Neural Networks (PINNs) to serve as Reduced Order Models (ROMs) for simulating the flow field within stirred tank reactors (STRs). We solve the two-dimensional stationary Navier-Stokes equations within a geometrically intricate domain and explore methodologies that allow us to integrate additional physical insights into the model. These approaches include imposing the Dirichlet boundary conditions (BCs) strongly and employing domain decomposition (DD), with both overlapping and non-overlapping subdomains. We adapt the Extended Physics-Informed Neural Network (XPINN) approach to solve different sets of equations in distinct subdomains based on the diverse flow characteristics present in each region. Our exploration results in a hierarchy of models spanning various levels of complexity, where the best models exhibit l1 prediction errors of less than 1% for both pressure and velocity. To illustrate the reproducibility of our approach, we track the errors over repeated independent training runs of the best identified model and show its reliability. Subsequently, by incorporating the stirring rate as a parametric input, we develop a fast-to-evaluate model of the flow capable of interpolating across a wide range of Reynolds numbers. Although we exclusively restrict ourselves to STRs in this work, we conclude that the steps taken to obtain the presented model hierarchy can be transferred to other applications.","sentences":["This paper explores the potential of Physics-Informed Neural Networks (PINNs) to serve as Reduced Order Models (ROMs) for simulating the flow field within stirred tank reactors (STRs).","We solve the two-dimensional stationary Navier-Stokes equations within a geometrically intricate domain and explore methodologies that allow us to integrate additional physical insights into the model.","These approaches include imposing the Dirichlet boundary conditions (BCs) strongly and employing domain decomposition (DD), with both overlapping and non-overlapping subdomains.","We adapt the Extended Physics-Informed Neural Network (XPINN) approach to solve different sets of equations in distinct subdomains based on the diverse flow characteristics present in each region.","Our exploration results in a hierarchy of models spanning various levels of complexity, where the best models exhibit l1 prediction errors of less than 1% for both pressure and velocity.","To illustrate the reproducibility of our approach, we track the errors over repeated independent training runs of the best identified model and show its reliability.","Subsequently, by incorporating the stirring rate as a parametric input, we develop a fast-to-evaluate model of the flow capable of interpolating across a wide range of Reynolds numbers.","Although we exclusively restrict ourselves to STRs in this work, we conclude that the steps taken to obtain the presented model hierarchy can be transferred to other applications."],"url":"http://arxiv.org/abs/2403.04576v1"}
{"created":"2024-03-07 15:21:40","title":"Children Age Group Detection based on Human-Computer Interaction and Time Series Analysis","abstract":"This article proposes a novel Children-Computer Interaction (CCI) approach for the task of age group detection. This approach focuses on the automatic analysis of the time series generated from the interaction of the children with mobile devices. In particular, we extract a set of 25 time series related to spatial, pressure, and kinematic information of the children interaction while colouring a tree through a pen stylus tablet, a specific test from the large-scale public ChildCIdb database.   A complete analysis of the proposed approach is carried out using different time series selection techniques to choose the most discriminative ones for the age group detection task: i) a statistical analysis, and ii) an automatic algorithm called Sequential Forward Search (SFS). In addition, different classification algorithms such as Dynamic Time Warping Barycenter Averaging (DBA) and Hidden Markov Models (HMM) are studied. Accuracy results over 85% are achieved, outperforming previous approaches in the literature and in more challenging age group conditions. Finally, the approach presented in this study can benefit many children-related applications, for example, towards an age-appropriate environment with the technology.","sentences":["This article proposes a novel Children-Computer Interaction (CCI) approach for the task of age group detection.","This approach focuses on the automatic analysis of the time series generated from the interaction of the children with mobile devices.","In particular, we extract a set of 25 time series related to spatial, pressure, and kinematic information of the children interaction while colouring a tree through a pen stylus tablet, a specific test from the large-scale public ChildCIdb database.   ","A complete analysis of the proposed approach is carried out using different time series selection techniques to choose the most discriminative ones for the age group detection task: i) a statistical analysis, and ii) an automatic algorithm called Sequential Forward Search (SFS).","In addition, different classification algorithms such as Dynamic Time Warping Barycenter Averaging (DBA) and Hidden Markov Models (HMM) are studied.","Accuracy results over 85% are achieved, outperforming previous approaches in the literature and in more challenging age group conditions.","Finally, the approach presented in this study can benefit many children-related applications, for example, towards an age-appropriate environment with the technology."],"url":"http://arxiv.org/abs/2403.04574v1"}
{"created":"2024-03-07 15:12:06","title":"Machine learning and information theory concepts towards an AI Mathematician","abstract":"The current state-of-the-art in artificial intelligence is impressive, especially in terms of mastery of language, but not so much in terms of mathematical reasoning. What could be missing? Can we learn something useful about that gap from how the brains of mathematicians go about their craft? This essay builds on the idea that current deep learning mostly succeeds at system 1 abilities -- which correspond to our intuition and habitual behaviors -- but still lacks something important regarding system 2 abilities -- which include reasoning and robust uncertainty estimation. It takes an information-theoretical posture to ask questions about what constitutes an interesting mathematical statement, which could guide future work in crafting an AI mathematician. The focus is not on proving a given theorem but on discovering new and interesting conjectures. The central hypothesis is that a desirable body of theorems better summarizes the set of all provable statements, for example by having a small description length while at the same time being close (in terms of number of derivation steps) to many provable statements.","sentences":["The current state-of-the-art in artificial intelligence is impressive, especially in terms of mastery of language, but not so much in terms of mathematical reasoning.","What could be missing?","Can we learn something useful about that gap from how the brains of mathematicians go about their craft?","This essay builds on the idea that current deep learning mostly succeeds at system 1 abilities -- which correspond to our intuition and habitual behaviors -- but still lacks something important regarding system 2 abilities -- which include reasoning and robust uncertainty estimation.","It takes an information-theoretical posture to ask questions about what constitutes an interesting mathematical statement, which could guide future work in crafting an AI mathematician.","The focus is not on proving a given theorem but on discovering new and interesting conjectures.","The central hypothesis is that a desirable body of theorems better summarizes the set of all provable statements, for example by having a small description length while at the same time being close (in terms of number of derivation steps) to many provable statements."],"url":"http://arxiv.org/abs/2403.04571v1"}
{"created":"2024-03-07 15:06:24","title":"ShuffleBench: A Benchmark for Large-Scale Data Shuffling Operations with Distributed Stream Processing Frameworks","abstract":"Distributed stream processing frameworks help building scalable and reliable applications that perform transformations and aggregations on continuous data streams. This paper introduces ShuffleBench, a novel benchmark to evaluate the performance of modern stream processing frameworks. In contrast to other benchmarks, it focuses on use cases where stream processing frameworks are mainly employed for shuffling (i.e., re-distributing) data records to perform state-local aggregations, while the actual aggregation logic is considered as black-box software components. ShuffleBench is inspired by requirements for near real-time analytics of a large cloud observability platform and takes up benchmarking metrics and methods for latency, throughput, and scalability established in the performance engineering research community. Although inspired by a real-world observability use case, it is highly configurable to allow domain-independent evaluations. ShuffleBench comes as a ready-to-use open-source software utilizing existing Kubernetes tooling and providing implementations for four state-of-the-art frameworks. Therefore, we expect ShuffleBench to be a valuable contribution to both industrial practitioners building stream processing applications and researchers working on new stream processing approaches. We complement this paper with an experimental performance evaluation that employs ShuffleBench with various configurations on Flink, Hazelcast, Kafka Streams, and Spark in a cloud-native environment. Our results show that Flink achieves the highest throughput while Hazelcast processes data streams with the lowest latency.","sentences":["Distributed stream processing frameworks help building scalable and reliable applications that perform transformations and aggregations on continuous data streams.","This paper introduces ShuffleBench, a novel benchmark to evaluate the performance of modern stream processing frameworks.","In contrast to other benchmarks, it focuses on use cases where stream processing frameworks are mainly employed for shuffling (i.e., re-distributing) data records to perform state-local aggregations, while the actual aggregation logic is considered as black-box software components.","ShuffleBench is inspired by requirements for near real-time analytics of a large cloud observability platform and takes up benchmarking metrics and methods for latency, throughput, and scalability established in the performance engineering research community.","Although inspired by a real-world observability use case, it is highly configurable to allow domain-independent evaluations.","ShuffleBench comes as a ready-to-use open-source software utilizing existing Kubernetes tooling and providing implementations for four state-of-the-art frameworks.","Therefore, we expect ShuffleBench to be a valuable contribution to both industrial practitioners building stream processing applications and researchers working on new stream processing approaches.","We complement this paper with an experimental performance evaluation that employs ShuffleBench with various configurations on Flink, Hazelcast, Kafka Streams, and Spark in a cloud-native environment.","Our results show that Flink achieves the highest throughput while Hazelcast processes data streams with the lowest latency."],"url":"http://arxiv.org/abs/2403.04570v1"}
{"created":"2024-03-07 15:03:50","title":"Improved Algorithm for Adversarial Linear Mixture MDPs with Bandit Feedback and Unknown Transition","abstract":"We study reinforcement learning with linear function approximation, unknown transition, and adversarial losses in the bandit feedback setting. Specifically, we focus on linear mixture MDPs whose transition kernel is a linear mixture model. We propose a new algorithm that attains an $\\widetilde{O}(d\\sqrt{HS^3K} + \\sqrt{HSAK})$ regret with high probability, where $d$ is the dimension of feature mappings, $S$ is the size of state space, $A$ is the size of action space, $H$ is the episode length and $K$ is the number of episodes. Our result strictly improves the previous best-known $\\widetilde{O}(dS^2 \\sqrt{K} + \\sqrt{HSAK})$ result in Zhao et al. (2023a) since $H \\leq S$ holds by the layered MDP structure. Our advancements are primarily attributed to (i) a new least square estimator for the transition parameter that leverages the visit information of all states, as opposed to only one state in prior work, and (ii) a new self-normalized concentration tailored specifically to handle non-independent noises, originally proposed in the dynamic assortment area and firstly applied in reinforcement learning to handle correlations between different states.","sentences":["We study reinforcement learning with linear function approximation, unknown transition, and adversarial losses in the bandit feedback setting.","Specifically, we focus on linear mixture MDPs whose transition kernel is a linear mixture model.","We propose a new algorithm that attains an $\\widetilde{O}(d\\sqrt{HS^3K} + \\sqrt{HSAK})$ regret with high probability, where $d$ is the dimension of feature mappings, $S$ is the size of state space, $A$ is the size of action space, $H$ is the episode length and $K$ is the number of episodes.","Our result strictly improves the previous best-known $\\widetilde{O}(dS^2 \\sqrt{K} + \\sqrt{HSAK})$ result in Zhao et al. (2023a) since $H \\leq S$ holds by the layered MDP structure.","Our advancements are primarily attributed to (i) a new least square estimator for the transition parameter that leverages the visit information of all states, as opposed to only one state in prior work, and (ii) a new self-normalized concentration tailored specifically to handle non-independent noises, originally proposed in the dynamic assortment area and firstly applied in reinforcement learning to handle correlations between different states."],"url":"http://arxiv.org/abs/2403.04568v1"}
{"created":"2024-03-07 14:59:34","title":"Out of the Room: Generalizing Event-Based Dynamic Motion Segmentation for Complex Scenes","abstract":"Rapid and reliable identification of dynamic scene parts, also known as motion segmentation, is a key challenge for mobile sensors. Contemporary RGB camera-based methods rely on modeling camera and scene properties however, are often under-constrained and fall short in unknown categories. Event cameras have the potential to overcome these limitations, but corresponding methods have only been demonstrated in smaller-scale indoor environments with simplified dynamic objects. This work presents an event-based method for class-agnostic motion segmentation that can successfully be deployed across complex large-scale outdoor environments too. To this end, we introduce a novel divide-and-conquer pipeline that combines: (a) ego-motion compensated events, computed via a scene understanding module that predicts monocular depth and camera pose as auxiliary tasks, and (b) optical flow from a dedicated optical flow module. These intermediate representations are then fed into a segmentation module that predicts motion segmentation masks. A novel transformer-based temporal attention module in the segmentation module builds correlations across adjacent 'frames' to get temporally consistent segmentation masks. Our method sets the new state-of-the-art on the classic EV-IMO benchmark (indoors), where we achieve improvements of 2.19 moving object IoU (2.22 mIoU) and 4.52 point IoU respectively, as well as on a newly-generated motion segmentation and tracking benchmark (outdoors) based on the DSEC event dataset, termed DSEC-MOTS, where we show improvement of 12.91 moving object IoU.","sentences":["Rapid and reliable identification of dynamic scene parts, also known as motion segmentation, is a key challenge for mobile sensors.","Contemporary RGB camera-based methods rely on modeling camera and scene properties however, are often under-constrained and fall short in unknown categories.","Event cameras have the potential to overcome these limitations, but corresponding methods have only been demonstrated in smaller-scale indoor environments with simplified dynamic objects.","This work presents an event-based method for class-agnostic motion segmentation that can successfully be deployed across complex large-scale outdoor environments too.","To this end, we introduce a novel divide-and-conquer pipeline that combines: (a) ego-motion compensated events, computed via a scene understanding module that predicts monocular depth and camera pose as auxiliary tasks, and (b) optical flow from a dedicated optical flow module.","These intermediate representations are then fed into a segmentation module that predicts motion segmentation masks.","A novel transformer-based temporal attention module in the segmentation module builds correlations across adjacent 'frames' to get temporally consistent segmentation masks.","Our method sets the new state-of-the-art on the classic EV-IMO benchmark (indoors), where we achieve improvements of 2.19 moving object IoU (2.22 mIoU) and 4.52 point IoU respectively, as well as on a newly-generated motion segmentation and tracking benchmark (outdoors) based on the DSEC event dataset, termed DSEC-MOTS, where we show improvement of 12.91 moving object IoU."],"url":"http://arxiv.org/abs/2403.04562v1"}
