{"created":"2024-05-16 17:59:51","title":"Toon3D: Seeing Cartoons from a New Perspective","abstract":"In this work, we recover the underlying 3D structure of non-geometrically consistent scenes. We focus our analysis on hand-drawn images from cartoons and anime. Many cartoons are created by artists without a 3D rendering engine, which means that any new image of a scene is hand-drawn. The hand-drawn images are usually faithful representations of the world, but only in a qualitative sense, since it is difficult for humans to draw multiple perspectives of an object or scene 3D consistently. Nevertheless, people can easily perceive 3D scenes from inconsistent inputs! In this work, we correct for 2D drawing inconsistencies to recover a plausible 3D structure such that the newly warped drawings are consistent with each other. Our pipeline consists of a user-friendly annotation tool, camera pose estimation, and image deformation to recover a dense structure. Our method warps images to obey a perspective camera model, enabling our aligned results to be plugged into novel-view synthesis reconstruction methods to experience cartoons from viewpoints never drawn before. Our project page is https://toon3d.studio/.","sentences":["In this work, we recover the underlying 3D structure of non-geometrically consistent scenes.","We focus our analysis on hand-drawn images from cartoons and anime.","Many cartoons are created by artists without a 3D rendering engine, which means that any new image of a scene is hand-drawn.","The hand-drawn images are usually faithful representations of the world, but only in a qualitative sense, since it is difficult for humans to draw multiple perspectives of an object or scene 3D consistently.","Nevertheless, people can easily perceive 3D scenes from inconsistent inputs!","In this work, we correct for 2D drawing inconsistencies to recover a plausible 3D structure such that the newly warped drawings are consistent with each other.","Our pipeline consists of a user-friendly annotation tool, camera pose estimation, and image deformation to recover a dense structure.","Our method warps images to obey a perspective camera model, enabling our aligned results to be plugged into novel-view synthesis reconstruction methods to experience cartoons from viewpoints never drawn before.","Our project page is https://toon3d.studio/."],"url":"http://arxiv.org/abs/2405.10320v1"}
{"created":"2024-05-16 17:59:22","title":"Text-to-Vector Generation with Neural Path Representation","abstract":"Vector graphics are widely used in digital art and highly favored by designers due to their scalability and layer-wise properties. However, the process of creating and editing vector graphics requires creativity and design expertise, making it a time-consuming task. Recent advancements in text-to-vector (T2V) generation have aimed to make this process more accessible. However, existing T2V methods directly optimize control points of vector graphics paths, often resulting in intersecting or jagged paths due to the lack of geometry constraints. To overcome these limitations, we propose a novel neural path representation by designing a dual-branch Variational Autoencoder (VAE) that learns the path latent space from both sequence and image modalities. By optimizing the combination of neural paths, we can incorporate geometric constraints while preserving expressivity in generated SVGs. Furthermore, we introduce a two-stage path optimization method to improve the visual and topological quality of generated SVGs. In the first stage, a pre-trained text-to-image diffusion model guides the initial generation of complex vector graphics through the Variational Score Distillation (VSD) process. In the second stage, we refine the graphics using a layer-wise image vectorization strategy to achieve clearer elements and structure. We demonstrate the effectiveness of our method through extensive experiments and showcase various applications. The project page is https://intchous.github.io/T2V-NPR.","sentences":["Vector graphics are widely used in digital art and highly favored by designers due to their scalability and layer-wise properties.","However, the process of creating and editing vector graphics requires creativity and design expertise, making it a time-consuming task.","Recent advancements in text-to-vector (T2V) generation have aimed to make this process more accessible.","However, existing T2V methods directly optimize control points of vector graphics paths, often resulting in intersecting or jagged paths due to the lack of geometry constraints.","To overcome these limitations, we propose a novel neural path representation by designing a dual-branch Variational Autoencoder (VAE) that learns the path latent space from both sequence and image modalities.","By optimizing the combination of neural paths, we can incorporate geometric constraints while preserving expressivity in generated SVGs.","Furthermore, we introduce a two-stage path optimization method to improve the visual and topological quality of generated SVGs.","In the first stage, a pre-trained text-to-image diffusion model guides the initial generation of complex vector graphics through the Variational Score Distillation (VSD) process.","In the second stage, we refine the graphics using a layer-wise image vectorization strategy to achieve clearer elements and structure.","We demonstrate the effectiveness of our method through extensive experiments and showcase various applications.","The project page is https://intchous.github.io/T2V-NPR."],"url":"http://arxiv.org/abs/2405.10317v1"}
{"created":"2024-05-16 17:59:21","title":"Analogist: Out-of-the-box Visual In-Context Learning with Image Diffusion Model","abstract":"Visual In-Context Learning (ICL) has emerged as a promising research area due to its capability to accomplish various tasks with limited example pairs through analogical reasoning. However, training-based visual ICL has limitations in its ability to generalize to unseen tasks and requires the collection of a diverse task dataset. On the other hand, existing methods in the inference-based visual ICL category solely rely on textual prompts, which fail to capture fine-grained contextual information from given examples and can be time-consuming when converting from images to text prompts. To address these challenges, we propose Analogist, a novel inference-based visual ICL approach that exploits both visual and textual prompting techniques using a text-to-image diffusion model pretrained for image inpainting. For visual prompting, we propose a self-attention cloning (SAC) method to guide the fine-grained structural-level analogy between image examples. For textual prompting, we leverage GPT-4V's visual reasoning capability to efficiently generate text prompts and introduce a cross-attention masking (CAM) operation to enhance the accuracy of semantic-level analogy guided by text prompts. Our method is out-of-the-box and does not require fine-tuning or optimization. It is also generic and flexible, enabling a wide range of visual tasks to be performed in an in-context manner. Extensive experiments demonstrate the superiority of our method over existing approaches, both qualitatively and quantitatively.","sentences":["Visual In-Context Learning (ICL) has emerged as a promising research area due to its capability to accomplish various tasks with limited example pairs through analogical reasoning.","However, training-based visual ICL has limitations in its ability to generalize to unseen tasks and requires the collection of a diverse task dataset.","On the other hand, existing methods in the inference-based visual ICL category solely rely on textual prompts, which fail to capture fine-grained contextual information from given examples and can be time-consuming when converting from images to text prompts.","To address these challenges, we propose Analogist, a novel inference-based visual ICL approach that exploits both visual and textual prompting techniques using a text-to-image diffusion model pretrained for image inpainting.","For visual prompting, we propose a self-attention cloning (SAC) method to guide the fine-grained structural-level analogy between image examples.","For textual prompting, we leverage GPT-4V's visual reasoning capability to efficiently generate text prompts and introduce a cross-attention masking (CAM) operation to enhance the accuracy of semantic-level analogy guided by text prompts.","Our method is out-of-the-box and does not require fine-tuning or optimization.","It is also generic and flexible, enabling a wide range of visual tasks to be performed in an in-context manner.","Extensive experiments demonstrate the superiority of our method over existing approaches, both qualitatively and quantitatively."],"url":"http://arxiv.org/abs/2405.10316v1"}
{"created":"2024-05-16 17:59:07","title":"TRANSIC: Sim-to-Real Policy Transfer by Learning from Online Correction","abstract":"Learning in simulation and transferring the learned policy to the real world has the potential to enable generalist robots. The key challenge of this approach is to address simulation-to-reality (sim-to-real) gaps. Previous methods often require domain-specific knowledge a priori. We argue that a straightforward way to obtain such knowledge is by asking humans to observe and assist robot policy execution in the real world. The robots can then learn from humans to close various sim-to-real gaps. We propose TRANSIC, a data-driven approach to enable successful sim-to-real transfer based on a human-in-the-loop framework. TRANSIC allows humans to augment simulation policies to overcome various unmodeled sim-to-real gaps holistically through intervention and online correction. Residual policies can be learned from human corrections and integrated with simulation policies for autonomous execution. We show that our approach can achieve successful sim-to-real transfer in complex and contact-rich manipulation tasks such as furniture assembly. Through synergistic integration of policies learned in simulation and from humans, TRANSIC is effective as a holistic approach to addressing various, often coexisting sim-to-real gaps. It displays attractive properties such as scaling with human effort. Videos and code are available at https://transic-robot.github.io/","sentences":["Learning in simulation and transferring the learned policy to the real world has the potential to enable generalist robots.","The key challenge of this approach is to address simulation-to-reality (sim-to-real) gaps.","Previous methods often require domain-specific knowledge a priori.","We argue that a straightforward way to obtain such knowledge is by asking humans to observe and assist robot policy execution in the real world.","The robots can then learn from humans to close various sim-to-real gaps.","We propose TRANSIC, a data-driven approach to enable successful sim-to-real transfer based on a human-in-the-loop framework.","TRANSIC allows humans to augment simulation policies to overcome various unmodeled sim-to-real gaps holistically through intervention and online correction.","Residual policies can be learned from human corrections and integrated with simulation policies for autonomous execution.","We show that our approach can achieve successful sim-to-real transfer in complex and contact-rich manipulation tasks such as furniture assembly.","Through synergistic integration of policies learned in simulation and from humans, TRANSIC is effective as a holistic approach to addressing various, often coexisting sim-to-real gaps.","It displays attractive properties such as scaling with human effort.","Videos and code are available at https://transic-robot.github.io/"],"url":"http://arxiv.org/abs/2405.10315v1"}
{"created":"2024-05-16 17:59:05","title":"CAT3D: Create Anything in 3D with Multi-View Diffusion Models","abstract":"Advances in 3D reconstruction have enabled high-quality 3D capture, but require a user to collect hundreds to thousands of images to create a 3D scene. We present CAT3D, a method for creating anything in 3D by simulating this real-world capture process with a multi-view diffusion model. Given any number of input images and a set of target novel viewpoints, our model generates highly consistent novel views of a scene. These generated views can be used as input to robust 3D reconstruction techniques to produce 3D representations that can be rendered from any viewpoint in real-time. CAT3D can create entire 3D scenes in as little as one minute, and outperforms existing methods for single image and few-view 3D scene creation. See our project page for results and interactive demos at https://cat3d.github.io .","sentences":["Advances in 3D reconstruction have enabled high-quality 3D capture, but require a user to collect hundreds to thousands of images to create a 3D scene.","We present CAT3D, a method for creating anything in 3D by simulating this real-world capture process with a multi-view diffusion model.","Given any number of input images and a set of target novel viewpoints, our model generates highly consistent novel views of a scene.","These generated views can be used as input to robust 3D reconstruction techniques to produce 3D representations that can be rendered from any viewpoint in real-time.","CAT3D can create entire 3D scenes in as little as one minute, and outperforms existing methods for single image and few-view 3D scene creation.","See our project page for results and interactive demos at https://cat3d.github.io ."],"url":"http://arxiv.org/abs/2405.10314v1"}
{"created":"2024-05-16 17:59:02","title":"How Far Are We From AGI","abstract":"The evolution of artificial intelligence (AI) has profoundly impacted human society, driving significant advancements in multiple sectors. Yet, the escalating demands on AI have highlighted the limitations of AI's current offerings, catalyzing a movement towards Artificial General Intelligence (AGI). AGI, distinguished by its ability to execute diverse real-world tasks with efficiency and effectiveness comparable to human intelligence, reflects a paramount milestone in AI evolution. While existing works have summarized specific recent advancements of AI, they lack a comprehensive discussion of AGI's definitions, goals, and developmental trajectories. Different from existing survey papers, this paper delves into the pivotal questions of our proximity to AGI and the strategies necessary for its realization through extensive surveys, discussions, and original perspectives. We start by articulating the requisite capability frameworks for AGI, integrating the internal, interface, and system dimensions. As the realization of AGI requires more advanced capabilities and adherence to stringent constraints, we further discuss necessary AGI alignment technologies to harmonize these factors. Notably, we emphasize the importance of approaching AGI responsibly by first defining the key levels of AGI progression, followed by the evaluation framework that situates the status-quo, and finally giving our roadmap of how to reach the pinnacle of AGI. Moreover, to give tangible insights into the ubiquitous impact of the integration of AI, we outline existing challenges and potential pathways toward AGI in multiple domains. In sum, serving as a pioneering exploration into the current state and future trajectory of AGI, this paper aims to foster a collective comprehension and catalyze broader public discussions among researchers and practitioners on AGI.","sentences":["The evolution of artificial intelligence (AI) has profoundly impacted human society, driving significant advancements in multiple sectors.","Yet, the escalating demands on AI have highlighted the limitations of AI's current offerings, catalyzing a movement towards Artificial General Intelligence (AGI).","AGI, distinguished by its ability to execute diverse real-world tasks with efficiency and effectiveness comparable to human intelligence, reflects a paramount milestone in AI evolution.","While existing works have summarized specific recent advancements of AI, they lack a comprehensive discussion of AGI's definitions, goals, and developmental trajectories.","Different from existing survey papers, this paper delves into the pivotal questions of our proximity to AGI and the strategies necessary for its realization through extensive surveys, discussions, and original perspectives.","We start by articulating the requisite capability frameworks for AGI, integrating the internal, interface, and system dimensions.","As the realization of AGI requires more advanced capabilities and adherence to stringent constraints, we further discuss necessary AGI alignment technologies to harmonize these factors.","Notably, we emphasize the importance of approaching AGI responsibly by first defining the key levels of AGI progression, followed by the evaluation framework that situates the status-quo, and finally giving our roadmap of how to reach the pinnacle of AGI.","Moreover, to give tangible insights into the ubiquitous impact of the integration of AI, we outline existing challenges and potential pathways toward AGI in multiple domains.","In sum, serving as a pioneering exploration into the current state and future trajectory of AGI, this paper aims to foster a collective comprehension and catalyze broader public discussions among researchers and practitioners on AGI."],"url":"http://arxiv.org/abs/2405.10313v1"}
{"created":"2024-05-16 17:58:45","title":"UniRAG: Universal Retrieval Augmentation for Multi-Modal Large Language Models","abstract":"Recently, Multi-Modal(MM) Large Language Models(LLMs) have unlocked many complex use-cases that require MM understanding (e.g., image captioning or visual question answering) and MM generation (e.g., text-guided image generation or editing) capabilities. To further improve the output fidelity of MM-LLMs we introduce the model-agnostic UniRAG technique that adds relevant retrieved information to prompts as few-shot examples during inference. Unlike the common belief that Retrieval Augmentation (RA) mainly improves generation or understanding of uncommon entities, our evaluation results on the MSCOCO dataset with common entities show that both proprietary models like GPT4 and Gemini-Pro and smaller open-source models like Llava, LaVIT, and Emu2 significantly enhance their generation quality when their input prompts are augmented with relevant information retrieved by MM retrievers like UniIR models.","sentences":["Recently, Multi-Modal(MM) Large Language Models(LLMs) have unlocked many complex use-cases that require MM understanding (e.g., image captioning or visual question answering) and MM generation (e.g., text-guided image generation or editing) capabilities.","To further improve the output fidelity of MM-LLMs we introduce the model-agnostic UniRAG technique that adds relevant retrieved information to prompts as few-shot examples during inference.","Unlike the common belief that Retrieval Augmentation (RA) mainly improves generation or understanding of uncommon entities, our evaluation results on the MSCOCO dataset with common entities show that both proprietary models like GPT4 and Gemini-Pro and smaller open-source models like Llava, LaVIT, and Emu2 significantly enhance their generation quality when their input prompts are augmented with relevant information retrieved by MM retrievers like UniIR models."],"url":"http://arxiv.org/abs/2405.10311v1"}
{"created":"2024-05-16 17:58:44","title":"Stochastic Q-learning for Large Discrete Action Spaces","abstract":"In complex environments with large discrete action spaces, effective decision-making is critical in reinforcement learning (RL). Despite the widespread use of value-based RL approaches like Q-learning, they come with a computational burden, necessitating the maximization of a value function over all actions in each iteration. This burden becomes particularly challenging when addressing large-scale problems and using deep neural networks as function approximators. In this paper, we present stochastic value-based RL approaches which, in each iteration, as opposed to optimizing over the entire set of $n$ actions, only consider a variable stochastic set of a sublinear number of actions, possibly as small as $\\mathcal{O}(\\log(n))$. The presented stochastic value-based RL methods include, among others, Stochastic Q-learning, StochDQN, and StochDDQN, all of which integrate this stochastic approach for both value-function updates and action selection. The theoretical convergence of Stochastic Q-learning is established, while an analysis of stochastic maximization is provided. Moreover, through empirical validation, we illustrate that the various proposed approaches outperform the baseline methods across diverse environments, including different control problems, achieving near-optimal average returns in significantly reduced time.","sentences":["In complex environments with large discrete action spaces, effective decision-making is critical in reinforcement learning (RL).","Despite the widespread use of value-based RL approaches like Q-learning, they come with a computational burden, necessitating the maximization of a value function over all actions in each iteration.","This burden becomes particularly challenging when addressing large-scale problems and using deep neural networks as function approximators.","In this paper, we present stochastic value-based RL approaches which, in each iteration, as opposed to optimizing over the entire set of $n$ actions, only consider a variable stochastic set of a sublinear number of actions, possibly as small as $\\mathcal{O}(\\log(n))$. The presented stochastic value-based RL methods include, among others, Stochastic Q-learning, StochDQN, and StochDDQN, all of which integrate this stochastic approach for both value-function updates and action selection.","The theoretical convergence of Stochastic Q-learning is established, while an analysis of stochastic maximization is provided.","Moreover, through empirical validation, we illustrate that the various proposed approaches outperform the baseline methods across diverse environments, including different control problems, achieving near-optimal average returns in significantly reduced time."],"url":"http://arxiv.org/abs/2405.10310v1"}
{"created":"2024-05-16 17:58:19","title":"Efficient Implementation of an Abstract Domain of Quantified First-Order Formulas","abstract":"This paper lays a practical foundation for using abstract interpretation with an abstract domain that consists of sets of quantified first-order logic formulas. This abstract domain seems infeasible at first sight due to the complexity of the formulas involved and the enormous size of sets of formulas (abstract elements). We introduce an efficient representation of abstract elements, which eliminates redundancies based on a novel syntactic subsumption relation that under-approximates semantic entailment. We develop algorithms and data-structures to efficiently compute the join of an abstract element with the abstraction of a concrete state, operating on the representation of abstract elements. To demonstrate feasibility of the domain, we use our data structures and algorithms to implement a symbolic abstraction algorithm that computes the least fixpoint of the best abstract transformer of a transition system, which corresponds to the strongest inductive invariant. We succeed at finding, for example, the least fixpoint for Paxos (which in our representation has 1,438 formulas with forall-exists-forall quantification) in time comparable to state-of-the-art property-directed approaches.","sentences":["This paper lays a practical foundation for using abstract interpretation with an abstract domain that consists of sets of quantified first-order logic formulas.","This abstract domain seems infeasible at first sight due to the complexity of the formulas involved and the enormous size of sets of formulas (abstract elements).","We introduce an efficient representation of abstract elements, which eliminates redundancies based on a novel syntactic subsumption relation that under-approximates semantic entailment.","We develop algorithms and data-structures to efficiently compute the join of an abstract element with the abstraction of a concrete state, operating on the representation of abstract elements.","To demonstrate feasibility of the domain, we use our data structures and algorithms to implement a symbolic abstraction algorithm that computes the least fixpoint of the best abstract transformer of a transition system, which corresponds to the strongest inductive invariant.","We succeed at finding, for example, the least fixpoint for Paxos (which in our representation has 1,438 formulas with forall-exists-forall quantification) in time comparable to state-of-the-art property-directed approaches."],"url":"http://arxiv.org/abs/2405.10308v1"}
{"created":"2024-05-16 17:56:55","title":"4D Panoptic Scene Graph Generation","abstract":"We are living in a three-dimensional space while moving forward through a fourth dimension: time. To allow artificial intelligence to develop a comprehensive understanding of such a 4D environment, we introduce 4D Panoptic Scene Graph (PSG-4D), a new representation that bridges the raw visual data perceived in a dynamic 4D world and high-level visual understanding. Specifically, PSG-4D abstracts rich 4D sensory data into nodes, which represent entities with precise location and status information, and edges, which capture the temporal relations. To facilitate research in this new area, we build a richly annotated PSG-4D dataset consisting of 3K RGB-D videos with a total of 1M frames, each of which is labeled with 4D panoptic segmentation masks as well as fine-grained, dynamic scene graphs. To solve PSG-4D, we propose PSG4DFormer, a Transformer-based model that can predict panoptic segmentation masks, track masks along the time axis, and generate the corresponding scene graphs via a relation component. Extensive experiments on the new dataset show that our method can serve as a strong baseline for future research on PSG-4D. In the end, we provide a real-world application example to demonstrate how we can achieve dynamic scene understanding by integrating a large language model into our PSG-4D system.","sentences":["We are living in a three-dimensional space while moving forward through a fourth dimension: time.","To allow artificial intelligence to develop a comprehensive understanding of such a 4D environment, we introduce 4D Panoptic Scene Graph (PSG-4D), a new representation that bridges the raw visual data perceived in a dynamic 4D world and high-level visual understanding.","Specifically, PSG-4D abstracts rich 4D sensory data into nodes, which represent entities with precise location and status information, and edges, which capture the temporal relations.","To facilitate research in this new area, we build a richly annotated PSG-4D dataset consisting of 3K RGB-D videos with a total of 1M frames, each of which is labeled with 4D panoptic segmentation masks as well as fine-grained, dynamic scene graphs.","To solve PSG-4D, we propose PSG4DFormer, a Transformer-based model that can predict panoptic segmentation masks, track masks along the time axis, and generate the corresponding scene graphs via a relation component.","Extensive experiments on the new dataset show that our method can serve as a strong baseline for future research on PSG-4D. In the end, we provide a real-world application example to demonstrate how we can achieve dynamic scene understanding by integrating a large language model into our PSG-4D system."],"url":"http://arxiv.org/abs/2405.10305v1"}
{"created":"2024-05-16 17:54:15","title":"Grounding DINO 1.5: Advance the \"Edge\" of Open-Set Object Detection","abstract":"This paper introduces Grounding DINO 1.5, a suite of advanced open-set object detection models developed by IDEA Research, which aims to advance the \"Edge\" of open-set object detection. The suite encompasses two models: Grounding DINO 1.5 Pro, a high-performance model designed for stronger generalization capability across a wide range of scenarios, and Grounding DINO 1.5 Edge, an efficient model optimized for faster speed demanded in many applications requiring edge deployment. The Grounding DINO 1.5 Pro model advances its predecessor by scaling up the model architecture, integrating an enhanced vision backbone, and expanding the training dataset to over 20 million images with grounding annotations, thereby achieving a richer semantic understanding. The Grounding DINO 1.5 Edge model, while designed for efficiency with reduced feature scales, maintains robust detection capabilities by being trained on the same comprehensive dataset. Empirical results demonstrate the effectiveness of Grounding DINO 1.5, with the Grounding DINO 1.5 Pro model attaining a 54.3 AP on the COCO detection benchmark and a 55.7 AP on the LVIS-minival zero-shot transfer benchmark, setting new records for open-set object detection. Furthermore, the Grounding DINO 1.5 Edge model, when optimized with TensorRT, achieves a speed of 75.2 FPS while attaining a zero-shot performance of 36.2 AP on the LVIS-minival benchmark, making it more suitable for edge computing scenarios. Model examples and demos with API will be released at https://github.com/IDEA-Research/Grounding-DINO-1.5-API","sentences":["This paper introduces Grounding DINO 1.5, a suite of advanced open-set object detection models developed by IDEA Research, which aims to advance the \"Edge\" of open-set object detection.","The suite encompasses two models:","Grounding DINO 1.5 Pro, a high-performance model designed for stronger generalization capability across a wide range of scenarios, and Grounding DINO 1.5 Edge, an efficient model optimized for faster speed demanded in many applications requiring edge deployment.","The Grounding DINO 1.5 Pro model advances its predecessor by scaling up the model architecture, integrating an enhanced vision backbone, and expanding the training dataset to over 20 million images with grounding annotations, thereby achieving a richer semantic understanding.","The Grounding DINO 1.5 Edge model, while designed for efficiency with reduced feature scales, maintains robust detection capabilities by being trained on the same comprehensive dataset.","Empirical results demonstrate the effectiveness of Grounding DINO 1.5, with the Grounding DINO 1.5 Pro model attaining a 54.3 AP on the COCO detection benchmark and a 55.7 AP on the LVIS-minival zero-shot transfer benchmark, setting new records for open-set object detection.","Furthermore, the Grounding DINO 1.5 Edge model, when optimized with TensorRT, achieves a speed of 75.2 FPS while attaining a zero-shot performance of 36.2 AP on the LVIS-minival benchmark, making it more suitable for edge computing scenarios.","Model examples and demos with API will be released at https://github.com/IDEA-Research/Grounding-DINO-1.5-API"],"url":"http://arxiv.org/abs/2405.10300v1"}
{"created":"2024-05-16 17:53:32","title":"HW-GPT-Bench: Hardware-Aware Architecture Benchmark for Language Models","abstract":"The expanding size of language models has created the necessity for a comprehensive examination across various dimensions that reflect the desiderata with respect to the tradeoffs between various hardware metrics, such as latency, energy consumption, GPU memory usage, and performance. There is a growing interest in establishing Pareto frontiers for different language model configurations to identify optimal models with specified hardware constraints. Notably, architectures that excel in latency on one device may not perform optimally on another. However, exhaustive training and evaluation of numerous architectures across diverse hardware configurations is computationally prohibitive. To this end, we propose HW-GPT-Bench, a hardware-aware language model surrogate benchmark, where we leverage weight-sharing techniques from Neural Architecture Search (NAS) to efficiently train a supernet proxy, encompassing language models of varying scales in a single model. We conduct profiling of these models across 13 devices, considering 5 hardware metrics and 3 distinct model scales. Finally, we showcase the usability of HW-GPT-Bench using 8 different multi-objective NAS algorithms and evaluate the quality of the resultant Pareto fronts. Through this benchmark, our objective is to propel and expedite research in the advancement of multi-objective methods for NAS and structural pruning in large language models.","sentences":["The expanding size of language models has created the necessity for a comprehensive examination across various dimensions that reflect the desiderata with respect to the tradeoffs between various hardware metrics, such as latency, energy consumption, GPU memory usage, and performance.","There is a growing interest in establishing Pareto frontiers for different language model configurations to identify optimal models with specified hardware constraints.","Notably, architectures that excel in latency on one device may not perform optimally on another.","However, exhaustive training and evaluation of numerous architectures across diverse hardware configurations is computationally prohibitive.","To this end, we propose HW-GPT-Bench, a hardware-aware language model surrogate benchmark, where we leverage weight-sharing techniques from Neural Architecture Search (NAS) to efficiently train a supernet proxy, encompassing language models of varying scales in a single model.","We conduct profiling of these models across 13 devices, considering 5 hardware metrics and 3 distinct model scales.","Finally, we showcase the usability of HW-GPT-Bench using 8 different multi-objective NAS algorithms and evaluate the quality of the resultant Pareto fronts.","Through this benchmark, our objective is to propel and expedite research in the advancement of multi-objective methods for NAS and structural pruning in large language models."],"url":"http://arxiv.org/abs/2405.10299v1"}
{"created":"2024-05-16 17:52:36","title":"Low-Degree Polynomials Are Good Extractors","abstract":"We prove that random low-degree polynomials (over $\\mathbb{F}_2$) are unbiased, in an extremely general sense. That is, we show that random low-degree polynomials are good randomness extractors for a wide class of distributions. Prior to our work, such results were only known for the small families of (1) uniform sources, (2) affine sources, and (3) local sources. We significantly generalize these results, and prove the following.   1. Low-degree polynomials extract from small families. We show that a random low-degree polynomial is a good low-error extractor for any small family of sources. In particular, we improve the positive result of Alrabiah, Chattopadhyay, Goodman, Li, and Ribeiro (ICALP 2022) for local sources, and give new results for polynomial sources and variety sources via a single unified approach.   2. Low-degree polynomials extract from sumset sources. We show that a random low-degree polynomial is a good extractor for sumset sources, which are the most general large family of sources (capturing independent sources, interleaved sources, small-space sources, and more). This extractor achieves polynomially small error, and its min-entropy requirement is tight up to a square.   Our results on sumset extractors imply new complexity separations for linear ROBPs, and the tools that go into its proof have further applications, as well. The two main tools we use are a new structural result on sumset-punctured Reed-Muller codes, paired with a novel type of reduction between randomness extractors. Using the first new tool, we strengthen and generalize the extractor impossibility results of Chattopadhyay, Goodman, and Gurumukhani (ITCS 2024). Using the second, we show the existence of sumset extractors for min-entropy $k=O(\\log(n/\\varepsilon))$, resolving an open problem of Chattopadhyay and Liao (STOC 2022).","sentences":["We prove that random low-degree polynomials (over $\\mathbb{F}_2$) are unbiased, in an extremely general sense.","That is, we show that random low-degree polynomials are good randomness extractors for a wide class of distributions.","Prior to our work, such results were only known for the small families of (1) uniform sources, (2) affine sources, and (3) local sources.","We significantly generalize these results, and prove the following.   ","1. Low-degree polynomials extract from small families.","We show that a random low-degree polynomial is a good low-error extractor for any small family of sources.","In particular, we improve the positive result of Alrabiah, Chattopadhyay, Goodman, Li, and Ribeiro (ICALP 2022) for local sources, and give new results for polynomial sources and variety sources via a single unified approach.   ","2. Low-degree polynomials extract from sumset sources.","We show that a random low-degree polynomial is a good extractor for sumset sources, which are the most general large family of sources (capturing independent sources, interleaved sources, small-space sources, and more).","This extractor achieves polynomially small error, and its min-entropy requirement is tight up to a square.   ","Our results on sumset extractors imply new complexity separations for linear ROBPs, and the tools that go into its proof have further applications, as well.","The two main tools we use are a new structural result on sumset-punctured Reed-Muller codes, paired with a novel type of reduction between randomness extractors.","Using the first new tool, we strengthen and generalize the extractor impossibility results of Chattopadhyay, Goodman, and Gurumukhani (ITCS 2024).","Using the second, we show the existence of sumset extractors for min-entropy $k=O(\\log(n/\\varepsilon))$, resolving an open problem of Chattopadhyay and Liao (STOC 2022)."],"url":"http://arxiv.org/abs/2405.10297v1"}
{"created":"2024-05-16 17:52:26","title":"Verifying Unboundedness via Amalgamation","abstract":"Well-structured transition systems (WSTS) are an abstract family of systems that encompasses a vast landscape of infinite-state systems. By requiring a well-quasi-ordering (wqo) on the set of states, a WSTS enables generic algorithms for classic verification tasks such as coverability and termination. However, even for systems that are WSTS like vector addition systems (VAS), the framework is notoriously ill-equipped to analyse reachability (as opposed to coverability). Moreover, some important types of infinite-state systems fall out of WSTS' scope entirely, such as pushdown systems (PDS).   Inspired by recent algorithmic techniques on VAS, we propose an abstract notion of systems where the set of runs is equipped with a wqo and supports amalgamation of runs. We show that it subsumes a large class of infinite-state systems, including (reachability languages of) VAS and PDS, and even all systems from the abstract framework of valence systems, except for those already known to be Turing-complete.   Moreover, this abstract setting enables simple and general algorithmic solutions to unboundedness problems, which have received much attention in recent years. We present algorithms for the (i) simultaneous unboundedness problem (which implies computability of downward closures and decidability of separability by piecewise testable languages), (ii) computing priority downward closures, (iii) deciding whether a language is bounded, meaning included in $w_1^*\\cdots w_k^*$ for some words $w_1,\\ldots,w_k$, and (iv)~effective regularity of unary languages. This leads to either drastically simpler proofs or new decidability results for a rich variety of systems.","sentences":["Well-structured transition systems (WSTS) are an abstract family of systems that encompasses a vast landscape of infinite-state systems.","By requiring a well-quasi-ordering (wqo) on the set of states, a WSTS enables generic algorithms for classic verification tasks such as coverability and termination.","However, even for systems that are WSTS like vector addition systems (VAS), the framework is notoriously ill-equipped to analyse reachability (as opposed to coverability).","Moreover, some important types of infinite-state systems fall out of WSTS' scope entirely, such as pushdown systems (PDS).   ","Inspired by recent algorithmic techniques on VAS, we propose an abstract notion of systems where the set of runs is equipped with a wqo and supports amalgamation of runs.","We show that it subsumes a large class of infinite-state systems, including (reachability languages of) VAS and PDS, and even all systems from the abstract framework of valence systems, except for those already known to be Turing-complete.   ","Moreover, this abstract setting enables simple and general algorithmic solutions to unboundedness problems, which have received much attention in recent years.","We present algorithms for the (i) simultaneous unboundedness problem (which implies computability of downward closures and decidability of separability by piecewise testable languages), (ii) computing priority downward closures, (iii) deciding whether a language is bounded, meaning included in $w_1^*\\cdots w_k^*$ for some words $w_1,\\ldots,w_k$, and (iv)~effective regularity of unary languages.","This leads to either drastically simpler proofs or new decidability results for a rich variety of systems."],"url":"http://arxiv.org/abs/2405.10296v1"}
{"created":"2024-05-16 17:52:12","title":"Societal Adaptation to Advanced AI","abstract":"Existing strategies for managing risks from advanced AI systems often focus on affecting what AI systems are developed and how they diffuse. However, this approach becomes less feasible as the number of developers of advanced AI grows, and impedes beneficial use-cases as well as harmful ones. In response, we urge a complementary approach: increasing societal adaptation to advanced AI, that is, reducing the expected negative impacts from a given level of diffusion of a given AI capability. We introduce a conceptual framework which helps identify adaptive interventions that avoid, defend against and remedy potentially harmful uses of AI systems, illustrated with examples in election manipulation, cyberterrorism, and loss of control to AI decision-makers. We discuss a three-step cycle that society can implement to adapt to AI. Increasing society's ability to implement this cycle builds its resilience to advanced AI. We conclude with concrete recommendations for governments, industry, and third-parties.","sentences":["Existing strategies for managing risks from advanced AI systems often focus on affecting what AI systems are developed and how they diffuse.","However, this approach becomes less feasible as the number of developers of advanced AI grows, and impedes beneficial use-cases as well as harmful ones.","In response, we urge a complementary approach: increasing societal adaptation to advanced AI, that is, reducing the expected negative impacts from a given level of diffusion of a given AI capability.","We introduce a conceptual framework which helps identify adaptive interventions that avoid, defend against and remedy potentially harmful uses of AI systems, illustrated with examples in election manipulation, cyberterrorism, and loss of control to AI decision-makers.","We discuss a three-step cycle that society can implement to adapt to AI.","Increasing society's ability to implement this cycle builds its resilience to advanced AI.","We conclude with concrete recommendations for governments, industry, and third-parties."],"url":"http://arxiv.org/abs/2405.10295v1"}
{"created":"2024-05-16 17:50:19","title":"Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning","abstract":"Large vision-language models (VLMs) fine-tuned on specialized visual instruction-following data have exhibited impressive language reasoning capabilities across various scenarios. However, this fine-tuning paradigm may not be able to efficiently learn optimal decision-making agents in multi-step goal-directed tasks from interactive environments. To address this challenge, we propose an algorithmic framework that fine-tunes VLMs with reinforcement learning (RL). Specifically, our framework provides a task description and then prompts the VLM to generate chain-of-thought (CoT) reasoning, enabling the VLM to efficiently explore intermediate reasoning steps that lead to the final text-based action. Next, the open-ended text output is parsed into an executable action to interact with the environment to obtain goal-directed task rewards. Finally, our framework uses these task rewards to fine-tune the entire VLM with RL. Empirically, we demonstrate that our proposed framework enhances the decision-making capabilities of VLM agents across various tasks, enabling 7b models to outperform commercial models such as GPT4-V or Gemini. Furthermore, we find that CoT reasoning is a crucial component for performance improvement, as removing the CoT reasoning results in a significant decrease in the overall performance of our method.","sentences":["Large vision-language models (VLMs) fine-tuned on specialized visual instruction-following data have exhibited impressive language reasoning capabilities across various scenarios.","However, this fine-tuning paradigm may not be able to efficiently learn optimal decision-making agents in multi-step goal-directed tasks from interactive environments.","To address this challenge, we propose an algorithmic framework that fine-tunes VLMs with reinforcement learning (RL).","Specifically, our framework provides a task description and then prompts the VLM to generate chain-of-thought (CoT) reasoning, enabling the VLM to efficiently explore intermediate reasoning steps that lead to the final text-based action.","Next, the open-ended text output is parsed into an executable action to interact with the environment to obtain goal-directed task rewards.","Finally, our framework uses these task rewards to fine-tune the entire VLM with RL.","Empirically, we demonstrate that our proposed framework enhances the decision-making capabilities of VLM agents across various tasks, enabling 7b models to outperform commercial models such as GPT4-V or Gemini.","Furthermore, we find that CoT reasoning is a crucial component for performance improvement, as removing the CoT reasoning results in a significant decrease in the overall performance of our method."],"url":"http://arxiv.org/abs/2405.10292v1"}
{"created":"2024-05-16 17:50:04","title":"On Sample Selection for Continual Learning: a Video Streaming Case Study","abstract":"Machine learning (ML) is a powerful tool to model the complexity of communication networks. As networks evolve, we cannot only train once and deploy. Retraining models, known as continual learning, is necessary. Yet, to date, there is no established methodology to answer the key questions: With which samples to retrain? When should we retrain?   We address these questions with the sample selection system Memento, which maintains a training set with the \"most useful\" samples to maximize sample space coverage. Memento particularly benefits rare patterns -- the notoriously long \"tail\" in networking -- and allows assessing rationally when retraining may help, i.e., when the coverage changes.   We deployed Memento on Puffer, the live-TV streaming project, and achieved a 14% reduction of stall time, 3.5x the improvement of random sample selection. Finally, Memento does not depend on a specific model architecture; it is likely to yield benefits in other ML-based networking applications.","sentences":["Machine learning (ML) is a powerful tool to model the complexity of communication networks.","As networks evolve, we cannot only train once and deploy.","Retraining models, known as continual learning, is necessary.","Yet, to date, there is no established methodology to answer the key questions: With which samples to retrain?","When should we retrain?   ","We address these questions with the sample selection system Memento, which maintains a training set with the \"most useful\" samples to maximize sample space coverage.","Memento particularly benefits rare patterns -- the notoriously long \"tail\" in networking -- and allows assessing rationally when retraining may help, i.e., when the coverage changes.   ","We deployed Memento on Puffer, the live-TV streaming project, and achieved a 14% reduction of stall time, 3.5x the improvement of random sample selection.","Finally, Memento does not depend on a specific model architecture; it is likely to yield benefits in other ML-based networking applications."],"url":"http://arxiv.org/abs/2405.10290v1"}
{"created":"2024-05-16 17:48:21","title":"Timeline-based Sentence Decomposition with In-Context Learning for Temporal Fact Extraction","abstract":"Facts extraction is pivotal for constructing knowledge graphs. Recently, the increasing demand for temporal facts in downstream tasks has led to the emergence of the task of temporal fact extraction. In this paper, we specifically address the extraction of temporal facts from natural language text. Previous studies fail to handle the challenge of establishing time-to-fact correspondences in complex sentences. To overcome this hurdle, we propose a timeline-based sentence decomposition strategy using large language models (LLMs) with in-context learning, ensuring a fine-grained understanding of the timeline associated with various facts. In addition, we evaluate the performance of LLMs for direct temporal fact extraction and get unsatisfactory results. To this end, we introduce TSDRE, a method that incorporates the decomposition capabilities of LLMs into the traditional fine-tuning of smaller pre-trained language models (PLMs). To support the evaluation, we construct ComplexTRED, a complex temporal fact extraction dataset. Our experiments show that TSDRE achieves state-of-the-art results on both HyperRED-Temporal and ComplexTRED datasets.","sentences":["Facts extraction is pivotal for constructing knowledge graphs.","Recently, the increasing demand for temporal facts in downstream tasks has led to the emergence of the task of temporal fact extraction.","In this paper, we specifically address the extraction of temporal facts from natural language text.","Previous studies fail to handle the challenge of establishing time-to-fact correspondences in complex sentences.","To overcome this hurdle, we propose a timeline-based sentence decomposition strategy using large language models (LLMs) with in-context learning, ensuring a fine-grained understanding of the timeline associated with various facts.","In addition, we evaluate the performance of LLMs for direct temporal fact extraction and get unsatisfactory results.","To this end, we introduce TSDRE, a method that incorporates the decomposition capabilities of LLMs into the traditional fine-tuning of smaller pre-trained language models (PLMs).","To support the evaluation, we construct ComplexTRED, a complex temporal fact extraction dataset.","Our experiments show that TSDRE achieves state-of-the-art results on both HyperRED-Temporal and ComplexTRED datasets."],"url":"http://arxiv.org/abs/2405.10288v1"}
{"created":"2024-05-16 17:46:54","title":"FFF: Fixing Flawed Foundations in contrastive pre-training results in very strong Vision-Language models","abstract":"Despite noise and caption quality having been acknowledged as important factors impacting vision-language contrastive pre-training, in this paper, we show that the full potential of improving the training process by addressing such issues is yet to be realized. Specifically, we firstly study and analyze two issues affecting training: incorrect assignment of negative pairs, and low caption quality and diversity. Then, we devise effective solutions for addressing both problems, which essentially require training with multiple true positive pairs. Finally, we propose training with sigmoid loss to address such a requirement. We show very large gains over the current state-of-the-art for both image recognition ($\\sim +6\\%$ on average over 11 datasets) and image retrieval ($\\sim +19\\%$ on Flickr30k and $\\sim +15\\%$ on MSCOCO).","sentences":["Despite noise and caption quality having been acknowledged as important factors impacting vision-language contrastive pre-training, in this paper, we show that the full potential of improving the training process by addressing such issues is yet to be realized.","Specifically, we firstly study and analyze two issues affecting training: incorrect assignment of negative pairs, and low caption quality and diversity.","Then, we devise effective solutions for addressing both problems, which essentially require training with multiple true positive pairs.","Finally, we propose training with sigmoid loss to address such a requirement.","We show very large gains over the current state-of-the-art for both image recognition ($\\sim +6\\%$ on average over 11 datasets) and image retrieval ($\\sim +19\\%$ on Flickr30k and $\\sim +15\\%$ on MSCOCO)."],"url":"http://arxiv.org/abs/2405.10286v1"}
{"created":"2024-05-16 17:37:01","title":"Evaluation of a Multi-Molecule Molecular Communication Testbed Based on Spectral Sensing","abstract":"This work presents a novel flow-based molecular communication (MC) testbed using spectral sensing and ink concentration estimation to enable real-time multi-molecule (MUMO) transmission. MUMO communication opens up crucial opportunities for increased throughput as well as implementing more complex coding, modulation, and resource allocation strategies for MC testbeds. A concentration estimator using non-invasive spectral sensing at the receiver is proposed based on a simple absorption model. We conduct in-depth channel impulse response (CIR) measurements and a preliminary communication performance evaluation. Additionally, a simple analytical model is used to check the consistency of the CIRs. The results indicate that by utilizing MUMO transmission, on-off-keying, and a simple difference detector, the testbed can achieve up to 3 bits per second for near-error-free communication, which is on par with comparable testbeds that utilize more sophisticated coding or detection methods. Our platform lays the ground for implementing MUMO communication and evaluating various physical layer and networking techniques based on multiple molecule types in future MC testbeds in real time.","sentences":["This work presents a novel flow-based molecular communication (MC) testbed using spectral sensing and ink concentration estimation to enable real-time multi-molecule (MUMO) transmission.","MUMO communication opens up crucial opportunities for increased throughput as well as implementing more complex coding, modulation, and resource allocation strategies for MC testbeds.","A concentration estimator using non-invasive spectral sensing at the receiver is proposed based on a simple absorption model.","We conduct in-depth channel impulse response (CIR) measurements and a preliminary communication performance evaluation.","Additionally, a simple analytical model is used to check the consistency of the CIRs.","The results indicate that by utilizing MUMO transmission, on-off-keying, and a simple difference detector, the testbed can achieve up to 3 bits per second for near-error-free communication, which is on par with comparable testbeds that utilize more sophisticated coding or detection methods.","Our platform lays the ground for implementing MUMO communication and evaluating various physical layer and networking techniques based on multiple molecule types in future MC testbeds in real time."],"url":"http://arxiv.org/abs/2405.10280v1"}
{"created":"2024-05-16 17:34:37","title":"Hilbert Functions and Low-Degree Randomness Extractors","abstract":"For $S\\subseteq \\mathbb{F}^n$, consider the linear space of restrictions of degree-$d$ polynomials to $S$. The Hilbert function of $S$, denoted $\\mathrm{h}_S(d,\\mathbb{F})$, is the dimension of this space. We obtain a tight lower bound on the smallest value of the Hilbert function of subsets $S$ of arbitrary finite grids in $\\mathbb{F}^n$ with a fixed size $|S|$. We achieve this by proving that this value coincides with a combinatorial quantity, namely the smallest number of low Hamming weight points in a down-closed set of size $|S|$.   Understanding the smallest values of Hilbert functions is closely related to the study of degree-$d$ closure of sets, a notion introduced by Nie and Wang (Journal of Combinatorial Theory, Series A, 2015). We use bounds on the Hilbert function to obtain a tight bound on the size of degree-$d$ closures of subsets of $\\mathbb{F}_q^n$, which answers a question posed by Doron, Ta-Shma, and Tell (Computational Complexity, 2022).   We use the bounds on the Hilbert function and degree-$d$ closure of sets to prove that a random low-degree polynomial is an extractor for samplable randomness sources. Most notably, we prove the existence of low-degree extractors and dispersers for sources generated by constant-degree polynomials and polynomial-size circuits. Until recently, even the existence of arbitrary deterministic extractors for such sources was not known.","sentences":["For $S\\subseteq \\mathbb{F}^n$, consider the linear space of restrictions of degree-$d$ polynomials to $S$. The Hilbert function of $S$, denoted $\\mathrm{h}_S(d,\\mathbb{F})$, is the dimension of this space.","We obtain a tight lower bound on the smallest value of the Hilbert function of subsets $S$ of arbitrary finite grids in $\\mathbb{F}^n$ with a fixed size $|S|$.","We achieve this by proving that this value coincides with a combinatorial quantity, namely the smallest number of low Hamming weight points in a down-closed set of size $|S|$.   Understanding the smallest values of Hilbert functions is closely related to the study of degree-$d$ closure of sets, a notion introduced by Nie and Wang (Journal of Combinatorial Theory, Series A, 2015).","We use bounds on the Hilbert function to obtain a tight bound on the size of degree-$d$ closures of subsets of $\\mathbb{F}_q^n$, which answers a question posed by Doron, Ta-Shma, and Tell (Computational Complexity, 2022).   ","We use the bounds on the Hilbert function and degree-$d$ closure of sets to prove that a random low-degree polynomial is an extractor for samplable randomness sources.","Most notably, we prove the existence of low-degree extractors and dispersers for sources generated by constant-degree polynomials and polynomial-size circuits.","Until recently, even the existence of arbitrary deterministic extractors for such sources was not known."],"url":"http://arxiv.org/abs/2405.10277v1"}
{"created":"2024-05-16 17:33:50","title":"Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers","abstract":"Numerous recent works aim to enhance the efficacy of Large Language Models (LLMs) through strategic prompting. In particular, the Optimization by PROmpting (OPRO) approach provides state-of-the-art performance by leveraging LLMs as optimizers where the optimization task is to find instructions that maximize the task accuracy. In this paper, we revisit OPRO for automated prompting with relatively small-scale LLMs, such as LLaMa-2 family and Mistral 7B. Our investigation reveals that OPRO shows limited effectiveness in small-scale LLMs, with limited inference capabilities constraining optimization ability. We suggest future automatic prompting engineering to consider both model capabilities and computational costs. Additionally, for small-scale LLMs, we recommend direct instructions that clearly outline objectives and methodologies as robust prompt baselines, ensuring efficient and effective prompt engineering in ongoing research.","sentences":["Numerous recent works aim to enhance the efficacy of Large Language Models (LLMs) through strategic prompting.","In particular, the Optimization by PROmpting (OPRO) approach provides state-of-the-art performance by leveraging LLMs as optimizers where the optimization task is to find instructions that maximize the task accuracy.","In this paper, we revisit OPRO for automated prompting with relatively small-scale LLMs, such as LLaMa-2 family and Mistral 7B.","Our investigation reveals that OPRO shows limited effectiveness in small-scale LLMs, with limited inference capabilities constraining optimization ability.","We suggest future automatic prompting engineering to consider both model capabilities and computational costs.","Additionally, for small-scale LLMs, we recommend direct instructions that clearly outline objectives and methodologies as robust prompt baselines, ensuring efficient and effective prompt engineering in ongoing research."],"url":"http://arxiv.org/abs/2405.10276v1"}
{"created":"2024-05-16 17:29:37","title":"Faces that Speak: Jointly Synthesising Talking Face and Speech from Text","abstract":"The goal of this work is to simultaneously generate natural talking faces and speech outputs from text. We achieve this by integrating Talking Face Generation (TFG) and Text-to-Speech (TTS) systems into a unified framework. We address the main challenges of each task: (1) generating a range of head poses representative of real-world scenarios, and (2) ensuring voice consistency despite variations in facial motion for the same identity. To tackle these issues, we introduce a motion sampler based on conditional flow matching, which is capable of high-quality motion code generation in an efficient way. Moreover, we introduce a novel conditioning method for the TTS system, which utilises motion-removed features from the TFG model to yield uniform speech outputs. Our extensive experiments demonstrate that our method effectively creates natural-looking talking faces and speech that accurately match the input text. To our knowledge, this is the first effort to build a multimodal synthesis system that can generalise to unseen identities.","sentences":["The goal of this work is to simultaneously generate natural talking faces and speech outputs from text.","We achieve this by integrating Talking Face Generation (TFG) and Text-to-Speech (TTS) systems into a unified framework.","We address the main challenges of each task: (1) generating a range of head poses representative of real-world scenarios, and (2) ensuring voice consistency despite variations in facial motion for the same identity.","To tackle these issues, we introduce a motion sampler based on conditional flow matching, which is capable of high-quality motion code generation in an efficient way.","Moreover, we introduce a novel conditioning method for the TTS system, which utilises motion-removed features from the TFG model to yield uniform speech outputs.","Our extensive experiments demonstrate that our method effectively creates natural-looking talking faces and speech that accurately match the input text.","To our knowledge, this is the first effort to build a multimodal synthesis system that can generalise to unseen identities."],"url":"http://arxiv.org/abs/2405.10272v1"}
{"created":"2024-05-16 17:27:41","title":"Automated Federated Learning via Informed Pruning","abstract":"Federated learning (FL) represents a pivotal shift in machine learning (ML) as it enables collaborative training of local ML models coordinated by a central aggregator, all without the need to exchange local data. However, its application on edge devices is hindered by limited computational capabilities and data communication challenges, compounded by the inherent complexity of Deep Learning (DL) models. Model pruning is identified as a key technique for compressing DL models on devices with limited resources. Nonetheless, conventional pruning techniques typically rely on manually crafted heuristics and demand human expertise to achieve a balance between model size, speed, and accuracy, often resulting in sub-optimal solutions.   In this study, we introduce an automated federated learning approach utilizing informed pruning, called AutoFLIP, which dynamically prunes and compresses DL models within both the local clients and the global server. It leverages a federated loss exploration phase to investigate model gradient behavior across diverse datasets and losses, providing insights into parameter significance. Our experiments showcase notable enhancements in scenarios with strong non-IID data, underscoring AutoFLIP's capacity to tackle computational constraints and achieve superior global convergence.","sentences":["Federated learning (FL) represents a pivotal shift in machine learning (ML) as it enables collaborative training of local ML models coordinated by a central aggregator, all without the need to exchange local data.","However, its application on edge devices is hindered by limited computational capabilities and data communication challenges, compounded by the inherent complexity of Deep Learning (DL) models.","Model pruning is identified as a key technique for compressing DL models on devices with limited resources.","Nonetheless, conventional pruning techniques typically rely on manually crafted heuristics and demand human expertise to achieve a balance between model size, speed, and accuracy, often resulting in sub-optimal solutions.   ","In this study, we introduce an automated federated learning approach utilizing informed pruning, called AutoFLIP, which dynamically prunes and compresses DL models within both the local clients and the global server.","It leverages a federated loss exploration phase to investigate model gradient behavior across diverse datasets and losses, providing insights into parameter significance.","Our experiments showcase notable enhancements in scenarios with strong non-IID data, underscoring AutoFLIP's capacity to tackle computational constraints and achieve superior global convergence."],"url":"http://arxiv.org/abs/2405.10271v1"}
{"created":"2024-05-16 17:19:58","title":"Sharpness-Aware Minimization in Genetic Programming","abstract":"Sharpness-Aware Minimization (SAM) was recently introduced as a regularization procedure for training deep neural networks. It simultaneously minimizes the fitness (or loss) function and the so-called fitness sharpness. The latter serves as a %connection between the geometry of the fitness landscape measure of the nonlinear behavior of a solution %and generalization and does so by finding solutions that lie in neighborhoods having uniformly similar loss values across all fitness cases. In this contribution, we adapt SAM for tree Genetic Programming (TGP) by exploring the semantic neighborhoods of solutions using two simple approaches By capitalizing upon perturbing input and output of program trees, sharpness can be estimated and used as a second optimization criterion during the evolution. To better understand the impact of this variant of SAM on TGP, we collect numerous indicators of the evolutionary process, including generalization ability, complexity, diversity, and a recently proposed genotype-phenotype mapping to study the amount of redundancy in trees. The experimental results demonstrate that using any of the two proposed SAM adaptations in TGP allows (i) a significant reduction of tree sizes in the population and (ii) a decrease in redundancy of the trees. When assessed on real-world benchmarks, the generalization ability of the elite solutions does not deteriorate.","sentences":["Sharpness-Aware Minimization (SAM) was recently introduced as a regularization procedure for training deep neural networks.","It simultaneously minimizes the fitness (or loss) function and the so-called fitness sharpness.","The latter serves as a %connection between the geometry of the fitness landscape measure of the nonlinear behavior of a solution %and generalization and does so by finding solutions that lie in neighborhoods having uniformly similar loss values across all fitness cases.","In this contribution, we adapt SAM for tree Genetic Programming (TGP) by exploring the semantic neighborhoods of solutions using two simple approaches By capitalizing upon perturbing input and output of program trees, sharpness can be estimated and used as a second optimization criterion during the evolution.","To better understand the impact of this variant of SAM on TGP, we collect numerous indicators of the evolutionary process, including generalization ability, complexity, diversity, and a recently proposed genotype-phenotype mapping to study the amount of redundancy in trees.","The experimental results demonstrate that using any of the two proposed SAM adaptations in TGP allows (i) a significant reduction of tree sizes in the population and (ii) a decrease in redundancy of the trees.","When assessed on real-world benchmarks, the generalization ability of the elite solutions does not deteriorate."],"url":"http://arxiv.org/abs/2405.10267v1"}
{"created":"2024-05-16 17:19:06","title":"A Tale of Two Languages: Large-Vocabulary Continuous Sign Language Recognition from Spoken Language Supervision","abstract":"In this work, our goals are two fold: large-vocabulary continuous sign language recognition (CSLR), and sign language retrieval. To this end, we introduce a multi-task Transformer model, CSLR2, that is able to ingest a signing sequence and output in a joint embedding space between signed language and spoken language text. To enable CSLR evaluation in the large-vocabulary setting, we introduce new dataset annotations that have been manually collected. These provide continuous sign-level annotations for six hours of test videos, and will be made publicly available. We demonstrate that by a careful choice of loss functions, training the model for both the CSLR and retrieval tasks is mutually beneficial in terms of performance -- retrieval improves CSLR performance by providing context, while CSLR improves retrieval with more fine-grained supervision. We further show the benefits of leveraging weak and noisy supervision from large-vocabulary datasets such as BOBSL, namely sign-level pseudo-labels, and English subtitles. Our model significantly outperforms the previous state of the art on both tasks.","sentences":["In this work, our goals are two fold: large-vocabulary continuous sign language recognition (CSLR), and sign language retrieval.","To this end, we introduce a multi-task Transformer model, CSLR2, that is able to ingest a signing sequence and output in a joint embedding space between signed language and spoken language text.","To enable CSLR evaluation in the large-vocabulary setting, we introduce new dataset annotations that have been manually collected.","These provide continuous sign-level annotations for six hours of test videos, and will be made publicly available.","We demonstrate that by a careful choice of loss functions, training the model for both the CSLR and retrieval tasks is mutually beneficial in terms of performance -- retrieval improves CSLR performance by providing context, while CSLR improves retrieval with more fine-grained supervision.","We further show the benefits of leveraging weak and noisy supervision from large-vocabulary datasets such as BOBSL, namely sign-level pseudo-labels, and English subtitles.","Our model significantly outperforms the previous state of the art on both tasks."],"url":"http://arxiv.org/abs/2405.10266v1"}
{"created":"2024-05-16 17:13:55","title":"On Partially Unitary Learning","abstract":"The problem of an optimal mapping between Hilbert spaces $IN$ of $\\left|\\psi\\right\\rangle$ and $OUT$ of $\\left|\\phi\\right\\rangle$ based on a set of wavefunction measurements (within a phase) $\\psi_l \\to \\phi_l$, $l=1\\dots M$, is formulated as an optimization problem maximizing the total fidelity $\\sum_{l=1}^{M} \\omega^{(l)} \\left|\\langle\\phi_l|\\mathcal{U}|\\psi_l\\rangle\\right|^2$ subject to probability preservation constraints on $\\mathcal{U}$ (partial unitarity). Constructed operator $\\mathcal{U}$ can be considered as a $IN$ to $OUT$ quantum channel; it is a partially unitary rectangular matrix of the dimension $\\dim(OUT) \\times \\dim(IN)$ transforming operators as $A^{OUT}=\\mathcal{U} A^{IN} \\mathcal{U}^{\\dagger}$. An iteration algorithm finding the global maximum of this optimization problem is developed and it's application to a number of problems is demonstrated. A software product implementing the algorithm is available from the authors.","sentences":["The problem of an optimal mapping between Hilbert spaces $IN$ of $\\left|\\psi\\right\\rangle$ and $OUT$ of $\\left|\\phi\\right\\rangle$ based on a set of wavefunction measurements (within a phase) $\\psi_l \\to \\phi_l$, $l=1\\dots M$, is formulated as an optimization problem maximizing the total fidelity $\\sum_{l=1}^{M} \\omega^{(l)} \\left|\\langle\\phi_l|\\mathcal{U}|\\psi_l\\rangle\\right|^2$ subject to probability preservation constraints on $\\mathcal{U}$ (partial unitarity).","Constructed operator $\\mathcal{U}$ can be considered as a $IN$ to $OUT$ quantum channel; it is a partially unitary rectangular matrix of the dimension $\\dim(OUT) \\times \\dim(IN)$ transforming operators as $A^{OUT}=\\mathcal{U} A^{IN} \\mathcal{U}^{\\dagger}$.","An iteration algorithm finding the global maximum of this optimization problem is developed and it's application to a number of problems is demonstrated.","A software product implementing the algorithm is available from the authors."],"url":"http://arxiv.org/abs/2405.10263v1"}
{"created":"2024-05-16 17:13:25","title":"Two-Phase Dynamics of Interactions Explains the Starting Point of a DNN Learning Over-Fitted Features","abstract":"This paper investigates the dynamics of a deep neural network (DNN) learning interactions. Previous studies have discovered and mathematically proven that given each input sample, a well-trained DNN usually only encodes a small number of interactions (non-linear relationships) between input variables in the sample. A series of theorems have been derived to prove that we can consider the DNN's inference equivalent to using these interactions as primitive patterns for inference. In this paper, we discover the DNN learns interactions in two phases. The first phase mainly penalizes interactions of medium and high orders, and the second phase mainly learns interactions of gradually increasing orders. We can consider the two-phase phenomenon as the starting point of a DNN learning over-fitted features. Such a phenomenon has been widely shared by DNNs with various architectures trained for different tasks. Therefore, the discovery of the two-phase dynamics provides a detailed mechanism for how a DNN gradually learns different inference patterns (interactions). In particular, we have also verified the claim that high-order interactions have weaker generalization power than low-order interactions. Thus, the discovered two-phase dynamics also explains how the generalization power of a DNN changes during the training process.","sentences":["This paper investigates the dynamics of a deep neural network (DNN) learning interactions.","Previous studies have discovered and mathematically proven that given each input sample, a well-trained DNN usually only encodes a small number of interactions (non-linear relationships) between input variables in the sample.","A series of theorems have been derived to prove that we can consider the DNN's inference equivalent to using these interactions as primitive patterns for inference.","In this paper, we discover the DNN learns interactions in two phases.","The first phase mainly penalizes interactions of medium and high orders, and the second phase mainly learns interactions of gradually increasing orders.","We can consider the two-phase phenomenon as the starting point of a DNN learning over-fitted features.","Such a phenomenon has been widely shared by DNNs with various architectures trained for different tasks.","Therefore, the discovery of the two-phase dynamics provides a detailed mechanism for how a DNN gradually learns different inference patterns (interactions).","In particular, we have also verified the claim that high-order interactions have weaker generalization power than low-order interactions.","Thus, the discovered two-phase dynamics also explains how the generalization power of a DNN changes during the training process."],"url":"http://arxiv.org/abs/2405.10262v1"}
{"created":"2024-05-16 17:12:18","title":"Keep It Private: Unsupervised Privatization of Online Text","abstract":"Authorship obfuscation techniques hold the promise of helping people protect their privacy in online communications by automatically rewriting text to hide the identity of the original author. However, obfuscation has been evaluated in narrow settings in the NLP literature and has primarily been addressed with superficial edit operations that can lead to unnatural outputs. In this work, we introduce an automatic text privatization framework that fine-tunes a large language model via reinforcement learning to produce rewrites that balance soundness, sense, and privacy. We evaluate it extensively on a large-scale test set of English Reddit posts by 68k authors composed of short-medium length texts. We study how the performance changes among evaluative conditions including authorial profile length and authorship detection strategy. Our method maintains high text quality according to both automated metrics and human evaluation, and successfully evades several automated authorship attacks.","sentences":["Authorship obfuscation techniques hold the promise of helping people protect their privacy in online communications by automatically rewriting text to hide the identity of the original author.","However, obfuscation has been evaluated in narrow settings in the NLP literature and has primarily been addressed with superficial edit operations that can lead to unnatural outputs.","In this work, we introduce an automatic text privatization framework that fine-tunes a large language model via reinforcement learning to produce rewrites that balance soundness, sense, and privacy.","We evaluate it extensively on a large-scale test set of English Reddit posts by 68k authors composed of short-medium length texts.","We study how the performance changes among evaluative conditions including authorial profile length and authorship detection strategy.","Our method maintains high text quality according to both automated metrics and human evaluation, and successfully evades several automated authorship attacks."],"url":"http://arxiv.org/abs/2405.10260v1"}
{"created":"2024-05-16 17:02:23","title":"Biasing & Debiasing based Approach Towards Fair Knowledge Transfer for Equitable Skin Analysis","abstract":"Deep learning models, particularly Convolutional Neural Networks (CNNs), have demonstrated exceptional performance in diagnosing skin diseases, often outperforming dermatologists. However, they have also unveiled biases linked to specific demographic traits, notably concerning diverse skin tones or gender, prompting concerns regarding fairness and limiting their widespread deployment. Researchers are actively working to ensure fairness in AI-based solutions, but existing methods incur an accuracy loss when striving for fairness. To solve this issue, we propose a `two-biased teachers' (i.e., biased on different sensitive attributes) based approach to transfer fair knowledge into the student network. Our approach mitigates biases present in the student network without harming its predictive accuracy. In fact, in most cases, our approach improves the accuracy of the baseline model. To achieve this goal, we developed a weighted loss function comprising biasing and debiasing loss terms. We surpassed available state-of-the-art approaches to attain fairness and also improved the accuracy at the same time. The proposed approach has been evaluated and validated on two dermatology datasets using standard accuracy and fairness evaluation measures. We will make source code publicly available to foster reproducibility and future research.","sentences":["Deep learning models, particularly Convolutional Neural Networks (CNNs), have demonstrated exceptional performance in diagnosing skin diseases, often outperforming dermatologists.","However, they have also unveiled biases linked to specific demographic traits, notably concerning diverse skin tones or gender, prompting concerns regarding fairness and limiting their widespread deployment.","Researchers are actively working to ensure fairness in AI-based solutions, but existing methods incur an accuracy loss when striving for fairness.","To solve this issue, we propose a `two-biased teachers' (i.e., biased on different sensitive attributes) based approach to transfer fair knowledge into the student network.","Our approach mitigates biases present in the student network without harming its predictive accuracy.","In fact, in most cases, our approach improves the accuracy of the baseline model.","To achieve this goal, we developed a weighted loss function comprising biasing and debiasing loss terms.","We surpassed available state-of-the-art approaches to attain fairness and also improved the accuracy at the same time.","The proposed approach has been evaluated and validated on two dermatology datasets using standard accuracy and fairness evaluation measures.","We will make source code publicly available to foster reproducibility and future research."],"url":"http://arxiv.org/abs/2405.10256v1"}
{"created":"2024-05-16 16:59:58","title":"When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models","abstract":"As large language models (LLMs) evolve, their integration with 3D spatial data (3D-LLMs) has seen rapid progress, offering unprecedented capabilities for understanding and interacting with physical spaces. This survey provides a comprehensive overview of the methodologies enabling LLMs to process, understand, and generate 3D data. Highlighting the unique advantages of LLMs, such as in-context learning, step-by-step reasoning, open-vocabulary capabilities, and extensive world knowledge, we underscore their potential to significantly advance spatial comprehension and interaction within embodied Artificial Intelligence (AI) systems. Our investigation spans various 3D data representations, from point clouds to Neural Radiance Fields (NeRFs). It examines their integration with LLMs for tasks such as 3D scene understanding, captioning, question-answering, and dialogue, as well as LLM-based agents for spatial reasoning, planning, and navigation. The paper also includes a brief review of other methods that integrate 3D and language. The meta-analysis presented in this paper reveals significant progress yet underscores the necessity for novel approaches to harness the full potential of 3D-LLMs. Hence, with this paper, we aim to chart a course for future research that explores and expands the capabilities of 3D-LLMs in understanding and interacting with the complex 3D world. To support this survey, we have established a project page where papers related to our topic are organized and listed: https://github.com/ActiveVisionLab/Awesome-LLM-3D.","sentences":["As large language models (LLMs) evolve, their integration with 3D spatial data (3D-LLMs) has seen rapid progress, offering unprecedented capabilities for understanding and interacting with physical spaces.","This survey provides a comprehensive overview of the methodologies enabling LLMs to process, understand, and generate 3D data.","Highlighting the unique advantages of LLMs, such as in-context learning, step-by-step reasoning, open-vocabulary capabilities, and extensive world knowledge, we underscore their potential to significantly advance spatial comprehension and interaction within embodied Artificial Intelligence (AI) systems.","Our investigation spans various 3D data representations, from point clouds to Neural Radiance Fields (NeRFs).","It examines their integration with LLMs for tasks such as 3D scene understanding, captioning, question-answering, and dialogue, as well as LLM-based agents for spatial reasoning, planning, and navigation.","The paper also includes a brief review of other methods that integrate 3D and language.","The meta-analysis presented in this paper reveals significant progress yet underscores the necessity for novel approaches to harness the full potential of 3D-LLMs.","Hence, with this paper, we aim to chart a course for future research that explores and expands the capabilities of 3D-LLMs in understanding and interacting with the complex 3D world.","To support this survey, we have established a project page where papers related to our topic are organized and listed: https://github.com/ActiveVisionLab/Awesome-LLM-3D."],"url":"http://arxiv.org/abs/2405.10255v1"}
{"created":"2024-05-16 16:58:14","title":"Adaptive Quotient Filters","abstract":"Adaptive filters, such as telescoping and adaptive cuckoo filters, update their representation upon detecting a false positive to avoid repeating the same error in the future. Adaptive filters require an auxiliary structure, typically much larger than the main filter and often residing on slow storage, to facilitate adaptation. However, existing adaptive filters are not practical and have seen no adoption in real-world systems due to two main reasons. Firstly, they offer weak adaptivity guarantees, meaning that fixing a new false positive can cause a previously fixed false positive to come back. Secondly, the sub-optimal design of the auxiliary structure results in adaptivity overheads so substantial that they can actually diminish the overall system performance compared to a traditional filter.   In this paper, we design and implement AdaptiveQF, the first practical adaptive filter with minimal adaptivity overhead and strong adaptivity guarantees, which means that the performance and false-positive guarantees continue to hold even for adversarial workloads. The AdaptiveQF is based on the state-of-the-art quotient filter design and preserves all the critical features of the quotient filter such as cache efficiency and mergeability. Furthermore, we employ a new auxiliary structure design which results in considerably low adaptivity overhead and makes the AdaptiveQF practical in real systems.","sentences":["Adaptive filters, such as telescoping and adaptive cuckoo filters, update their representation upon detecting a false positive to avoid repeating the same error in the future.","Adaptive filters require an auxiliary structure, typically much larger than the main filter and often residing on slow storage, to facilitate adaptation.","However, existing adaptive filters are not practical and have seen no adoption in real-world systems due to two main reasons.","Firstly, they offer weak adaptivity guarantees, meaning that fixing a new false positive can cause a previously fixed false positive to come back.","Secondly, the sub-optimal design of the auxiliary structure results in adaptivity overheads so substantial that they can actually diminish the overall system performance compared to a traditional filter.   ","In this paper, we design and implement AdaptiveQF, the first practical adaptive filter with minimal adaptivity overhead and strong adaptivity guarantees, which means that the performance and false-positive guarantees continue to hold even for adversarial workloads.","The AdaptiveQF is based on the state-of-the-art quotient filter design and preserves all the critical features of the quotient filter such as cache efficiency and mergeability.","Furthermore, we employ a new auxiliary structure design which results in considerably low adaptivity overhead and makes the AdaptiveQF practical in real systems."],"url":"http://arxiv.org/abs/2405.10253v1"}
{"created":"2024-05-16 16:56:54","title":"A Systematic Evaluation of Large Language Models for Natural Language Generation Tasks","abstract":"Recent efforts have evaluated large language models (LLMs) in areas such as commonsense reasoning, mathematical reasoning, and code generation. However, to the best of our knowledge, no work has specifically investigated the performance of LLMs in natural language generation (NLG) tasks, a pivotal criterion for determining model excellence. Thus, this paper conducts a comprehensive evaluation of well-known and high-performing LLMs, namely ChatGPT, ChatGLM, T5-based models, LLaMA-based models, and Pythia-based models, in the context of NLG tasks. We select English and Chinese datasets encompassing Dialogue Generation and Text Summarization. Moreover, we propose a common evaluation setting that incorporates input templates and post-processing strategies. Our study reports both automatic results, accompanied by a detailed analysis.","sentences":["Recent efforts have evaluated large language models (LLMs) in areas such as commonsense reasoning, mathematical reasoning, and code generation.","However, to the best of our knowledge, no work has specifically investigated the performance of LLMs in natural language generation (NLG) tasks, a pivotal criterion for determining model excellence.","Thus, this paper conducts a comprehensive evaluation of well-known and high-performing LLMs, namely ChatGPT, ChatGLM, T5-based models, LLaMA-based models, and Pythia-based models, in the context of NLG tasks.","We select English and Chinese datasets encompassing Dialogue Generation and Text Summarization.","Moreover, we propose a common evaluation setting that incorporates input templates and post-processing strategies.","Our study reports both automatic results, accompanied by a detailed analysis."],"url":"http://arxiv.org/abs/2405.10251v1"}
{"created":"2024-05-16 16:55:06","title":"IntelliExplain: Enhancing Interactive Code Generation through Natural Language Explanations for Non-Professional Programmers","abstract":"Large language models (LLMs) have exhibited a strong promise in automatically generating executable code from natural language descriptions, particularly with interactive features that allow users to engage in the code-generation process by instructing the LLM with iterative feedback. However, existing interaction paradigms often assume that users have expert knowledge to debug source code and are not optimized for non-professional programmers' use. This raises challenges in making interactive code generation more accessible for individuals with varying levels of programming expertise. To tackle these challenges, we present IntelliExplain, which offers a novel human-LLM interaction paradigm to enhance non-professional programmers' experience by enabling them to interact with source code via natural language explanations. Users interact with IntelliExplain by providing natural language corrective feedback on errors they identify from the explanations. Feedback is used by the system to revise the code, until the user is satisfied with explanations by the system of the code. Our user study demonstrates that users with IntelliExplain achieve a significantly higher success rate 11.6% and 25.3% better than with vanilla GPT-3.5, while also requiring 39.0% and 15.6% less time in Text-to-SQL and Python code generation tasks, respectively.","sentences":["Large language models (LLMs) have exhibited a strong promise in automatically generating executable code from natural language descriptions, particularly with interactive features that allow users to engage in the code-generation process by instructing the LLM with iterative feedback.","However, existing interaction paradigms often assume that users have expert knowledge to debug source code and are not optimized for non-professional programmers' use.","This raises challenges in making interactive code generation more accessible for individuals with varying levels of programming expertise.","To tackle these challenges, we present IntelliExplain, which offers a novel human-LLM interaction paradigm to enhance non-professional programmers' experience by enabling them to interact with source code via natural language explanations.","Users interact with IntelliExplain by providing natural language corrective feedback on errors they identify from the explanations.","Feedback is used by the system to revise the code, until the user is satisfied with explanations by the system of the code.","Our user study demonstrates that users with IntelliExplain achieve a significantly higher success rate 11.6% and 25.3% better than with vanilla GPT-3.5, while also requiring 39.0% and 15.6% less time in Text-to-SQL and Python code generation tasks, respectively."],"url":"http://arxiv.org/abs/2405.10250v1"}
{"created":"2024-05-16 16:51:25","title":"Unifying Partial Synchrony","abstract":"The distributed computing literature considers multiple options for modeling communication. Most simply, communication is categorized as either synchronous or asynchronous. Synchronous communication assumes that messages get delivered within a publicly known timeframe and that parties' clocks are synchronized. Asynchronous communication, on the other hand, only assumes that messages get delivered eventually. A more nuanced approach, or a middle ground between the two extremes, is given by the partially synchronous model, which is arguably the most realistic option. This model comes in two commonly considered flavors:   (i) The Global Stabilization Time (GST) model: after an (unknown) amount of time, the network becomes synchronous. This captures scenarios where network issues are transient.   (ii) The Unknown Latency (UL) model: the network is, in fact, synchronous, but the message delay bound is unknown.   This work formally establishes that any time-agnostic property that can be achieved by a protocol in the UL model can also be achieved by a (possibly different) protocol in the GST model. By time-agnostic, we mean properties that can depend on the order in which events happen but not on time as measured by the parties. Most properties considered in distributed computing are time-agnostic. The converse was already known, even without the time-agnostic requirement, so our result shows that the two network conditions are, under one sensible assumption, equally demanding.","sentences":["The distributed computing literature considers multiple options for modeling communication.","Most simply, communication is categorized as either synchronous or asynchronous.","Synchronous communication assumes that messages get delivered within a publicly known timeframe and that parties' clocks are synchronized.","Asynchronous communication, on the other hand, only assumes that messages get delivered eventually.","A more nuanced approach, or a middle ground between the two extremes, is given by the partially synchronous model, which is arguably the most realistic option.","This model comes in two commonly considered flavors:   (i) The Global Stabilization Time (GST) model: after an (unknown) amount of time, the network becomes synchronous.","This captures scenarios where network issues are transient.   ","(ii) The Unknown Latency (UL) model: the network is, in fact, synchronous, but the message delay bound is unknown.   ","This work formally establishes that any time-agnostic property that can be achieved by a protocol in the UL model can also be achieved by a (possibly different) protocol in the GST model.","By time-agnostic, we mean properties that can depend on the order in which events happen but not on time as measured by the parties.","Most properties considered in distributed computing are time-agnostic.","The converse was already known, even without the time-agnostic requirement, so our result shows that the two network conditions are, under one sensible assumption, equally demanding."],"url":"http://arxiv.org/abs/2405.10249v1"}
{"created":"2024-05-16 16:50:31","title":"Co-Matching: Towards Human-Machine Collaborative Legal Case Matching","abstract":"Recent efforts have aimed to improve AI machines in legal case matching by integrating legal domain knowledge. However, successful legal case matching requires the tacit knowledge of legal practitioners, which is difficult to verbalize and encode into machines. This emphasizes the crucial role of involving legal practitioners in high-stakes legal case matching. To address this, we propose a collaborative matching framework called Co-Matching, which encourages both the machine and the legal practitioner to participate in the matching process, integrating tacit knowledge. Unlike existing methods that rely solely on the machine, Co-Matching allows both the legal practitioner and the machine to determine key sentences and then combine them probabilistically. Co-Matching introduces a method called ProtoEM to estimate human decision uncertainty, facilitating the probabilistic combination. Experimental results demonstrate that Co-Matching consistently outperforms existing legal case matching methods, delivering significant performance improvements over human- and machine-based matching in isolation (on average, +5.51% and +8.71%, respectively). Further analysis shows that Co-Matching also ensures better human-machine collaboration effectiveness. Our study represents a pioneering effort in human-machine collaboration for the matching task, marking a milestone for future collaborative matching studies.","sentences":["Recent efforts have aimed to improve AI machines in legal case matching by integrating legal domain knowledge.","However, successful legal case matching requires the tacit knowledge of legal practitioners, which is difficult to verbalize and encode into machines.","This emphasizes the crucial role of involving legal practitioners in high-stakes legal case matching.","To address this, we propose a collaborative matching framework called Co-Matching, which encourages both the machine and the legal practitioner to participate in the matching process, integrating tacit knowledge.","Unlike existing methods that rely solely on the machine, Co-Matching allows both the legal practitioner and the machine to determine key sentences and then combine them probabilistically.","Co-Matching introduces a method called ProtoEM to estimate human decision uncertainty, facilitating the probabilistic combination.","Experimental results demonstrate that Co-Matching consistently outperforms existing legal case matching methods, delivering significant performance improvements over human- and machine-based matching in isolation (on average, +5.51% and +8.71%, respectively).","Further analysis shows that Co-Matching also ensures better human-machine collaboration effectiveness.","Our study represents a pioneering effort in human-machine collaboration for the matching task, marking a milestone for future collaborative matching studies."],"url":"http://arxiv.org/abs/2405.10248v1"}
{"created":"2024-05-16 16:47:46","title":"Towards Task-Compatible Compressible Representations","abstract":"We identify an issue in multi-task learnable compression, in which a representation learned for one task does not positively contribute to the rate-distortion performance of a different task as much as expected, given the estimated amount of information available in it. We interpret this issue using the predictive $\\mathcal{V}$-information framework. In learnable scalable coding, previous work increased the utilization of side-information for input reconstruction by also rewarding input reconstruction when learning this shared representation. We evaluate the impact of this idea in the context of input reconstruction more rigorously and extended it to other computer vision tasks. We perform experiments using representations trained for object detection on COCO 2017 and depth estimation on the Cityscapes dataset, and use them to assist in image reconstruction and semantic segmentation tasks. The results show considerable improvements in the rate-distortion performance of the assisted tasks. Moreover, using the proposed representations, the performance of the base tasks are also improved. Results suggest that the proposed method induces simpler representations that are more compatible with downstream processes.","sentences":["We identify an issue in multi-task learnable compression, in which a representation learned for one task does not positively contribute to the rate-distortion performance of a different task as much as expected, given the estimated amount of information available in it.","We interpret this issue using the predictive $\\mathcal{V}$-information framework.","In learnable scalable coding, previous work increased the utilization of side-information for input reconstruction by also rewarding input reconstruction when learning this shared representation.","We evaluate the impact of this idea in the context of input reconstruction more rigorously and extended it to other computer vision tasks.","We perform experiments using representations trained for object detection on COCO 2017 and depth estimation on the Cityscapes dataset, and use them to assist in image reconstruction and semantic segmentation tasks.","The results show considerable improvements in the rate-distortion performance of the assisted tasks.","Moreover, using the proposed representations, the performance of the base tasks are also improved.","Results suggest that the proposed method induces simpler representations that are more compatible with downstream processes."],"url":"http://arxiv.org/abs/2405.10244v1"}
{"created":"2024-05-16 16:46:46","title":"DocuMint: Docstring Generation for Python using Small Language Models","abstract":"Effective communication, specifically through documentation, is the beating heart of collaboration among contributors in software development. Recent advancements in language models (LMs) have enabled the introduction of a new type of actor in that ecosystem: LM-powered assistants capable of code generation, optimization, and maintenance. Our study investigates the efficacy of small language models (SLMs) for generating high-quality docstrings by assessing accuracy, conciseness, and clarity, benchmarking performance quantitatively through mathematical formulas and qualitatively through human evaluation using Likert scale. Further, we introduce DocuMint, as a large-scale supervised fine-tuning dataset with 100,000 samples. In quantitative experiments, Llama 3 8B achieved the best performance across all metrics, with conciseness and clarity scores of 0.605 and 64.88, respectively. However, under human evaluation, CodeGemma 7B achieved the highest overall score with an average of 8.3 out of 10 across all metrics. Fine-tuning the CodeGemma 2B model using the DocuMint dataset led to significant improvements in performance across all metrics, with gains of up to 22.5% in conciseness. The fine-tuned model and the dataset can be found in HuggingFace and the code can be found in the repository.","sentences":["Effective communication, specifically through documentation, is the beating heart of collaboration among contributors in software development.","Recent advancements in language models (LMs) have enabled the introduction of a new type of actor in that ecosystem: LM-powered assistants capable of code generation, optimization, and maintenance.","Our study investigates the efficacy of small language models (SLMs) for generating high-quality docstrings by assessing accuracy, conciseness, and clarity, benchmarking performance quantitatively through mathematical formulas and qualitatively through human evaluation using Likert scale.","Further, we introduce DocuMint, as a large-scale supervised fine-tuning dataset with 100,000 samples.","In quantitative experiments, Llama 3 8B achieved the best performance across all metrics, with conciseness and clarity scores of 0.605 and 64.88, respectively.","However, under human evaluation, CodeGemma 7B achieved the highest overall score with an average of 8.3 out of 10 across all metrics.","Fine-tuning the CodeGemma 2B model using the DocuMint dataset led to significant improvements in performance across all metrics, with gains of up to 22.5% in conciseness.","The fine-tuned model and the dataset can be found in HuggingFace and the code can be found in the repository."],"url":"http://arxiv.org/abs/2405.10243v1"}
{"created":"2024-05-16 16:38:56","title":"Rounding Large Independent Sets on Expanders","abstract":"We develop a new approach for approximating large independent sets when the input graph is a one-sided spectral expander - that is, the uniform random walk matrix of the graph has the second eigenvalue bounded away from 1. Consequently, we obtain a polynomial time algorithm to find linear-sized independent sets in one-sided expanders that are almost $3$-colorable or are promised to contain an independent set of size $(1/2-\\epsilon)n$. Our second result above can be refined to require only a weaker vertex expansion property with an efficient certificate. Somewhat surprisingly, we observe that the analogous task of finding a linear-sized independent set in almost $4$-colorable one-sided expanders (even when the second eigenvalue is $o_n(1)$) is NP-hard, assuming the Unique Games Conjecture.   All prior algorithms that beat the worst-case guarantees for this problem rely on bottom eigenspace enumeration techniques (following the classical spectral methods of Alon and Kahale) and require two-sided expansion, meaning a bounded number of negative eigenvalues of magnitude $\\Omega(1)$. Such techniques naturally extend to almost $k$-colorable graphs for any constant $k$, in contrast to analogous guarantees on one-sided expanders, which are Unique Games-hard to achieve for $k \\geq 4$.   Our rounding builds on the method of simulating multiple samples from a pseudodistribution introduced by Barak et. al. for rounding Unique Games instances. The key to our analysis is a new clustering property of large independent sets in expanding graphs - every large independent set has a larger-than-expected intersection with some member of a small list - and its formalization in the low-degree sum-of-squares proof system.","sentences":["We develop a new approach for approximating large independent sets when the input graph is a one-sided spectral expander - that is, the uniform random walk matrix of the graph has the second eigenvalue bounded away from 1.","Consequently, we obtain a polynomial time algorithm to find linear-sized independent sets in one-sided expanders that are almost $3$-colorable or are promised to contain an independent set of size $(1/2-\\epsilon)n$. Our second result above can be refined to require only a weaker vertex expansion property with an efficient certificate.","Somewhat surprisingly, we observe that the analogous task of finding a linear-sized independent set in almost $4$-colorable one-sided expanders (even when the second eigenvalue is $o_n(1)$) is NP-hard, assuming the Unique Games Conjecture.   ","All prior algorithms that beat the worst-case guarantees for this problem rely on bottom eigenspace enumeration techniques (following the classical spectral methods of Alon and Kahale) and require two-sided expansion, meaning a bounded number of negative eigenvalues of magnitude $\\Omega(1)$. Such techniques naturally extend to almost $k$-colorable graphs for any constant $k$, in contrast to analogous guarantees on one-sided expanders, which are Unique Games-hard to achieve for $k \\geq 4$.   ","Our rounding builds on the method of simulating multiple samples from a pseudodistribution introduced by Barak et.","al. for rounding Unique Games instances.","The key to our analysis is a new clustering property of large independent sets in expanding graphs - every large independent set has a larger-than-expected intersection with some member of a small list - and its formalization in the low-degree sum-of-squares proof system."],"url":"http://arxiv.org/abs/2405.10238v1"}
{"created":"2024-05-16 16:36:16","title":"Novel Data Models for Inter-operable LCA Frameworks","abstract":"Life cycle assessment (LCA) plays a critical role in assessing the environmental impacts of a product, technology, or service throughout its entire life cycle. Nonetheless, many existing LCA tools and methods lack adequate metadata management, which can hinder their further development and wide adoption. In the example of LCA for clean energy technologies, metadata helps monitor data and the environment that holds the integrity of the energy assets and sustainability of the materials sources across their entire value chains. Ontologizing metadata, i.e. a common vocabulary and language to connect multiple data sources, as well as implementing AI-aware data management, can have long-lasting, positive, and accelerating effects along with collecting and utilizing quality data from different sources and across the entire data lifecycle. The integration of ontologies in life cycle assessments has garnered significant attention in recent years. We synthesized the existing literature on ontologies for LCAs, providing insights into this interdisciplinary field's evolution, current state, and future directions. We also proposed the framework for a suitable data model and the workflow thereof to warrant the alignment with existing ontologies, practical frameworks, and industry standards.","sentences":["Life cycle assessment (LCA) plays a critical role in assessing the environmental impacts of a product, technology, or service throughout its entire life cycle.","Nonetheless, many existing LCA tools and methods lack adequate metadata management, which can hinder their further development and wide adoption.","In the example of LCA for clean energy technologies, metadata helps monitor data and the environment that holds the integrity of the energy assets and sustainability of the materials sources across their entire value chains.","Ontologizing metadata, i.e. a common vocabulary and language to connect multiple data sources, as well as implementing AI-aware data management, can have long-lasting, positive, and accelerating effects along with collecting and utilizing quality data from different sources and across the entire data lifecycle.","The integration of ontologies in life cycle assessments has garnered significant attention in recent years.","We synthesized the existing literature on ontologies for LCAs, providing insights into this interdisciplinary field's evolution, current state, and future directions.","We also proposed the framework for a suitable data model and the workflow thereof to warrant the alignment with existing ontologies, practical frameworks, and industry standards."],"url":"http://arxiv.org/abs/2405.10235v1"}
{"created":"2024-05-16 16:34:03","title":"iDRAMA-Scored-2024: A Dataset of the Scored Social Media Platform from 2020 to 2023","abstract":"Online web communities often face bans for violating platform policies, encouraging their migration to alternative platforms. This migration, however, can result in increased toxicity and unforeseen consequences on the new platform. In recent years, researchers have collected data from many alternative platforms, indicating coordinated efforts leading to offline events, conspiracy movements, hate speech propagation, and harassment. Thus, it becomes crucial to characterize and understand these alternative platforms. To advance research in this direction, we collect and release a large-scale dataset from Scored -- an alternative Reddit platform that sheltered banned fringe communities, for example, c/TheDonald (a prominent right-wing community) and c/GreatAwakening (a conspiratorial community). Over four years, we collected approximately 57M posts from Scored, with at least 58 communities identified as migrating from Reddit and over 950 communities created since the platform's inception. Furthermore, we provide sentence embeddings of all posts in our dataset, generated through a state-of-the-art model, to further advance the field in characterizing the discussions within these communities. We aim to provide these resources to facilitate their investigations without the need for extensive data collection and processing efforts.","sentences":["Online web communities often face bans for violating platform policies, encouraging their migration to alternative platforms.","This migration, however, can result in increased toxicity and unforeseen consequences on the new platform.","In recent years, researchers have collected data from many alternative platforms, indicating coordinated efforts leading to offline events, conspiracy movements, hate speech propagation, and harassment.","Thus, it becomes crucial to characterize and understand these alternative platforms.","To advance research in this direction, we collect and release a large-scale dataset from Scored -- an alternative Reddit platform that sheltered banned fringe communities, for example, c/TheDonald (a prominent right-wing community) and c/GreatAwakening (a conspiratorial community).","Over four years, we collected approximately 57M posts from Scored, with at least 58 communities identified as migrating from Reddit and over 950 communities created since the platform's inception.","Furthermore, we provide sentence embeddings of all posts in our dataset, generated through a state-of-the-art model, to further advance the field in characterizing the discussions within these communities.","We aim to provide these resources to facilitate their investigations without the need for extensive data collection and processing efforts."],"url":"http://arxiv.org/abs/2405.10233v1"}
{"created":"2024-05-16 16:33:34","title":"Beyond Static Calibration: The Impact of User Preference Dynamics on Calibrated Recommendation","abstract":"Calibration in recommender systems is an important performance criterion that ensures consistency between the distribution of user preference categories and that of recommendations generated by the system. Standard methods for mitigating miscalibration typically assume that user preference profiles are static, and they measure calibration relative to the full history of user's interactions, including possibly outdated and stale preference categories. We conjecture that this approach can lead to recommendations that, while appearing calibrated, in fact, distort users' true preferences. In this paper, we conduct a preliminary investigation of recommendation calibration at a more granular level, taking into account evolving user preferences. By analyzing differently sized training time windows from the most recent interactions to the oldest, we identify the most relevant segment of user's preferences that optimizes the calibration metric. We perform an exploratory analysis with datasets from different domains with distinctive user-interaction characteristics. We demonstrate how the evolving nature of user preferences affects recommendation calibration, and how this effect is manifested differently depending on the characteristics of the data in a given domain. Datasets, codes, and more detailed experimental results are available at: https://github.com/nicolelin13/DynamicCalibrationUMAP.","sentences":["Calibration in recommender systems is an important performance criterion that ensures consistency between the distribution of user preference categories and that of recommendations generated by the system.","Standard methods for mitigating miscalibration typically assume that user preference profiles are static, and they measure calibration relative to the full history of user's interactions, including possibly outdated and stale preference categories.","We conjecture that this approach can lead to recommendations that, while appearing calibrated, in fact, distort users' true preferences.","In this paper, we conduct a preliminary investigation of recommendation calibration at a more granular level, taking into account evolving user preferences.","By analyzing differently sized training time windows from the most recent interactions to the oldest, we identify the most relevant segment of user's preferences that optimizes the calibration metric.","We perform an exploratory analysis with datasets from different domains with distinctive user-interaction characteristics.","We demonstrate how the evolving nature of user preferences affects recommendation calibration, and how this effect is manifested differently depending on the characteristics of the data in a given domain.","Datasets, codes, and more detailed experimental results are available at: https://github.com/nicolelin13/DynamicCalibrationUMAP."],"url":"http://arxiv.org/abs/2405.10232v1"}
{"created":"2024-05-16 16:18:35","title":"GDPR: Is it worth it? Perceptions of workers who have experienced its implementation","abstract":"The General Data Protection Regulation (GDPR) remains the gold standard in privacy and security regulation. We investigate how the cost and effort required to implement GDPR is viewed by workers who have also experienced the regulations' benefits as citizens: is it worth it? In a multi-stage study, we survey N = 273 & 102 individuals who remained working in the same companies before, during, and after the implementation of GDPR. The survey finds that participants recognise their rights when prompted but know little about their regulator. They have observed concrete changes to data practices in their workplaces and appreciate the trade-offs. They take comfort that their personal data is handled as carefully as their employers' client data. The very people who comply with and execute the GDPR consider it to be positive for their company, positive for privacy and not a pointless, bureaucratic regulation. This is rare as it contradicts the conventional negative narrative about regulation. Policymakers may wish to build upon this public support while it lasts and consider early feedback from a similar dual professional-consumer group as the GDPR evolves.","sentences":["The General Data Protection Regulation (GDPR) remains the gold standard in privacy and security regulation.","We investigate how the cost and effort required to implement GDPR is viewed by workers who have also experienced the regulations' benefits as citizens: is it worth it?","In a multi-stage study, we survey N = 273 & 102 individuals who remained working in the same companies before, during, and after the implementation of GDPR.","The survey finds that participants recognise their rights when prompted but know little about their regulator.","They have observed concrete changes to data practices in their workplaces and appreciate the trade-offs.","They take comfort that their personal data is handled as carefully as their employers' client data.","The very people who comply with and execute the GDPR consider it to be positive for their company, positive for privacy and not a pointless, bureaucratic regulation.","This is rare as it contradicts the conventional negative narrative about regulation.","Policymakers may wish to build upon this public support while it lasts and consider early feedback from a similar dual professional-consumer group as the GDPR evolves."],"url":"http://arxiv.org/abs/2405.10225v1"}
{"created":"2024-05-16 16:10:41","title":"SoK: Prudent Evaluation Practices for Fuzzing","abstract":"Fuzzing has proven to be a highly effective approach to uncover software bugs over the past decade. After AFL popularized the groundbreaking concept of lightweight coverage feedback, the field of fuzzing has seen a vast amount of scientific work proposing new techniques, improving methodological aspects of existing strategies, or porting existing methods to new domains. All such work must demonstrate its merit by showing its applicability to a problem, measuring its performance, and often showing its superiority over existing works in a thorough, empirical evaluation. Yet, fuzzing is highly sensitive to its target, environment, and circumstances, e.g., randomness in the testing process. After all, relying on randomness is one of the core principles of fuzzing, governing many aspects of a fuzzer's behavior. Combined with the often highly difficult to control environment, the reproducibility of experiments is a crucial concern and requires a prudent evaluation setup. To address these threats to validity, several works, most notably Evaluating Fuzz Testing by Klees et al., have outlined how a carefully designed evaluation setup should be implemented, but it remains unknown to what extent their recommendations have been adopted in practice. In this work, we systematically analyze the evaluation of 150 fuzzing papers published at the top venues between 2018 and 2023. We study how existing guidelines are implemented and observe potential shortcomings and pitfalls. We find a surprising disregard of the existing guidelines regarding statistical tests and systematic errors in fuzzing evaluations. For example, when investigating reported bugs, ...","sentences":["Fuzzing has proven to be a highly effective approach to uncover software bugs over the past decade.","After AFL popularized the groundbreaking concept of lightweight coverage feedback, the field of fuzzing has seen a vast amount of scientific work proposing new techniques, improving methodological aspects of existing strategies, or porting existing methods to new domains.","All such work must demonstrate its merit by showing its applicability to a problem, measuring its performance, and often showing its superiority over existing works in a thorough, empirical evaluation.","Yet, fuzzing is highly sensitive to its target, environment, and circumstances, e.g., randomness in the testing process.","After all, relying on randomness is one of the core principles of fuzzing, governing many aspects of a fuzzer's behavior.","Combined with the often highly difficult to control environment, the reproducibility of experiments is a crucial concern and requires a prudent evaluation setup.","To address these threats to validity, several works, most notably Evaluating Fuzz Testing by Klees et al., have outlined how a carefully designed evaluation setup should be implemented, but it remains unknown to what extent their recommendations have been adopted in practice.","In this work, we systematically analyze the evaluation of 150 fuzzing papers published at the top venues between 2018 and 2023.","We study how existing guidelines are implemented and observe potential shortcomings and pitfalls.","We find a surprising disregard of the existing guidelines regarding statistical tests and systematic errors in fuzzing evaluations.","For example, when investigating reported bugs, ..."],"url":"http://arxiv.org/abs/2405.10220v1"}
{"created":"2024-05-16 16:08:49","title":"ENADPool: The Edge-Node Attention-based Differentiable Pooling for Graph Neural Networks","abstract":"Graph Neural Networks (GNNs) are powerful tools for graph classification. One important operation for GNNs is the downsampling or pooling that can learn effective embeddings from the node representations. In this paper, we propose a new hierarchical pooling operation, namely the Edge-Node Attention-based Differentiable Pooling (ENADPool), for GNNs to learn effective graph representations. Unlike the classical hierarchical pooling operation that is based on the unclear node assignment and simply computes the averaged feature over the nodes of each cluster, the proposed ENADPool not only employs a hard clustering strategy to assign each node into an unique cluster, but also compress the node features as well as their edge connectivity strengths into the resulting hierarchical structure based on the attention mechanism after each pooling step. As a result, the proposed ENADPool simultaneously identifies the importance of different nodes within each separated cluster and edges between corresponding clusters, that significantly addresses the shortcomings of the uniform edge-node based structure information aggregation arising in the classical hierarchical pooling operation. Moreover, to mitigate the over-smoothing problem arising in existing GNNs, we propose a Multi-distance GNN (MD-GNN) model associated with the proposed ENADPool operation, allowing the nodes to actively and directly receive the feature information from neighbors at different random walk steps. Experiments demonstrate the effectiveness of the MD-GNN associated with the proposed ENADPool.","sentences":["Graph Neural Networks (GNNs) are powerful tools for graph classification.","One important operation for GNNs is the downsampling or pooling that can learn effective embeddings from the node representations.","In this paper, we propose a new hierarchical pooling operation, namely the Edge-Node Attention-based Differentiable Pooling (ENADPool), for GNNs to learn effective graph representations.","Unlike the classical hierarchical pooling operation that is based on the unclear node assignment and simply computes the averaged feature over the nodes of each cluster, the proposed ENADPool not only employs a hard clustering strategy to assign each node into an unique cluster, but also compress the node features as well as their edge connectivity strengths into the resulting hierarchical structure based on the attention mechanism after each pooling step.","As a result, the proposed ENADPool simultaneously identifies the importance of different nodes within each separated cluster and edges between corresponding clusters, that significantly addresses the shortcomings of the uniform edge-node based structure information aggregation arising in the classical hierarchical pooling operation.","Moreover, to mitigate the over-smoothing problem arising in existing GNNs, we propose a Multi-distance GNN (MD-GNN) model associated with the proposed ENADPool operation, allowing the nodes to actively and directly receive the feature information from neighbors at different random walk steps.","Experiments demonstrate the effectiveness of the MD-GNN associated with the proposed ENADPool."],"url":"http://arxiv.org/abs/2405.10218v1"}
{"created":"2024-05-16 16:05:33","title":"Low-Rank Adaptation of Time Series Foundational Models for Out-of-Domain Modality Forecasting","abstract":"Low-Rank Adaptation (LoRA) is a widely used technique for fine-tuning large pre-trained or foundational models across different modalities and tasks. However, its application to time series data, particularly within foundational models, remains underexplored. This paper examines the impact of LoRA on contemporary time series foundational models: Lag-Llama, MOIRAI, and Chronos. We demonstrate LoRA's fine-tuning potential for forecasting the vital signs of sepsis patients in intensive care units (ICUs), emphasizing the models' adaptability to previously unseen, out-of-domain modalities. Integrating LoRA aims to enhance forecasting performance while reducing inefficiencies associated with fine-tuning large models on limited domain-specific data. Our experiments show that LoRA fine-tuning of time series foundational models significantly improves forecasting, achieving results comparable to state-of-the-art models trained from scratch on similar modalities. We conduct comprehensive ablation studies to demonstrate the trade-offs between the number of tunable parameters and forecasting performance and assess the impact of varying LoRA matrix ranks on model performance.","sentences":["Low-Rank Adaptation (LoRA) is a widely used technique for fine-tuning large pre-trained or foundational models across different modalities and tasks.","However, its application to time series data, particularly within foundational models, remains underexplored.","This paper examines the impact of LoRA on contemporary time series foundational models: Lag-Llama, MOIRAI, and Chronos.","We demonstrate LoRA's fine-tuning potential for forecasting the vital signs of sepsis patients in intensive care units (ICUs), emphasizing the models' adaptability to previously unseen, out-of-domain modalities.","Integrating LoRA aims to enhance forecasting performance while reducing inefficiencies associated with fine-tuning large models on limited domain-specific data.","Our experiments show that LoRA fine-tuning of time series foundational models significantly improves forecasting, achieving results comparable to state-of-the-art models trained from scratch on similar modalities.","We conduct comprehensive ablation studies to demonstrate the trade-offs between the number of tunable parameters and forecasting performance and assess the impact of varying LoRA matrix ranks on model performance."],"url":"http://arxiv.org/abs/2405.10216v1"}
{"created":"2024-05-16 16:05:21","title":"SMLP: Symbolic Machine Learning Prover (User Manual)","abstract":"SMLP: Symbolic Machine Learning Prover an open source tool for exploration and optimization of systems represented by machine learning models. SMLP uses symbolic reasoning for ML model exploration and optimization under verification and stability constraints, based on SMT, constraint and NN solvers. In addition its exploration methods are guided by probabilistic and statistical methods. SMLP is a general purpose tool that requires only data suitable for ML modelling in the csv format (usually samples of the system's input/output). SMLP has been applied at Intel for analyzing and optimizing hardware designs at the analog level. Currently SMLP supports NNs, polynomial and tree models, and uses SMT solvers for reasoning and optimization at the backend, integration of specialized NN solvers is in progress.","sentences":["SMLP:","Symbolic Machine Learning Prover an open source tool for exploration and optimization of systems represented by machine learning models.","SMLP uses symbolic reasoning for ML model exploration and optimization under verification and stability constraints, based on SMT, constraint and NN solvers.","In addition its exploration methods are guided by probabilistic and statistical methods.","SMLP is a general purpose tool that requires only data suitable for ML modelling in the csv format (usually samples of the system's input/output).","SMLP has been applied at Intel for analyzing and optimizing hardware designs at the analog level.","Currently SMLP supports NNs, polynomial and tree models, and uses SMT solvers for reasoning and optimization at the backend, integration of specialized NN solvers is in progress."],"url":"http://arxiv.org/abs/2405.10215v1"}
{"created":"2024-05-16 16:04:20","title":"A Design Trajectory Map of Human-AI Collaborative Reinforcement Learning Systems: Survey and Taxonomy","abstract":"Driven by the algorithmic advancements in reinforcement learning and the increasing number of implementations of human-AI collaboration, Collaborative Reinforcement Learning (CRL) has been receiving growing attention. Despite this recent upsurge, this area is still rarely systematically studied. In this paper, we provide an extensive survey, investigating CRL methods based on both interactive reinforcement learning algorithms and human-AI collaborative frameworks that were proposed in the past decade. We elucidate and discuss via synergistic analysis methods both the growth of the field and the state-of-the-art; we conceptualise the existing frameworks from the perspectives of design patterns, collaborative levels, parties and capabilities, and review interactive methods and algorithmic models. Specifically, we create a new Human-AI CRL Design Trajectory Map, as a systematic modelling tool for the selection of existing CRL frameworks, as well as a method of designing new CRL systems, and finally of improving future CRL designs. Furthermore, we elaborate generic Human-AI CRL challenges, providing the research community with a guide towards novel research directions. The aim of this paper is to empower researchers with a systematic framework for the design of efficient and 'natural' human-AI collaborative methods, making it possible to work on maximised realisation of humans' and AI's potentials.","sentences":["Driven by the algorithmic advancements in reinforcement learning and the increasing number of implementations of human-AI collaboration, Collaborative Reinforcement Learning (CRL) has been receiving growing attention.","Despite this recent upsurge, this area is still rarely systematically studied.","In this paper, we provide an extensive survey, investigating CRL methods based on both interactive reinforcement learning algorithms and human-AI collaborative frameworks that were proposed in the past decade.","We elucidate and discuss via synergistic analysis methods both the growth of the field and the state-of-the-art; we conceptualise the existing frameworks from the perspectives of design patterns, collaborative levels, parties and capabilities, and review interactive methods and algorithmic models.","Specifically, we create a new Human-AI CRL Design Trajectory Map, as a systematic modelling tool for the selection of existing CRL frameworks, as well as a method of designing new CRL systems, and finally of improving future CRL designs.","Furthermore, we elaborate generic Human-AI CRL challenges, providing the research community with a guide towards novel research directions.","The aim of this paper is to empower researchers with a systematic framework for the design of efficient and 'natural' human-AI collaborative methods, making it possible to work on maximised realisation of humans' and AI's potentials."],"url":"http://arxiv.org/abs/2405.10214v1"}
{"created":"2024-05-16 16:02:42","title":"Words as Trigger Points in Social Media Discussions","abstract":"Trigger points are a concept introduced by Mau, Lux, and Westheuser (2023) to study qualitative focus group interviews and understand polarisation in Germany. When people communicate, trigger points represent moments when individuals feel that their understanding of what is fair, normal, or appropriate in society is questioned. In the original studies, individuals react affectively to such triggers and show strong and negative emotional responses. In this paper, we introduce the first systematic study of the large-scale effect of individual words as trigger points by analysing a large amount of social media posts. We examine online deliberations on Reddit between 2020 and 2022 and collect >100 million posts from subreddits related to a set of words identified as trigger points in UK politics. We find that such trigger words affect user engagement and have noticeable consequences on animosity in online discussions. We share empirical evidence of trigger words causing animosity, and how they provide incentives for hate speech, adversarial debates, and disagreements. Our work is the first to introduce trigger points to computational studies of online communication. Our findings are relevant to researchers interested in online harms and who examine how citizens debate politics and society in light of affective polarisation.","sentences":["Trigger points are a concept introduced by Mau, Lux, and Westheuser (2023) to study qualitative focus group interviews and understand polarisation in Germany.","When people communicate, trigger points represent moments when individuals feel that their understanding of what is fair, normal, or appropriate in society is questioned.","In the original studies, individuals react affectively to such triggers and show strong and negative emotional responses.","In this paper, we introduce the first systematic study of the large-scale effect of individual words as trigger points by analysing a large amount of social media posts.","We examine online deliberations on Reddit between 2020 and 2022 and collect >100 million posts from subreddits related to a set of words identified as trigger points in UK politics.","We find that such trigger words affect user engagement and have noticeable consequences on animosity in online discussions.","We share empirical evidence of trigger words causing animosity, and how they provide incentives for hate speech, adversarial debates, and disagreements.","Our work is the first to introduce trigger points to computational studies of online communication.","Our findings are relevant to researchers interested in online harms and who examine how citizens debate politics and society in light of affective polarisation."],"url":"http://arxiv.org/abs/2405.10213v1"}
{"created":"2024-05-16 16:02:18","title":"CPsyExam: A Chinese Benchmark for Evaluating Psychology using Examinations","abstract":"In this paper, we introduce a novel psychological benchmark, CPsyExam, constructed from questions sourced from Chinese language examinations. CPsyExam is designed to prioritize psychological knowledge and case analysis separately, recognizing the significance of applying psychological knowledge to real-world scenarios. From the pool of 22k questions, we utilize 4k to create the benchmark that offers balanced coverage of subjects and incorporates a diverse range of case analysis techniques.Furthermore, we evaluate a range of existing large language models~(LLMs), spanning from open-sourced to API-based models. Our experiments and analysis demonstrate that CPsyExam serves as an effective benchmark for enhancing the understanding of psychology within LLMs and enables the comparison of LLMs across various granularities.","sentences":["In this paper, we introduce a novel psychological benchmark, CPsyExam, constructed from questions sourced from Chinese language examinations.","CPsyExam is designed to prioritize psychological knowledge and case analysis separately, recognizing the significance of applying psychological knowledge to real-world scenarios.","From the pool of 22k questions, we utilize 4k to create the benchmark that offers balanced coverage of subjects and incorporates a diverse range of case analysis techniques.","Furthermore, we evaluate a range of existing large language models~(LLMs), spanning from open-sourced to API-based models.","Our experiments and analysis demonstrate that CPsyExam serves as an effective benchmark for enhancing the understanding of psychology within LLMs and enables the comparison of LLMs across various granularities."],"url":"http://arxiv.org/abs/2405.10212v1"}
{"created":"2024-05-16 16:00:47","title":"Building a Luganda Text-to-Speech Model From Crowdsourced Data","abstract":"Text-to-speech (TTS) development for African languages such as Luganda is still limited, primarily due to the scarcity of high-quality, single-speaker recordings essential for training TTS models. Prior work has focused on utilizing the Luganda Common Voice recordings of multiple speakers aged between 20-49. Although the generated speech is intelligible, it is still of lower quality than the model trained on studio-grade recordings. This is due to the insufficient data preprocessing methods applied to improve the quality of the Common Voice recordings. Furthermore, speech convergence is more difficult to achieve due to varying intonations, as well as background noise. In this paper, we show that the quality of Luganda TTS from Common Voice can improve by training on multiple speakers of close intonation in addition to further preprocessing of the training data. Specifically, we selected six female speakers with close intonation determined by subjectively listening and comparing their voice recordings. In addition to trimming out silent portions from the beginning and end of the recordings, we applied a pre-trained speech enhancement model to reduce background noise and enhance audio quality. We also utilized a pre-trained, non-intrusive, self-supervised Mean Opinion Score (MOS) estimation model to filter recordings with an estimated MOS over 3.5, indicating high perceived quality. Subjective MOS evaluations from nine native Luganda speakers demonstrate that our TTS model achieves a significantly better MOS of 3.55 compared to the reported 2.5 MOS of the existing model. Moreover, for a fair comparison, our model trained on six speakers outperforms models trained on a single-speaker (3.13 MOS) or two speakers (3.22 MOS). This showcases the effectiveness of compensating for the lack of data from one speaker with data from multiple speakers of close intonation to improve TTS quality.","sentences":["Text-to-speech (TTS) development for African languages such as Luganda is still limited, primarily due to the scarcity of high-quality, single-speaker recordings essential for training TTS models.","Prior work has focused on utilizing the Luganda Common Voice recordings of multiple speakers aged between 20-49.","Although the generated speech is intelligible, it is still of lower quality than the model trained on studio-grade recordings.","This is due to the insufficient data preprocessing methods applied to improve the quality of the Common Voice recordings.","Furthermore, speech convergence is more difficult to achieve due to varying intonations, as well as background noise.","In this paper, we show that the quality of Luganda TTS from Common Voice can improve by training on multiple speakers of close intonation in addition to further preprocessing of the training data.","Specifically, we selected six female speakers with close intonation determined by subjectively listening and comparing their voice recordings.","In addition to trimming out silent portions from the beginning and end of the recordings, we applied a pre-trained speech enhancement model to reduce background noise and enhance audio quality.","We also utilized a pre-trained, non-intrusive, self-supervised Mean Opinion Score (MOS) estimation model to filter recordings with an estimated MOS over 3.5, indicating high perceived quality.","Subjective MOS evaluations from nine native Luganda speakers demonstrate that our TTS model achieves a significantly better MOS of 3.55 compared to the reported 2.5 MOS of the existing model.","Moreover, for a fair comparison, our model trained on six speakers outperforms models trained on a single-speaker (3.13 MOS) or two speakers (3.22 MOS).","This showcases the effectiveness of compensating for the lack of data from one speaker with data from multiple speakers of close intonation to improve TTS quality."],"url":"http://arxiv.org/abs/2405.10211v1"}
{"created":"2024-05-16 16:00:35","title":"GPT Store Mining and Analysis","abstract":"As a pivotal extension of the renowned ChatGPT, the GPT Store serves as a dynamic marketplace for various Generative Pre-trained Transformer (GPT) models, shaping the frontier of conversational AI. This paper presents an in-depth measurement study of the GPT Store, with a focus on the categorization of GPTs by topic, factors influencing GPT popularity, and the potential security risks. Our investigation starts with assessing the categorization of GPTs in the GPT Store, analyzing how they are organized by topics, and evaluating the effectiveness of the classification system. We then examine the factors that affect the popularity of specific GPTs, looking into user preferences, algorithmic influences, and market trends. Finally, the study delves into the security risks of the GPT Store, identifying potential threats and evaluating the robustness of existing security measures. This study offers a detailed overview of the GPT Store's current state, shedding light on its operational dynamics and user interaction patterns. Our findings aim to enhance understanding of the GPT ecosystem, providing valuable insights for future research, development, and policy-making in generative AI.","sentences":["As a pivotal extension of the renowned ChatGPT, the GPT Store serves as a dynamic marketplace for various Generative Pre-trained Transformer (GPT) models, shaping the frontier of conversational AI.","This paper presents an in-depth measurement study of the GPT Store, with a focus on the categorization of GPTs by topic, factors influencing GPT popularity, and the potential security risks.","Our investigation starts with assessing the categorization of GPTs in the GPT Store, analyzing how they are organized by topics, and evaluating the effectiveness of the classification system.","We then examine the factors that affect the popularity of specific GPTs, looking into user preferences, algorithmic influences, and market trends.","Finally, the study delves into the security risks of the GPT Store, identifying potential threats and evaluating the robustness of existing security measures.","This study offers a detailed overview of the GPT Store's current state, shedding light on its operational dynamics and user interaction patterns.","Our findings aim to enhance understanding of the GPT ecosystem, providing valuable insights for future research, development, and policy-making in generative AI."],"url":"http://arxiv.org/abs/2405.10210v1"}
{"created":"2024-05-16 15:59:29","title":"How To Save A World: The Go-Along Interview as Game Preservation Methodology in Wurm Online","abstract":"Massively multiplayer online (MMO) games boomed in the late 1990s to 2000s. In parallel, ethnographic studies of these communities emerged, generally involving participant observation and interviews. Several decades on, many MMOs have been reconfigured, remastered or are potentially no longer accessible at all, which presents challenges for their continued study and long-term preservation. In this paper we explore the \"go-along\" methodology, in which a researcher joins a participant on a walk through a familiar place and asks them questions, as a qualitative research method applicable for the study and preservation of games culture. Though the methodology has been introduced in digital media studies, to date it has had limited application in digital games, if at all. We report on a pilot study exploring applications of the go-along method to the sandbox MMO Wurm Online; a persistent, player-directed world with a rich history. We report on our motivations for the work, our analysis of the resulting interviews, and our reflections on both the use of go-alongs in digital games, as well as the unique and inspiring culture and community of this lesser-known game.","sentences":["Massively multiplayer online (MMO) games boomed in the late 1990s to 2000s.","In parallel, ethnographic studies of these communities emerged, generally involving participant observation and interviews.","Several decades on, many MMOs have been reconfigured, remastered or are potentially no longer accessible at all, which presents challenges for their continued study and long-term preservation.","In this paper we explore the \"go-along\" methodology, in which a researcher joins a participant on a walk through a familiar place and asks them questions, as a qualitative research method applicable for the study and preservation of games culture.","Though the methodology has been introduced in digital media studies, to date it has had limited application in digital games, if at all.","We report on a pilot study exploring applications of the go-along method to the sandbox MMO Wurm Online; a persistent, player-directed world with a rich history.","We report on our motivations for the work, our analysis of the resulting interviews, and our reflections on both the use of go-alongs in digital games, as well as the unique and inspiring culture and community of this lesser-known game."],"url":"http://arxiv.org/abs/2405.10208v1"}
{"created":"2024-05-16 15:51:54","title":"A Participatory Budgeting based Truthful Budget-Limited Incentive Mechanism for Time-Constrained Tasks in Crowdsensing Systems","abstract":"Crowdsensing, also known as participatory sensing, is a method of data collection that involves gathering information from a large number of common people (or individuals), often using mobile devices or other personal technologies. This paper considers the set-up with multiple task requesters and several task executors in a strategic setting. Each task requester has multiple heterogeneous tasks and an estimated budget for the tasks. In our proposed model, the Government has a publicly known fund (or budget) and is limited. Due to limited funds, it may not be possible for the platform to offer the funds to all the available task requesters. For that purpose, in the first tier, the voting by the city dwellers over the task requesters is carried out to decide on the subset of task requesters receiving the Government fund. In the second tier, each task of the task requesters has start and finish times. Based on that, firstly, the tasks are distributed to distinct slots. In each slot, we have multiple task executors for executing the floated tasks. Each task executor reports a cost (private) for completing the floated task(s). Given the above-discussed set-up, the objectives of the second tier are: (1) to schedule each task of the task requesters in the available slots in a non-conflicting manner and (2) to select a set of executors for the available tasks in such a way that the total incentive given to the task executors should be at most the budget for the tasks. For the discussed scenario, a truthful incentive based mechanism is designed that also takes care of budget criteria. Theoretical analysis is done, and it shows that the proposed mechanism is computationally efficient, truthful, budget-feasible, and individually rational. The simulation is carried out, and the efficacy of the designed mechanism is compared with the state-of-the-art mechanisms.","sentences":["Crowdsensing, also known as participatory sensing, is a method of data collection that involves gathering information from a large number of common people (or individuals), often using mobile devices or other personal technologies.","This paper considers the set-up with multiple task requesters and several task executors in a strategic setting.","Each task requester has multiple heterogeneous tasks and an estimated budget for the tasks.","In our proposed model, the Government has a publicly known fund (or budget) and is limited.","Due to limited funds, it may not be possible for the platform to offer the funds to all the available task requesters.","For that purpose, in the first tier, the voting by the city dwellers over the task requesters is carried out to decide on the subset of task requesters receiving the Government fund.","In the second tier, each task of the task requesters has start and finish times.","Based on that, firstly, the tasks are distributed to distinct slots.","In each slot, we have multiple task executors for executing the floated tasks.","Each task executor reports a cost (private) for completing the floated task(s).","Given the above-discussed set-up, the objectives of the second tier are: (1) to schedule each task of the task requesters in the available slots in a non-conflicting manner and (2) to select a set of executors for the available tasks in such a way that the total incentive given to the task executors should be at most the budget for the tasks.","For the discussed scenario, a truthful incentive based mechanism is designed that also takes care of budget criteria.","Theoretical analysis is done, and it shows that the proposed mechanism is computationally efficient, truthful, budget-feasible, and individually rational.","The simulation is carried out, and the efficacy of the designed mechanism is compared with the state-of-the-art mechanisms."],"url":"http://arxiv.org/abs/2405.10206v1"}
{"created":"2024-05-16 15:51:28","title":"\"The Death of Wikipedia?\" -- Exploring the Impact of ChatGPT on Wikipedia Engagement","abstract":"Wikipedia is one of the most popular websites in the world, serving as a major source of information and learning resource for millions of users worldwide. While motivations for its usage vary, prior research suggests shallow information gathering -- looking up facts and information or answering questions -- dominates over more in-depth usage. On the 22nd of November 2022, ChatGPT was released to the public and has quickly become a popular source of information, serving as an effective question-answering and knowledge gathering resource. Early indications have suggested that it may be drawing users away from traditional question answering services such as Stack Overflow, raising the question of how it may have impacted Wikipedia. In this paper, we explore Wikipedia user metrics across four areas: page views, unique visitor numbers, edit counts and editor numbers within twelve language instances of Wikipedia. We perform pairwise comparisons of these metrics before and after the release of ChatGPT and implement a panel regression model to observe and quantify longer-term trends. We find no evidence of a fall in engagement across any of the four metrics, instead observing that page views and visitor numbers increased in the period following ChatGPT's launch. However, we observe a lower increase in languages where ChatGPT was available than in languages where it was not, which may suggest ChatGPT's availability limited growth in those languages. Our results contribute to the understanding of how emerging generative AI tools are disrupting the Web ecosystem.","sentences":["Wikipedia is one of the most popular websites in the world, serving as a major source of information and learning resource for millions of users worldwide.","While motivations for its usage vary, prior research suggests shallow information gathering -- looking up facts and information or answering questions -- dominates over more in-depth usage.","On the 22nd of November 2022, ChatGPT was released to the public and has quickly become a popular source of information, serving as an effective question-answering and knowledge gathering resource.","Early indications have suggested that it may be drawing users away from traditional question answering services such as Stack Overflow, raising the question of how it may have impacted Wikipedia.","In this paper, we explore Wikipedia user metrics across four areas: page views, unique visitor numbers, edit counts and editor numbers within twelve language instances of Wikipedia.","We perform pairwise comparisons of these metrics before and after the release of ChatGPT and implement a panel regression model to observe and quantify longer-term trends.","We find no evidence of a fall in engagement across any of the four metrics, instead observing that page views and visitor numbers increased in the period following ChatGPT's launch.","However, we observe a lower increase in languages where ChatGPT was available than in languages where it was not, which may suggest ChatGPT's availability limited growth in those languages.","Our results contribute to the understanding of how emerging generative AI tools are disrupting the Web ecosystem."],"url":"http://arxiv.org/abs/2405.10205v1"}
{"created":"2024-05-16 15:46:30","title":"Hierarchical Attention Graph for Scientific Document Summarization in Global and Local Level","abstract":"Scientific document summarization has been a challenging task due to the long structure of the input text. The long input hinders the simultaneous effective modeling of both global high-order relations between sentences and local intra-sentence relations which is the most critical step in extractive summarization. However, existing methods mostly focus on one type of relation, neglecting the simultaneous effective modeling of both relations, which can lead to insufficient learning of semantic representations. In this paper, we propose HAESum, a novel approach utilizing graph neural networks to locally and globally model documents based on their hierarchical discourse structure. First, intra-sentence relations are learned using a local heterogeneous graph. Subsequently, a novel hypergraph self-attention layer is introduced to further enhance the characterization of high-order inter-sentence relations. We validate our approach on two benchmark datasets, and the experimental results demonstrate the effectiveness of HAESum and the importance of considering hierarchical structures in modeling long scientific documents. Our code will be available at \\url{https://github.com/MoLICHENXI/HAESum}","sentences":["Scientific document summarization has been a challenging task due to the long structure of the input text.","The long input hinders the simultaneous effective modeling of both global high-order relations between sentences and local intra-sentence relations which is the most critical step in extractive summarization.","However, existing methods mostly focus on one type of relation, neglecting the simultaneous effective modeling of both relations, which can lead to insufficient learning of semantic representations.","In this paper, we propose HAESum, a novel approach utilizing graph neural networks to locally and globally model documents based on their hierarchical discourse structure.","First, intra-sentence relations are learned using a local heterogeneous graph.","Subsequently, a novel hypergraph self-attention layer is introduced to further enhance the characterization of high-order inter-sentence relations.","We validate our approach on two benchmark datasets, and the experimental results demonstrate the effectiveness of HAESum and the importance of considering hierarchical structures in modeling long scientific documents.","Our code will be available at \\url{https://github.com/MoLICHENXI/HAESum}"],"url":"http://arxiv.org/abs/2405.10202v1"}
{"created":"2024-05-16 15:31:37","title":"Bridging Syntax and Semantics of Lean Expressions in E-Graphs","abstract":"Interactive theorem provers, like Isabelle/HOL, Coq and Lean, have expressive languages that allow the formalization of general mathematical objects and proofs. In this context, an important goal is to reduce the time and effort needed to prove theorems. A significant means of achieving this is by improving proof automation. We have implemented an early prototype of proof automation for equational reasoning in Lean by using equality saturation. To achieve this, we need to bridge the gap between Lean's expression semantics and the syntactically driven e-graphs in equality saturation. This involves handling bound variables, implicit typing, as well as Lean's definitional equality, which is more general than syntactic equality and involves notions like $\\alpha$-equivalence, $\\beta$-reduction, and $\\eta$-reduction. In this extended abstract, we highlight how we attempt to bridge this gap, and which challenges remain to be solved. Notably, while our techniques are partially unsound, the resulting proof automation remains sound by virtue of Lean's proof checking.","sentences":["Interactive theorem provers, like Isabelle/HOL, Coq and Lean, have expressive languages that allow the formalization of general mathematical objects and proofs.","In this context, an important goal is to reduce the time and effort needed to prove theorems.","A significant means of achieving this is by improving proof automation.","We have implemented an early prototype of proof automation for equational reasoning in Lean by using equality saturation.","To achieve this, we need to bridge the gap between Lean's expression semantics and the syntactically driven e-graphs in equality saturation.","This involves handling bound variables, implicit typing, as well as Lean's definitional equality, which is more general than syntactic equality and involves notions like $\\alpha$-equivalence, $\\beta$-reduction, and $\\eta$-reduction.","In this extended abstract, we highlight how we attempt to bridge this gap, and which challenges remain to be solved.","Notably, while our techniques are partially unsound, the resulting proof automation remains sound by virtue of Lean's proof checking."],"url":"http://arxiv.org/abs/2405.10188v1"}
{"created":"2024-05-16 15:31:28","title":"Influence Maximization in Hypergraphs using Multi-Objective Evolutionary Algorithms","abstract":"The Influence Maximization (IM) problem is a well-known NP-hard combinatorial problem over graphs whose goal is to find the set of nodes in a network that spreads influence at most. Among the various methods for solving the IM problem, evolutionary algorithms (EAs) have been shown to be particularly effective. While the literature on the topic is particularly ample, only a few attempts have been made at solving the IM problem over higher-order networks, namely extensions of standard graphs that can capture interactions that involve more than two nodes. Hypergraphs are a valuable tool for modeling complex interaction networks in various domains; however, they require rethinking of several graph-based problems, including IM. In this work, we propose a multi-objective EA for the IM problem over hypergraphs that leverages smart initialization and hypergraph-aware mutation. While the existing methods rely on greedy or heuristic methods, to our best knowledge this is the first attempt at applying EAs to this problem. Our results over nine real-world datasets and three propagation models, compared with five baseline algorithms, reveal that our method achieves in most cases state-of-the-art results in terms of hypervolume and solution diversity.","sentences":["The Influence Maximization (IM) problem is a well-known NP-hard combinatorial problem over graphs whose goal is to find the set of nodes in a network that spreads influence at most.","Among the various methods for solving the IM problem, evolutionary algorithms (EAs) have been shown to be particularly effective.","While the literature on the topic is particularly ample, only a few attempts have been made at solving the IM problem over higher-order networks, namely extensions of standard graphs that can capture interactions that involve more than two nodes.","Hypergraphs are a valuable tool for modeling complex interaction networks in various domains; however, they require rethinking of several graph-based problems, including IM.","In this work, we propose a multi-objective EA for the IM problem over hypergraphs that leverages smart initialization and hypergraph-aware mutation.","While the existing methods rely on greedy or heuristic methods, to our best knowledge this is the first attempt at applying EAs to this problem.","Our results over nine real-world datasets and three propagation models, compared with five baseline algorithms, reveal that our method achieves in most cases state-of-the-art results in terms of hypervolume and solution diversity."],"url":"http://arxiv.org/abs/2405.10187v1"}
{"created":"2024-05-16 15:30:18","title":"DiverGen: Improving Instance Segmentation by Learning Wider Data Distribution with More Diverse Generative Data","abstract":"Instance segmentation is data-hungry, and as model capacity increases, data scale becomes crucial for improving the accuracy. Most instance segmentation datasets today require costly manual annotation, limiting their data scale. Models trained on such data are prone to overfitting on the training set, especially for those rare categories. While recent works have delved into exploiting generative models to create synthetic datasets for data augmentation, these approaches do not efficiently harness the full potential of generative models.   To address these issues, we introduce a more efficient strategy to construct generative datasets for data augmentation, termed DiverGen. Firstly, we provide an explanation of the role of generative data from the perspective of distribution discrepancy. We investigate the impact of different data on the distribution learned by the model. We argue that generative data can expand the data distribution that the model can learn, thus mitigating overfitting. Additionally, we find that the diversity of generative data is crucial for improving model performance and enhance it through various strategies, including category diversity, prompt diversity, and generative model diversity. With these strategies, we can scale the data to millions while maintaining the trend of model performance improvement. On the LVIS dataset, DiverGen significantly outperforms the strong model X-Paste, achieving +1.1 box AP and +1.1 mask AP across all categories, and +1.9 box AP and +2.5 mask AP for rare categories.","sentences":["Instance segmentation is data-hungry, and as model capacity increases, data scale becomes crucial for improving the accuracy.","Most instance segmentation datasets today require costly manual annotation, limiting their data scale.","Models trained on such data are prone to overfitting on the training set, especially for those rare categories.","While recent works have delved into exploiting generative models to create synthetic datasets for data augmentation, these approaches do not efficiently harness the full potential of generative models.   ","To address these issues, we introduce a more efficient strategy to construct generative datasets for data augmentation, termed DiverGen.","Firstly, we provide an explanation of the role of generative data from the perspective of distribution discrepancy.","We investigate the impact of different data on the distribution learned by the model.","We argue that generative data can expand the data distribution that the model can learn, thus mitigating overfitting.","Additionally, we find that the diversity of generative data is crucial for improving model performance and enhance it through various strategies, including category diversity, prompt diversity, and generative model diversity.","With these strategies, we can scale the data to millions while maintaining the trend of model performance improvement.","On the LVIS dataset, DiverGen significantly outperforms the strong model X-Paste, achieving +1.1 box AP and +1.1 mask AP across all categories, and +1.9 box AP and +2.5 mask AP for rare categories."],"url":"http://arxiv.org/abs/2405.10185v1"}
{"created":"2024-05-16 15:27:51","title":"A Guide to Tracking Phylogenies in Parallel and Distributed Agent-based Evolution Models","abstract":"Computer simulations are an important tool for studying the mechanics of biological evolution. In particular, in silico work with agent-based models provides an opportunity to collect high-quality records of ancestry relationships among simulated agents. Such phylogenies can provide insight into evolutionary dynamics within these simulations. Existing work generally tracks lineages directly, yielding an exact phylogenetic record of evolutionary history. However, direct tracking can be inefficient for large-scale, many-processor evolutionary simulations. An alternate approach to extracting phylogenetic information from simulation that scales more favorably is post hoc estimation, akin to how bioinformaticians build phylogenies by assessing genetic similarities between organisms. Recently introduced ``hereditary stratigraphy'' algorithms provide means for efficient inference of phylogenetic history from non-coding annotations on simulated organisms' genomes. A number of options exist in configuring hereditary stratigraphy methodology, but no work has yet tested how they impact reconstruction quality. To address this question, we surveyed reconstruction accuracy under alternate configurations across a matrix of evolutionary conditions varying in selection pressure, spatial structure, and ecological dynamics. We synthesize results from these experiments to suggest a prescriptive system of best practices for work with hereditary stratigraphy, ultimately guiding researchers in choosing appropriate instrumentation for large-scale simulation studies.","sentences":["Computer simulations are an important tool for studying the mechanics of biological evolution.","In particular, in silico work with agent-based models provides an opportunity to collect high-quality records of ancestry relationships among simulated agents.","Such phylogenies can provide insight into evolutionary dynamics within these simulations.","Existing work generally tracks lineages directly, yielding an exact phylogenetic record of evolutionary history.","However, direct tracking can be inefficient for large-scale, many-processor evolutionary simulations.","An alternate approach to extracting phylogenetic information from simulation that scales more favorably is post hoc estimation, akin to how bioinformaticians build phylogenies by assessing genetic similarities between organisms.","Recently introduced ``hereditary stratigraphy'' algorithms provide means for efficient inference of phylogenetic history from non-coding annotations on simulated organisms' genomes.","A number of options exist in configuring hereditary stratigraphy methodology, but no work has yet tested how they impact reconstruction quality.","To address this question, we surveyed reconstruction accuracy under alternate configurations across a matrix of evolutionary conditions varying in selection pressure, spatial structure, and ecological dynamics.","We synthesize results from these experiments to suggest a prescriptive system of best practices for work with hereditary stratigraphy, ultimately guiding researchers in choosing appropriate instrumentation for large-scale simulation studies."],"url":"http://arxiv.org/abs/2405.10183v1"}
{"created":"2024-05-16 15:13:42","title":"Filling Missing Values Matters for Range Image-Based Point Cloud Segmentation","abstract":"Point cloud segmentation (PCS) plays an essential role in robot perception and navigation tasks. To efficiently understand large-scale outdoor point clouds, their range image representation is commonly adopted. This image-like representation is compact and structured, making range image-based PCS models practical. However, undesirable missing values in the range images damage the shapes and patterns of objects. This problem creates difficulty for the models in learning coherent and complete geometric information from the objects. Consequently, the PCS models only achieve inferior performance. Delving deeply into this issue, we find that the use of unreasonable projection approaches and deskewing scans mainly leads to unwanted missing values in the range images. Besides, almost all previous works fail to consider filling in the unexpected missing values in the PCS task. To alleviate this problem, we first propose a new projection method, namely scan unfolding++ (SU++), to avoid massive missing values in the generated range images. Then, we introduce a simple yet effective approach, namely range-dependent $K$-nearest neighbor interpolation ($K$NNI), to further fill in missing values. Finally, we introduce the Filling Missing Values Network (FMVNet) and Fast FMVNet. Extensive experimental results on SemanticKITTI, SemanticPOSS, and nuScenes datasets demonstrate that by employing the proposed SU++ and $K$NNI, existing range image-based PCS models consistently achieve better performance than the baseline models. Besides, both FMVNet and Fast FMVNet achieve state-of-the-art performance in terms of the speed-accuracy trade-off. The proposed methods can be applied to other range image-based tasks and practical applications.","sentences":["Point cloud segmentation (PCS) plays an essential role in robot perception and navigation tasks.","To efficiently understand large-scale outdoor point clouds, their range image representation is commonly adopted.","This image-like representation is compact and structured, making range image-based PCS models practical.","However, undesirable missing values in the range images damage the shapes and patterns of objects.","This problem creates difficulty for the models in learning coherent and complete geometric information from the objects.","Consequently, the PCS models only achieve inferior performance.","Delving deeply into this issue, we find that the use of unreasonable projection approaches and deskewing scans mainly leads to unwanted missing values in the range images.","Besides, almost all previous works fail to consider filling in the unexpected missing values in the PCS task.","To alleviate this problem, we first propose a new projection method, namely scan unfolding++ (SU++), to avoid massive missing values in the generated range images.","Then, we introduce a simple yet effective approach, namely range-dependent $K$-nearest neighbor interpolation ($K$NNI), to further fill in missing values.","Finally, we introduce the Filling Missing Values Network (FMVNet) and Fast FMVNet.","Extensive experimental results on SemanticKITTI, SemanticPOSS, and nuScenes datasets demonstrate that by employing the proposed SU++ and $K$NNI, existing range image-based PCS models consistently achieve better performance than the baseline models.","Besides, both FMVNet and Fast FMVNet achieve state-of-the-art performance in terms of the speed-accuracy trade-off.","The proposed methods can be applied to other range image-based tasks and practical applications."],"url":"http://arxiv.org/abs/2405.10175v1"}
{"created":"2024-05-16 15:07:56","title":"A Mess of Memory System Benchmarking, Simulation and Application Profiling","abstract":"The Memory stress (Mess) framework provides a unified view of the memory system benchmarking, simulation and application profiling. The Mess benchmark provides a holistic and detailed memory system characterization. It is based on hundreds of measurements that are represented as a family of bandwidth--latency curves. The benchmark increases the coverage of all the previous tools and leads to new findings in the behavior of the actual and simulated memory systems. We deploy the Mess benchmark to characterize Intel, AMD, IBM, Fujitsu, Amazon and NVIDIA servers with DDR4, DDR5, HBM2 and HBM2E memory. The Mess memory simulator uses bandwidth--latency concept for the memory performance simulation. We integrate Mess with widely-used CPUs simulators enabling modeling of all high-end memory technologies. The Mess simulator is fast, easy to integrate and it closely matches the actual system performance. By design, it enables a quick adoption of new memory technologies in hardware simulators. Finally, the Mess application profiling positions the application in the bandwidth--latency space of the target memory system. This information can be correlated with other application runtime activities and the source code, leading to a better overall understanding of the application's behavior. The current Mess benchmark release covers all major CPU and GPU ISAs, x86, ARM, Power, RISC-V, and NVIDIA's PTX. We also release as open source the ZSim, gem5 and OpenPiton Metro-MPI integrated with the Mess memory simulator for DDR4, DDR5, Optane, HBM2, HBM2E and CXL memory expanders. The Mess application profiling is already integrated into a suite of production HPC performance analysis tools.","sentences":["The Memory stress (Mess) framework provides a unified view of the memory system benchmarking, simulation and application profiling.","The Mess benchmark provides a holistic and detailed memory system characterization.","It is based on hundreds of measurements that are represented as a family of bandwidth--latency curves.","The benchmark increases the coverage of all the previous tools and leads to new findings in the behavior of the actual and simulated memory systems.","We deploy the Mess benchmark to characterize Intel, AMD, IBM, Fujitsu, Amazon and NVIDIA servers with DDR4, DDR5, HBM2 and HBM2E memory.","The Mess memory simulator uses bandwidth--latency concept for the memory performance simulation.","We integrate Mess with widely-used CPUs simulators enabling modeling of all high-end memory technologies.","The Mess simulator is fast, easy to integrate and it closely matches the actual system performance.","By design, it enables a quick adoption of new memory technologies in hardware simulators.","Finally, the Mess application profiling positions the application in the bandwidth--latency space of the target memory system.","This information can be correlated with other application runtime activities and the source code, leading to a better overall understanding of the application's behavior.","The current Mess benchmark release covers all major CPU and GPU ISAs, x86, ARM, Power, RISC-V, and NVIDIA's PTX.","We also release as open source the ZSim, gem5 and OpenPiton Metro-MPI integrated with the Mess memory simulator for DDR4, DDR5, Optane, HBM2, HBM2E and CXL memory expanders.","The Mess application profiling is already integrated into a suite of production HPC performance analysis tools."],"url":"http://arxiv.org/abs/2405.10170v1"}
{"created":"2024-05-16 15:03:40","title":"Near Uniform Triangle Sampling Over Adjacency List Graph Streams","abstract":"Triangle counting and sampling are two fundamental problems for streaming algorithms. Arguably, designing sampling algorithms is more challenging than their counting variants. It may be noted that triangle counting has received far greater attention in the literature than the sampling variant. In this work, we consider the problem of approximately sampling triangles in different models of streaming with the focus being on the adjacency list model.   In this problem, the edges of a graph $G$ will arrive over a data stream. The goal is to design efficient streaming algorithms that can sample and output a triangle from a distribution, over the triangles in $G$, that is close to the uniform distribution over the triangles in $G$. The distance between distributions is measured in terms of $\\ell_1$-distance. The main technical contribution of this paper is to design algorithms for this triangle sampling problem in the adjacency list model with the space complexities matching their counting variants. For the sake of completeness, we also show results on the vertex and edge arrival models.","sentences":["Triangle counting and sampling are two fundamental problems for streaming algorithms.","Arguably, designing sampling algorithms is more challenging than their counting variants.","It may be noted that triangle counting has received far greater attention in the literature than the sampling variant.","In this work, we consider the problem of approximately sampling triangles in different models of streaming with the focus being on the adjacency list model.   ","In this problem, the edges of a graph $G$ will arrive over a data stream.","The goal is to design efficient streaming algorithms that can sample and output a triangle from a distribution, over the triangles in $G$, that is close to the uniform distribution over the triangles in $G$. The distance between distributions is measured in terms of $\\ell_1$-distance.","The main technical contribution of this paper is to design algorithms for this triangle sampling problem in the adjacency list model with the space complexities matching their counting variants.","For the sake of completeness, we also show results on the vertex and edge arrival models."],"url":"http://arxiv.org/abs/2405.10167v1"}
{"created":"2024-05-16 15:02:24","title":"LFED: A Literary Fiction Evaluation Dataset for Large Language Models","abstract":"The rapid evolution of large language models (LLMs) has ushered in the need for comprehensive assessments of their performance across various dimensions. In this paper, we propose LFED, a Literary Fiction Evaluation Dataset, which aims to evaluate the capability of LLMs on the long fiction comprehension and reasoning. We collect 95 literary fictions that are either originally written in Chinese or translated into Chinese, covering a wide range of topics across several centuries. We define a question taxonomy with 8 question categories to guide the creation of 1,304 questions. Additionally, we conduct an in-depth analysis to ascertain how specific attributes of literary fictions (e.g., novel types, character numbers, the year of publication) impact LLM performance in evaluations. Through a series of experiments with various state-of-the-art LLMs, we demonstrate that these models face considerable challenges in effectively addressing questions related to literary fictions, with ChatGPT reaching only 57.08% under the zero-shot setting. The dataset will be publicly available at https://github.com/tjunlp-lab/LFED.git","sentences":["The rapid evolution of large language models (LLMs) has ushered in the need for comprehensive assessments of their performance across various dimensions.","In this paper, we propose LFED, a Literary Fiction Evaluation Dataset, which aims to evaluate the capability of LLMs on the long fiction comprehension and reasoning.","We collect 95 literary fictions that are either originally written in Chinese or translated into Chinese, covering a wide range of topics across several centuries.","We define a question taxonomy with 8 question categories to guide the creation of 1,304 questions.","Additionally, we conduct an in-depth analysis to ascertain how specific attributes of literary fictions (e.g., novel types, character numbers, the year of publication) impact LLM performance in evaluations.","Through a series of experiments with various state-of-the-art LLMs, we demonstrate that these models face considerable challenges in effectively addressing questions related to literary fictions, with ChatGPT reaching only 57.08% under the zero-shot setting.","The dataset will be publicly available at https://github.com/tjunlp-lab/LFED.git"],"url":"http://arxiv.org/abs/2405.10166v1"}
{"created":"2024-05-16 14:53:45","title":"PIR: Remote Sensing Image-Text Retrieval with Prior Instruction Representation Learning","abstract":"Remote sensing image-text retrieval constitutes a foundational aspect of remote sensing interpretation tasks, facilitating the alignment of vision and language representations. This paper introduces a prior instruction representation (PIR) learning paradigm that draws on prior knowledge to instruct adaptive learning of vision and text representations. Based on PIR, a domain-adapted remote sensing image-text retrieval framework PIR-ITR is designed to address semantic noise issues in vision-language understanding tasks. However, with massive additional data for pre-training the vision-language foundation model, remote sensing image-text retrieval is further developed into an open-domain retrieval task. Continuing with the above, we propose PIR-CLIP, a domain-specific CLIP-based framework for remote sensing image-text retrieval, to address semantic noise in remote sensing vision-language representations and further improve open-domain retrieval performance. In vision representation, Vision Instruction Representation (VIR) based on Spatial-PAE utilizes the prior-guided knowledge of the remote sensing scene recognition by building a belief matrix to select key features for reducing the impact of semantic noise. In text representation, Language Cycle Attention (LCA) based on Temporal-PAE uses the previous time step to cyclically activate the current time step to enhance text representation capability. A cluster-wise Affiliation Loss (AL) is proposed to constrain the inter-classes and to reduce the semantic confusion zones in the common subspace. Comprehensive experiments demonstrate that PIR could enhance vision and text representations and outperform the state-of-the-art methods of closed-domain and open-domain retrieval on two benchmark datasets, RSICD and RSITMD.","sentences":["Remote sensing image-text retrieval constitutes a foundational aspect of remote sensing interpretation tasks, facilitating the alignment of vision and language representations.","This paper introduces a prior instruction representation (PIR) learning paradigm that draws on prior knowledge to instruct adaptive learning of vision and text representations.","Based on PIR, a domain-adapted remote sensing image-text retrieval framework PIR-ITR is designed to address semantic noise issues in vision-language understanding tasks.","However, with massive additional data for pre-training the vision-language foundation model, remote sensing image-text retrieval is further developed into an open-domain retrieval task.","Continuing with the above, we propose PIR-CLIP, a domain-specific CLIP-based framework for remote sensing image-text retrieval, to address semantic noise in remote sensing vision-language representations and further improve open-domain retrieval performance.","In vision representation, Vision Instruction Representation (VIR) based on Spatial-PAE utilizes the prior-guided knowledge of the remote sensing scene recognition by building a belief matrix to select key features for reducing the impact of semantic noise.","In text representation, Language Cycle Attention (LCA) based on Temporal-PAE uses the previous time step to cyclically activate the current time step to enhance text representation capability.","A cluster-wise Affiliation Loss (AL) is proposed to constrain the inter-classes and to reduce the semantic confusion zones in the common subspace.","Comprehensive experiments demonstrate that PIR could enhance vision and text representations and outperform the state-of-the-art methods of closed-domain and open-domain retrieval on two benchmark datasets, RSICD and RSITMD."],"url":"http://arxiv.org/abs/2405.10160v1"}
{"created":"2024-05-16 14:48:24","title":"Firefighters' Perceptions on Collaboration and Interaction with Autonomous Drones: Results of a Field Trial","abstract":"Applications of drones in emergency response, like firefighting, have been promoted in the past decade. As the autonomy of drones continues to improve, the ways in which they are integrated into firefighting teams and their impact on crews are changing. This demands more understanding of how firefighters perceive and interact with autonomous drones. This paper presents a drone-based system for emergency operations with which firefighters can interact through sound, lights, and a graphical user interface. We use interviews with stakeholders collected in two field trials to explore their perceptions of the interaction and collaboration with drones. Our result shows that firefighters perceived visual interaction as adequate. However, for audio instructions and interfaces, information overload emerges as an essential problem. The potential impact of drones on current work configurations may involve shifting the position of humans closer to supervisory decision-makers and changing the training structure and content.","sentences":["Applications of drones in emergency response, like firefighting, have been promoted in the past decade.","As the autonomy of drones continues to improve, the ways in which they are integrated into firefighting teams and their impact on crews are changing.","This demands more understanding of how firefighters perceive and interact with autonomous drones.","This paper presents a drone-based system for emergency operations with which firefighters can interact through sound, lights, and a graphical user interface.","We use interviews with stakeholders collected in two field trials to explore their perceptions of the interaction and collaboration with drones.","Our result shows that firefighters perceived visual interaction as adequate.","However, for audio instructions and interfaces, information overload emerges as an essential problem.","The potential impact of drones on current work configurations may involve shifting the position of humans closer to supervisory decision-makers and changing the training structure and content."],"url":"http://arxiv.org/abs/2405.10153v1"}
{"created":"2024-05-16 14:48:06","title":"Braids, twists, trace and duality in combinatory algebras","abstract":"We investigate a class of combinatory algebras, called ribbon combinatory algebras, in which we can interpret both the braided untyped linear lambda calculus and framed oriented tangles. Any reflexive object in a ribbon category gives rise to a ribbon combinatory algebra. Conversely, From a ribbon combinatory algebra, we can construct a ribbon category with a reflexive object, from which the combinatory algebra can be recovered. To show this, and also to give the equational characterisation of ribbon combinatory algebras, we make use of the internal PRO construction developed in Hasegawa's recent work. Interestingly, we can characterise ribbon combinatory algebras in two different ways: as balanced combinatory algebras with a trace combinator, and as balanced combinatory algebras with duality.","sentences":["We investigate a class of combinatory algebras, called ribbon combinatory algebras, in which we can interpret both the braided untyped linear lambda calculus and framed oriented tangles.","Any reflexive object in a ribbon category gives rise to a ribbon combinatory algebra.","Conversely, From a ribbon combinatory algebra, we can construct a ribbon category with a reflexive object, from which the combinatory algebra can be recovered.","To show this, and also to give the equational characterisation of ribbon combinatory algebras, we make use of the internal PRO construction developed in Hasegawa's recent work.","Interestingly, we can characterise ribbon combinatory algebras in two different ways: as balanced combinatory algebras with a trace combinator, and as balanced combinatory algebras with duality."],"url":"http://arxiv.org/abs/2405.10152v1"}
{"created":"2024-05-16 14:46:18","title":"Speaker Verification in Agent-Generated Conversations","abstract":"The recent success of large language models (LLMs) has attracted widespread interest to develop role-playing conversational agents personalized to the characteristics and styles of different speakers to enhance their abilities to perform both general and special purpose dialogue tasks. However, the ability to personalize the generated utterances to speakers, whether conducted by human or LLM, has not been well studied. To bridge this gap, our study introduces a novel evaluation challenge: speaker verification in agent-generated conversations, which aimed to verify whether two sets of utterances originate from the same speaker. To this end, we assemble a large dataset collection encompassing thousands of speakers and their utterances. We also develop and evaluate speaker verification models under experiment setups. We further utilize the speaker verification models to evaluate the personalization abilities of LLM-based role-playing models. Comprehensive experiments suggest that the current role-playing models fail in accurately mimicking speakers, primarily due to their inherent linguistic characteristics.","sentences":["The recent success of large language models (LLMs) has attracted widespread interest to develop role-playing conversational agents personalized to the characteristics and styles of different speakers to enhance their abilities to perform both general and special purpose dialogue tasks.","However, the ability to personalize the generated utterances to speakers, whether conducted by human or LLM, has not been well studied.","To bridge this gap, our study introduces a novel evaluation challenge: speaker verification in agent-generated conversations, which aimed to verify whether two sets of utterances originate from the same speaker.","To this end, we assemble a large dataset collection encompassing thousands of speakers and their utterances.","We also develop and evaluate speaker verification models under experiment setups.","We further utilize the speaker verification models to evaluate the personalization abilities of LLM-based role-playing models.","Comprehensive experiments suggest that the current role-playing models fail in accurately mimicking speakers, primarily due to their inherent linguistic characteristics."],"url":"http://arxiv.org/abs/2405.10150v1"}
{"created":"2024-05-16 14:45:20","title":"Delooping cyclic groups with lens spaces in homotopy type theory","abstract":"In the setting of homotopy type theory, each type can be interpreted as a space. Moreover, given an element of a type, i.e. a point in the corresponding space, one can define another type which encodes the space of loops based at this point. In particular, when the type we started with is a groupoid, this loop space is always a group. Conversely, to every group we can associate a type (more precisely, a pointed connected groupoid) whose loop space is this group: this operation is called delooping. The generic procedures for constructing such deloopings of groups (based on torsors, or on descriptions of Eilenberg-MacLane spaces as higher inductive types) are unfortunately equipped with elimination principles which do not directly allow eliminating to untruncated types, and are thus difficult to work with in practice. Here, we construct deloopings of the cyclic groups $\\mathbb{Z}_m$ which are cellular, and thus do not suffer from this shortcoming. In order to do so, we provide type-theoretic implementations of lens spaces, which constitute an important family of spaces in algebraic topology. Our definition is based on the computation of an iterative join of suitable maps from the circle to an arbitrary delooping of $\\mathbb{Z}_m$. In some sense, this work generalizes the construction of real projective spaces by Buchholtz and Rijke, which handles the case m=2, although the general setting requires more involved tools. Finally, we use this construction to also provide cellular descriptions of dihedral groups, and explain how we can hope to use those to compute the cohomology and higher actions of such groups.","sentences":["In the setting of homotopy type theory, each type can be interpreted as a space.","Moreover, given an element of a type, i.e. a point in the corresponding space, one can define another type which encodes the space of loops based at this point.","In particular, when the type we started with is a groupoid, this loop space is always a group.","Conversely, to every group we can associate a type (more precisely, a pointed connected groupoid) whose loop space is this group: this operation is called delooping.","The generic procedures for constructing such deloopings of groups (based on torsors, or on descriptions of Eilenberg-MacLane spaces as higher inductive types) are unfortunately equipped with elimination principles which do not directly allow eliminating to untruncated types, and are thus difficult to work with in practice.","Here, we construct deloopings of the cyclic groups $\\mathbb{Z}_m$ which are cellular, and thus do not suffer from this shortcoming.","In order to do so, we provide type-theoretic implementations of lens spaces, which constitute an important family of spaces in algebraic topology.","Our definition is based on the computation of an iterative join of suitable maps from the circle to an arbitrary delooping of $\\mathbb{Z}_m$. In some sense, this work generalizes the construction of real projective spaces by Buchholtz and Rijke, which handles the case m=2, although the general setting requires more involved tools.","Finally, we use this construction to also provide cellular descriptions of dihedral groups, and explain how we can hope to use those to compute the cohomology and higher actions of such groups."],"url":"http://arxiv.org/abs/2405.10149v1"}
{"created":"2024-05-16 14:45:06","title":"SpecDETR: A Transformer-based Hyperspectral Point Object Detection Network","abstract":"Hyperspectral target detection (HTD) aims to identify specific materials based on spectral information in hyperspectral imagery and can detect point targets, some of which occupy a smaller than one-pixel area. However, existing HTD methods are developed based on per-pixel binary classification, which limits the feature representation capability for point targets. In this paper, we rethink the hyperspectral point target detection from the object detection perspective, and focus more on the object-level prediction capability rather than the pixel classification capability. Inspired by the token-based processing flow of Detection Transformer (DETR), we propose the first specialized network for hyperspectral multi-class point object detection, SpecDETR. Without the backbone part of the current object detection framework, SpecDETR treats the spectral features of each pixel in hyperspectral images as a token and utilizes a multi-layer Transformer encoder with local and global coordination attention modules to extract deep spatial-spectral joint features. SpecDETR regards point object detection as a one-to-many set prediction problem, thereby achieving a concise and efficient DETR decoder that surpasses the current state-of-the-art DETR decoder in terms of parameters and accuracy in point object detection. We develop a simulated hyperSpectral Point Object Detection benchmark termed SPOD, and for the first time, evaluate and compare the performance of current object detection networks and HTD methods on hyperspectral multi-class point object detection. SpecDETR demonstrates superior performance as compared to current object detection networks and HTD methods on the SPOD dataset. Additionally, we validate on a public HTD dataset that by using data simulation instead of manual annotation, SpecDETR can detect real-world single-spectral point objects directly.","sentences":["Hyperspectral target detection (HTD) aims to identify specific materials based on spectral information in hyperspectral imagery and can detect point targets, some of which occupy a smaller than one-pixel area.","However, existing HTD methods are developed based on per-pixel binary classification, which limits the feature representation capability for point targets.","In this paper, we rethink the hyperspectral point target detection from the object detection perspective, and focus more on the object-level prediction capability rather than the pixel classification capability.","Inspired by the token-based processing flow of Detection Transformer (DETR), we propose the first specialized network for hyperspectral multi-class point object detection, SpecDETR.","Without the backbone part of the current object detection framework, SpecDETR treats the spectral features of each pixel in hyperspectral images as a token and utilizes a multi-layer Transformer encoder with local and global coordination attention modules to extract deep spatial-spectral joint features.","SpecDETR regards point object detection as a one-to-many set prediction problem, thereby achieving a concise and efficient DETR decoder that surpasses the current state-of-the-art DETR decoder in terms of parameters and accuracy in point object detection.","We develop a simulated hyperSpectral Point Object Detection benchmark termed SPOD, and for the first time, evaluate and compare the performance of current object detection networks and HTD methods on hyperspectral multi-class point object detection.","SpecDETR demonstrates superior performance as compared to current object detection networks and HTD methods on the SPOD dataset.","Additionally, we validate on a public HTD dataset that by using data simulation instead of manual annotation, SpecDETR can detect real-world single-spectral point objects directly."],"url":"http://arxiv.org/abs/2405.10148v1"}
{"created":"2024-05-16 14:35:50","title":"Relational DNN Verification With Cross Executional Bound Refinement","abstract":"We focus on verifying relational properties defined over deep neural networks (DNNs) such as robustness against universal adversarial perturbations (UAP), certified worst-case hamming distance for binary string classifications, etc. Precise verification of these properties requires reasoning about multiple executions of the same DNN. However, most of the existing works in DNN verification only handle properties defined over single executions and as a result, are imprecise for relational properties. Though few recent works for relational DNN verification, capture linear dependencies between the inputs of multiple executions, they do not leverage dependencies between the outputs of hidden layers producing imprecise results. We develop a scalable relational verifier RACoon that utilizes cross-execution dependencies at all layers of the DNN gaining substantial precision over SOTA baselines on a wide range of datasets, networks, and relational properties.","sentences":["We focus on verifying relational properties defined over deep neural networks (DNNs) such as robustness against universal adversarial perturbations (UAP), certified worst-case hamming distance for binary string classifications, etc.","Precise verification of these properties requires reasoning about multiple executions of the same DNN.","However, most of the existing works in DNN verification only handle properties defined over single executions and as a result, are imprecise for relational properties.","Though few recent works for relational DNN verification, capture linear dependencies between the inputs of multiple executions, they do not leverage dependencies between the outputs of hidden layers producing imprecise results.","We develop a scalable relational verifier RACoon that utilizes cross-execution dependencies at all layers of the DNN gaining substantial precision over SOTA baselines on a wide range of datasets, networks, and relational properties."],"url":"http://arxiv.org/abs/2405.10143v1"}
{"created":"2024-05-16 14:35:12","title":"GS-Planner: A Gaussian-Splatting-based Planning Framework for Active High-Fidelity Reconstruction","abstract":"Active reconstruction technique enables robots to autonomously collect scene data for full coverage, relieving users from tedious and time-consuming data capturing process. However, designed based on unsuitable scene representations, existing methods show unrealistic reconstruction results or the inability of online quality evaluation. Due to the recent advancements in explicit radiance field technology, online active high-fidelity reconstruction has become achievable. In this paper, we propose GS-Planner, a planning framework for active high-fidelity reconstruction using 3D Gaussian Splatting. With improvement on 3DGS to recognize unobserved regions, we evaluate the reconstruction quality and completeness of 3DGS map online to guide the robot. Then we design a sampling-based active reconstruction strategy to explore the unobserved areas and improve the reconstruction geometric and textural quality. To establish a complete robot active reconstruction system, we choose quadrotor as the robotic platform for its high agility. Then we devise a safety constraint with 3DGS to generate executable trajectories for quadrotor navigation in the 3DGS map. To validate the effectiveness of our method, we conduct extensive experiments and ablation studies in highly realistic simulation scenes.","sentences":["Active reconstruction technique enables robots to autonomously collect scene data for full coverage, relieving users from tedious and time-consuming data capturing process.","However, designed based on unsuitable scene representations, existing methods show unrealistic reconstruction results or the inability of online quality evaluation.","Due to the recent advancements in explicit radiance field technology, online active high-fidelity reconstruction has become achievable.","In this paper, we propose GS-Planner, a planning framework for active high-fidelity reconstruction using 3D Gaussian Splatting.","With improvement on 3DGS to recognize unobserved regions, we evaluate the reconstruction quality and completeness of 3DGS map online to guide the robot.","Then we design a sampling-based active reconstruction strategy to explore the unobserved areas and improve the reconstruction geometric and textural quality.","To establish a complete robot active reconstruction system, we choose quadrotor as the robotic platform for its high agility.","Then we devise a safety constraint with 3DGS to generate executable trajectories for quadrotor navigation in the 3DGS map.","To validate the effectiveness of our method, we conduct extensive experiments and ablation studies in highly realistic simulation scenes."],"url":"http://arxiv.org/abs/2405.10142v1"}
{"created":"2024-05-16 14:34:44","title":"Libra: Building Decoupled Vision System on Large Language Models","abstract":"In this work, we introduce Libra, a prototype model with a decoupled vision system on a large language model (LLM). The decoupled vision system decouples inner-modal modeling and cross-modal interaction, yielding unique visual information modeling and effective cross-modal comprehension. Libra is trained through discrete auto-regressive modeling on both vision and language inputs. Specifically, we incorporate a routed visual expert with a cross-modal bridge module into a pretrained LLM to route the vision and language flows during attention computing to enable different attention patterns in inner-modal modeling and cross-modal interaction scenarios. Experimental results demonstrate that the dedicated design of Libra achieves a strong MLLM baseline that rivals existing works in the image-to-text scenario with merely 50 million training data, providing a new perspective for future multimodal foundation models. Code is available at https://github.com/YifanXu74/Libra.","sentences":["In this work, we introduce Libra, a prototype model with a decoupled vision system on a large language model (LLM).","The decoupled vision system decouples inner-modal modeling and cross-modal interaction, yielding unique visual information modeling and effective cross-modal comprehension.","Libra is trained through discrete auto-regressive modeling on both vision and language inputs.","Specifically, we incorporate a routed visual expert with a cross-modal bridge module into a pretrained LLM to route the vision and language flows during attention computing to enable different attention patterns in inner-modal modeling and cross-modal interaction scenarios.","Experimental results demonstrate that the dedicated design of Libra achieves a strong MLLM baseline that rivals existing works in the image-to-text scenario with merely 50 million training data, providing a new perspective for future multimodal foundation models.","Code is available at https://github.com/YifanXu74/Libra."],"url":"http://arxiv.org/abs/2405.10140v1"}
{"created":"2024-05-16 14:34:04","title":"Mental Well-being Opportunities in Interacting and Reflecting with Personal Data Sculptures of EEG","abstract":"Data physicalization is a research area in quick expansion whose necessity and popularity are motivated by the pervasiveness of data in our everyday. While the reflective ability of personal data physicalization has been vastly documented, their mental health and emotional well-being benefits remain largely unexplored. We present a qualitative study where we create personal data sculptures of electroencephalograms (EEG) and mental activity, observe users' interactions with them, and analyze their reflections for hints of self-discovery and intended behavioral change. We argue that there is a ground for using personal data sculptures as prompts for reflection on mental well-being and motivators for self-caring, and that data sculptures for mental well-being are a finalized use of data physicalization worth exploring further.","sentences":["Data physicalization is a research area in quick expansion whose necessity and popularity are motivated by the pervasiveness of data in our everyday.","While the reflective ability of personal data physicalization has been vastly documented, their mental health and emotional well-being benefits remain largely unexplored.","We present a qualitative study where we create personal data sculptures of electroencephalograms (EEG) and mental activity, observe users' interactions with them, and analyze their reflections for hints of self-discovery and intended behavioral change.","We argue that there is a ground for using personal data sculptures as prompts for reflection on mental well-being and motivators for self-caring, and that data sculptures for mental well-being are a finalized use of data physicalization worth exploring further."],"url":"http://arxiv.org/abs/2405.10139v1"}
{"created":"2024-05-16 14:33:39","title":"PL-MTEB: Polish Massive Text Embedding Benchmark","abstract":"In this paper, we introduce the Polish Massive Text Embedding Benchmark (PL-MTEB), a comprehensive benchmark for text embeddings in Polish. The PL-MTEB consists of 28 diverse NLP tasks from 5 task types. We adapted the tasks based on previously used datasets by the Polish NLP community. In addition, we created a new PLSC (Polish Library of Science Corpus) dataset consisting of titles and abstracts of scientific publications in Polish, which was used as the basis for two novel clustering tasks. We evaluated 15 publicly available models for text embedding, including Polish and multilingual ones, and collected detailed results for individual tasks and aggregated results for each task type and the entire benchmark. PL-MTEB comes with open-source code at https://github.com/rafalposwiata/pl-mteb.","sentences":["In this paper, we introduce the Polish Massive Text Embedding Benchmark (PL-MTEB), a comprehensive benchmark for text embeddings in Polish.","The PL-MTEB consists of 28 diverse NLP tasks from 5 task types.","We adapted the tasks based on previously used datasets by the Polish NLP community.","In addition, we created a new PLSC (Polish Library of Science Corpus) dataset consisting of titles and abstracts of scientific publications in Polish, which was used as the basis for two novel clustering tasks.","We evaluated 15 publicly available models for text embedding, including Polish and multilingual ones, and collected detailed results for individual tasks and aggregated results for each task type and the entire benchmark.","PL-MTEB comes with open-source code at https://github.com/rafalposwiata/pl-mteb."],"url":"http://arxiv.org/abs/2405.10138v1"}
{"created":"2024-05-16 14:31:30","title":"Self-supervised feature distillation and design of experiments for efficient training of micromechanical deep learning surrogates","abstract":"Machine learning surrogate emulators are needed in engineering design and optimization tasks to rapidly emulate computationally expensive physics-based models. In micromechanics problems the local full-field response variables are desired at microstructural length scales. While there has been a great deal of work on establishing architectures for these tasks there has been relatively little work on establishing microstructural experimental design strategies. This work demonstrates that intelligent selection of microstructural volume elements for subsequent physics simulations enables the establishment of more accurate surrogate models. There exist two key challenges towards establishing a suitable framework: (1) microstructural feature quantification and (2) establishment of a criteria which encourages construction of a diverse training data set. Three feature extraction strategies are used as well as three design criteria. A novel contrastive feature extraction approach is established for automated self-supervised extraction of microstructural summary statistics. Results indicate that for the problem considered up to a 8\\% improvement in surrogate performance may be achieved using the proposed design and training strategy. Trends indicate this approach may be even more beneficial when scaled towards larger problems. These results demonstrate that the selection of an efficient experimental design is an important consideration when establishing machine learning based surrogate models.","sentences":["Machine learning surrogate emulators are needed in engineering design and optimization tasks to rapidly emulate computationally expensive physics-based models.","In micromechanics problems the local full-field response variables are desired at microstructural length scales.","While there has been a great deal of work on establishing architectures for these tasks there has been relatively little work on establishing microstructural experimental design strategies.","This work demonstrates that intelligent selection of microstructural volume elements for subsequent physics simulations enables the establishment of more accurate surrogate models.","There exist two key challenges towards establishing a suitable framework: (1) microstructural feature quantification and (2) establishment of a criteria which encourages construction of a diverse training data set.","Three feature extraction strategies are used as well as three design criteria.","A novel contrastive feature extraction approach is established for automated self-supervised extraction of microstructural summary statistics.","Results indicate that for the problem considered up to a 8\\% improvement in surrogate performance may be achieved using the proposed design and training strategy.","Trends indicate this approach may be even more beneficial when scaled towards larger problems.","These results demonstrate that the selection of an efficient experimental design is an important consideration when establishing machine learning based surrogate models."],"url":"http://arxiv.org/abs/2405.10135v1"}
{"created":"2024-05-16 14:31:15","title":"Towards Consistent and Explainable Motion Prediction using Heterogeneous Graph Attention","abstract":"In autonomous driving, accurately interpreting the movements of other road users and leveraging this knowledge to forecast future trajectories is crucial. This is typically achieved through the integration of map data and tracked trajectories of various agents. Numerous methodologies combine this information into a singular embedding for each agent, which is then utilized to predict future behavior. However, these approaches have a notable drawback in that they may lose exact location information during the encoding process. The encoding still includes general map information. However, the generation of valid and consistent trajectories is not guaranteed. This can cause the predicted trajectories to stray from the actual lanes. This paper introduces a new refinement module designed to project the predicted trajectories back onto the actual map, rectifying these discrepancies and leading towards more consistent predictions. This versatile module can be readily incorporated into a wide range of architectures. Additionally, we propose a novel scene encoder that handles all relations between agents and their environment in a single unified heterogeneous graph attention network. By analyzing the attention values on the different edges in this graph, we can gain unique insights into the neural network's inner workings leading towards a more explainable prediction.","sentences":["In autonomous driving, accurately interpreting the movements of other road users and leveraging this knowledge to forecast future trajectories is crucial.","This is typically achieved through the integration of map data and tracked trajectories of various agents.","Numerous methodologies combine this information into a singular embedding for each agent, which is then utilized to predict future behavior.","However, these approaches have a notable drawback in that they may lose exact location information during the encoding process.","The encoding still includes general map information.","However, the generation of valid and consistent trajectories is not guaranteed.","This can cause the predicted trajectories to stray from the actual lanes.","This paper introduces a new refinement module designed to project the predicted trajectories back onto the actual map, rectifying these discrepancies and leading towards more consistent predictions.","This versatile module can be readily incorporated into a wide range of architectures.","Additionally, we propose a novel scene encoder that handles all relations between agents and their environment in a single unified heterogeneous graph attention network.","By analyzing the attention values on the different edges in this graph, we can gain unique insights into the neural network's inner workings leading towards a more explainable prediction."],"url":"http://arxiv.org/abs/2405.10134v1"}
{"created":"2024-05-16 14:31:07","title":"Turkronicles: Diachronic Resources for the Fast Evolving Turkish Language","abstract":"Over the past century, the Turkish language has undergone substantial changes, primarily driven by governmental interventions. In this work, our goal is to investigate the evolution of the Turkish language since the establishment of T\\\"urkiye in 1923. Thus, we first introduce Turkronicles which is a diachronic corpus for Turkish derived from the Official Gazette of T\\\"urkiye. Turkronicles contains 45,375 documents, detailing governmental actions, making it a pivotal resource for analyzing the linguistic evolution influenced by the state policies. In addition, we expand an existing diachronic Turkish corpus which consists of the records of the Grand National Assembly of T\\\"urkiye by covering additional years. Next, combining these two diachronic corpora, we seek answers for two main research questions: How have the Turkish vocabulary and the writing conventions changed since the 1920s? Our analysis reveals that the vocabularies of two different time periods diverge more as the time between them increases, and newly coined Turkish words take the place of their old counterparts. We also observe changes in writing conventions. In particular, the use of circumflex noticeably decreases and words ending with the letters \"-b\" and \"-d\" are successively replaced with \"-p\" and \"-t\" letters, respectively. Overall, this study quantitatively highlights the dramatic changes in Turkish from various aspects of the language in a diachronic perspective.","sentences":["Over the past century, the Turkish language has undergone substantial changes, primarily driven by governmental interventions.","In this work, our goal is to investigate the evolution of the Turkish language since the establishment of T\\\"urkiye in 1923.","Thus, we first introduce Turkronicles which is a diachronic corpus for Turkish derived from the Official Gazette of T\\\"urkiye.","Turkronicles contains 45,375 documents, detailing governmental actions, making it a pivotal resource for analyzing the linguistic evolution influenced by the state policies.","In addition, we expand an existing diachronic Turkish corpus which consists of the records of the Grand National Assembly of T\\\"urkiye by covering additional years.","Next, combining these two diachronic corpora, we seek answers for two main research questions: How have the Turkish vocabulary and the writing conventions changed since the 1920s?","Our analysis reveals that the vocabularies of two different time periods diverge more as the time between them increases, and newly coined Turkish words take the place of their old counterparts.","We also observe changes in writing conventions.","In particular, the use of circumflex noticeably decreases and words ending with the letters \"-b\" and \"-d\" are successively replaced with \"-p\" and \"-t\" letters, respectively.","Overall, this study quantitatively highlights the dramatic changes in Turkish from various aspects of the language in a diachronic perspective."],"url":"http://arxiv.org/abs/2405.10133v1"}
{"created":"2024-05-16 14:29:56","title":"Cooperative Visual-LiDAR Extrinsic Calibration Technology for Intersection Vehicle-Infrastructure: A review","abstract":"In the typical urban intersection scenario, both vehicles and infrastructures are equipped with visual and LiDAR sensors. By successfully integrating the data from vehicle-side and road monitoring devices, a more comprehensive and accurate environmental perception and information acquisition can be achieved. The Calibration of sensors, as an essential component of autonomous driving technology, has consistently drawn significant attention. Particularly in scenarios involving multiple sensors collaboratively perceiving and addressing localization challenges, the requirement for inter-sensor calibration becomes crucial. Recent years have witnessed the emergence of the concept of multi-end cooperation, where infrastructure captures and transmits surrounding environment information to vehicles, bolstering their perception capabilities while mitigating costs. However, this also poses technical complexities, underscoring the pressing need for diverse end calibration. Camera and LiDAR, the bedrock sensors in autonomous driving, exhibit expansive applicability. This paper comprehensively examines and analyzes the calibration of multi-end camera-LiDAR setups from vehicle, roadside, and vehicle-road cooperation perspectives, outlining their relevant applications and profound significance. Concluding with a summary, we present our future-oriented ideas and hypotheses.","sentences":["In the typical urban intersection scenario, both vehicles and infrastructures are equipped with visual and LiDAR sensors.","By successfully integrating the data from vehicle-side and road monitoring devices, a more comprehensive and accurate environmental perception and information acquisition can be achieved.","The Calibration of sensors, as an essential component of autonomous driving technology, has consistently drawn significant attention.","Particularly in scenarios involving multiple sensors collaboratively perceiving and addressing localization challenges, the requirement for inter-sensor calibration becomes crucial.","Recent years have witnessed the emergence of the concept of multi-end cooperation, where infrastructure captures and transmits surrounding environment information to vehicles, bolstering their perception capabilities while mitigating costs.","However, this also poses technical complexities, underscoring the pressing need for diverse end calibration.","Camera and LiDAR, the bedrock sensors in autonomous driving, exhibit expansive applicability.","This paper comprehensively examines and analyzes the calibration of multi-end camera-LiDAR setups from vehicle, roadside, and vehicle-road cooperation perspectives, outlining their relevant applications and profound significance.","Concluding with a summary, we present our future-oriented ideas and hypotheses."],"url":"http://arxiv.org/abs/2405.10132v1"}
{"created":"2024-05-16 14:29:28","title":"Trusting the Cloud-Native Edge: Remotely Attested Kubernetes Workers","abstract":"A Kubernetes cluster typically consists of trusted nodes, running within the confines of a physically secure datacenter. With recent advances in edge orchestration, this is no longer the case. This poses a new challenge: how can we trust a device that an attacker has physical access to? This paper presents an architecture and open-source implementation that securely enrolls edge devices as trusted Kubernetes worker nodes. By providing boot attestation rooted in a hardware Trusted Platform Module, a strong base of trust is provided. A new custom controller directs a modified version of Keylime to cross the cloud-edge gap and securely deliver unique cluster credentials required to enroll an edge worker. The controller dynamically grants and revokes these credentials based on attestation events, preventing a possibly compromised node from accessing sensitive cluster resources. We provide both a qualitative and a quantitative evaluation of the architecture. The qualitative scenarios prove its ability to attest and enroll an edge device with role-based access control (RBAC) permissions that dynamically adjust to attestation events. The quantitative evaluation reflects an average of 10.28 seconds delay incurred on the startup time of the edge node due to attestation for a total average enrollment time of 20.91 seconds. The presented architecture thus provides a strong base of trust, securing a physically exposed edge device and paving the way for a robust and resilient edge computing ecosystem.","sentences":["A Kubernetes cluster typically consists of trusted nodes, running within the confines of a physically secure datacenter.","With recent advances in edge orchestration, this is no longer the case.","This poses a new challenge: how can we trust a device that an attacker has physical access to?","This paper presents an architecture and open-source implementation that securely enrolls edge devices as trusted Kubernetes worker nodes.","By providing boot attestation rooted in a hardware Trusted Platform Module, a strong base of trust is provided.","A new custom controller directs a modified version of Keylime to cross the cloud-edge gap and securely deliver unique cluster credentials required to enroll an edge worker.","The controller dynamically grants and revokes these credentials based on attestation events, preventing a possibly compromised node from accessing sensitive cluster resources.","We provide both a qualitative and a quantitative evaluation of the architecture.","The qualitative scenarios prove its ability to attest and enroll an edge device with role-based access control (RBAC) permissions that dynamically adjust to attestation events.","The quantitative evaluation reflects an average of 10.28 seconds delay incurred on the startup time of the edge node due to attestation for a total average enrollment time of 20.91 seconds.","The presented architecture thus provides a strong base of trust, securing a physically exposed edge device and paving the way for a robust and resilient edge computing ecosystem."],"url":"http://arxiv.org/abs/2405.10131v1"}
{"created":"2024-05-16 14:29:02","title":"PyOptInterface: Design and implementation of an efficient modeling language for mathematical optimization","abstract":"This paper introduces the design and implementation of PyOptInterface, a modeling language for mathematical optimization embedded in Python programming language. PyOptInterface uses lightweight and compact data structure to bridge high-level entities in optimization models like variables and constraints to internal indices of optimizers efficiently. It supports a variety of optimization solvers and a range of common problem classes. We provide benchmarks to exhibit the competitive performance of PyOptInterface compared with other state-of-the-art modeling languages.","sentences":["This paper introduces the design and implementation of PyOptInterface, a modeling language for mathematical optimization embedded in Python programming language.","PyOptInterface uses lightweight and compact data structure to bridge high-level entities in optimization models like variables and constraints to internal indices of optimizers efficiently.","It supports a variety of optimization solvers and a range of common problem classes.","We provide benchmarks to exhibit the competitive performance of PyOptInterface compared with other state-of-the-art modeling languages."],"url":"http://arxiv.org/abs/2405.10130v1"}
{"created":"2024-05-16 14:28:01","title":"StyloAI: Distinguishing AI-Generated Content with Stylometric Analysis","abstract":"The emergence of large language models (LLMs) capable of generating realistic texts and images has sparked ethical concerns across various sectors. In response, researchers in academia and industry are actively exploring methods to distinguish AI-generated content from human-authored material. However, a crucial question remains: What are the unique characteristics of AI-generated text? Addressing this gap, this study proposes StyloAI, a data-driven model that uses 31 stylometric features to identify AI-generated texts by applying a Random Forest classifier on two multi-domain datasets. StyloAI achieves accuracy rates of 81% and 98% on the test set of the AuTextification dataset and the Education dataset, respectively. This approach surpasses the performance of existing state-of-the-art models and provides valuable insights into the differences between AI-generated and human-authored texts.","sentences":["The emergence of large language models (LLMs) capable of generating realistic texts and images has sparked ethical concerns across various sectors.","In response, researchers in academia and industry are actively exploring methods to distinguish AI-generated content from human-authored material.","However, a crucial question remains: What are the unique characteristics of AI-generated text?","Addressing this gap, this study proposes StyloAI, a data-driven model that uses 31 stylometric features to identify AI-generated texts by applying a Random Forest classifier on two multi-domain datasets.","StyloAI achieves accuracy rates of 81% and 98% on the test set of the AuTextification dataset and the Education dataset, respectively.","This approach surpasses the performance of existing state-of-the-art models and provides valuable insights into the differences between AI-generated and human-authored texts."],"url":"http://arxiv.org/abs/2405.10129v1"}
{"created":"2024-05-16 14:27:32","title":"Red Teaming Language Models for Contradictory Dialogues","abstract":"Most language models currently available are prone to self-contradiction during dialogues. To mitigate this issue, this study explores a novel contradictory dialogue processing task that aims to detect and modify contradictory statements in a conversation. This task is inspired by research on context faithfulness and dialogue comprehension, which have demonstrated that the detection and understanding of contradictions often necessitate detailed explanations. We develop a dataset comprising contradictory dialogues, in which one side of the conversation contradicts itself. Each dialogue is accompanied by an explanatory label that highlights the location and details of the contradiction. With this dataset, we present a Red Teaming framework for contradictory dialogue processing. The framework detects and attempts to explain the dialogue, then modifies the existing contradictory content using the explanation. Our experiments demonstrate that the framework improves the ability to detect contradictory dialogues and provides valid explanations. Additionally, it showcases distinct capabilities for modifying such dialogues. Our study highlights the importance of the logical inconsistency problem in conversational AI.","sentences":["Most language models currently available are prone to self-contradiction during dialogues.","To mitigate this issue, this study explores a novel contradictory dialogue processing task that aims to detect and modify contradictory statements in a conversation.","This task is inspired by research on context faithfulness and dialogue comprehension, which have demonstrated that the detection and understanding of contradictions often necessitate detailed explanations.","We develop a dataset comprising contradictory dialogues, in which one side of the conversation contradicts itself.","Each dialogue is accompanied by an explanatory label that highlights the location and details of the contradiction.","With this dataset, we present a Red Teaming framework for contradictory dialogue processing.","The framework detects and attempts to explain the dialogue, then modifies the existing contradictory content using the explanation.","Our experiments demonstrate that the framework improves the ability to detect contradictory dialogues and provides valid explanations.","Additionally, it showcases distinct capabilities for modifying such dialogues.","Our study highlights the importance of the logical inconsistency problem in conversational AI."],"url":"http://arxiv.org/abs/2405.10128v1"}
{"created":"2024-05-16 14:22:54","title":"Smoothing Linear Codes by R\u00e9nyi Divergence and Applications to Security Reduction","abstract":"The concept of the smoothing parameter plays a crucial role in both lattice-based and code-based cryptography, primarily due to its effectiveness in achieving nearly uniform distributions through the addition of noise. Recent research by Pathegama and Barg has determined the optimal smoothing bound for random codes under R\\'enyi Divergence for any order $\\alpha \\in (1, \\infty)$ \\cite{pathegama2024r}. Considering the inherent complexity of encoding/decoding algorithms in random codes, our research introduces enhanced structural elements into these coding schemes. Specifically, this paper presents a novel derivation of the smoothing bound for random linear codes, maintaining the same order of R\\'enyi Divergence and achieving optimality for any $\\alpha\\in (1,\\infty)$. We extend this framework under KL Divergence by transitioning from random linear codes to random self-dual codes, and subsequently to random quasi-cyclic codes, incorporating progressively more structures. As an application, we derive an average-case to average-case reduction from the Learning Parity with Noise (LPN) problem to the average-case decoding problem. This reduction aligns with the parameter regime in \\cite{debris2022worst}, but uniquely employs R\\'enyi divergence and directly considers Bernoulli noise, instead of combining ball noise and Bernoulli noise.","sentences":["The concept of the smoothing parameter plays a crucial role in both lattice-based and code-based cryptography, primarily due to its effectiveness in achieving nearly uniform distributions through the addition of noise.","Recent research by Pathegama and Barg has determined the optimal smoothing bound for random codes under R\\'enyi Divergence for any order $\\alpha \\in (1, \\infty)$ \\cite{pathegama2024r}.","Considering the inherent complexity of encoding/decoding algorithms in random codes, our research introduces enhanced structural elements into these coding schemes.","Specifically, this paper presents a novel derivation of the smoothing bound for random linear codes, maintaining the same order of R\\'enyi Divergence and achieving optimality for any $\\alpha\\in (1,\\infty)$. We extend this framework under KL Divergence by transitioning from random linear codes to random self-dual codes, and subsequently to random quasi-cyclic codes, incorporating progressively more structures.","As an application, we derive an average-case to average-case reduction from the Learning Parity with Noise (LPN) problem to the average-case decoding problem.","This reduction aligns with the parameter regime in \\cite{debris2022worst}, but uniquely employs R\\'enyi divergence and directly considers Bernoulli noise, instead of combining ball noise and Bernoulli noise."],"url":"http://arxiv.org/abs/2405.10124v1"}
{"created":"2024-05-16 14:22:49","title":"Asynchronous Federated Stochastic Optimization with Exact Averaging for Heterogeneous Local Objectives","abstract":"Federated learning (FL) was recently proposed to securely train models with data held over multiple locations (\"clients\") under the coordination of a central server. Two major challenges hindering the performance of FL algorithms are long training times caused by straggling clients and a decrease in training accuracy induced by non-iid local distributions (\"client drift\"). In this work we propose and analyze AREA, a new stochastic (sub)gradient algorithm that is robust to client drift and utilizes asynchronous communication to speed up convergence in the presence of stragglers. Moreover, AREA is, to the best of our knowledge, the first method that is both guaranteed to converge under arbitrarily long delays, and converges to an error neighborhood whose size depends only on the variance of the stochastic (sub)gradients used and thus is independent of both the heterogeneity between the local datasets and the length of client delays, without the use of delay-adaptive stepsizes. Our numerical results confirm our theoretical analysis and suggest that AREA outperforms state-of-the-art methods when local data are highly non-iid.","sentences":["Federated learning (FL) was recently proposed to securely train models with data held over multiple locations (\"clients\") under the coordination of a central server.","Two major challenges hindering the performance of FL algorithms are long training times caused by straggling clients and a decrease in training accuracy induced by non-iid local distributions (\"client drift\").","In this work we propose and analyze AREA, a new stochastic (sub)gradient algorithm that is robust to client drift and utilizes asynchronous communication to speed up convergence in the presence of stragglers.","Moreover, AREA is, to the best of our knowledge, the first method that is both guaranteed to converge under arbitrarily long delays, and converges to an error neighborhood whose size depends only on the variance of the stochastic (sub)gradients used and thus is independent of both the heterogeneity between the local datasets and the length of client delays, without the use of delay-adaptive stepsizes.","Our numerical results confirm our theoretical analysis and suggest that AREA outperforms state-of-the-art methods when local data are highly non-iid."],"url":"http://arxiv.org/abs/2405.10123v1"}
{"created":"2024-05-16 14:22:20","title":"Generating Coherent Sequences of Visual Illustrations for Real-World Manual Tasks","abstract":"Multistep instructions, such as recipes and how-to guides, greatly benefit from visual aids, such as a series of images that accompany the instruction steps. While Large Language Models (LLMs) have become adept at generating coherent textual steps, Large Vision/Language Models (LVLMs) are less capable of generating accompanying image sequences. The most challenging aspect is that each generated image needs to adhere to the relevant textual step instruction, as well as be visually consistent with earlier images in the sequence. To address this problem, we propose an approach for generating consistent image sequences, which integrates a Latent Diffusion Model (LDM) with an LLM to transform the sequence into a caption to maintain the semantic coherence of the sequence. In addition, to maintain the visual coherence of the image sequence, we introduce a copy mechanism to initialise reverse diffusion processes with a latent vector iteration from a previously generated image from a relevant step. Both strategies will condition the reverse diffusion process on the sequence of instruction steps and tie the contents of the current image to previous instruction steps and corresponding images. Experiments show that the proposed approach is preferred by humans in 46.6% of the cases against 26.6% for the second best method. In addition, automatic metrics showed that the proposed method maintains semantic coherence and visual consistency across steps in both domains.","sentences":["Multistep instructions, such as recipes and how-to guides, greatly benefit from visual aids, such as a series of images that accompany the instruction steps.","While Large Language Models (LLMs) have become adept at generating coherent textual steps, Large Vision/Language Models (LVLMs) are less capable of generating accompanying image sequences.","The most challenging aspect is that each generated image needs to adhere to the relevant textual step instruction, as well as be visually consistent with earlier images in the sequence.","To address this problem, we propose an approach for generating consistent image sequences, which integrates a Latent Diffusion Model (LDM) with an LLM to transform the sequence into a caption to maintain the semantic coherence of the sequence.","In addition, to maintain the visual coherence of the image sequence, we introduce a copy mechanism to initialise reverse diffusion processes with a latent vector iteration from a previously generated image from a relevant step.","Both strategies will condition the reverse diffusion process on the sequence of instruction steps and tie the contents of the current image to previous instruction steps and corresponding images.","Experiments show that the proposed approach is preferred by humans in 46.6% of the cases against 26.6% for the second best method.","In addition, automatic metrics showed that the proposed method maintains semantic coherence and visual consistency across steps in both domains."],"url":"http://arxiv.org/abs/2405.10122v1"}
{"created":"2024-05-16 14:21:33","title":"Distilling Implicit Multimodal Knowledge into LLMs for Zero-Resource Dialogue Generation","abstract":"Integrating multimodal knowledge into large language models (LLMs) represents a significant advancement in dialogue generation capabilities. However, the effective incorporation of such knowledge in zero-resource scenarios remains a substantial challenge due to the scarcity of diverse, high-quality dialogue datasets. To address this, we propose the Visual Implicit Knowledge Distillation Framework (VIKDF), an innovative approach aimed at enhancing LLMs for enriched dialogue generation in zero-resource contexts by leveraging implicit multimodal knowledge. VIKDF comprises two main stages: knowledge distillation, using an Implicit Query Transformer to extract and encode visual implicit knowledge from image-text pairs into knowledge vectors; and knowledge integration, employing a novel Bidirectional Variational Information Fusion technique to seamlessly integrate these distilled vectors into LLMs. This enables the LLMs to generate dialogues that are not only coherent and engaging but also exhibit a deep understanding of the context through implicit multimodal cues, effectively overcoming the limitations of zero-resource scenarios. Our extensive experimentation across two dialogue datasets shows that VIKDF outperforms existing state-of-the-art models in generating high-quality dialogues. The code will be publicly available following acceptance.","sentences":["Integrating multimodal knowledge into large language models (LLMs) represents a significant advancement in dialogue generation capabilities.","However, the effective incorporation of such knowledge in zero-resource scenarios remains a substantial challenge due to the scarcity of diverse, high-quality dialogue datasets.","To address this, we propose the Visual Implicit Knowledge Distillation Framework (VIKDF), an innovative approach aimed at enhancing LLMs for enriched dialogue generation in zero-resource contexts by leveraging implicit multimodal knowledge.","VIKDF comprises two main stages: knowledge distillation, using an Implicit Query Transformer to extract and encode visual implicit knowledge from image-text pairs into knowledge vectors; and knowledge integration, employing a novel Bidirectional Variational Information Fusion technique to seamlessly integrate these distilled vectors into LLMs.","This enables the LLMs to generate dialogues that are not only coherent and engaging but also exhibit a deep understanding of the context through implicit multimodal cues, effectively overcoming the limitations of zero-resource scenarios.","Our extensive experimentation across two dialogue datasets shows that VIKDF outperforms existing state-of-the-art models in generating high-quality dialogues.","The code will be publicly available following acceptance."],"url":"http://arxiv.org/abs/2405.10121v1"}
