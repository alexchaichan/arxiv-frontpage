{"created":"2024-04-29 17:59:41","title":"Hallucination of Multimodal Large Language Models: A Survey","abstract":"This survey presents a comprehensive analysis of the phenomenon of hallucination in multimodal large language models (MLLMs), also known as Large Vision-Language Models (LVLMs), which have demonstrated significant advancements and remarkable abilities in multimodal tasks. Despite these promising developments, MLLMs often generate outputs that are inconsistent with the visual content, a challenge known as hallucination, which poses substantial obstacles to their practical deployment and raises concerns regarding their reliability in real-world applications. This problem has attracted increasing attention, prompting efforts to detect and mitigate such inaccuracies. We review recent advances in identifying, evaluating, and mitigating these hallucinations, offering a detailed overview of the underlying causes, evaluation benchmarks, metrics, and strategies developed to address this issue. Additionally, we analyze the current challenges and limitations, formulating open questions that delineate potential pathways for future research. By drawing the granular classification and landscapes of hallucination causes, evaluation benchmarks, and mitigation methods, this survey aims to deepen the understanding of hallucinations in MLLMs and inspire further advancements in the field. Through our thorough and in-depth review, we contribute to the ongoing dialogue on enhancing the robustness and reliability of MLLMs, providing valuable insights and resources for researchers and practitioners alike. Resources are available at: https://github.com/showlab/Awesome-MLLM-Hallucination.","sentences":["This survey presents a comprehensive analysis of the phenomenon of hallucination in multimodal large language models (MLLMs), also known as Large Vision-Language Models (LVLMs), which have demonstrated significant advancements and remarkable abilities in multimodal tasks.","Despite these promising developments, MLLMs often generate outputs that are inconsistent with the visual content, a challenge known as hallucination, which poses substantial obstacles to their practical deployment and raises concerns regarding their reliability in real-world applications.","This problem has attracted increasing attention, prompting efforts to detect and mitigate such inaccuracies.","We review recent advances in identifying, evaluating, and mitigating these hallucinations, offering a detailed overview of the underlying causes, evaluation benchmarks, metrics, and strategies developed to address this issue.","Additionally, we analyze the current challenges and limitations, formulating open questions that delineate potential pathways for future research.","By drawing the granular classification and landscapes of hallucination causes, evaluation benchmarks, and mitigation methods, this survey aims to deepen the understanding of hallucinations in MLLMs and inspire further advancements in the field.","Through our thorough and in-depth review, we contribute to the ongoing dialogue on enhancing the robustness and reliability of MLLMs, providing valuable insights and resources for researchers and practitioners alike.","Resources are available at: https://github.com/showlab/Awesome-MLLM-Hallucination."],"url":"http://arxiv.org/abs/2404.18930v1"}
{"created":"2024-04-29 17:59:30","title":"DGE: Direct Gaussian 3D Editing by Consistent Multi-view Editing","abstract":"We consider the problem of editing 3D objects and scenes based on open-ended language instructions. The established paradigm to solve this problem is to use a 2D image generator or editor to guide the 3D editing process. However, this is often slow as it requires do update a computationally expensive 3D representations such as a neural radiance field, and to do so by using contradictory guidance from a 2D model which is inherently not multi-view consistent. We thus introduce the Direct Gaussian Editor (DGE), a method that addresses these issues in two ways. First, we modify a given high-quality image editor like InstructPix2Pix to be multi-view consistent. We do so by utilizing a training-free approach which integrates cues from the underlying 3D geometry of the scene. Second, given a multi-view consistent edited sequence of images of the object, we directly and efficiently optimize the 3D object representation, which is based on 3D Gaussian Splatting. Because it does not require to apply edits incrementally and iteratively, DGE is significantly more efficient than existing approaches, and comes with other perks such as allowing selective editing of parts of the scene.","sentences":["We consider the problem of editing 3D objects and scenes based on open-ended language instructions.","The established paradigm to solve this problem is to use a 2D image generator or editor to guide the 3D editing process.","However, this is often slow as it requires do update a computationally expensive 3D representations such as a neural radiance field, and to do so by using contradictory guidance from a 2D model which is inherently not multi-view consistent.","We thus introduce the Direct Gaussian Editor (DGE), a method that addresses these issues in two ways.","First, we modify a given high-quality image editor like InstructPix2Pix to be multi-view consistent.","We do so by utilizing a training-free approach which integrates cues from the underlying 3D geometry of the scene.","Second, given a multi-view consistent edited sequence of images of the object, we directly and efficiently optimize the 3D object representation, which is based on 3D Gaussian Splatting.","Because it does not require to apply edits incrementally and iteratively, DGE is significantly more efficient than existing approaches, and comes with other perks such as allowing selective editing of parts of the scene."],"url":"http://arxiv.org/abs/2404.18929v1"}
{"created":"2024-04-29 17:59:16","title":"Stylus: Automatic Adapter Selection for Diffusion Models","abstract":"Beyond scaling base models with more data or parameters, fine-tuned adapters provide an alternative way to generate high fidelity, custom images at reduced costs. As such, adapters have been widely adopted by open-source communities, accumulating a database of over 100K adapters-most of which are highly customized with insufficient descriptions. This paper explores the problem of matching the prompt to a set of relevant adapters, built on recent work that highlight the performance gains of composing adapters. We introduce Stylus, which efficiently selects and automatically composes task-specific adapters based on a prompt's keywords. Stylus outlines a three-stage approach that first summarizes adapters with improved descriptions and embeddings, retrieves relevant adapters, and then further assembles adapters based on prompts' keywords by checking how well they fit the prompt. To evaluate Stylus, we developed StylusDocs, a curated dataset featuring 75K adapters with pre-computed adapter embeddings. In our evaluation on popular Stable Diffusion checkpoints, Stylus achieves greater CLIP-FID Pareto efficiency and is twice as preferred, with humans and multimodal models as evaluators, over the base model. See stylus-diffusion.github.io for more.","sentences":["Beyond scaling base models with more data or parameters, fine-tuned adapters provide an alternative way to generate high fidelity, custom images at reduced costs.","As such, adapters have been widely adopted by open-source communities, accumulating a database of over 100K adapters-most of which are highly customized with insufficient descriptions.","This paper explores the problem of matching the prompt to a set of relevant adapters, built on recent work that highlight the performance gains of composing adapters.","We introduce Stylus, which efficiently selects and automatically composes task-specific adapters based on a prompt's keywords.","Stylus outlines a three-stage approach that first summarizes adapters with improved descriptions and embeddings, retrieves relevant adapters, and then further assembles adapters based on prompts' keywords by checking how well they fit the prompt.","To evaluate Stylus, we developed StylusDocs, a curated dataset featuring 75K adapters with pre-computed adapter embeddings.","In our evaluation on popular Stable Diffusion checkpoints, Stylus achieves greater CLIP-FID Pareto efficiency and is twice as preferred, with humans and multimodal models as evaluators, over the base model.","See stylus-diffusion.github.io for more."],"url":"http://arxiv.org/abs/2404.18928v1"}
{"created":"2024-04-29 17:59:11","title":"Point Cloud Models Improve Visual Robustness in Robotic Learners","abstract":"Visual control policies can encounter significant performance degradation when visual conditions like lighting or camera position differ from those seen during training -- often exhibiting sharp declines in capability even for minor differences. In this work, we examine robustness to a suite of these types of visual changes for RGB-D and point cloud based visual control policies. To perform these experiments on both model-free and model-based reinforcement learners, we introduce a novel Point Cloud World Model (PCWM) and point cloud based control policies. Our experiments show that policies that explicitly encode point clouds are significantly more robust than their RGB-D counterparts. Further, we find our proposed PCWM significantly outperforms prior works in terms of sample efficiency during training. Taken together, these results suggest reasoning about the 3D scene through point clouds can improve performance, reduce learning time, and increase robustness for robotic learners. Project Webpage: https://pvskand.github.io/projects/PCWM","sentences":["Visual control policies can encounter significant performance degradation when visual conditions like lighting or camera position differ from those seen during training -- often exhibiting sharp declines in capability even for minor differences.","In this work, we examine robustness to a suite of these types of visual changes for RGB-D and point cloud based visual control policies.","To perform these experiments on both model-free and model-based reinforcement learners, we introduce a novel Point Cloud World Model (PCWM) and point cloud based control policies.","Our experiments show that policies that explicitly encode point clouds are significantly more robust than their RGB-D counterparts.","Further, we find our proposed PCWM significantly outperforms prior works in terms of sample efficiency during training.","Taken together, these results suggest reasoning about the 3D scene through point clouds can improve performance, reduce learning time, and increase robustness for robotic learners.","Project Webpage: https://pvskand.github.io/projects/PCWM"],"url":"http://arxiv.org/abs/2404.18926v1"}
{"created":"2024-04-29 17:59:02","title":"Swin2-MoSE: A New Single Image Super-Resolution Model for Remote Sensing","abstract":"Due to the limitations of current optical and sensor technologies and the high cost of updating them, the spectral and spatial resolution of satellites may not always meet desired requirements. For these reasons, Remote-Sensing Single-Image Super-Resolution (RS-SISR) techniques have gained significant interest. In this paper, we propose Swin2-MoSE model, an enhanced version of Swin2SR. Our model introduces MoE-SM, an enhanced Mixture-of-Experts (MoE) to replace the Feed-Forward inside all Transformer block. MoE-SM is designed with Smart-Merger, and new layer for merging the output of individual experts, and with a new way to split the work between experts, defining a new per-example strategy instead of the commonly used per-token one. Furthermore, we analyze how positional encodings interact with each other, demonstrating that per-channel bias and per-head bias can positively cooperate. Finally, we propose to use a combination of Normalized-Cross-Correlation (NCC) and Structural Similarity Index Measure (SSIM) losses, to avoid typical MSE loss limitations. Experimental results demonstrate that Swin2-MoSE outperforms SOTA by up to 0.377 ~ 0.958 dB (PSNR) on task of 2x, 3x and 4x resolution-upscaling (Sen2Venus and OLI2MSI datasets). We show the efficacy of Swin2-MoSE, applying it to a semantic segmentation task (SeasoNet dataset). Code and pretrained are available on https://github.com/IMPLabUniPr/swin2-mose/tree/official_code","sentences":["Due to the limitations of current optical and sensor technologies and the high cost of updating them, the spectral and spatial resolution of satellites may not always meet desired requirements.","For these reasons, Remote-Sensing Single-Image Super-Resolution (RS-SISR) techniques have gained significant interest.","In this paper, we propose Swin2-MoSE model, an enhanced version of Swin2SR.","Our model introduces MoE-SM, an enhanced Mixture-of-Experts (MoE) to replace the Feed-Forward inside all Transformer block.","MoE-SM is designed with Smart-Merger, and new layer for merging the output of individual experts, and with a new way to split the work between experts, defining a new per-example strategy instead of the commonly used per-token one.","Furthermore, we analyze how positional encodings interact with each other, demonstrating that per-channel bias and per-head bias can positively cooperate.","Finally, we propose to use a combination of Normalized-Cross-Correlation (NCC) and Structural Similarity Index Measure (SSIM) losses, to avoid typical MSE loss limitations.","Experimental results demonstrate that Swin2-MoSE outperforms SOTA by up to 0.377 ~ 0.958 dB (PSNR) on task of 2x, 3x and 4x resolution-upscaling (Sen2Venus and OLI2MSI datasets).","We show the efficacy of Swin2-MoSE, applying it to a semantic segmentation task (SeasoNet dataset).","Code and pretrained are available on https://github.com/IMPLabUniPr/swin2-mose/tree/official_code"],"url":"http://arxiv.org/abs/2404.18924v1"}
{"created":"2024-04-29 17:58:36","title":"Holmes: Benchmark the Linguistic Competence of Language Models","abstract":"We introduce Holmes, a benchmark to assess the linguistic competence of language models (LMs) - their ability to grasp linguistic phenomena. Unlike prior prompting-based evaluations, Holmes assesses the linguistic competence of LMs via their internal representations using classifier-based probing. In doing so, we disentangle specific phenomena (e.g., part-of-speech of words) from other cognitive abilities, like following textual instructions, and meet recent calls to assess LMs' linguistic competence in isolation. Composing Holmes, we review over 250 probing studies and feature more than 200 datasets to assess syntax, morphology, semantics, reasoning, and discourse phenomena. Analyzing over 50 LMs reveals that, aligned with known trends, their linguistic competence correlates with model size. However, surprisingly, model architecture and instruction tuning also significantly influence performance, particularly in morphology and syntax. Finally, we propose FlashHolmes, a streamlined version of Holmes designed to lower the high computation load while maintaining high-ranking precision.","sentences":["We introduce Holmes, a benchmark to assess the linguistic competence of language models (LMs) - their ability to grasp linguistic phenomena.","Unlike prior prompting-based evaluations, Holmes assesses the linguistic competence of LMs via their internal representations using classifier-based probing.","In doing so, we disentangle specific phenomena (e.g., part-of-speech of words) from other cognitive abilities, like following textual instructions, and meet recent calls to assess LMs' linguistic competence in isolation.","Composing Holmes, we review over 250 probing studies and feature more than 200 datasets to assess syntax, morphology, semantics, reasoning, and discourse phenomena.","Analyzing over 50 LMs reveals that, aligned with known trends, their linguistic competence correlates with model size.","However, surprisingly, model architecture and instruction tuning also significantly influence performance, particularly in morphology and syntax.","Finally, we propose FlashHolmes, a streamlined version of Holmes designed to lower the high computation load while maintaining high-ranking precision."],"url":"http://arxiv.org/abs/2404.18923v1"}
{"created":"2024-04-29 17:58:30","title":"DPO Meets PPO: Reinforced Token Optimization for RLHF","abstract":"In the classical Reinforcement Learning from Human Feedback (RLHF) framework, Proximal Policy Optimization (PPO) is employed to learn from sparse, sentence-level rewards -- a challenging scenario in traditional deep reinforcement learning. Despite the great successes of PPO in the alignment of state-of-the-art closed-source large language models (LLMs), its open-source implementation is still largely sub-optimal, as widely reported by numerous research studies. To address these issues, we introduce a framework that models RLHF problems as a Markov decision process (MDP), enabling the capture of fine-grained token-wise information. Furthermore, we provide theoretical insights that demonstrate the superiority of our MDP framework over the previous sentence-level bandit formulation. Under this framework, we introduce an algorithm, dubbed as Reinforced Token Optimization (\\texttt{RTO}), which learns the token-wise reward function from preference data and performs policy optimization based on this learned token-wise reward signal. Theoretically, \\texttt{RTO} is proven to have the capability of finding the near-optimal policy sample-efficiently. For its practical implementation, \\texttt{RTO} innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO, originally derived from sparse sentence rewards, surprisingly provides us with a token-wise characterization of response quality, which is seamlessly incorporated into our subsequent PPO training stage. Extensive real-world alignment experiments verify the effectiveness of the proposed approach.","sentences":["In the classical Reinforcement Learning from Human Feedback (RLHF) framework, Proximal Policy Optimization (PPO) is employed to learn from sparse, sentence-level rewards -- a challenging scenario in traditional deep reinforcement learning.","Despite the great successes of PPO in the alignment of state-of-the-art closed-source large language models (LLMs), its open-source implementation is still largely sub-optimal, as widely reported by numerous research studies.","To address these issues, we introduce a framework that models RLHF problems as a Markov decision process (MDP), enabling the capture of fine-grained token-wise information.","Furthermore, we provide theoretical insights that demonstrate the superiority of our MDP framework over the previous sentence-level bandit formulation.","Under this framework, we introduce an algorithm, dubbed as Reinforced Token Optimization (\\texttt{RTO}), which learns the token-wise reward function from preference data and performs policy optimization based on this learned token-wise reward signal.","Theoretically, \\texttt{RTO} is proven to have the capability of finding the near-optimal policy sample-efficiently.","For its practical implementation, \\texttt{RTO} innovatively integrates Direct Preference Optimization (DPO) and PPO.","DPO, originally derived from sparse sentence rewards, surprisingly provides us with a token-wise characterization of response quality, which is seamlessly incorporated into our subsequent PPO training stage.","Extensive real-world alignment experiments verify the effectiveness of the proposed approach."],"url":"http://arxiv.org/abs/2404.18922v1"}
{"created":"2024-04-29 17:58:14","title":"TheaterGen: Character Management with LLM for Consistent Multi-turn Image Generation","abstract":"Recent advances in diffusion models can generate high-quality and stunning images from text. However, multi-turn image generation, which is of high demand in real-world scenarios, still faces challenges in maintaining semantic consistency between images and texts, as well as contextual consistency of the same subject across multiple interactive turns. To address this issue, we introduce TheaterGen, a training-free framework that integrates large language models (LLMs) and text-to-image (T2I) models to provide the capability of multi-turn image generation. Within this framework, LLMs, acting as a \"Screenwriter\", engage in multi-turn interaction, generating and managing a standardized prompt book that encompasses prompts and layout designs for each character in the target image. Based on these, Theatergen generate a list of character images and extract guidance information, akin to the \"Rehearsal\". Subsequently, through incorporating the prompt book and guidance information into the reverse denoising process of T2I diffusion models, Theatergen generate the final image, as conducting the \"Final Performance\". With the effective management of prompt books and character images, TheaterGen significantly improves semantic and contextual consistency in synthesized images. Furthermore, we introduce a dedicated benchmark, CMIGBench (Consistent Multi-turn Image Generation Benchmark) with 8000 multi-turn instructions. Different from previous multi-turn benchmarks, CMIGBench does not define characters in advance. Both the tasks of story generation and multi-turn editing are included on CMIGBench for comprehensive evaluation. Extensive experimental results show that TheaterGen outperforms state-of-the-art methods significantly. It raises the performance bar of the cutting-edge Mini DALLE 3 model by 21% in average character-character similarity and 19% in average text-image similarity.","sentences":["Recent advances in diffusion models can generate high-quality and stunning images from text.","However, multi-turn image generation, which is of high demand in real-world scenarios, still faces challenges in maintaining semantic consistency between images and texts, as well as contextual consistency of the same subject across multiple interactive turns.","To address this issue, we introduce TheaterGen, a training-free framework that integrates large language models (LLMs) and text-to-image (T2I) models to provide the capability of multi-turn image generation.","Within this framework, LLMs, acting as a \"Screenwriter\", engage in multi-turn interaction, generating and managing a standardized prompt book that encompasses prompts and layout designs for each character in the target image.","Based on these, Theatergen generate a list of character images and extract guidance information, akin to the \"Rehearsal\".","Subsequently, through incorporating the prompt book and guidance information into the reverse denoising process of T2I diffusion models, Theatergen generate the final image, as conducting the \"Final Performance\".","With the effective management of prompt books and character images, TheaterGen significantly improves semantic and contextual consistency in synthesized images.","Furthermore, we introduce a dedicated benchmark, CMIGBench (Consistent Multi-turn Image Generation Benchmark) with 8000 multi-turn instructions.","Different from previous multi-turn benchmarks, CMIGBench does not define characters in advance.","Both the tasks of story generation and multi-turn editing are included on CMIGBench for comprehensive evaluation.","Extensive experimental results show that TheaterGen outperforms state-of-the-art methods significantly.","It raises the performance bar of the cutting-edge Mini DALLE 3 model by 21% in average character-character similarity and 19% in average text-image similarity."],"url":"http://arxiv.org/abs/2404.18919v1"}
{"created":"2024-04-29 17:53:54","title":"Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting","abstract":"Speculative decoding has demonstrated its effectiveness in accelerating the inference of large language models while maintaining a consistent sampling distribution. However, the conventional approach of training a separate draft model to achieve a satisfactory token acceptance rate can be costly. Drawing inspiration from early exiting, we propose a novel self-speculative decoding framework \\emph{Kangaroo}, which uses a fixed shallow sub-network as a self-draft model, with the remaining layers serving as the larger target model. We train a lightweight and efficient adapter module on top of the sub-network to bridge the gap between the sub-network and the full model's representation ability. It is noteworthy that the inference latency of the self-draft model may no longer be negligible compared to the large model, necessitating strategies to increase the token acceptance rate while minimizing the drafting steps of the small model. To address this challenge, we introduce an additional early exiting mechanism for generating draft tokens. Specifically, we halt the small model's subsequent prediction during the drafting phase once the confidence level for the current token falls below a certain threshold. Extensive experiments on the Spec-Bench demonstrate the effectiveness of Kangaroo. Under single-sequence verification, Kangaroo achieves speedups up to $1.68\\times$ on Spec-Bench, outperforming Medusa-1 with 88.7\\% fewer additional parameters (67M compared to 591M). The code for Kangaroo is available at https://github.com/Equationliu/Kangaroo.","sentences":["Speculative decoding has demonstrated its effectiveness in accelerating the inference of large language models while maintaining a consistent sampling distribution.","However, the conventional approach of training a separate draft model to achieve a satisfactory token acceptance rate can be costly.","Drawing inspiration from early exiting, we propose a novel self-speculative decoding framework \\emph{Kangaroo}, which uses a fixed shallow sub-network as a self-draft model, with the remaining layers serving as the larger target model.","We train a lightweight and efficient adapter module on top of the sub-network to bridge the gap between the sub-network and the full model's representation ability.","It is noteworthy that the inference latency of the self-draft model may no longer be negligible compared to the large model, necessitating strategies to increase the token acceptance rate while minimizing the drafting steps of the small model.","To address this challenge, we introduce an additional early exiting mechanism for generating draft tokens.","Specifically, we halt the small model's subsequent prediction during the drafting phase once the confidence level for the current token falls below a certain threshold.","Extensive experiments on the Spec-Bench demonstrate the effectiveness of Kangaroo.","Under single-sequence verification, Kangaroo achieves speedups up to $1.68\\times$ on Spec-Bench, outperforming Medusa-1 with 88.7\\% fewer additional parameters (67M compared to 591M).","The code for Kangaroo is available at https://github.com/Equationliu/Kangaroo."],"url":"http://arxiv.org/abs/2404.18911v1"}
{"created":"2024-04-29 17:51:47","title":"Sample-Efficient Robust Multi-Agent Reinforcement Learning in the Face of Environmental Uncertainty","abstract":"To overcome the sim-to-real gap in reinforcement learning (RL), learned policies must maintain robustness against environmental uncertainties. While robust RL has been widely studied in single-agent regimes, in multi-agent environments, the problem remains understudied -- despite the fact that the problems posed by environmental uncertainties are often exacerbated by strategic interactions. This work focuses on learning in distributionally robust Markov games (RMGs), a robust variant of standard Markov games, wherein each agent aims to learn a policy that maximizes its own worst-case performance when the deployed environment deviates within its own prescribed uncertainty set. This results in a set of robust equilibrium strategies for all agents that align with classic notions of game-theoretic equilibria. Assuming a non-adaptive sampling mechanism from a generative model, we propose a sample-efficient model-based algorithm (DRNVI) with finite-sample complexity guarantees for learning robust variants of various notions of game-theoretic equilibria. We also establish an information-theoretic lower bound for solving RMGs, which confirms the near-optimal sample complexity of DRNVI with respect to problem-dependent factors such as the size of the state space, the target accuracy, and the horizon length.","sentences":["To overcome the sim-to-real gap in reinforcement learning (RL), learned policies must maintain robustness against environmental uncertainties.","While robust RL has been widely studied in single-agent regimes, in multi-agent environments, the problem remains understudied -- despite the fact that the problems posed by environmental uncertainties are often exacerbated by strategic interactions.","This work focuses on learning in distributionally robust Markov games (RMGs), a robust variant of standard Markov games, wherein each agent aims to learn a policy that maximizes its own worst-case performance when the deployed environment deviates within its own prescribed uncertainty set.","This results in a set of robust equilibrium strategies for all agents that align with classic notions of game-theoretic equilibria.","Assuming a non-adaptive sampling mechanism from a generative model, we propose a sample-efficient model-based algorithm (DRNVI) with finite-sample complexity guarantees for learning robust variants of various notions of game-theoretic equilibria.","We also establish an information-theoretic lower bound for solving RMGs, which confirms the near-optimal sample complexity of DRNVI with respect to problem-dependent factors such as the size of the state space, the target accuracy, and the horizon length."],"url":"http://arxiv.org/abs/2404.18909v1"}
{"created":"2024-04-29 17:44:32","title":"On Clustering Induced Voronoi Diagrams","abstract":"In this paper, we study a generalization of the classical Voronoi diagram, called clustering induced Voronoi diagram (CIVD). Different from the traditional model, CIVD takes as its sites the power set $U$ of an input set $P$ of objects. For each subset $C$ of $P$, CIVD uses an influence function $F(C,q)$ to measure the total (or joint) influence of all objects in $C$ on an arbitrary point $q$ in the space $\\mathbb{R}^d$, and determines the influence-based Voronoi cell in $\\mathbb{R}^d$ for $C$. This generalized model offers a number of new features (e.g., simultaneous clustering and space partition) to Voronoi diagram which are useful in various new applications. We investigate the general conditions for the influence function which ensure the existence of a small-size (e.g., nearly linear) approximate CIVD for a set $P$ of $n$ points in $\\mathbb{R}^d$ for some fixed $d$. To construct CIVD, we first present a standalone new technique, called approximate influence (AI) decomposition, for the general CIVD problem. With only $O(n\\log n)$ time, the AI decomposition partitions the space $\\mathbb{R}^{d}$ into a nearly linear number of cells so that all points in each cell receive their approximate maximum influence from the same (possibly unknown) site (i.e., a subset of $P$). Based on this technique, we develop assignment algorithms to determine a proper site for each cell in the decomposition and form various $(1-\\epsilon)$-approximate CIVDs for some small fixed $\\epsilon>0$. Particularly, we consider two representative CIVD problems, vector CIVD and density-based CIVD, and show that both of them admit fast assignment algorithms; consequently, their $(1-\\epsilon)$-approximate CIVDs can be built in $O(n \\log^{\\max\\{3,d+1\\}}n)$ and $O(n \\log^{2} n)$ time, respectively.","sentences":["In this paper, we study a generalization of the classical Voronoi diagram, called clustering induced Voronoi diagram (CIVD).","Different from the traditional model, CIVD takes as its sites the power set $U$ of an input set $P$ of objects.","For each subset $C$ of $P$, CIVD uses an influence function $F(C,q)$ to measure the total (or joint) influence of all objects in $C$ on an arbitrary point $q$ in the space $\\mathbb{R}^d$, and determines the influence-based Voronoi cell in $\\mathbb{R}^d$ for $C$.","This generalized model offers a number of new features (e.g., simultaneous clustering and space partition) to Voronoi diagram which are useful in various new applications.","We investigate the general conditions for the influence function which ensure the existence of a small-size (e.g., nearly linear) approximate CIVD for a set $P$ of $n$ points in $\\mathbb{R}^d$ for some fixed $d$. To construct CIVD, we first present a standalone new technique, called approximate influence (AI) decomposition, for the general CIVD problem.","With only $O(n\\log n)$ time, the AI decomposition partitions the space $\\mathbb{R}^{d}$ into a nearly linear number of cells so that all points in each cell receive their approximate maximum influence from the same (possibly unknown) site (i.e., a subset of $P$).","Based on this technique, we develop assignment algorithms to determine a proper site for each cell in the decomposition and form various $(1-\\epsilon)$-approximate CIVDs for some small fixed $\\epsilon>0$. Particularly, we consider two representative CIVD problems, vector CIVD and density-based CIVD, and show that both of them admit fast assignment algorithms; consequently, their $(1-\\epsilon)$-approximate CIVDs can be built in $O(n \\log^{\\max\\{3,d+1\\}}n)$ and $O(n \\log^{2} n)$ time, respectively."],"url":"http://arxiv.org/abs/2404.18906v1"}
{"created":"2024-04-29 17:43:38","title":"On classes of bounded tree rank, their interpretations, and efficient sparsification","abstract":"Graph classes of bounded tree rank were introduced recently in the context of the model checking problem for first-order logic of graphs. These graph classes are a common generalization of graph classes of bounded degree and bounded treedepth, and they are a special case of graph classes of bounded expansion. We introduce a notion of decomposition for these classes and show that these decompositions can be efficiently computed. Also, a natural extension of our decomposition leads to a new characterization and decomposition for graph classes of bounded expansion (and an efficient algorithm computing this decomposition).   We then focus on interpretations of graph classes of bounded tree rank. We give a characterization of graph classes interpretable in graph classes of tree rank $2$. Importantly, our characterization leads to an efficient sparsification procedure: For any graph class $C$ interpretable in a efficiently bounded graph class of tree rank at most $2$, there is a polynomial time algorithm that to any $G \\in C$ computes a (sparse) graph $H$ from a fixed graph class of tree rank at most $2$ such that $G = I(H)$ for a fixed interpretation $I$. To the best of our knowledge, this is the first efficient \"interpretation reversal\" result that generalizes the result of Gajarsk\\'y et al. [LICS 2016], who showed an analogous result for graph classes interpretable in classes of graphs of bounded degree.","sentences":["Graph classes of bounded tree rank were introduced recently in the context of the model checking problem for first-order logic of graphs.","These graph classes are a common generalization of graph classes of bounded degree and bounded treedepth, and they are a special case of graph classes of bounded expansion.","We introduce a notion of decomposition for these classes and show that these decompositions can be efficiently computed.","Also, a natural extension of our decomposition leads to a new characterization and decomposition for graph classes of bounded expansion (and an efficient algorithm computing this decomposition).   ","We then focus on interpretations of graph classes of bounded tree rank.","We give a characterization of graph classes interpretable in graph classes of tree rank $2$. Importantly, our characterization leads to an efficient sparsification procedure: For any graph class $C$ interpretable in a efficiently bounded graph class of tree rank at most $2$, there is a polynomial time algorithm that to any $G \\in C$ computes a (sparse) graph $H$ from a fixed graph class of tree rank at most $2$ such that $G = I(H)$ for a fixed interpretation $I$. To the best of our knowledge, this is the first efficient \"interpretation reversal\" result that generalizes the result of Gajarsk\\'y et al.","[LICS 2016], who showed an analogous result for graph classes interpretable in classes of graphs of bounded degree."],"url":"http://arxiv.org/abs/2404.18904v1"}
{"created":"2024-04-29 17:33:52","title":"Overcoming Knowledge Barriers: Online Imitation Learning from Observation with Pretrained World Models","abstract":"Incorporating the successful paradigm of pretraining and finetuning from Computer Vision and Natural Language Processing into decision-making has become increasingly popular in recent years. In this paper, we study Imitation Learning from Observation with pretrained models and find existing approaches such as BCO and AIME face knowledge barriers, specifically the Embodiment Knowledge Barrier (EKB) and the Demonstration Knowledge Barrier (DKB), greatly limiting their performance. The EKB arises when pretrained models lack knowledge about unseen observations, leading to errors in action inference. The DKB results from policies trained on limited demonstrations, hindering adaptability to diverse scenarios. We thoroughly analyse the underlying mechanism of these barriers and propose AIME-v2 upon AIME as a solution. AIME-v2 uses online interactions with data-driven regulariser to alleviate the EKB and mitigates the DKB by introducing a surrogate reward function to enhance policy training. Experimental results on tasks from the DeepMind Control Suite and Meta-World benchmarks demonstrate the effectiveness of these modifications in improving both sample-efficiency and converged performance. The study contributes valuable insights into resolving knowledge barriers for enhanced decision-making in pretraining-based approaches. Code will be available at https://github.com/argmax-ai/aime-v2.","sentences":["Incorporating the successful paradigm of pretraining and finetuning from Computer Vision and Natural Language Processing into decision-making has become increasingly popular in recent years.","In this paper, we study Imitation Learning from Observation with pretrained models and find existing approaches such as BCO and AIME face knowledge barriers, specifically the Embodiment Knowledge Barrier (EKB) and the Demonstration Knowledge Barrier (DKB), greatly limiting their performance.","The EKB arises when pretrained models lack knowledge about unseen observations, leading to errors in action inference.","The DKB results from policies trained on limited demonstrations, hindering adaptability to diverse scenarios.","We thoroughly analyse the underlying mechanism of these barriers and propose AIME-v2 upon AIME as a solution.","AIME-v2 uses online interactions with data-driven regulariser to alleviate the EKB and mitigates the DKB by introducing a surrogate reward function to enhance policy training.","Experimental results on tasks from the DeepMind Control Suite and Meta-World benchmarks demonstrate the effectiveness of these modifications in improving both sample-efficiency and converged performance.","The study contributes valuable insights into resolving knowledge barriers for enhanced decision-making in pretraining-based approaches.","Code will be available at https://github.com/argmax-ai/aime-v2."],"url":"http://arxiv.org/abs/2404.18896v1"}
{"created":"2024-04-29 17:31:00","title":"RSCaMa: Remote Sensing Image Change Captioning with State Space Model","abstract":"Remote Sensing Image Change Captioning (RSICC) aims to identify surface changes in multi-temporal remote sensing images and describe them in natural language. Current methods typically rely on an encoder-decoder architecture and focus on designing a sophisticated neck to process bi-temporal features extracted by the backbone. Recently, State Space Models (SSMs), especially Mamba, have demonstrated outstanding performance in many fields, owing to their efficient feature-selective modelling capability. However, their potential in the RSICC task remains unexplored. In this paper, we introduce Mamba into RSICC and propose a novel approach called RSCaMa (Remote Sensing Change Captioning Mamba). Specifically, we utilize Siamese backbones to extract bi-temporal features, which are then processed through multiple CaMa layers consisting of Spatial Difference-guided SSM (SD-SSM) and Temporal Traveling SSM (TT-SSM). SD-SSM uses differential features to enhance change perception, while TT-SSM promotes bitemporal interactions in a token-wise cross-scanning manner. Experimental results validate the effectiveness of CaMa layers and demonstrate the superior performance of RSCaMa, as well as the potential of Mamba in the RSICC task. Additionally, we systematically compare the effects of three language decoders, including Mamba, GPT-style decoder with causal attention mechanism, and Transformer decoder with cross-attention mechanism. This provides valuable insights for future RSICC research. The code will be available at https://github.com/Chen-Yang-Liu/RSCaMa","sentences":["Remote Sensing Image Change Captioning (RSICC) aims to identify surface changes in multi-temporal remote sensing images and describe them in natural language.","Current methods typically rely on an encoder-decoder architecture and focus on designing a sophisticated neck to process bi-temporal features extracted by the backbone.","Recently, State Space Models (SSMs), especially Mamba, have demonstrated outstanding performance in many fields, owing to their efficient feature-selective modelling capability.","However, their potential in the RSICC task remains unexplored.","In this paper, we introduce Mamba into RSICC and propose a novel approach called RSCaMa","(Remote Sensing Change Captioning Mamba).","Specifically, we utilize Siamese backbones to extract bi-temporal features, which are then processed through multiple CaMa layers consisting of Spatial Difference-guided SSM (SD-SSM) and Temporal Traveling SSM (TT-SSM).","SD-SSM uses differential features to enhance change perception, while TT-SSM promotes bitemporal interactions in a token-wise cross-scanning manner.","Experimental results validate the effectiveness of CaMa layers and demonstrate the superior performance of RSCaMa, as well as the potential of Mamba in the RSICC task.","Additionally, we systematically compare the effects of three language decoders, including Mamba, GPT-style decoder with causal attention mechanism, and Transformer decoder with cross-attention mechanism.","This provides valuable insights for future RSICC research.","The code will be available at https://github.com/Chen-Yang-Liu/RSCaMa"],"url":"http://arxiv.org/abs/2404.18895v1"}
{"created":"2024-04-29 17:30:36","title":"Learning general Gaussian mixtures with efficient score matching","abstract":"We study the problem of learning mixtures of $k$ Gaussians in $d$ dimensions. We make no separation assumptions on the underlying mixture components: we only require that the covariance matrices have bounded condition number and that the means and covariances lie in a ball of bounded radius. We give an algorithm that draws $d^{\\mathrm{poly}(k/\\varepsilon)}$ samples from the target mixture, runs in sample-polynomial time, and constructs a sampler whose output distribution is $\\varepsilon$-far from the unknown mixture in total variation. Prior works for this problem either (i) required exponential runtime in the dimension $d$, (ii) placed strong assumptions on the instance (e.g., spherical covariances or clusterability), or (iii) had doubly exponential dependence on the number of components $k$.   Our approach departs from commonly used techniques for this problem like the method of moments. Instead, we leverage a recently developed reduction, based on diffusion models, from distribution learning to a supervised learning task called score matching. We give an algorithm for the latter by proving a structural result showing that the score function of a Gaussian mixture can be approximated by a piecewise-polynomial function, and there is an efficient algorithm for finding it. To our knowledge, this is the first example of diffusion models achieving a state-of-the-art theoretical guarantee for an unsupervised learning task.","sentences":["We study the problem of learning mixtures of $k$ Gaussians in $d$ dimensions.","We make no separation assumptions on the underlying mixture components: we only require that the covariance matrices have bounded condition number and that the means and covariances lie in a ball of bounded radius.","We give an algorithm that draws $d^{\\mathrm{poly}(k/\\varepsilon)}$ samples from the target mixture, runs in sample-polynomial time, and constructs a sampler whose output distribution is $\\varepsilon$-far from the unknown mixture in total variation.","Prior works for this problem either (i) required exponential runtime in the dimension $d$, (ii) placed strong assumptions on the instance (e.g., spherical covariances or clusterability), or (iii) had doubly exponential dependence on the number of components $k$.   Our approach departs from commonly used techniques for this problem like the method of moments.","Instead, we leverage a recently developed reduction, based on diffusion models, from distribution learning to a supervised learning task called score matching.","We give an algorithm for the latter by proving a structural result showing that the score function of a Gaussian mixture can be approximated by a piecewise-polynomial function, and there is an efficient algorithm for finding it.","To our knowledge, this is the first example of diffusion models achieving a state-of-the-art theoretical guarantee for an unsupervised learning task."],"url":"http://arxiv.org/abs/2404.18893v1"}
{"created":"2024-04-29 17:27:37","title":"IPixMatch: Boost Semi-supervised Semantic Segmentation with Inter-Pixel Relation","abstract":"The scarcity of labeled data in real-world scenarios is a critical bottleneck of deep learning's effectiveness. Semi-supervised semantic segmentation has been a typical solution to achieve a desirable tradeoff between annotation cost and segmentation performance. However, previous approaches, whether based on consistency regularization or self-training, tend to neglect the contextual knowledge embedded within inter-pixel relations. This negligence leads to suboptimal performance and limited generalization. In this paper, we propose a novel approach IPixMatch designed to mine the neglected but valuable Inter-Pixel information for semi-supervised learning. Specifically, IPixMatch is constructed as an extension of the standard teacher-student network, incorporating additional loss terms to capture inter-pixel relations. It shines in low-data regimes by efficiently leveraging the limited labeled data and extracting maximum utility from the available unlabeled data. Furthermore, IPixMatch can be integrated seamlessly into most teacher-student frameworks without the need of model modification or adding additional components. Our straightforward IPixMatch method demonstrates consistent performance improvements across various benchmark datasets under different partitioning protocols.","sentences":["The scarcity of labeled data in real-world scenarios is a critical bottleneck of deep learning's effectiveness.","Semi-supervised semantic segmentation has been a typical solution to achieve a desirable tradeoff between annotation cost and segmentation performance.","However, previous approaches, whether based on consistency regularization or self-training, tend to neglect the contextual knowledge embedded within inter-pixel relations.","This negligence leads to suboptimal performance and limited generalization.","In this paper, we propose a novel approach IPixMatch designed to mine the neglected but valuable Inter-Pixel information for semi-supervised learning.","Specifically, IPixMatch is constructed as an extension of the standard teacher-student network, incorporating additional loss terms to capture inter-pixel relations.","It shines in low-data regimes by efficiently leveraging the limited labeled data and extracting maximum utility from the available unlabeled data.","Furthermore, IPixMatch can be integrated seamlessly into most teacher-student frameworks without the need of model modification or adding additional components.","Our straightforward IPixMatch method demonstrates consistent performance improvements across various benchmark datasets under different partitioning protocols."],"url":"http://arxiv.org/abs/2404.18891v1"}
{"created":"2024-04-29 17:27:08","title":"Hide and Seek: How Does Watermarking Impact Face Recognition?","abstract":"The recent progress in generative models has revolutionized the synthesis of highly realistic images, including face images. This technological development has undoubtedly helped face recognition, such as training data augmentation for higher recognition accuracy and data privacy. However, it has also introduced novel challenges concerning the responsible use and proper attribution of computer generated images. We investigate the impact of digital watermarking, a technique for embedding ownership signatures into images, on the effectiveness of face recognition models. We propose a comprehensive pipeline that integrates face image generation, watermarking, and face recognition to systematically examine this question. The proposed watermarking scheme, based on an encoder-decoder architecture, successfully embeds and recovers signatures from both real and synthetic face images while preserving their visual fidelity. Through extensive experiments, we unveil that while watermarking enables robust image attribution, it results in a slight decline in face recognition accuracy, particularly evident for face images with challenging poses and expressions. Additionally, we find that directly training face recognition models on watermarked images offers only a limited alleviation of this performance decline. Our findings underscore the intricate trade off between watermarking and face recognition accuracy. This work represents a pivotal step towards the responsible utilization of generative models in face recognition and serves to initiate discussions regarding the broader implications of watermarking in biometrics.","sentences":["The recent progress in generative models has revolutionized the synthesis of highly realistic images, including face images.","This technological development has undoubtedly helped face recognition, such as training data augmentation for higher recognition accuracy and data privacy.","However, it has also introduced novel challenges concerning the responsible use and proper attribution of computer generated images.","We investigate the impact of digital watermarking, a technique for embedding ownership signatures into images, on the effectiveness of face recognition models.","We propose a comprehensive pipeline that integrates face image generation, watermarking, and face recognition to systematically examine this question.","The proposed watermarking scheme, based on an encoder-decoder architecture, successfully embeds and recovers signatures from both real and synthetic face images while preserving their visual fidelity.","Through extensive experiments, we unveil that while watermarking enables robust image attribution, it results in a slight decline in face recognition accuracy, particularly evident for face images with challenging poses and expressions.","Additionally, we find that directly training face recognition models on watermarked images offers only a limited alleviation of this performance decline.","Our findings underscore the intricate trade off between watermarking and face recognition accuracy.","This work represents a pivotal step towards the responsible utilization of generative models in face recognition and serves to initiate discussions regarding the broader implications of watermarking in biometrics."],"url":"http://arxiv.org/abs/2404.18890v1"}
{"created":"2024-04-29 17:21:18","title":"PrescientFuzz: A more effective exploration approach for grey-box fuzzing","abstract":"In this paper, we introduce an approach for improving the early exploration of grey-box fuzzing campaigns; allowing the fuzzer to reach the interesting coverage earlier. To do this, it leverages information from the system under test's (SUT's) control flow graph in order to decide which inputs are likely to lead to discovering most coverage when mutated.","sentences":["In this paper, we introduce an approach for improving the early exploration of grey-box fuzzing campaigns; allowing the fuzzer to reach the interesting coverage earlier.","To do this, it leverages information from the system under test's (SUT's) control flow graph in order to decide which inputs are likely to lead to discovering most coverage when mutated."],"url":"http://arxiv.org/abs/2404.18887v1"}
{"created":"2024-04-29 17:19:40","title":"A Survey on Diffusion Models for Time Series and Spatio-Temporal Data","abstract":"The study of time series data is crucial for understanding trends and anomalies over time, enabling predictive insights across various sectors. Spatio-temporal data, on the other hand, is vital for analyzing phenomena in both space and time, providing a dynamic perspective on complex system interactions. Recently, diffusion models have seen widespread application in time series and spatio-temporal data mining. Not only do they enhance the generative and inferential capabilities for sequential and temporal data, but they also extend to other downstream tasks. In this survey, we comprehensively and thoroughly review the use of diffusion models in time series and spatio-temporal data, categorizing them by model category, task type, data modality, and practical application domain. In detail, we categorize diffusion models into unconditioned and conditioned types and discuss time series data and spatio-temporal data separately. Unconditioned models, which operate unsupervised, are subdivided into probability-based and score-based models, serving predictive and generative tasks such as forecasting, anomaly detection, classification, and imputation. Conditioned models, on the other hand, utilize extra information to enhance performance and are similarly divided for both predictive and generative tasks. Our survey extensively covers their application in various fields, including healthcare, recommendation, climate, energy, audio, and transportation, providing a foundational understanding of how these models analyze and generate data. Through this structured overview, we aim to provide researchers and practitioners with a comprehensive understanding of diffusion models for time series and spatio-temporal data analysis, aiming to direct future innovations and applications by addressing traditional challenges and exploring innovative solutions within the diffusion model framework.","sentences":["The study of time series data is crucial for understanding trends and anomalies over time, enabling predictive insights across various sectors.","Spatio-temporal data, on the other hand, is vital for analyzing phenomena in both space and time, providing a dynamic perspective on complex system interactions.","Recently, diffusion models have seen widespread application in time series and spatio-temporal data mining.","Not only do they enhance the generative and inferential capabilities for sequential and temporal data, but they also extend to other downstream tasks.","In this survey, we comprehensively and thoroughly review the use of diffusion models in time series and spatio-temporal data, categorizing them by model category, task type, data modality, and practical application domain.","In detail, we categorize diffusion models into unconditioned and conditioned types and discuss time series data and spatio-temporal data separately.","Unconditioned models, which operate unsupervised, are subdivided into probability-based and score-based models, serving predictive and generative tasks such as forecasting, anomaly detection, classification, and imputation.","Conditioned models, on the other hand, utilize extra information to enhance performance and are similarly divided for both predictive and generative tasks.","Our survey extensively covers their application in various fields, including healthcare, recommendation, climate, energy, audio, and transportation, providing a foundational understanding of how these models analyze and generate data.","Through this structured overview, we aim to provide researchers and practitioners with a comprehensive understanding of diffusion models for time series and spatio-temporal data analysis, aiming to direct future innovations and applications by addressing traditional challenges and exploring innovative solutions within the diffusion model framework."],"url":"http://arxiv.org/abs/2404.18886v1"}
{"created":"2024-04-29 17:16:27","title":"Human-in-the-Loop Synthetic Text Data Inspection with Provenance Tracking","abstract":"Data augmentation techniques apply transformations to existing texts to generate additional data. The transformations may produce low-quality texts, where the meaning of the text is changed and the text may even be mangled beyond human comprehension. Analyzing the synthetically generated texts and their corresponding labels is slow and demanding. To winnow out texts with incorrect labels, we develop INSPECTOR, a human-in-the-loop data inspection technique. INSPECTOR combines the strengths of provenance tracking techniques with assistive labeling. INSPECTOR allows users to group related texts by their transformation provenance, i.e., the transformations applied to the original text, or feature provenance, the linguistic features of the original text. For assistive labeling, INSPECTOR computes metrics that approximate data quality, and allows users to compare the corresponding label of each text against the predictions of a large language model. In a user study, INSPECTOR increases the number of texts with correct labels identified by 3X on a sentiment analysis task and by 4X on a hate speech detection task. The participants found grouping the synthetically generated texts by their common transformation to be the most useful technique. Surprisingly, grouping texts by common linguistic features was perceived to be unhelpful. Contrary to prior work, our study finds that no single technique obviates the need for human inspection effort. This validates the design of INSPECTOR which combines both analysis of data provenance and assistive labeling to reduce human inspection effort.","sentences":["Data augmentation techniques apply transformations to existing texts to generate additional data.","The transformations may produce low-quality texts, where the meaning of the text is changed and the text may even be mangled beyond human comprehension.","Analyzing the synthetically generated texts and their corresponding labels is slow and demanding.","To winnow out texts with incorrect labels, we develop INSPECTOR, a human-in-the-loop data inspection technique.","INSPECTOR combines the strengths of provenance tracking techniques with assistive labeling.","INSPECTOR allows users to group related texts by their transformation provenance, i.e., the transformations applied to the original text, or feature provenance, the linguistic features of the original text.","For assistive labeling, INSPECTOR computes metrics that approximate data quality, and allows users to compare the corresponding label of each text against the predictions of a large language model.","In a user study, INSPECTOR increases the number of texts with correct labels identified by 3X on a sentiment analysis task and by 4X on a hate speech detection task.","The participants found grouping the synthetically generated texts by their common transformation to be the most useful technique.","Surprisingly, grouping texts by common linguistic features was perceived to be unhelpful.","Contrary to prior work, our study finds that no single technique obviates the need for human inspection effort.","This validates the design of INSPECTOR which combines both analysis of data provenance and assistive labeling to reduce human inspection effort."],"url":"http://arxiv.org/abs/2404.18881v1"}
{"created":"2024-04-29 17:16:22","title":"Spivavtor: An Instruction Tuned Ukrainian Text Editing Model","abstract":"We introduce Spivavtor, a dataset, and instruction-tuned models for text editing focused on the Ukrainian language. Spivavtor is the Ukrainian-focused adaptation of the English-only CoEdIT model. Similar to CoEdIT, Spivavtor performs text editing tasks by following instructions in Ukrainian. This paper describes the details of the Spivavtor-Instruct dataset and Spivavtor models. We evaluate Spivavtor on a variety of text editing tasks in Ukrainian, such as Grammatical Error Correction (GEC), Text Simplification, Coherence, and Paraphrasing, and demonstrate its superior performance on all of them. We publicly release our best-performing models and data as resources to the community to advance further research in this space.","sentences":["We introduce Spivavtor, a dataset, and instruction-tuned models for text editing focused on the Ukrainian language.","Spivavtor is the Ukrainian-focused adaptation of the English-only CoEdIT model.","Similar to CoEdIT, Spivavtor performs text editing tasks by following instructions in Ukrainian.","This paper describes the details of the Spivavtor-Instruct dataset and Spivavtor models.","We evaluate Spivavtor on a variety of text editing tasks in Ukrainian, such as Grammatical Error Correction (GEC), Text Simplification, Coherence, and Paraphrasing, and demonstrate its superior performance on all of them.","We publicly release our best-performing models and data as resources to the community to advance further research in this space."],"url":"http://arxiv.org/abs/2404.18880v1"}
{"created":"2024-04-29 17:10:41","title":"A Multilevel Strategy to Improve People Tracking in a Real-World Scenario","abstract":"The Pal\\'acio do Planalto, office of the President of Brazil, was invaded by protesters on January 8, 2023. Surveillance videos taken from inside the building were subsequently released by the Brazilian Supreme Court for public scrutiny. We used segments of such footage to create the UFPR-Planalto801 dataset for people tracking and re-identification in a real-world scenario. This dataset consists of more than 500,000 images. This paper presents a tracking approach targeting this dataset. The method proposed in this paper relies on the use of known state-of-the-art trackers combined in a multilevel hierarchy to correct the ID association over the trajectories. We evaluated our method using IDF1, MOTA, MOTP and HOTA metrics. The results show improvements for every tracker used in the experiments, with IDF1 score increasing by a margin up to 9.5%.","sentences":["The Pal\\'acio do Planalto, office of the President of Brazil, was invaded by protesters on January 8, 2023.","Surveillance videos taken from inside the building were subsequently released by the Brazilian Supreme Court for public scrutiny.","We used segments of such footage to create the UFPR-Planalto801 dataset for people tracking and re-identification in a real-world scenario.","This dataset consists of more than 500,000 images.","This paper presents a tracking approach targeting this dataset.","The method proposed in this paper relies on the use of known state-of-the-art trackers combined in a multilevel hierarchy to correct the ID association over the trajectories.","We evaluated our method using IDF1, MOTA, MOTP and HOTA metrics.","The results show improvements for every tracker used in the experiments, with IDF1 score increasing by a margin up to 9.5%."],"url":"http://arxiv.org/abs/2404.18876v1"}
{"created":"2024-04-29 17:08:15","title":"The Essense of Useful Evaluation Through Quantitative Types (Extended Version)","abstract":"Several evaluation notions for lambda calculus qualify as reasonable cost models according to Slot and van Emde Boas' Invariance Thesis. A notable result achieved by Accattoli and Dal Lago is that leftmost-outermost reduction is reasonable, where the term representation uses sharing and the steps are useful. These results, initially studied in call-by-name, have also been extended to call-by-value. However, the existing formulations of usefulness lack inductive structure, making it challenging in particular to define and reason about type systems on top of the untyped syntax. Additionally, no type-based quantitative interpretations exist for useful evaluation. In this work, we establish the first inductive definition of useful evaluation for open weak call-by-value. This new useful strategy connects to a previous implementation of usefulness through a low-level abstract machine, incurring only in linear time overhead, thus providing a reasonable cost model for open call-by-value implementation. We also propose a semantic interpretation of useful call-by-value using a non-idempotent intersection type system equipped with a notion of tightness. The resulting interpretation is quantitative, i.e. provides exact step-count information for program evaluation. This turns out to be the first semantical interpretation in the literature for a notion of useful evaluation.","sentences":["Several evaluation notions for lambda calculus qualify as reasonable cost models according to Slot and van Emde Boas' Invariance Thesis.","A notable result achieved by Accattoli and Dal Lago is that leftmost-outermost reduction is reasonable, where the term representation uses sharing and the steps are useful.","These results, initially studied in call-by-name, have also been extended to call-by-value.","However, the existing formulations of usefulness lack inductive structure, making it challenging in particular to define and reason about type systems on top of the untyped syntax.","Additionally, no type-based quantitative interpretations exist for useful evaluation.","In this work, we establish the first inductive definition of useful evaluation for open weak call-by-value.","This new useful strategy connects to a previous implementation of usefulness through a low-level abstract machine, incurring only in linear time overhead, thus providing a reasonable cost model for open call-by-value implementation.","We also propose a semantic interpretation of useful call-by-value using a non-idempotent intersection type system equipped with a notion of tightness.","The resulting interpretation is quantitative, i.e. provides exact step-count information for program evaluation.","This turns out to be the first semantical interpretation in the literature for a notion of useful evaluation."],"url":"http://arxiv.org/abs/2404.18874v1"}
{"created":"2024-04-29 17:06:44","title":"OpenStreetView-5M: The Many Roads to Global Visual Geolocation","abstract":"Determining the location of an image anywhere on Earth is a complex visual task, which makes it particularly relevant for evaluating computer vision algorithms. Yet, the absence of standard, large-scale, open-access datasets with reliably localizable images has limited its potential. To address this issue, we introduce OpenStreetView-5M, a large-scale, open-access dataset comprising over 5.1 million geo-referenced street view images, covering 225 countries and territories. In contrast to existing benchmarks, we enforce a strict train/test separation, allowing us to evaluate the relevance of learned geographical features beyond mere memorization. To demonstrate the utility of our dataset, we conduct an extensive benchmark of various state-of-the-art image encoders, spatial representations, and training strategies. All associated codes and models can be found at https://github.com/gastruc/osv5m.","sentences":["Determining the location of an image anywhere on Earth is a complex visual task, which makes it particularly relevant for evaluating computer vision algorithms.","Yet, the absence of standard, large-scale, open-access datasets with reliably localizable images has limited its potential.","To address this issue, we introduce OpenStreetView-5M, a large-scale, open-access dataset comprising over 5.1 million geo-referenced street view images, covering 225 countries and territories.","In contrast to existing benchmarks, we enforce a strict train/test separation, allowing us to evaluate the relevance of learned geographical features beyond mere memorization.","To demonstrate the utility of our dataset, we conduct an extensive benchmark of various state-of-the-art image encoders, spatial representations, and training strategies.","All associated codes and models can be found at https://github.com/gastruc/osv5m."],"url":"http://arxiv.org/abs/2404.18873v1"}
{"created":"2024-04-29 17:00:53","title":"More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness","abstract":"The surge in Large Language Models (LLMs) development has led to improved performance on cognitive tasks as well as an urgent need to align these models with human values in order to safely exploit their power. Despite the effectiveness of preference learning algorithms like Reinforcement Learning From Human Feedback (RLHF) in aligning human preferences, their assumed improvements on model trustworthiness haven't been thoroughly testified. Toward this end, this study investigates how models that have been aligned with general-purpose preference data on helpfulness and harmlessness perform across five trustworthiness verticals: toxicity, stereotypical bias, machine ethics, truthfulness, and privacy. For model alignment, we focus on three widely used RLHF variants: Supervised Finetuning (SFT), Proximal Policy Optimization (PPO), and Direct Preference Optimization (DPO). Through extensive empirical investigations, we discover that the improvement in trustworthiness by RLHF is far from guaranteed, and there exists a complex interplay between preference data, alignment algorithms, and specific trustworthiness aspects. Together, our results underscore the need for more nuanced approaches for model alignment. By shedding light on the intricate dynamics of these components within model alignment, we hope this research will guide the community towards developing language models that are both capable and trustworthy.","sentences":["The surge in Large Language Models (LLMs) development has led to improved performance on cognitive tasks as well as an urgent need to align these models with human values in order to safely exploit their power.","Despite the effectiveness of preference learning algorithms like Reinforcement Learning From Human Feedback (RLHF) in aligning human preferences, their assumed improvements on model trustworthiness haven't been thoroughly testified.","Toward this end, this study investigates how models that have been aligned with general-purpose preference data on helpfulness and harmlessness perform across five trustworthiness verticals: toxicity, stereotypical bias, machine ethics, truthfulness, and privacy.","For model alignment, we focus on three widely used RLHF variants: Supervised Finetuning (SFT), Proximal Policy Optimization (PPO), and Direct Preference Optimization (DPO).","Through extensive empirical investigations, we discover that the improvement in trustworthiness by RLHF is far from guaranteed, and there exists a complex interplay between preference data, alignment algorithms, and specific trustworthiness aspects.","Together, our results underscore the need for more nuanced approaches for model alignment.","By shedding light on the intricate dynamics of these components within model alignment, we hope this research will guide the community towards developing language models that are both capable and trustworthy."],"url":"http://arxiv.org/abs/2404.18870v1"}
{"created":"2024-04-29 17:00:20","title":"Learning Mixtures of Gaussians Using Diffusion Models","abstract":"We give a new algorithm for learning mixtures of $k$ Gaussians (with identity covariance in $\\mathbb{R}^n$) to TV error $\\varepsilon$, with quasi-polynomial ($O(n^{\\text{poly log}\\left(\\frac{n+k}{\\varepsilon}\\right)})$) time and sample complexity, under a minimum weight assumption. Unlike previous approaches, most of which are algebraic in nature, our approach is analytic and relies on the framework of diffusion models. Diffusion models are a modern paradigm for generative modeling, which typically rely on learning the score function (gradient log-pdf) along a process transforming a pure noise distribution, in our case a Gaussian, to the data distribution. Despite their dazzling performance in tasks such as image generation, there are few end-to-end theoretical guarantees that they can efficiently learn nontrivial families of distributions; we give some of the first such guarantees. We proceed by deriving higher-order Gaussian noise sensitivity bounds for the score functions for a Gaussian mixture to show that that they can be inductively learned using piecewise polynomial regression (up to poly-logarithmic degree), and combine this with known convergence results for diffusion models. Our results extend to continuous mixtures of Gaussians where the mixing distribution is supported on a union of $k$ balls of constant radius. In particular, this applies to the case of Gaussian convolutions of distributions on low-dimensional manifolds, or more generally sets with small covering number.","sentences":["We give a new algorithm for learning mixtures of $k$ Gaussians (with identity covariance in $\\mathbb{R}^n$) to TV error $\\varepsilon$, with quasi-polynomial ($O(n^{\\text{poly log}\\left(\\frac{n+k}{\\varepsilon}\\right)})$) time and sample complexity, under a minimum weight assumption.","Unlike previous approaches, most of which are algebraic in nature, our approach is analytic and relies on the framework of diffusion models.","Diffusion models are a modern paradigm for generative modeling, which typically rely on learning the score function (gradient log-pdf) along a process transforming a pure noise distribution, in our case a Gaussian, to the data distribution.","Despite their dazzling performance in tasks such as image generation, there are few end-to-end theoretical guarantees that they can efficiently learn nontrivial families of distributions; we give some of the first such guarantees.","We proceed by deriving higher-order Gaussian noise sensitivity bounds for the score functions for a Gaussian mixture to show that that they can be inductively learned using piecewise polynomial regression (up to poly-logarithmic degree), and combine this with known convergence results for diffusion models.","Our results extend to continuous mixtures of Gaussians where the mixing distribution is supported on a union of $k$ balls of constant radius.","In particular, this applies to the case of Gaussian convolutions of distributions on low-dimensional manifolds, or more generally sets with small covering number."],"url":"http://arxiv.org/abs/2404.18869v1"}
{"created":"2024-04-29 16:56:33","title":"Feminist Interaction Techniques: Deterring Non-Consensual Screenshots with Interaction Techniques","abstract":"Non-consensual Intimate Media (NCIM) refers to the distribution of sexual or intimate content without consent. NCIM is common and causes significant emotional, financial, and reputational harm. We developed Hands-Off, an interaction technique for messaging applications that deters non-consensual screenshots. Hands-Off requires recipients to perform a hand gesture in the air, above the device, to unlock media -- which makes simultaneous screenshotting difficult. A lab study shows that Hands-Off gestures are easy to perform and reduce non-consensual screenshots by 67 percent. We conclude by generalizing this approach and introduce the idea of Feminist Interaction Techniques (FIT), interaction techniques that encode feminist values and speak to societal problems, and reflect on FIT's opportunities and limitations.","sentences":["Non-consensual Intimate Media (NCIM) refers to the distribution of sexual or intimate content without consent.","NCIM is common and causes significant emotional, financial, and reputational harm.","We developed Hands-Off, an interaction technique for messaging applications that deters non-consensual screenshots.","Hands-Off requires recipients to perform a hand gesture in the air, above the device, to unlock media -- which makes simultaneous screenshotting difficult.","A lab study shows that Hands-Off gestures are easy to perform and reduce non-consensual screenshots by 67 percent.","We conclude by generalizing this approach and introduce the idea of Feminist Interaction Techniques (FIT), interaction techniques that encode feminist values and speak to societal problems, and reflect on FIT's opportunities and limitations."],"url":"http://arxiv.org/abs/2404.18867v1"}
{"created":"2024-04-29 16:52:57","title":"Truth-value judgment in language models: belief directions are context sensitive","abstract":"Recent work has demonstrated that the latent spaces of large language models (LLMs) contain directions predictive of the truth of sentences. Multiple methods recover such directions and build probes that are described as getting at a model's \"knowledge\" or \"beliefs\". We investigate this phenomenon, looking closely at the impact of context on the probes. Our experiments establish where in the LLM the probe's predictions can be described as being conditional on the preceding (related) sentences. Specifically, we quantify the responsiveness of the probes to the presence of (negated) supporting and contradicting sentences, and score the probes on their consistency. We also perform a causal intervention experiment, investigating whether moving the representation of a premise along these belief directions influences the position of the hypothesis along that same direction. We find that the probes we test are generally context sensitive, but that contexts which should not affect the truth often still impact the probe outputs. Our experiments show that the type of errors depend on the layer, the (type of) model, and the kind of data. Finally, our results suggest that belief directions are (one of the) causal mediators in the inference process that incorporates in-context information.","sentences":["Recent work has demonstrated that the latent spaces of large language models (LLMs) contain directions predictive of the truth of sentences.","Multiple methods recover such directions and build probes that are described as getting at a model's \"knowledge\" or \"beliefs\".","We investigate this phenomenon, looking closely at the impact of context on the probes.","Our experiments establish where in the LLM the probe's predictions can be described as being conditional on the preceding (related) sentences.","Specifically, we quantify the responsiveness of the probes to the presence of (negated) supporting and contradicting sentences, and score the probes on their consistency.","We also perform a causal intervention experiment, investigating whether moving the representation of a premise along these belief directions influences the position of the hypothesis along that same direction.","We find that the probes we test are generally context sensitive, but that contexts which should not affect the truth often still impact the probe outputs.","Our experiments show that the type of errors depend on the layer, the (type of) model, and the kind of data.","Finally, our results suggest that belief directions are (one of the) causal mediators in the inference process that incorporates in-context information."],"url":"http://arxiv.org/abs/2404.18865v1"}
{"created":"2024-04-29 16:52:38","title":"Performance-Aligned LLMs for Generating Fast Code","abstract":"Optimizing scientific software is a difficult task because codebases are often large and complex, and performance can depend upon several factors including the algorithm, its implementation, and hardware among others. Causes of poor performance can originate from disparate sources and be difficult to diagnose. Recent years have seen a multitude of work that use large language models (LLMs) to assist in software development tasks. However, these tools are trained to model the distribution of code as text, and are not specifically designed to understand performance aspects of code. In this work, we introduce a reinforcement learning based methodology to align the outputs of code LLMs with performance. This allows us to build upon the current code modeling capabilities of LLMs and extend them to generate better performing code. We demonstrate that our fine-tuned model improves the expected speedup of generated code over base models for a set of benchmark tasks from 0.9 to 1.6 for serial code and 1.9 to 4.5 for OpenMP code.","sentences":["Optimizing scientific software is a difficult task because codebases are often large and complex, and performance can depend upon several factors including the algorithm, its implementation, and hardware among others.","Causes of poor performance can originate from disparate sources and be difficult to diagnose.","Recent years have seen a multitude of work that use large language models (LLMs) to assist in software development tasks.","However, these tools are trained to model the distribution of code as text, and are not specifically designed to understand performance aspects of code.","In this work, we introduce a reinforcement learning based methodology to align the outputs of code LLMs with performance.","This allows us to build upon the current code modeling capabilities of LLMs and extend them to generate better performing code.","We demonstrate that our fine-tuned model improves the expected speedup of generated code over base models for a set of benchmark tasks from 0.9 to 1.6 for serial code and 1.9 to 4.5 for OpenMP code."],"url":"http://arxiv.org/abs/2404.18864v1"}
{"created":"2024-04-29 16:52:07","title":"PlanNetX: Learning an Efficient Neural Network Planner from MPC for Longitudinal Control","abstract":"Model predictive control (MPC) is a powerful, optimization-based approach for controlling dynamical systems. However, the computational complexity of online optimization can be problematic on embedded devices. Especially, when we need to guarantee fixed control frequencies. Thus, previous work proposed to reduce the computational burden using imitation learning (IL) approximating the MPC policy by a neural network. In this work, we instead learn the whole planned trajectory of the MPC. We introduce a combination of a novel neural network architecture PlanNetX and a simple loss function based on the state trajectory that leverages the parameterized optimal control structure of the MPC. We validate our approach in the context of autonomous driving by learning a longitudinal planner and benchmarking it extensively in the CommonRoad simulator using synthetic scenarios and scenarios derived from real data. Our experimental results show that we can learn the open-loop MPC trajectory with high accuracy while improving the closed-loop performance of the learned control policy over other baselines like behavior cloning.","sentences":["Model predictive control (MPC) is a powerful, optimization-based approach for controlling dynamical systems.","However, the computational complexity of online optimization can be problematic on embedded devices.","Especially, when we need to guarantee fixed control frequencies.","Thus, previous work proposed to reduce the computational burden using imitation learning (IL) approximating the MPC policy by a neural network.","In this work, we instead learn the whole planned trajectory of the MPC.","We introduce a combination of a novel neural network architecture PlanNetX and a simple loss function based on the state trajectory that leverages the parameterized optimal control structure of the MPC.","We validate our approach in the context of autonomous driving by learning a longitudinal planner and benchmarking it extensively in the CommonRoad simulator using synthetic scenarios and scenarios derived from real data.","Our experimental results show that we can learn the open-loop MPC trajectory with high accuracy while improving the closed-loop performance of the learned control policy over other baselines like behavior cloning."],"url":"http://arxiv.org/abs/2404.18863v1"}
{"created":"2024-04-29 16:51:30","title":"A Survey on Vision Mamba: Models, Applications and Challenges","abstract":"Mamba, a recent selective structured state space model, performs excellently on long sequence modeling tasks. Mamba mitigates the modeling constraints of convolutional neural networks and offers advanced modeling capabilities similar to those of Transformers, through global receptive fields and dynamic weighting. Crucially, it achieves this without incurring the quadratic computational complexity typically associated with Transformers. Due to its advantages over the former two mainstream foundation models, Mamba exhibits great potential to be a visual foundation model. Researchers are actively applying Mamba to various computer vision tasks, leading to numerous emerging works. To help keep pace with the rapid advancements in computer vision, this paper aims to provide a comprehensive review of visual Mamba approaches. This paper begins by delineating the formulation of the original Mamba model. Subsequently, our review of visual Mamba delves into several representative backbone networks to elucidate the core insights of the visual Mamba. We then categorize related works using different modalities, including image, video, point cloud, multi-modal, and others. Specifically, for image applications, we further organize them into distinct tasks to facilitate a more structured discussion. Finally, we discuss the challenges and future research directions for visual Mamba, providing insights for future research in this quickly evolving area. A comprehensive list of visual Mamba models reviewed in this work is available at https://github.com/Ruixxxx/Awesome-Vision-Mamba-Models.","sentences":["Mamba, a recent selective structured state space model, performs excellently on long sequence modeling tasks.","Mamba mitigates the modeling constraints of convolutional neural networks and offers advanced modeling capabilities similar to those of Transformers, through global receptive fields and dynamic weighting.","Crucially, it achieves this without incurring the quadratic computational complexity typically associated with Transformers.","Due to its advantages over the former two mainstream foundation models, Mamba exhibits great potential to be a visual foundation model.","Researchers are actively applying Mamba to various computer vision tasks, leading to numerous emerging works.","To help keep pace with the rapid advancements in computer vision, this paper aims to provide a comprehensive review of visual Mamba approaches.","This paper begins by delineating the formulation of the original Mamba model.","Subsequently, our review of visual Mamba delves into several representative backbone networks to elucidate the core insights of the visual Mamba.","We then categorize related works using different modalities, including image, video, point cloud, multi-modal, and others.","Specifically, for image applications, we further organize them into distinct tasks to facilitate a more structured discussion.","Finally, we discuss the challenges and future research directions for visual Mamba, providing insights for future research in this quickly evolving area.","A comprehensive list of visual Mamba models reviewed in this work is available at https://github.com/Ruixxxx/Awesome-Vision-Mamba-Models."],"url":"http://arxiv.org/abs/2404.18861v1"}
{"created":"2024-04-29 16:45:03","title":"VERT: Verified Equivalent Rust Transpilation with Few-Shot Learning","abstract":"Rust is a programming language that combines memory safety and low-level control, providing C-like performance while guaranteeing the absence of undefined behaviors by default. Rust's growing popularity has prompted research on safe and correct transpiling of existing code-bases to Rust. Existing work falls into two categories: rule-based and large language model (LLM)-based. While rule-based approaches can theoretically produce correct transpilations that maintain input-output equivalence to the original, they often yield unreadable Rust code that uses unsafe subsets of the Rust language. On the other hand, while LLM-based approaches typically produce more readable, maintainable, and safe code, they do not provide any guarantees about correctness. In this work, we present VERT, a tool that can produce readable Rust transpilations with formal guarantees of correctness. VERT's only requirement is that there is Web Assembly compiler for the source language, which is true for most major languages. VERT first uses the Web Assembly compiler to obtain an oracle Rust program. In parallel, VERT uses an LLM to generate a readable candidate Rust program. This candidate is verified against the oracle, and if verification fails, we regenerate a new candidate transpilation until verification succeeds. We evaluate VERT by transpiling a suite of 1,394 programs taken from competitive programming style benchmarks. Combining Anthropic's Claude-2 and VERT increases Rust transpilations passing property-based testing from 31% to 54% and bounded model-checking from 1% to 42% compared to using Claude alone. In addition, we evaluate VERT's ability to generate non-trivial safe Rust on programs taken from real-world C projects that make significant use of pointers. Our results provide insights into the limitations of LLMs to write safe Rust.","sentences":["Rust is a programming language that combines memory safety and low-level control, providing C-like performance while guaranteeing the absence of undefined behaviors by default.","Rust's growing popularity has prompted research on safe and correct transpiling of existing code-bases to Rust.","Existing work falls into two categories: rule-based and large language model (LLM)-based.","While rule-based approaches can theoretically produce correct transpilations that maintain input-output equivalence to the original, they often yield unreadable Rust code that uses unsafe subsets of the Rust language.","On the other hand, while LLM-based approaches typically produce more readable, maintainable, and safe code, they do not provide any guarantees about correctness.","In this work, we present VERT, a tool that can produce readable Rust transpilations with formal guarantees of correctness.","VERT's only requirement is that there is Web Assembly compiler for the source language, which is true for most major languages.","VERT first uses the Web Assembly compiler to obtain an oracle Rust program.","In parallel, VERT uses an LLM to generate a readable candidate Rust program.","This candidate is verified against the oracle, and if verification fails, we regenerate a new candidate transpilation until verification succeeds.","We evaluate VERT by transpiling a suite of 1,394 programs taken from competitive programming style benchmarks.","Combining Anthropic's Claude-2 and VERT increases Rust transpilations passing property-based testing from 31% to 54% and bounded model-checking from 1% to 42% compared to using Claude alone.","In addition, we evaluate VERT's ability to generate non-trivial safe Rust on programs taken from real-world C projects that make significant use of pointers.","Our results provide insights into the limitations of LLMs to write safe Rust."],"url":"http://arxiv.org/abs/2404.18852v1"}
{"created":"2024-04-29 16:44:27","title":"A Comprehensive Rubric for Annotating Pathological Speech","abstract":"Rubrics are a commonly used tool for labeling voice corpora in speech quality assessment, although their application in the context of pathological speech remains relatively limited. In this study, we introduce a comprehensive rubric based on various dimensions of speech quality, including phonetics, fluency, and prosody. The objective is to establish standardized criteria for identifying errors within the speech of individuals with Down syndrome, thereby enabling the development of automated assessment systems. To achieve this objective, we utilized the Prautocal corpus. To assess the quality of annotations using our rubric, two experiments were conducted, focusing on phonetics and fluency. For phonetic evaluation, we employed the Goodness of Pronunciation (GoP) metric, utilizing automatic segmentation systems and correlating the results with evaluations conducted by a specialized speech therapist. While the obtained correlation values were not notably high, a positive trend was observed. In terms of fluency assessment, deep learning models like wav2vec were used to extract audio features, and we employed an SVM classifier trained on a corpus focused on identifying fluency issues to categorize Prautocal corpus samples. The outcomes highlight the complexities of evaluating such phenomena, with variability depending on the specific type of disfluency detected.","sentences":["Rubrics are a commonly used tool for labeling voice corpora in speech quality assessment, although their application in the context of pathological speech remains relatively limited.","In this study, we introduce a comprehensive rubric based on various dimensions of speech quality, including phonetics, fluency, and prosody.","The objective is to establish standardized criteria for identifying errors within the speech of individuals with Down syndrome, thereby enabling the development of automated assessment systems.","To achieve this objective, we utilized the Prautocal corpus.","To assess the quality of annotations using our rubric, two experiments were conducted, focusing on phonetics and fluency.","For phonetic evaluation, we employed the Goodness of Pronunciation (GoP) metric, utilizing automatic segmentation systems and correlating the results with evaluations conducted by a specialized speech therapist.","While the obtained correlation values were not notably high, a positive trend was observed.","In terms of fluency assessment, deep learning models like wav2vec were used to extract audio features, and we employed an SVM classifier trained on a corpus focused on identifying fluency issues to categorize Prautocal corpus samples.","The outcomes highlight the complexities of evaluating such phenomena, with variability depending on the specific type of disfluency detected."],"url":"http://arxiv.org/abs/2404.18851v1"}
{"created":"2024-04-29 16:43:45","title":"Sparse Sampling in Fractional Fourier Domain: Recovery Guarantees and Cram\u00e9r-Rao Bounds","abstract":"Sampling theory in fractional Fourier Transform (FrFT) domain has been studied extensively in the last decades. This interest stems from the ability of the FrFT to generalize the traditional Fourier Transform, broadening the traditional concept of bandwidth and accommodating a wider range of functions that may not be bandlimited in the Fourier sense. Beyond bandlimited functions, sampling and recovery of sparse signals has also been studied in the FrFT domain. Existing methods for sparse recovery typically operate in the transform domain, capitalizing on the spectral features of spikes in the FrFT domain. Our paper contributes two new theoretical advancements in this area. First, we introduce a novel time-domain sparse recovery method that avoids the typical bottlenecks of transform domain methods, such as spectral leakage. This method is backed by a sparse sampling theorem applicable to arbitrary FrFT-bandlimited kernels and is validated through a hardware experiment. Second, we present Cram\\'er-Rao Bounds for the sparse sampling problem, addressing a gap in existing literature.","sentences":["Sampling theory in fractional Fourier Transform (FrFT) domain has been studied extensively in the last decades.","This interest stems from the ability of the FrFT to generalize the traditional Fourier Transform, broadening the traditional concept of bandwidth and accommodating a wider range of functions that may not be bandlimited in the Fourier sense.","Beyond bandlimited functions, sampling and recovery of sparse signals has also been studied in the FrFT domain.","Existing methods for sparse recovery typically operate in the transform domain, capitalizing on the spectral features of spikes in the FrFT domain.","Our paper contributes two new theoretical advancements in this area.","First, we introduce a novel time-domain sparse recovery method that avoids the typical bottlenecks of transform domain methods, such as spectral leakage.","This method is backed by a sparse sampling theorem applicable to arbitrary FrFT-bandlimited kernels and is validated through a hardware experiment.","Second, we present Cram\\'er-Rao Bounds for the sparse sampling problem, addressing a gap in existing literature."],"url":"http://arxiv.org/abs/2404.18850v1"}
{"created":"2024-04-29 16:42:58","title":"MiPa: Mixed Patch Infrared-Visible Modality Agnostic Object Detection","abstract":"In this paper, we present a different way to use two modalities, in which either one modality or the other is seen by a single model. This can be useful when adapting an unimodal model to leverage more information while respecting a limited computational budget. This would mean having a single model that is able to deal with any modalities. To describe this, we coined the term anymodal learning. An example of this, is a use case where, surveillance in a room when the lights are off would be much more valuable using an infrared modality while a visible one would provide more discriminative information when lights are on. This work investigates how to efficiently leverage visible and infrared/thermal modalities for transformer-based object detection backbone to create an anymodal architecture. Our work does not create any inference overhead during the testing while exploring an effective way to exploit the two modalities during the training. To accomplish such a task, we introduce the novel anymodal training technique: Mixed Patches (MiPa), in conjunction with a patch-wise domain agnostic module, which is responsible of learning the best way to find a common representation of both modalities. This approach proves to be able to balance modalities by reaching competitive results on individual modality benchmarks with the alternative of using an unimodal architecture on three different visible-infrared object detection datasets. Finally, our proposed method, when used as a regularization for the strongest modality, can beat the performance of multimodal fusion methods while only requiring a single modality during inference. Notably, MiPa became the state-of-the-art on the LLVIP visible/infrared benchmark. Code: https://github.com/heitorrapela/MiPa","sentences":["In this paper, we present a different way to use two modalities, in which either one modality or the other is seen by a single model.","This can be useful when adapting an unimodal model to leverage more information while respecting a limited computational budget.","This would mean having a single model that is able to deal with any modalities.","To describe this, we coined the term anymodal learning.","An example of this, is a use case where, surveillance in a room when the lights are off would be much more valuable using an infrared modality while a visible one would provide more discriminative information when lights are on.","This work investigates how to efficiently leverage visible and infrared/thermal modalities for transformer-based object detection backbone to create an anymodal architecture.","Our work does not create any inference overhead during the testing while exploring an effective way to exploit the two modalities during the training.","To accomplish such a task, we introduce the novel anymodal training technique: Mixed Patches (MiPa), in conjunction with a patch-wise domain agnostic module, which is responsible of learning the best way to find a common representation of both modalities.","This approach proves to be able to balance modalities by reaching competitive results on individual modality benchmarks with the alternative of using an unimodal architecture on three different visible-infrared object detection datasets.","Finally, our proposed method, when used as a regularization for the strongest modality, can beat the performance of multimodal fusion methods while only requiring a single modality during inference.","Notably, MiPa became the state-of-the-art on the LLVIP visible/infrared benchmark.","Code: https://github.com/heitorrapela/MiPa"],"url":"http://arxiv.org/abs/2404.18849v1"}
{"created":"2024-04-29 16:42:26","title":"FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning Leveraging Weight Decomposition","abstract":"Pre-trained Language Models (PLMs) have shown excellent performance on various downstream tasks after fine-tuning. Nevertheless, the escalating concerns surrounding user privacy have posed significant challenges to centralized training reliant on extensive data collection. Federated learning(FL), which only requires training on the clients and aggregates weights on the server without sharing data, has emerged as a solution. However, the substantial parameter size of PLMs places a significant burden on the computational resources of client devices, while also leading to costly communication expenses. Introducing Parameter-Efficient Fine-Tuning(PEFT) into FL can effectively address this problem. However, we observe that the non-IID data in federated learning leads to a gap in performance between the PEFT method and full parameter fine-tuning(FT). To overcome this, we propose FeDeRA, an improvement over the LoRA method in FL. FeDeRA uses the same adapter module as LoRA. However, the difference lies in FeDeRA's initialization of the adapter module by performing Singular Value Decomposition (SVD) on the pre-trained matrix and selecting its principal components. We conducted extensive experiments, using RoBERTa and DeBERTaV3, on three tasks and six datasets, comparing the methods including FT and the other three different PEFT methods. FeDeRA outperforms all other PEFT methods and is comparable to or even surpasses the performance of FT methods. We also deployed federated learning on Jetson AGX Orin and compared the time required by different methods to achieve the target accuracy on specific tasks. Compared to FT, FeDeRA reduces the training time by 95.9%, 97.9%, 96.9%, and 97.3%, 96.5%, and 96.5% respectively on three tasks using RoBERTa and DeBERTaV3. The overall experiments indicate that FeDeRA achieves good performance while also maintaining efficiency.","sentences":["Pre-trained Language Models (PLMs) have shown excellent performance on various downstream tasks after fine-tuning.","Nevertheless, the escalating concerns surrounding user privacy have posed significant challenges to centralized training reliant on extensive data collection.","Federated learning(FL), which only requires training on the clients and aggregates weights on the server without sharing data, has emerged as a solution.","However, the substantial parameter size of PLMs places a significant burden on the computational resources of client devices, while also leading to costly communication expenses.","Introducing Parameter-Efficient Fine-Tuning(PEFT) into FL can effectively address this problem.","However, we observe that the non-IID data in federated learning leads to a gap in performance between the PEFT method and full parameter fine-tuning(FT).","To overcome this, we propose FeDeRA, an improvement over the LoRA method in FL. FeDeRA uses the same adapter module as LoRA.","However, the difference lies in FeDeRA's initialization of the adapter module by performing Singular Value Decomposition (SVD) on the pre-trained matrix and selecting its principal components.","We conducted extensive experiments, using RoBERTa and DeBERTaV3, on three tasks and six datasets, comparing the methods including FT and the other three different PEFT methods.","FeDeRA outperforms all other PEFT methods and is comparable to or even surpasses the performance of FT methods.","We also deployed federated learning on Jetson AGX Orin and compared the time required by different methods to achieve the target accuracy on specific tasks.","Compared to FT, FeDeRA reduces the training time by 95.9%, 97.9%, 96.9%, and 97.3%, 96.5%, and 96.5% respectively on three tasks using RoBERTa and DeBERTaV3.","The overall experiments indicate that FeDeRA achieves good performance while also maintaining efficiency."],"url":"http://arxiv.org/abs/2404.18848v1"}
{"created":"2024-04-29 16:30:24","title":"VISION: Toward a Standardized Process for Radiology Image Management at the National Level","abstract":"The compilation and analysis of radiological images poses numerous challenges for researchers. The sheer volume of data as well as the computational needs of algorithms capable of operating on images are extensive. Additionally, the assembly of these images alone is difficult, as these exams may differ widely in terms of clinical context, structured annotation available for model training, modality, and patient identifiers. In this paper, we describe our experiences and challenges in establishing a trusted collection of radiology images linked to the United States Department of Veterans Affairs (VA) electronic health record database. We also discuss implications in making this repository research-ready for medical investigators. Key insights include uncovering the specific procedures required for transferring images from a clinical to a research-ready environment, as well as roadblocks and bottlenecks in this process that may hinder future efforts at automation.","sentences":["The compilation and analysis of radiological images poses numerous challenges for researchers.","The sheer volume of data as well as the computational needs of algorithms capable of operating on images are extensive.","Additionally, the assembly of these images alone is difficult, as these exams may differ widely in terms of clinical context, structured annotation available for model training, modality, and patient identifiers.","In this paper, we describe our experiences and challenges in establishing a trusted collection of radiology images linked to the United States Department of Veterans Affairs (VA) electronic health record database.","We also discuss implications in making this repository research-ready for medical investigators.","Key insights include uncovering the specific procedures required for transferring images from a clinical to a research-ready environment, as well as roadblocks and bottlenecks in this process that may hinder future efforts at automation."],"url":"http://arxiv.org/abs/2404.18842v1"}
{"created":"2024-04-29 16:19:47","title":"It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation of Patient Comments","abstract":"Sentiment analysis is an important tool for aggregating patient voices, in order to provide targeted improvements in healthcare services. A prerequisite for this is the availability of in-domain data annotated for sentiment. This article documents an effort to add sentiment annotations to free-text comments in patient surveys collected by the Norwegian Institute of Public Health (NIPH). However, annotation can be a time-consuming and resource-intensive process, particularly when it requires domain expertise. We therefore also evaluate a possible alternative to human annotation, using large language models (LLMs) as annotators. We perform an extensive evaluation of the approach for two openly available pretrained LLMs for Norwegian, experimenting with different configurations of prompts and in-context learning, comparing their performance to human annotators. We find that even for zero-shot runs, models perform well above the baseline for binary sentiment, but still cannot compete with human annotators on the full dataset.","sentences":["Sentiment analysis is an important tool for aggregating patient voices, in order to provide targeted improvements in healthcare services.","A prerequisite for this is the availability of in-domain data annotated for sentiment.","This article documents an effort to add sentiment annotations to free-text comments in patient surveys collected by the Norwegian Institute of Public Health (NIPH).","However, annotation can be a time-consuming and resource-intensive process, particularly when it requires domain expertise.","We therefore also evaluate a possible alternative to human annotation, using large language models (LLMs) as annotators.","We perform an extensive evaluation of the approach for two openly available pretrained LLMs for Norwegian, experimenting with different configurations of prompts and in-context learning, comparing their performance to human annotators.","We find that even for zero-shot runs, models perform well above the baseline for binary sentiment, but still cannot compete with human annotators on the full dataset."],"url":"http://arxiv.org/abs/2404.18832v1"}
{"created":"2024-04-29 16:16:42","title":"ConPro: Learning Severity Representation for Medical Images using Contrastive Learning and Preference Optimization","abstract":"Understanding the severity of conditions shown in images in medical diagnosis is crucial, serving as a key guide for clinical assessment, treatment, as well as evaluating longitudinal progression. This paper proposes Con- PrO: a novel representation learning method for severity assessment in medical images using Contrastive learningintegrated Preference Optimization. Different from conventional contrastive learning methods that maximize the distance between classes, ConPrO injects into the latent vector the distance preference knowledge between various severity classes and the normal class. We systematically examine the key components of our framework to illuminate how contrastive prediction tasks acquire valuable representations. We show that our representation learning framework offers valuable severity ordering in the feature space while outperforming previous state-of-the-art methods on classification tasks. We achieve a 6% and 20% relative improvement compared to a supervised and a self-supervised baseline, respectively. In addition, we derived discussions on severity indicators and related applications of preference comparison in the medical domain.","sentences":["Understanding the severity of conditions shown in images in medical diagnosis is crucial, serving as a key guide for clinical assessment, treatment, as well as evaluating longitudinal progression.","This paper proposes Con- PrO: a novel representation learning method for severity assessment in medical images using Contrastive learningintegrated Preference Optimization.","Different from conventional contrastive learning methods that maximize the distance between classes, ConPrO injects into the latent vector the distance preference knowledge between various severity classes and the normal class.","We systematically examine the key components of our framework to illuminate how contrastive prediction tasks acquire valuable representations.","We show that our representation learning framework offers valuable severity ordering in the feature space while outperforming previous state-of-the-art methods on classification tasks.","We achieve a 6% and 20% relative improvement compared to a supervised and a self-supervised baseline, respectively.","In addition, we derived discussions on severity indicators and related applications of preference comparison in the medical domain."],"url":"http://arxiv.org/abs/2404.18831v1"}
{"created":"2024-04-29 16:10:32","title":"Winning the Social Media Influence Battle: Uncertainty-Aware Opinions to Understand and Spread True Information via Competitive Influence Maximization","abstract":"Competitive Influence Maximization (CIM) involves entities competing to maximize influence in online social networks (OSNs). Current Deep Reinforcement Learning (DRL) methods in CIM rely on simplistic binary opinion models (i.e., an opinion is represented by either 0 or 1) and often overlook the complexity of user behaviors and prior knowledge. We propose a novel DRL-based framework that enhances CIM analysis by integrating Subjective Logic (SL) to accommodate uncertain opinions, user behaviors, and preferences. This approach targets the mitigation of false information by effectively propagating true information. By modeling two competitive agents, one spreading true information and the other spreading false information, we capture the strategic interplay essential to CIM. Our framework utilizes an uncertainty-based opinion model (UOM) to assess the impact on information quality in OSNs, emphasizing the importance of user behavior alongside network topology in selecting influential seed nodes. Extensive experiments demonstrate that our approach significantly outperforms state-of-the-art methods, achieving faster and more influential results (i.e., outperforming over 20%) under realistic network conditions. Moreover, our method shows robust performance in partially observable networks, effectively doubling the performance when users are predisposed to disbelieve true information.","sentences":["Competitive Influence Maximization (CIM) involves entities competing to maximize influence in online social networks (OSNs).","Current Deep Reinforcement Learning (DRL) methods in CIM rely on simplistic binary opinion models (i.e., an opinion is represented by either 0 or 1) and often overlook the complexity of user behaviors and prior knowledge.","We propose a novel DRL-based framework that enhances CIM analysis by integrating Subjective Logic (SL) to accommodate uncertain opinions, user behaviors, and preferences.","This approach targets the mitigation of false information by effectively propagating true information.","By modeling two competitive agents, one spreading true information and the other spreading false information, we capture the strategic interplay essential to CIM.","Our framework utilizes an uncertainty-based opinion model (UOM) to assess the impact on information quality in OSNs, emphasizing the importance of user behavior alongside network topology in selecting influential seed nodes.","Extensive experiments demonstrate that our approach significantly outperforms state-of-the-art methods, achieving faster and more influential results (i.e., outperforming over 20%) under realistic network conditions.","Moreover, our method shows robust performance in partially observable networks, effectively doubling the performance when users are predisposed to disbelieve true information."],"url":"http://arxiv.org/abs/2404.18826v1"}
{"created":"2024-04-29 16:07:36","title":"Harmonic Machine Learning Models are Robust","abstract":"We introduce Harmonic Robustness, a powerful and intuitive method to test the robustness of any machine-learning model either during training or in black-box real-time inference monitoring without ground-truth labels. It is based on functional deviation from the harmonic mean value property, indicating instability and lack of explainability. We show implementation examples in low-dimensional trees and feedforward NNs, where the method reliably identifies overfitting, as well as in more complex high-dimensional models such as ResNet-50 and Vision Transformer where it efficiently measures adversarial vulnerability across image classes.","sentences":["We introduce Harmonic Robustness, a powerful and intuitive method to test the robustness of any machine-learning model either during training or in black-box real-time inference monitoring without ground-truth labels.","It is based on functional deviation from the harmonic mean value property, indicating instability and lack of explainability.","We show implementation examples in low-dimensional trees and feedforward NNs, where the method reliably identifies overfitting, as well as in more complex high-dimensional models such as ResNet-50 and Vision Transformer where it efficiently measures adversarial vulnerability across image classes."],"url":"http://arxiv.org/abs/2404.18825v1"}
{"created":"2024-04-29 16:05:36","title":"Benchmarking Benchmark Leakage in Large Language Models","abstract":"Amid the expanding use of pre-training data, the phenomenon of benchmark dataset leakage has become increasingly prominent, exacerbated by opaque training processes and the often undisclosed inclusion of supervised data in contemporary Large Language Models (LLMs). This issue skews benchmark effectiveness and fosters potentially unfair comparisons, impeding the field's healthy development. To address this, we introduce a detection pipeline utilizing Perplexity and N-gram accuracy, two simple and scalable metrics that gauge a model's prediction precision on benchmark, to identify potential data leakages. By analyzing 31 LLMs under the context of mathematical reasoning, we reveal substantial instances of training even test set misuse, resulting in potentially unfair comparisons. These findings prompt us to offer several recommendations regarding model documentation, benchmark setup, and future evaluations. Notably, we propose the \"Benchmark Transparency Card\" to encourage clear documentation of benchmark utilization, promoting transparency and healthy developments of LLMs. we have made our leaderboard, pipeline implementation, and model predictions publicly available, fostering future research.","sentences":["Amid the expanding use of pre-training data, the phenomenon of benchmark dataset leakage has become increasingly prominent, exacerbated by opaque training processes and the often undisclosed inclusion of supervised data in contemporary Large Language Models (LLMs).","This issue skews benchmark effectiveness and fosters potentially unfair comparisons, impeding the field's healthy development.","To address this, we introduce a detection pipeline utilizing Perplexity and N-gram accuracy, two simple and scalable metrics that gauge a model's prediction precision on benchmark, to identify potential data leakages.","By analyzing 31 LLMs under the context of mathematical reasoning, we reveal substantial instances of training even test set misuse, resulting in potentially unfair comparisons.","These findings prompt us to offer several recommendations regarding model documentation, benchmark setup, and future evaluations.","Notably, we propose the \"Benchmark Transparency Card\" to encourage clear documentation of benchmark utilization, promoting transparency and healthy developments of LLMs.","we have made our leaderboard, pipeline implementation, and model predictions publicly available, fostering future research."],"url":"http://arxiv.org/abs/2404.18824v1"}
{"created":"2024-04-29 15:53:03","title":"Hiding from Facebook: An Encryption Protocol resistant to Correlation Attacks","abstract":"In many social networks, one publishes information that one wants to reveal (e.g., the photograph of some friends) together with information that may lead to privacy breaches (e.g., the name of these people). One might want to hide this sensitive information by encrypting it and sharing the decryption key only with trusted people, but this might not be enough. If the cipher associated to a face is always the same, correlation between the output of a face recognition system and the cipher can give useful clues and help train recognizers to identify untagged instances of the face. We refer to these as \"correlation attacks\".   In this paper we present a coding system that attempts to counter correlation attacks by associating to each instance of a face a different encryption of the same tag in such a way that the correlation between different instances is minimal.   In addition, we present a key distribution code that allows only the owner of the images to encode the tags, but allows a group of trusted friends to decode them.","sentences":["In many social networks, one publishes information that one wants to reveal (e.g., the photograph of some friends) together with information that may lead to privacy breaches (e.g., the name of these people).","One might want to hide this sensitive information by encrypting it and sharing the decryption key only with trusted people, but this might not be enough.","If the cipher associated to a face is always the same, correlation between the output of a face recognition system and the cipher can give useful clues and help train recognizers to identify untagged instances of the face.","We refer to these as \"correlation attacks\".   ","In this paper we present a coding system that attempts to counter correlation attacks by associating to each instance of a face a different encryption of the same tag in such a way that the correlation between different instances is minimal.   ","In addition, we present a key distribution code that allows only the owner of the images to encode the tags, but allows a group of trusted friends to decode them."],"url":"http://arxiv.org/abs/2404.18817v1"}
{"created":"2024-04-29 15:52:45","title":"AppPoet: Large Language Model based Android malware detection via multi-view prompt engineering","abstract":"Due to the vast array of Android applications, their multifarious functions and intricate behavioral semantics, attackers can adopt various tactics to conceal their genuine attack intentions within legitimate functions. However, numerous feature engineering based methods suffer from a limitation in mining behavioral semantic information, thus impeding the accuracy and efficiency of Android malware detection. Besides, the majority of existing feature engineering based methods are weakly interpretive and fail to furnish researchers with effective and readable detection reports. Inspired by the success of the Large Language Models (LLMs) in natural language understanding, we propose AppPoet, a LLM-assisted multi-view system for Android malware detection. Firstly, AppPoet employs a static method to comprehensively collect application features and formulate various observation views. Subsequently, it steers the LLM to produce function descriptions and behavioral summaries for views via our meticulously devised multi-view prompt engineering technique to realize the deep mining of view semantics. Finally, we collaboratively fuse the multi-view information to efficiently and accurately detect malware through a deep neural network (DNN) classifier and then generate the heuristic diagnostic reports. Experimental results demonstrate that our method achieves a detection accuracy of 97.15% and an F1 score of 97.21%, which is superior to the baseline method Drebin and its variant. Furthermore, the case study evaluates the effectiveness of our generated diagnostic reports.","sentences":["Due to the vast array of Android applications, their multifarious functions and intricate behavioral semantics, attackers can adopt various tactics to conceal their genuine attack intentions within legitimate functions.","However, numerous feature engineering based methods suffer from a limitation in mining behavioral semantic information, thus impeding the accuracy and efficiency of Android malware detection.","Besides, the majority of existing feature engineering based methods are weakly interpretive and fail to furnish researchers with effective and readable detection reports.","Inspired by the success of the Large Language Models (LLMs) in natural language understanding, we propose AppPoet, a LLM-assisted multi-view system for Android malware detection.","Firstly, AppPoet employs a static method to comprehensively collect application features and formulate various observation views.","Subsequently, it steers the LLM to produce function descriptions and behavioral summaries for views via our meticulously devised multi-view prompt engineering technique to realize the deep mining of view semantics.","Finally, we collaboratively fuse the multi-view information to efficiently and accurately detect malware through a deep neural network (DNN) classifier and then generate the heuristic diagnostic reports.","Experimental results demonstrate that our method achieves a detection accuracy of 97.15% and an F1 score of 97.21%, which is superior to the baseline method Drebin and its variant.","Furthermore, the case study evaluates the effectiveness of our generated diagnostic reports."],"url":"http://arxiv.org/abs/2404.18816v1"}
{"created":"2024-04-29 15:51:49","title":"Belt and Brace: When Federated Learning Meets Differential Privacy","abstract":"Federated learning (FL) has great potential for large-scale machine learning (ML) without exposing raw data.Differential privacy (DP) is the de facto standard of privacy protection with provable guarantees.Advances in ML suggest that DP would be a perfect fit for FL with comprehensive privacy preservation. Hence, extensive efforts have been devoted to achieving practically usable FL with DP, which however is still challenging.Practitioners often not only are not fully aware of its development and categorization, but also face a hard choice between privacy and utility. Therefore, it calls for a holistic review of current advances and an investigation on the challenges and opportunities for highly usable FL systems with a DP guarantee. In this article, we first introduce the primary concepts of FL and DP, and highlight the benefits of integration. We then review the current developments by categorizing different paradigms and notions. Aiming at usable FL with DP, we present the optimization principles to seek a better tradeoff between model utility and privacy loss. Finally, we discuss future challenges in the emergent areas and relevant research topics.","sentences":["Federated learning (FL) has great potential for large-scale machine learning (ML) without exposing raw data.","Differential privacy (DP) is the de facto standard of privacy protection with provable guarantees.","Advances in ML suggest that DP would be a perfect fit for FL with comprehensive privacy preservation.","Hence, extensive efforts have been devoted to achieving practically usable FL with DP, which however is still challenging.","Practitioners often not only are not fully aware of its development and categorization, but also face a hard choice between privacy and utility.","Therefore, it calls for a holistic review of current advances and an investigation on the challenges and opportunities for highly usable FL systems with a DP guarantee.","In this article, we first introduce the primary concepts of FL and DP, and highlight the benefits of integration.","We then review the current developments by categorizing different paradigms and notions.","Aiming at usable FL with DP, we present the optimization principles to seek a better tradeoff between model utility and privacy loss.","Finally, we discuss future challenges in the emergent areas and relevant research topics."],"url":"http://arxiv.org/abs/2404.18814v1"}
{"created":"2024-04-29 15:49:27","title":"Efficient Inverted Indexes for Approximate Retrieval over Learned Sparse Representations","abstract":"Learned sparse representations form an attractive class of contextual embeddings for text retrieval. That is so because they are effective models of relevance and are interpretable by design. Despite their apparent compatibility with inverted indexes, however, retrieval over sparse embeddings remains challenging. That is due to the distributional differences between learned embeddings and term frequency-based lexical models of relevance such as BM25. Recognizing this challenge, a great deal of research has gone into, among other things, designing retrieval algorithms tailored to the properties of learned sparse representations, including approximate retrieval systems. In fact, this task featured prominently in the latest BigANN Challenge at NeurIPS 2023, where approximate algorithms were evaluated on a large benchmark dataset by throughput and recall. In this work, we propose a novel organization of the inverted index that enables fast yet effective approximate retrieval over learned sparse embeddings. Our approach organizes inverted lists into geometrically-cohesive blocks, each equipped with a summary vector. During query processing, we quickly determine if a block must be evaluated using the summaries. As we show experimentally, single-threaded query processing using our method, Seismic, reaches sub-millisecond per-query latency on various sparse embeddings of the MS MARCO dataset while maintaining high recall. Our results indicate that Seismic is one to two orders of magnitude faster than state-of-the-art inverted index-based solutions and further outperforms the winning (graph-based) submissions to the BigANN Challenge by a significant margin.","sentences":["Learned sparse representations form an attractive class of contextual embeddings for text retrieval.","That is so because they are effective models of relevance and are interpretable by design.","Despite their apparent compatibility with inverted indexes, however, retrieval over sparse embeddings remains challenging.","That is due to the distributional differences between learned embeddings and term frequency-based lexical models of relevance such as BM25.","Recognizing this challenge, a great deal of research has gone into, among other things, designing retrieval algorithms tailored to the properties of learned sparse representations, including approximate retrieval systems.","In fact, this task featured prominently in the latest BigANN Challenge at NeurIPS 2023, where approximate algorithms were evaluated on a large benchmark dataset by throughput and recall.","In this work, we propose a novel organization of the inverted index that enables fast yet effective approximate retrieval over learned sparse embeddings.","Our approach organizes inverted lists into geometrically-cohesive blocks, each equipped with a summary vector.","During query processing, we quickly determine if a block must be evaluated using the summaries.","As we show experimentally, single-threaded query processing using our method, Seismic, reaches sub-millisecond per-query latency on various sparse embeddings of the MS MARCO dataset while maintaining high recall.","Our results indicate that Seismic is one to two orders of magnitude faster than state-of-the-art inverted index-based solutions and further outperforms the winning (graph-based) submissions to the BigANN Challenge by a significant margin."],"url":"http://arxiv.org/abs/2404.18812v1"}
{"created":"2024-04-29 15:48:01","title":"Unknown Script: Impact of Script on Cross-Lingual Transfer","abstract":"Cross-lingual transfer has become an effective way of transferring knowledge between languages. In this paper, we explore an often-overlooked aspect in this domain: the influence of the source language of the base language model on transfer performance. We conduct a series of experiments to determine the effect of the script and tokenizer used in the pre-trained model on the performance of the downstream task. Our findings reveal the importance of the tokenizer as a stronger factor than the sharing of the script, the language typology match, and the model size.","sentences":["Cross-lingual transfer has become an effective way of transferring knowledge between languages.","In this paper, we explore an often-overlooked aspect in this domain: the influence of the source language of the base language model on transfer performance.","We conduct a series of experiments to determine the effect of the script and tokenizer used in the pre-trained model on the performance of the downstream task.","Our findings reveal the importance of the tokenizer as a stronger factor than the sharing of the script, the language typology match, and the model size."],"url":"http://arxiv.org/abs/2404.18810v1"}
{"created":"2024-04-29 15:40:40","title":"A Partial Replication of MaskFormer in TensorFlow on TPUs for the TensorFlow Model Garden","abstract":"This paper undertakes the task of replicating the MaskFormer model a universal image segmentation model originally developed using the PyTorch framework, within the TensorFlow ecosystem, specifically optimized for execution on Tensor Processing Units (TPUs). Our implementation exploits the modular constructs available within the TensorFlow Model Garden (TFMG), encompassing elements such as the data loader, training orchestrator, and various architectural components, tailored and adapted to meet the specifications of the MaskFormer model. We address key challenges encountered during the replication, non-convergence issues, slow training, adaptation of loss functions, and the integration of TPU-specific functionalities. We verify our reproduced implementation and present qualitative results on the COCO dataset. Although our implementation meets some of the objectives for end-to-end reproducibility, we encountered challenges in replicating the PyTorch version of MaskFormer in TensorFlow. This replication process is not straightforward and requires substantial engineering efforts. Specifically, it necessitates the customization of various components within the TFMG, alongside thorough verification and hyper-parameter tuning. The replication is available at: https://github.com/PurdueDualityLab/tf-maskformer/tree/main/official/projects/maskformer","sentences":["This paper undertakes the task of replicating the MaskFormer model a universal image segmentation model originally developed using the PyTorch framework, within the TensorFlow ecosystem, specifically optimized for execution on Tensor Processing Units (TPUs).","Our implementation exploits the modular constructs available within the TensorFlow Model Garden (TFMG), encompassing elements such as the data loader, training orchestrator, and various architectural components, tailored and adapted to meet the specifications of the MaskFormer model.","We address key challenges encountered during the replication, non-convergence issues, slow training, adaptation of loss functions, and the integration of TPU-specific functionalities.","We verify our reproduced implementation and present qualitative results on the COCO dataset.","Although our implementation meets some of the objectives for end-to-end reproducibility, we encountered challenges in replicating the PyTorch version of MaskFormer in TensorFlow.","This replication process is not straightforward and requires substantial engineering efforts.","Specifically, it necessitates the customization of various components within the TFMG, alongside thorough verification and hyper-parameter tuning.","The replication is available at: https://github.com/PurdueDualityLab/tf-maskformer/tree/main/official/projects/maskformer"],"url":"http://arxiv.org/abs/2404.18801v1"}
{"created":"2024-04-29 15:34:32","title":"Multi-Agent Synchronization Tasks","abstract":"In multi-agent reinforcement learning (MARL), coordination plays a crucial role in enhancing agents' performance beyond what they could achieve through cooperation alone. The interdependence of agents' actions, coupled with the need for communication, leads to a domain where effective coordination is crucial. In this paper, we introduce and define $\\textit{Multi-Agent Synchronization Tasks}$ (MSTs), a novel subset of multi-agent tasks. We describe one MST, that we call $\\textit{Synchronized Predator-Prey}$, offering a detailed description that will serve as the basis for evaluating a selection of recent state-of-the-art (SOTA) MARL algorithms explicitly designed to address coordination challenges through the use of communication strategies. Furthermore, we present empirical evidence that reveals the limitations of the algorithms assessed to solve MSTs, demonstrating their inability to scale effectively beyond 2-agent coordination tasks in scenarios where communication is a requisite component. Finally, the results raise questions about the applicability of recent SOTA approaches for complex coordination tasks (i.e. MSTs) and prompt further exploration into the underlying causes of their limitations in this context.","sentences":["In multi-agent reinforcement learning (MARL), coordination plays a crucial role in enhancing agents' performance beyond what they could achieve through cooperation alone.","The interdependence of agents' actions, coupled with the need for communication, leads to a domain where effective coordination is crucial.","In this paper, we introduce and define $\\textit{Multi-Agent Synchronization Tasks}$ (MSTs), a novel subset of multi-agent tasks.","We describe one MST, that we call $\\textit{Synchronized Predator-Prey}$, offering a detailed description that will serve as the basis for evaluating a selection of recent state-of-the-art (SOTA) MARL algorithms explicitly designed to address coordination challenges through the use of communication strategies.","Furthermore, we present empirical evidence that reveals the limitations of the algorithms assessed to solve MSTs, demonstrating their inability to scale effectively beyond 2-agent coordination tasks in scenarios where communication is a requisite component.","Finally, the results raise questions about the applicability of recent SOTA approaches for complex coordination tasks (i.e. MSTs) and prompt further exploration into the underlying causes of their limitations in this context."],"url":"http://arxiv.org/abs/2404.18798v1"}
{"created":"2024-04-29 15:33:56","title":"Efficiency-Effectiveness Tradeoff of Probabilistic Structured Queries for Cross-Language Information Retrieval","abstract":"Probabilistic Structured Queries (PSQ) is a cross-language information retrieval (CLIR) method that uses translation probabilities statistically derived from aligned corpora. PSQ is a strong baseline for efficient CLIR using sparse indexing. It is, therefore, useful as the first stage in a cascaded neural CLIR system whose second stage is more effective but too inefficient to be used on its own to search a large text collection. In this reproducibility study, we revisit PSQ by introducing an efficient Python implementation. Unconstrained use of all translation probabilities that can be estimated from aligned parallel text would in the limit assign a weight to every vocabulary term, precluding use of an inverted index to serve queries efficiently. Thus, PSQ's effectiveness and efficiency both depend on how translation probabilities are pruned. This paper presents experiments over a range of modern CLIR test collections to demonstrate that achieving Pareto optimal PSQ effectiveness-efficiency tradeoffs benefits from multi-criteria pruning, which has not been fully explored in prior work. Our Python PSQ implementation is available on GitHub(https://github.com/hltcoe/PSQ) and unpruned translation tables are available on Huggingface Models(https://huggingface.co/hltcoe/psq_translation_tables).","sentences":["Probabilistic Structured Queries (PSQ) is a cross-language information retrieval (CLIR) method that uses translation probabilities statistically derived from aligned corpora.","PSQ is a strong baseline for efficient CLIR using sparse indexing.","It is, therefore, useful as the first stage in a cascaded neural CLIR system whose second stage is more effective but too inefficient to be used on its own to search a large text collection.","In this reproducibility study, we revisit PSQ by introducing an efficient Python implementation.","Unconstrained use of all translation probabilities that can be estimated from aligned parallel text would in the limit assign a weight to every vocabulary term, precluding use of an inverted index to serve queries efficiently.","Thus, PSQ's effectiveness and efficiency both depend on how translation probabilities are pruned.","This paper presents experiments over a range of modern CLIR test collections to demonstrate that achieving Pareto optimal PSQ effectiveness-efficiency tradeoffs benefits from multi-criteria pruning, which has not been fully explored in prior work.","Our Python PSQ implementation is available on GitHub(https://github.com/hltcoe/PSQ) and unpruned translation tables are available on Huggingface Models(https://huggingface.co/hltcoe/psq_translation_tables)."],"url":"http://arxiv.org/abs/2404.18797v1"}
{"created":"2024-04-29 15:33:23","title":"Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models","abstract":"As Large Language Models (LLMs) have become more advanced, they have outpaced our abilities to accurately evaluate their quality. Not only is finding data to adequately probe particular model properties difficult, but evaluating the correctness of a model's freeform generation alone is a challenge. To address this, many evaluations now rely on using LLMs themselves as judges to score the quality of outputs from other LLMs. Evaluations most commonly use a single large model like GPT4. While this method has grown in popularity, it is costly, has been shown to introduce intramodel bias, and in this work, we find that very large models are often unnecessary. We propose instead to evaluate models using a Panel of LLm evaluators (PoLL). Across three distinct judge settings and spanning six different datasets, we find that using a PoLL composed of a larger number of smaller models outperforms a single large judge, exhibits less intra-model bias due to its composition of disjoint model families, and does so while being over seven times less expensive.","sentences":["As Large Language Models (LLMs) have become more advanced, they have outpaced our abilities to accurately evaluate their quality.","Not only is finding data to adequately probe particular model properties difficult, but evaluating the correctness of a model's freeform generation alone is a challenge.","To address this, many evaluations now rely on using LLMs themselves as judges to score the quality of outputs from other LLMs.","Evaluations most commonly use a single large model like GPT4.","While this method has grown in popularity, it is costly, has been shown to introduce intramodel bias, and in this work, we find that very large models are often unnecessary.","We propose instead to evaluate models using a Panel of LLm evaluators (PoLL).","Across three distinct judge settings and spanning six different datasets, we find that using a PoLL composed of a larger number of smaller models outperforms a single large judge, exhibits less intra-model bias due to its composition of disjoint model families, and does so while being over seven times less expensive."],"url":"http://arxiv.org/abs/2404.18796v1"}
{"created":"2024-04-29 15:23:26","title":"Certification of Speaker Recognition Models to Additive Perturbations","abstract":"Speaker recognition technology is applied in various tasks ranging from personal virtual assistants to secure access systems. However, the robustness of these systems against adversarial attacks, particularly to additive perturbations, remains a significant challenge. In this paper, we pioneer applying robustness certification techniques to speaker recognition, originally developed for the image domain. In our work, we cover this gap by transferring and improving randomized smoothing certification techniques against norm-bounded additive perturbations for classification and few-shot learning tasks to speaker recognition. We demonstrate the effectiveness of these methods on VoxCeleb 1 and 2 datasets for several models. We expect this work to improve voice-biometry robustness, establish a new certification benchmark, and accelerate research of certification methods in the audio domain.","sentences":["Speaker recognition technology is applied in various tasks ranging from personal virtual assistants to secure access systems.","However, the robustness of these systems against adversarial attacks, particularly to additive perturbations, remains a significant challenge.","In this paper, we pioneer applying robustness certification techniques to speaker recognition, originally developed for the image domain.","In our work, we cover this gap by transferring and improving randomized smoothing certification techniques against norm-bounded additive perturbations for classification and few-shot learning tasks to speaker recognition.","We demonstrate the effectiveness of these methods on VoxCeleb 1 and 2 datasets for several models.","We expect this work to improve voice-biometry robustness, establish a new certification benchmark, and accelerate research of certification methods in the audio domain."],"url":"http://arxiv.org/abs/2404.18791v1"}
{"created":"2024-04-29 15:23:16","title":"3D Mapping of Glacier Moulins: Challenges and lessons learned","abstract":"In this paper, we present a field report of the mapping of the Athabasca Glacier, using a custom-made lidar-inertial mapping platform. With the increasing autonomy of robotics, a wider spectrum of applications emerges. Among these, the surveying of environmental areas presents arduous and hazardous challenges for human operators. Leveraging automated platforms for data collection holds the promise of unlocking new applications and a deeper comprehension of the environment. Over the course of a week-long deployment, we collected glacier data using a tailor-made measurement platform and reflected on the inherent challenges associated with such experiments. We focus on the insights gained and the forthcoming challenges that robotics must surmount to effectively map these terrains.","sentences":["In this paper, we present a field report of the mapping of the Athabasca Glacier, using a custom-made lidar-inertial mapping platform.","With the increasing autonomy of robotics, a wider spectrum of applications emerges.","Among these, the surveying of environmental areas presents arduous and hazardous challenges for human operators.","Leveraging automated platforms for data collection holds the promise of unlocking new applications and a deeper comprehension of the environment.","Over the course of a week-long deployment, we collected glacier data using a tailor-made measurement platform and reflected on the inherent challenges associated with such experiments.","We focus on the insights gained and the forthcoming challenges that robotics must surmount to effectively map these terrains."],"url":"http://arxiv.org/abs/2404.18790v1"}
{"created":"2024-04-29 15:18:33","title":"Where on Earth Do Users Say They Are?: Geo-Entity Linking for Noisy Multilingual User Input","abstract":"Geo-entity linking is the task of linking a location mention to the real-world geographic location. In this paper we explore the challenging task of geo-entity linking for noisy, multilingual social media data. There are few open-source multilingual geo-entity linking tools available and existing ones are often rule-based, which break easily in social media settings, or LLM-based, which are too expensive for large-scale datasets. We present a method which represents real-world locations as averaged embeddings from labeled user-input location names and allows for selective prediction via an interpretable confidence score. We show that our approach improves geo-entity linking on a global and multilingual social media dataset, and discuss progress and problems with evaluating at different geographic granularities.","sentences":["Geo-entity linking is the task of linking a location mention to the real-world geographic location.","In this paper we explore the challenging task of geo-entity linking for noisy, multilingual social media data.","There are few open-source multilingual geo-entity linking tools available and existing ones are often rule-based, which break easily in social media settings, or LLM-based, which are too expensive for large-scale datasets.","We present a method which represents real-world locations as averaged embeddings from labeled user-input location names and allows for selective prediction via an interpretable confidence score.","We show that our approach improves geo-entity linking on a global and multilingual social media dataset, and discuss progress and problems with evaluating at different geographic granularities."],"url":"http://arxiv.org/abs/2404.18784v1"}
{"created":"2024-04-29 15:18:07","title":"Improved bounds for group testing in arbitrary hypergraphs","abstract":"Recent papers initiated the study of a generalization of group testing where the potentially contaminated sets are the members of a given hypergraph F=(V,E). This generalization finds application in contexts where contaminations can be conditioned by some kinds of social and geographical clusterings. The paper focuses on few-stage group testing algorithms, i.e., slightly adaptive algorithms where tests are performed in stages and all tests performed in the same stage should be decided at the very beginning of the stage. In particular, the paper presents the first two-stage algorithm that uses o(dlog|E|) tests for general hypergraphs with hyperedges of size at most d, and a three-stage algorithm that improves by a d^{1/6} factor on the number of tests of the best known three-stage algorithm. These algorithms are special cases of an s-stage algorithm designed for an arbitrary positive integer s<= d. The design of this algorithm resort to a new non-adaptive algorithm (one-stage algorithm), i.e., an algorithm where all tests must be decided beforehand. Further, we derive a lower bound for non-adaptive group testing. For E sufficiently large, the lower bound is very close to the upper bound on the number of tests of the best non-adaptive group testing algorithm known in the literature, and it is the first lower bound that improves on the information theoretic lower bound Omega(log |E|).","sentences":["Recent papers initiated the study of a generalization of group testing where the potentially contaminated sets are the members of a given hypergraph F=(V,E).","This generalization finds application in contexts where contaminations can be conditioned by some kinds of social and geographical clusterings.","The paper focuses on few-stage group testing algorithms, i.e., slightly adaptive algorithms where tests are performed in stages and all tests performed in the same stage should be decided at the very beginning of the stage.","In particular, the paper presents the first two-stage algorithm that uses o(dlog|E|) tests for general hypergraphs with hyperedges of size at most d, and a three-stage algorithm that improves by a d^{1/6} factor on the number of tests of the best known three-stage algorithm.","These algorithms are special cases of an s-stage algorithm designed for an arbitrary positive integer s<= d.","The design of this algorithm resort to a new non-adaptive algorithm (one-stage algorithm), i.e., an algorithm where all tests must be decided beforehand.","Further, we derive a lower bound for non-adaptive group testing.","For E sufficiently large, the lower bound is very close to the upper bound on the number of tests of the best non-adaptive group testing algorithm known in the literature, and it is the first lower bound that improves on the information theoretic lower bound Omega(log |E|)."],"url":"http://arxiv.org/abs/2404.18783v1"}
{"created":"2024-04-29 15:16:33","title":"Optimal time sampling in physics-informed neural networks","abstract":"Physics-informed neural networks (PINN) is a extremely powerful paradigm used to solve equations encountered in scientific computing applications. An important part of the procedure is the minimization of the equation residual which includes, when the equation is time-dependent, a time sampling. It was argued in the literature that the sampling need not be uniform but should overweight initial time instants, but no rigorous explanation was provided for these choice. In this paper we take some prototypical examples and, under standard hypothesis concerning the neural network convergence, we show that the optimal time sampling follows a truncated exponential distribution. In particular we explain when the time sampling is best to be uniform and when it should not be. The findings are illustrated with numerical examples on linear equation, Burgers' equation and the Lorenz system.","sentences":["Physics-informed neural networks (PINN) is a extremely powerful paradigm used to solve equations encountered in scientific computing applications.","An important part of the procedure is the minimization of the equation residual which includes, when the equation is time-dependent, a time sampling.","It was argued in the literature that the sampling need not be uniform but should overweight initial time instants, but no rigorous explanation was provided for these choice.","In this paper we take some prototypical examples and, under standard hypothesis concerning the neural network convergence, we show that the optimal time sampling follows a truncated exponential distribution.","In particular we explain when the time sampling is best to be uniform and when it should not be.","The findings are illustrated with numerical examples on linear equation, Burgers' equation and the Lorenz system."],"url":"http://arxiv.org/abs/2404.18780v1"}
{"created":"2024-04-29 15:08:24","title":"A Universal Metric of Dataset Similarity for Cross-silo Federated Learning","abstract":"Federated Learning is increasingly used in domains such as healthcare to facilitate collaborative model training without data-sharing. However, datasets located in different sites are often non-identically distributed, leading to degradation of model performance in FL. Most existing methods for assessing these distribution shifts are limited by being dataset or task-specific. Moreover, these metrics can only be calculated by exchanging data, a practice restricted in many FL scenarios. To address these challenges, we propose a novel metric for assessing dataset similarity. Our metric exhibits several desirable properties for FL: it is dataset-agnostic, is calculated in a privacy-preserving manner, and is computationally efficient, requiring no model training. In this paper, we first establish a theoretical connection between our metric and training dynamics in FL. Next, we extensively evaluate our metric on a range of datasets including synthetic, benchmark, and medical imaging datasets. We demonstrate that our metric shows a robust and interpretable relationship with model performance and can be calculated in privacy-preserving manner. As the first federated dataset similarity metric, we believe this metric can better facilitate successful collaborations between sites.","sentences":["Federated Learning is increasingly used in domains such as healthcare to facilitate collaborative model training without data-sharing.","However, datasets located in different sites are often non-identically distributed, leading to degradation of model performance in FL.","Most existing methods for assessing these distribution shifts are limited by being dataset or task-specific.","Moreover, these metrics can only be calculated by exchanging data, a practice restricted in many FL scenarios.","To address these challenges, we propose a novel metric for assessing dataset similarity.","Our metric exhibits several desirable properties for FL: it is dataset-agnostic, is calculated in a privacy-preserving manner, and is computationally efficient, requiring no model training.","In this paper, we first establish a theoretical connection between our metric and training dynamics in FL.","Next, we extensively evaluate our metric on a range of datasets including synthetic, benchmark, and medical imaging datasets.","We demonstrate that our metric shows a robust and interpretable relationship with model performance and can be calculated in privacy-preserving manner.","As the first federated dataset similarity metric, we believe this metric can better facilitate successful collaborations between sites."],"url":"http://arxiv.org/abs/2404.18773v1"}
{"created":"2024-04-29 15:05:42","title":"Saliency Suppressed, Semantics Surfaced: Visual Transformations in Neural Networks and the Brain","abstract":"Deep learning algorithms lack human-interpretable accounts of how they transform raw visual input into a robust semantic understanding, which impedes comparisons between different architectures, training objectives, and the human brain. In this work, we take inspiration from neuroscience and employ representational approaches to shed light on how neural networks encode information at low (visual saliency) and high (semantic similarity) levels of abstraction. Moreover, we introduce a custom image dataset where we systematically manipulate salient and semantic information. We find that ResNets are more sensitive to saliency information than ViTs, when trained with object classification objectives. We uncover that networks suppress saliency in early layers, a process enhanced by natural language supervision (CLIP) in ResNets. CLIP also enhances semantic encoding in both architectures. Finally, we show that semantic encoding is a key factor in aligning AI with human visual perception, while saliency suppression is a non-brain-like strategy.","sentences":["Deep learning algorithms lack human-interpretable accounts of how they transform raw visual input into a robust semantic understanding, which impedes comparisons between different architectures, training objectives, and the human brain.","In this work, we take inspiration from neuroscience and employ representational approaches to shed light on how neural networks encode information at low (visual saliency) and high (semantic similarity) levels of abstraction.","Moreover, we introduce a custom image dataset where we systematically manipulate salient and semantic information.","We find that ResNets are more sensitive to saliency information than ViTs, when trained with object classification objectives.","We uncover that networks suppress saliency in early layers, a process enhanced by natural language supervision (CLIP) in ResNets.","CLIP also enhances semantic encoding in both architectures.","Finally, we show that semantic encoding is a key factor in aligning AI with human visual perception, while saliency suppression is a non-brain-like strategy."],"url":"http://arxiv.org/abs/2404.18772v1"}
{"created":"2024-04-29 15:05:27","title":"KBX: Verified Model Synchronization via Formal Bidirectional Transformation","abstract":"Complex safety-critical systems require multiple models for a comprehensive description, resulting in error-prone development and laborious verification. Bidirectional transformation (BX) is an approach to automatically synchronizing these models. However, existing BX frameworks lack formal verification to enforce these models' consistency rigorously. This paper introduces KBX, a formal bidirectional transformation framework for verified model synchronization. First, we present a matching logic-based BX model, providing a logical foundation for constructing BX definitions within the $\\mathbb{K}$ framework. Second, we propose algorithms to synthesize formal BX definitions from unidirectional ones, which allows developers to focus on crafting the unidirectional definitions while disregarding the reverse direction and missing information recovery for synchronization. Afterward, we harness $\\mathbb{K}$ to generate a formal synchronizer from the synthesized definitions for consistency maintenance and verification. To evaluate the effectiveness of KBX, we conduct a comparative analysis against existing BX frameworks. Furthermore, we demonstrate the application of KBX in constructing a BX between UML and HCSP for real-world scenarios, showcasing an 82.8\\% reduction in BX development effort compared to manual specification writing in $\\mathbb{K}$.","sentences":["Complex safety-critical systems require multiple models for a comprehensive description, resulting in error-prone development and laborious verification.","Bidirectional transformation (BX) is an approach to automatically synchronizing these models.","However, existing BX frameworks lack formal verification to enforce these models' consistency rigorously.","This paper introduces KBX, a formal bidirectional transformation framework for verified model synchronization.","First, we present a matching logic-based BX model, providing a logical foundation for constructing BX definitions within the $\\mathbb{K}$ framework.","Second, we propose algorithms to synthesize formal BX definitions from unidirectional ones, which allows developers to focus on crafting the unidirectional definitions while disregarding the reverse direction and missing information recovery for synchronization.","Afterward, we harness $\\mathbb{K}$ to generate a formal synchronizer from the synthesized definitions for consistency maintenance and verification.","To evaluate the effectiveness of KBX, we conduct a comparative analysis against existing BX frameworks.","Furthermore, we demonstrate the application of KBX in constructing a BX between UML and HCSP for real-world scenarios, showcasing an 82.8\\% reduction in BX development effort compared to manual specification writing in $\\mathbb{K}$."],"url":"http://arxiv.org/abs/2404.18771v1"}
{"created":"2024-04-29 15:02:57","title":"A Port-Hamiltonian System Perspective on Electromagneto-Quasistatic Field Formulations of Darwin-Type","abstract":"Electromagneto-quasistatic (EMQS) field formulations are often dubbed as Darwin-type field formulations which approximate the Maxwell equations by neglecting radiation effects while modelling resistive, capacitive, and inductive effects. A common feature of EMQS field models is the Darwin-Amp\\'ere equation formulated with the magnetic vector potential and the electric scalar potential. EMQS field formulations yield different approximations to the Maxwell equations by choice of additional gauge equations. These EMQS formulations are analyzed within the port-Hamiltonian system (PHS) framework. It is shown via the PHS compatibility equation that formulations based on the combination of the Darwin-Amp\\'ere equation and the full Maxwell continuity equation yield port-Hamiltonian systems implying numerical stability and specific EMQS energy conservation.","sentences":["Electromagneto-quasistatic (EMQS) field formulations are often dubbed as Darwin-type field formulations which approximate the Maxwell equations by neglecting radiation effects while modelling resistive, capacitive, and inductive effects.","A common feature of EMQS field models is the Darwin-Amp\\'ere equation formulated with the magnetic vector potential and the electric scalar potential.","EMQS field formulations yield different approximations to the Maxwell equations by choice of additional gauge equations.","These EMQS formulations are analyzed within the port-Hamiltonian system (PHS) framework.","It is shown via the PHS compatibility equation that formulations based on the combination of the Darwin-Amp\\'ere equation and the full Maxwell continuity equation yield port-Hamiltonian systems implying numerical stability and specific EMQS energy conservation."],"url":"http://arxiv.org/abs/2404.18767v1"}
{"created":"2024-04-29 15:02:14","title":"PECC: Problem Extraction and Coding Challenges","abstract":"Recent advancements in large language models (LLMs) have showcased their exceptional abilities across various tasks, such as code generation, problem-solving and reasoning. Existing benchmarks evaluate tasks in isolation, yet the extent to which LLMs can understand prose-style tasks, identify the underlying problems, and then generate appropriate code solutions is still unexplored. Addressing this gap, we introduce PECC, a novel benchmark derived from Advent Of Code (AoC) challenges and Project Euler, including 2396 problems. Unlike conventional benchmarks, PECC requires LLMs to interpret narrative-embedded problems, extract requirements, and generate executable code. A key feature of our dataset is the complexity added by natural language prompting in chat-based evaluations, mirroring real-world instruction ambiguities. Results show varying model performance between narrative and neutral problems, with specific challenges in the Euler math-based subset with GPT-3.5-Turbo passing 50% of the AoC challenges and only 8% on the Euler problems. By probing the limits of LLMs' capabilities, our benchmark provides a framework to monitor and assess the subsequent progress of LLMs as a universal problem solver.","sentences":["Recent advancements in large language models (LLMs) have showcased their exceptional abilities across various tasks, such as code generation, problem-solving and reasoning.","Existing benchmarks evaluate tasks in isolation, yet the extent to which LLMs can understand prose-style tasks, identify the underlying problems, and then generate appropriate code solutions is still unexplored.","Addressing this gap, we introduce PECC, a novel benchmark derived from Advent Of Code (AoC) challenges and Project Euler, including 2396 problems.","Unlike conventional benchmarks, PECC requires LLMs to interpret narrative-embedded problems, extract requirements, and generate executable code.","A key feature of our dataset is the complexity added by natural language prompting in chat-based evaluations, mirroring real-world instruction ambiguities.","Results show varying model performance between narrative and neutral problems, with specific challenges in the Euler math-based subset with GPT-3.5-Turbo passing 50% of the AoC challenges and only 8% on the Euler problems.","By probing the limits of LLMs' capabilities, our benchmark provides a framework to monitor and assess the subsequent progress of LLMs as a universal problem solver."],"url":"http://arxiv.org/abs/2404.18766v1"}
{"created":"2024-04-29 15:01:09","title":"From Density to Geometry: YOLOv8 Instance Segmentation for Reverse Engineering of Optimized Structures","abstract":"This paper introduces YOLOv8-TO, a novel approach for reverse engineering of topology-optimized structures into interpretable geometric parameters using the YOLOv8 instance segmentation model. Density-based topology optimization methods require post-processing to convert the optimal density distribution into a parametric representation for design exploration and integration with CAD tools. Traditional methods such as skeletonization struggle with complex geometries and require manual intervention. YOLOv8-TO addresses these challenges by training a custom YOLOv8 model to automatically detect and reconstruct structural components from binary density distributions. The model is trained on a diverse dataset of both optimized and random structures generated using the Moving Morphable Components method. A custom reconstruction loss function based on the dice coefficient of the predicted geometry is used to train the new regression head of the model via self-supervised learning. The method is evaluated on test sets generated from different topology optimization methods, including out-of-distribution samples, and compared against a skeletonization approach. Results show that YOLOv8-TO significantly outperforms skeletonization in reconstructing visually and structurally similar designs. The method showcases an average improvement of 13.84% in the Dice coefficient, with peak enhancements reaching 20.78%. The method demonstrates good generalization to complex geometries and fast inference times, making it suitable for integration into design workflows using regular workstations. Limitations include the sensitivity to non-max suppression thresholds. YOLOv8-TO represents a significant advancement in topology optimization post-processing, enabling efficient and accurate reverse engineering of optimized structures for design exploration and manufacturing.","sentences":["This paper introduces YOLOv8-TO, a novel approach for reverse engineering of topology-optimized structures into interpretable geometric parameters using the YOLOv8 instance segmentation model.","Density-based topology optimization methods require post-processing to convert the optimal density distribution into a parametric representation for design exploration and integration with CAD tools.","Traditional methods such as skeletonization struggle with complex geometries and require manual intervention.","YOLOv8-TO addresses these challenges by training a custom YOLOv8 model to automatically detect and reconstruct structural components from binary density distributions.","The model is trained on a diverse dataset of both optimized and random structures generated using the Moving Morphable Components method.","A custom reconstruction loss function based on the dice coefficient of the predicted geometry is used to train the new regression head of the model via self-supervised learning.","The method is evaluated on test sets generated from different topology optimization methods, including out-of-distribution samples, and compared against a skeletonization approach.","Results show that YOLOv8-TO significantly outperforms skeletonization in reconstructing visually and structurally similar designs.","The method showcases an average improvement of 13.84% in the Dice coefficient, with peak enhancements reaching 20.78%.","The method demonstrates good generalization to complex geometries and fast inference times, making it suitable for integration into design workflows using regular workstations.","Limitations include the sensitivity to non-max suppression thresholds.","YOLOv8-TO represents a significant advancement in topology optimization post-processing, enabling efficient and accurate reverse engineering of optimized structures for design exploration and manufacturing."],"url":"http://arxiv.org/abs/2404.18763v1"}
{"created":"2024-04-29 14:57:16","title":"Flow AM: Generating Point Cloud Global Explanations by Latent Alignment","abstract":"Although point cloud models have gained significant improvements in prediction accuracy over recent years, their trustworthiness is still not sufficiently investigated. In terms of global explainability, Activation Maximization (AM) techniques in the image domain are not directly transplantable due to the special structure of the point cloud models. Existing studies exploit generative models to yield global explanations that can be perceived by humans. However, the opacity of the generative models themselves and the introduction of additional priors call into question the plausibility and fidelity of the explanations. In this work, we demonstrate that when the classifier predicts different types of instances, the intermediate layer activations are differently activated, known as activation flows. Based on this property, we propose an activation flow-based AM method that generates global explanations that can be perceived without incorporating any generative model. Furthermore, we reveal that AM based on generative models fails the sanity checks and thus lack of fidelity. Extensive experiments show that our approach dramatically enhances the perceptibility of explanations compared to other AM methods that are not based on generative models. Our code is available at: https://github.com/Explain3D/FlowAM","sentences":["Although point cloud models have gained significant improvements in prediction accuracy over recent years, their trustworthiness is still not sufficiently investigated.","In terms of global explainability, Activation Maximization (AM) techniques in the image domain are not directly transplantable due to the special structure of the point cloud models.","Existing studies exploit generative models to yield global explanations that can be perceived by humans.","However, the opacity of the generative models themselves and the introduction of additional priors call into question the plausibility and fidelity of the explanations.","In this work, we demonstrate that when the classifier predicts different types of instances, the intermediate layer activations are differently activated, known as activation flows.","Based on this property, we propose an activation flow-based AM method that generates global explanations that can be perceived without incorporating any generative model.","Furthermore, we reveal that AM based on generative models fails the sanity checks and thus lack of fidelity.","Extensive experiments show that our approach dramatically enhances the perceptibility of explanations compared to other AM methods that are not based on generative models.","Our code is available at: https://github.com/Explain3D/FlowAM"],"url":"http://arxiv.org/abs/2404.18760v1"}
{"created":"2024-04-29 14:56:47","title":"Towards A Structured Overview of Use Cases for Natural Language Processing in the Legal Domain: A German Perspective","abstract":"In recent years, the field of Legal Tech has risen in prevalence, as the Natural Language Processing (NLP) and legal disciplines have combined forces to digitalize legal processes. Amidst the steady flow of research solutions stemming from the NLP domain, the study of use cases has fallen behind, leading to a number of innovative technical methods without a place in practice. In this work, we aim to build a structured overview of Legal Tech use cases, grounded in NLP literature, but also supplemented by voices from legal practice in Germany. Based upon a Systematic Literature Review, we identify seven categories of NLP technologies for the legal domain, which are then studied in juxtaposition to 22 legal use cases. In the investigation of these use cases, we identify 15 ethical, legal, and social aspects (ELSA), shedding light on the potential concerns of digitally transforming the legal domain.","sentences":["In recent years, the field of Legal Tech has risen in prevalence, as the Natural Language Processing (NLP) and legal disciplines have combined forces to digitalize legal processes.","Amidst the steady flow of research solutions stemming from the NLP domain, the study of use cases has fallen behind, leading to a number of innovative technical methods without a place in practice.","In this work, we aim to build a structured overview of Legal Tech use cases, grounded in NLP literature, but also supplemented by voices from legal practice in Germany.","Based upon a Systematic Literature Review, we identify seven categories of NLP technologies for the legal domain, which are then studied in juxtaposition to 22 legal use cases.","In the investigation of these use cases, we identify 15 ethical, legal, and social aspects (ELSA), shedding light on the potential concerns of digitally transforming the legal domain."],"url":"http://arxiv.org/abs/2404.18759v1"}
{"created":"2024-04-29 14:56:11","title":"Transitive Vision-Language Prompt Learning for Domain Generalization","abstract":"The vision-language pre-training has enabled deep models to make a huge step forward in generalizing across unseen domains. The recent learning method based on the vision-language pre-training model is a great tool for domain generalization and can solve this problem to a large extent. However, there are still some issues that an advancement still suffers from trading-off between domain invariance and class separability, which are crucial in current DG problems. However, there are still some issues that an advancement still suffers from trading-off between domain invariance and class separability, which are crucial in current DG problems. In this paper, we introduce a novel prompt learning strategy that leverages deep vision prompts to address domain invariance while utilizing language prompts to ensure class separability, coupled with adaptive weighting mechanisms to balance domain invariance and class separability. Extensive experiments demonstrate that deep vision prompts effectively extract domain-invariant features, significantly improving the generalization ability of deep models and achieving state-of-the-art performance on three datasets.","sentences":["The vision-language pre-training has enabled deep models to make a huge step forward in generalizing across unseen domains.","The recent learning method based on the vision-language pre-training model is a great tool for domain generalization and can solve this problem to a large extent.","However, there are still some issues that an advancement still suffers from trading-off between domain invariance and class separability, which are crucial in current DG problems.","However, there are still some issues that an advancement still suffers from trading-off between domain invariance and class separability, which are crucial in current DG problems.","In this paper, we introduce a novel prompt learning strategy that leverages deep vision prompts to address domain invariance while utilizing language prompts to ensure class separability, coupled with adaptive weighting mechanisms to balance domain invariance and class separability.","Extensive experiments demonstrate that deep vision prompts effectively extract domain-invariant features, significantly improving the generalization ability of deep models and achieving state-of-the-art performance on three datasets."],"url":"http://arxiv.org/abs/2404.18758v1"}
{"created":"2024-04-29 14:54:50","title":"K-CIRCT: A Layered, Composable, and Executable Formal Semantics for CIRCT Hardware IRs","abstract":"CIRCT, an open-source EDA framework akin to LLVM for software, is a foundation for various hardware description languages. Despite its crucial role, CIRCT's lack of formal semantics challenges necessary rigorous hardware verification. Thus, this paper introduces K-CIRCT, the first formal semantics in {\\K} for a substantial CIRCT subset adequate for simulating a RISC-V processor. Our semantics are structured into multiple layers: (1) MLIR static semantics, which covers fundamental MLIR concepts across domains; (2) CIRCT common semantics, featuring a generic hardware model that captures key hardware features across dialects; and (3) composable and extensible semantics for specific dialects, formalized individually using a unified approach. This approach has been applied to formalize CIRCT core dialects. We validated our semantics through full-rule coverage tests and assessed its practicality using the popular RISC-V hardware design, riscv-mini.","sentences":["CIRCT, an open-source EDA framework akin to LLVM for software, is a foundation for various hardware description languages.","Despite its crucial role, CIRCT's lack of formal semantics challenges necessary rigorous hardware verification.","Thus, this paper introduces K-CIRCT, the first formal semantics in {\\K} for a substantial CIRCT subset adequate for simulating a RISC-V processor.","Our semantics are structured into multiple layers: (1) MLIR static semantics, which covers fundamental MLIR concepts across domains; (2) CIRCT common semantics, featuring a generic hardware model that captures key hardware features across dialects; and (3) composable and extensible semantics for specific dialects, formalized individually using a unified approach.","This approach has been applied to formalize CIRCT core dialects.","We validated our semantics through full-rule coverage tests and assessed its practicality using the popular RISC-V hardware design, riscv-mini."],"url":"http://arxiv.org/abs/2404.18756v1"}
{"created":"2024-04-29 14:53:16","title":"Desirability and social rankings","abstract":"In coalitional games, a player $i$ is regarded as strictly more desirable than player $j$ if substituting $j$ with $i$ within any coalition leads to a strict augmentation in the value of certain coalitions, while preserving the value of the others. We adopt a property-driven approach to 'integrate' the notion of the desirability relation into a total relation by establishing sets of independent axioms leading to the characterization of solutionconcepts from the related literature. We focus on social ranking solutions consistent with the desirability relation and propose complementary sets of properties for the axiomatic characterization of five existing solutions: Ceteris Paribus (CP-)majority, lexicographic excellence (lex-cel), dual-lex, $L^{(1)}$ solution and its dual version $L^{(1)}_{*}$ . These characterizations reveal additional similarities among the five solutions and emphasize the essential characteristics that should be taken into account when selecting a social ranking. A practical scenario involving a bicameral legislature is studied.","sentences":["In coalitional games, a player $i$ is regarded as strictly more desirable than player $j$ if substituting $j$ with $i$ within any coalition leads to a strict augmentation in the value of certain coalitions, while preserving the value of the others.","We adopt a property-driven approach to 'integrate' the notion of the desirability relation into a total relation by establishing sets of independent axioms leading to the characterization of solutionconcepts from the related literature.","We focus on social ranking solutions consistent with the desirability relation and propose complementary sets of properties for the axiomatic characterization of five existing solutions: Ceteris Paribus (CP-)majority, lexicographic excellence (lex-cel), dual-lex, $L^{(1)}$ solution and its dual version $L^{(1)}_{*}$ .","These characterizations reveal additional similarities among the five solutions and emphasize the essential characteristics that should be taken into account when selecting a social ranking.","A practical scenario involving a bicameral legislature is studied."],"url":"http://arxiv.org/abs/2404.18755v1"}
{"created":"2024-04-29 14:49:35","title":"Survey on Datasets for Perception in Unstructured Outdoor Environments","abstract":"Perception is an essential component of pipelines in field robotics. In this survey, we quantitatively compare publicly available datasets available in unstructured outdoor environments. We focus on datasets for common perception tasks in field robotics. Our survey categorizes and compares available research datasets. This survey also reports on relevant dataset characteristics to help practitioners determine which dataset fits best for their own application. We believe more consideration should be taken in choosing compatible annotation policies across the datasets in unstructured outdoor environments.","sentences":["Perception is an essential component of pipelines in field robotics.","In this survey, we quantitatively compare publicly available datasets available in unstructured outdoor environments.","We focus on datasets for common perception tasks in field robotics.","Our survey categorizes and compares available research datasets.","This survey also reports on relevant dataset characteristics to help practitioners determine which dataset fits best for their own application.","We believe more consideration should be taken in choosing compatible annotation policies across the datasets in unstructured outdoor environments."],"url":"http://arxiv.org/abs/2404.18750v1"}
{"created":"2024-04-29 14:47:32","title":"Evaluating the Effectiveness of Video Anomaly Detection in the Wild: Online Learning and Inference for Real-world Deployment","abstract":"Video Anomaly Detection (VAD) identifies unusual activities in video streams, a key technology with broad applications ranging from surveillance to healthcare. Tackling VAD in real-life settings poses significant challenges due to the dynamic nature of human actions, environmental variations, and domain shifts. Many research initiatives neglect these complexities, often concentrating on traditional testing methods that fail to account for performance on unseen datasets, creating a gap between theoretical models and their real-world utility. Online learning is a potential strategy to mitigate this issue by allowing models to adapt to new information continuously. This paper assesses how well current VAD algorithms can adjust to real-life conditions through an online learning framework, particularly those based on pose analysis, for their efficiency and privacy advantages. Our proposed framework enables continuous model updates with streaming data from novel environments, thus mirroring actual world challenges and evaluating the models' ability to adapt in real-time while maintaining accuracy. We investigate three state-of-the-art models in this setting, focusing on their adaptability across different domains. Our findings indicate that, even under the most challenging conditions, our online learning approach allows a model to preserve 89.39% of its original effectiveness compared to its offline-trained counterpart in a specific target domain.","sentences":["Video Anomaly Detection (VAD) identifies unusual activities in video streams, a key technology with broad applications ranging from surveillance to healthcare.","Tackling VAD in real-life settings poses significant challenges due to the dynamic nature of human actions, environmental variations, and domain shifts.","Many research initiatives neglect these complexities, often concentrating on traditional testing methods that fail to account for performance on unseen datasets, creating a gap between theoretical models and their real-world utility.","Online learning is a potential strategy to mitigate this issue by allowing models to adapt to new information continuously.","This paper assesses how well current VAD algorithms can adjust to real-life conditions through an online learning framework, particularly those based on pose analysis, for their efficiency and privacy advantages.","Our proposed framework enables continuous model updates with streaming data from novel environments, thus mirroring actual world challenges and evaluating the models' ability to adapt in real-time while maintaining accuracy.","We investigate three state-of-the-art models in this setting, focusing on their adaptability across different domains.","Our findings indicate that, even under the most challenging conditions, our online learning approach allows a model to preserve 89.39% of its original effectiveness compared to its offline-trained counterpart in a specific target domain."],"url":"http://arxiv.org/abs/2404.18747v1"}
{"created":"2024-04-29 14:46:35","title":"Enhancing Interactive Image Retrieval With Query Rewriting Using Large Language Models and Vision Language Models","abstract":"Image search stands as a pivotal task in multimedia and computer vision, finding applications across diverse domains, ranging from internet search to medical diagnostics. Conventional image search systems operate by accepting textual or visual queries, retrieving the top-relevant candidate results from the database. However, prevalent methods often rely on single-turn procedures, introducing potential inaccuracies and limited recall. These methods also face the challenges, such as vocabulary mismatch and the semantic gap, constraining their overall effectiveness. To address these issues, we propose an interactive image retrieval system capable of refining queries based on user relevance feedback in a multi-turn setting. This system incorporates a vision language model (VLM) based image captioner to enhance the quality of text-based queries, resulting in more informative queries with each iteration. Moreover, we introduce a large language model (LLM) based denoiser to refine text-based query expansions, mitigating inaccuracies in image descriptions generated by captioning models. To evaluate our system, we curate a new dataset by adapting the MSR-VTT video retrieval dataset to the image retrieval task, offering multiple relevant ground truth images for each query. Through comprehensive experiments, we validate the effectiveness of our proposed system against baseline methods, achieving state-of-the-art performance with a notable 10\\% improvement in terms of recall. Our contributions encompass the development of an innovative interactive image retrieval system, the integration of an LLM-based denoiser, the curation of a meticulously designed evaluation dataset, and thorough experimental validation.","sentences":["Image search stands as a pivotal task in multimedia and computer vision, finding applications across diverse domains, ranging from internet search to medical diagnostics.","Conventional image search systems operate by accepting textual or visual queries, retrieving the top-relevant candidate results from the database.","However, prevalent methods often rely on single-turn procedures, introducing potential inaccuracies and limited recall.","These methods also face the challenges, such as vocabulary mismatch and the semantic gap, constraining their overall effectiveness.","To address these issues, we propose an interactive image retrieval system capable of refining queries based on user relevance feedback in a multi-turn setting.","This system incorporates a vision language model (VLM) based image captioner to enhance the quality of text-based queries, resulting in more informative queries with each iteration.","Moreover, we introduce a large language model (LLM) based denoiser to refine text-based query expansions, mitigating inaccuracies in image descriptions generated by captioning models.","To evaluate our system, we curate a new dataset by adapting the MSR-VTT video retrieval dataset to the image retrieval task, offering multiple relevant ground truth images for each query.","Through comprehensive experiments, we validate the effectiveness of our proposed system against baseline methods, achieving state-of-the-art performance with a notable 10\\% improvement in terms of recall.","Our contributions encompass the development of an innovative interactive image retrieval system, the integration of an LLM-based denoiser, the curation of a meticulously designed evaluation dataset, and thorough experimental validation."],"url":"http://arxiv.org/abs/2404.18746v1"}
{"created":"2024-04-29 14:41:59","title":"Towards Dog Bark Decoding: Leveraging Human Speech Processing for Automated Bark Classification","abstract":"Similar to humans, animals make extensive use of verbal and non-verbal forms of communication, including a large range of audio signals. In this paper, we address dog vocalizations and explore the use of self-supervised speech representation models pre-trained on human speech to address dog bark classification tasks that find parallels in human-centered tasks in speech recognition. We specifically address four tasks: dog recognition, breed identification, gender classification, and context grounding. We show that using speech embedding representations significantly improves over simpler classification baselines. Further, we also find that models pre-trained on large human speech acoustics can provide additional performance boosts on several tasks.","sentences":["Similar to humans, animals make extensive use of verbal and non-verbal forms of communication, including a large range of audio signals.","In this paper, we address dog vocalizations and explore the use of self-supervised speech representation models pre-trained on human speech to address dog bark classification tasks that find parallels in human-centered tasks in speech recognition.","We specifically address four tasks: dog recognition, breed identification, gender classification, and context grounding.","We show that using speech embedding representations significantly improves over simpler classification baselines.","Further, we also find that models pre-trained on large human speech acoustics can provide additional performance boosts on several tasks."],"url":"http://arxiv.org/abs/2404.18739v1"}
{"created":"2024-04-29 14:37:56","title":"A faster algorithm for the Fr\u00e9chet distance in 1D for the imbalanced case","abstract":"The fine-grained complexity of computing the Fr\\'echet distance has been a topic of much recent work, starting with the quadratic SETH-based conditional lower bound by Bringmann from 2014. Subsequent work established largely the same complexity lower bounds for the Fr\\'echet distance in 1D. However, the imbalanced case, which was shown by Bringmann to be tight in dimensions $d\\geq 2$, was still left open. Filling in this gap, we show that a faster algorithm for the Fr\\'echet distance in the imbalanced case is possible: Given two 1-dimensional curves of complexity $n$ and $n^{\\alpha}$ for some $\\alpha \\in (0,1)$, we can compute their Fr\\'echet distance in $O(n^{2\\alpha} \\log^2 n + n \\log n)$ time. This rules out a conditional lower bound of the form $O((nm)^{1-\\epsilon})$ that Bringmann showed for $d \\geq 2$ and any $\\varepsilon>0$ in turn showing a strict separation with the setting $d=1$. At the heart of our approach lies a data structure that stores a 1-dimensional curve $P$ of complexity $n$, and supports queries with a curve $Q$ of complexity~$m$ for the continuous Fr\\'echet distance between $P$ and $Q$. The data structure has size in $\\mathcal{O}(n\\log n)$ and uses query time in $\\mathcal{O}(m^2 \\log^2 n)$. Our proof uses a key lemma that is based on the concept of visiting orders and may be of independent interest. We demonstrate this by substantially simplifying the correctness proof of a clustering algorithm by Driemel, Krivo\\v{s}ija and Sohler from 2015.","sentences":["The fine-grained complexity of computing the Fr\\'echet distance has been a topic of much recent work, starting with the quadratic SETH-based conditional lower bound by Bringmann from 2014.","Subsequent work established largely the same complexity lower bounds for the Fr\\'echet distance in 1D. However, the imbalanced case, which was shown by Bringmann to be tight in dimensions $d\\geq 2$, was still left open.","Filling in this gap, we show that a faster algorithm for the Fr\\'echet distance in the imbalanced case is possible: Given two 1-dimensional curves of complexity $n$ and $n^{\\alpha}$ for some $\\alpha \\in (0,1)$, we can compute their Fr\\'echet distance in $O(n^{2\\alpha} \\log^2 n + n \\log n)$ time.","This rules out a conditional lower bound of the form $O((nm)^{1-\\epsilon})$ that Bringmann showed for $d \\geq 2$ and any $\\varepsilon>0$ in turn showing a strict separation with the setting $d=1$. At the heart of our approach lies a data structure that stores a 1-dimensional curve $P$ of complexity $n$, and supports queries with a curve $Q$ of complexity~$m$ for the continuous Fr\\'echet distance between $P$ and $Q$. The data structure has size in $\\mathcal{O}(n\\log n)$ and uses query time in $\\mathcal{O}(m^2 \\log^2 n)$. Our proof uses a key lemma that is based on the concept of visiting orders and may be of independent interest.","We demonstrate this by substantially simplifying the correctness proof of a clustering algorithm by Driemel, Krivo\\v{s}ija and Sohler from 2015."],"url":"http://arxiv.org/abs/2404.18738v1"}
{"created":"2024-04-29 14:34:43","title":"Mapping the Potential of Explainable Artificial Intelligence (XAI) for Fairness Along the AI Lifecycle","abstract":"The widespread use of artificial intelligence (AI) systems across various domains is increasingly highlighting issues related to algorithmic fairness, especially in high-stakes scenarios. Thus, critical considerations of how fairness in AI systems might be improved, and what measures are available to aid this process, are overdue. Many researchers and policymakers see explainable AI (XAI) as a promising way to increase fairness in AI systems. However, there is a wide variety of XAI methods and fairness conceptions expressing different desiderata, and the precise connections between XAI and fairness remain largely nebulous. Besides, different measures to increase algorithmic fairness might be applicable at different points throughout an AI system's lifecycle. Yet, there currently is no coherent mapping of fairness desiderata along the AI lifecycle. In this paper, we set out to bridge both these gaps: We distill eight fairness desiderata, map them along the AI lifecycle, and discuss how XAI could help address each of them. We hope to provide orientation for practical applications and to inspire XAI research specifically focused on these fairness desiderata.","sentences":["The widespread use of artificial intelligence (AI) systems across various domains is increasingly highlighting issues related to algorithmic fairness, especially in high-stakes scenarios.","Thus, critical considerations of how fairness in AI systems might be improved, and what measures are available to aid this process, are overdue.","Many researchers and policymakers see explainable AI (XAI) as a promising way to increase fairness in AI systems.","However, there is a wide variety of XAI methods and fairness conceptions expressing different desiderata, and the precise connections between XAI and fairness remain largely nebulous.","Besides, different measures to increase algorithmic fairness might be applicable at different points throughout an AI system's lifecycle.","Yet, there currently is no coherent mapping of fairness desiderata along the AI lifecycle.","In this paper, we set out to bridge both these gaps: We distill eight fairness desiderata, map them along the AI lifecycle, and discuss how XAI could help address each of them.","We hope to provide orientation for practical applications and to inspire XAI research specifically focused on these fairness desiderata."],"url":"http://arxiv.org/abs/2404.18736v1"}
{"created":"2024-04-29 14:17:52","title":"Real Time Multi Organ Classification on Computed Tomography Images","abstract":"Organ segmentation is a fundamental task in medical imaging, and it is useful for many clinical automation pipelines. Typically, the process involves segmenting the entire volume, which can be unnecessary when the points of interest are limited. In those cases, a classifier could be used instead of segmentation. However, there is an inherent trade-off between the context size and the speed of classifiers. To address this issue, we propose a new method that employs a data selection strategy with sparse sampling across a wide field of view without image resampling. This sparse sampling strategy makes it possible to classify voxels into multiple organs in real time without using accelerators. Although our method is an independent classifier, it can generate full segmentation by querying grid locations at any resolution. We have compared our method with existing segmentation techniques, demonstrating its potential for superior runtime in practical applications in medical imaging.","sentences":["Organ segmentation is a fundamental task in medical imaging, and it is useful for many clinical automation pipelines.","Typically, the process involves segmenting the entire volume, which can be unnecessary when the points of interest are limited.","In those cases, a classifier could be used instead of segmentation.","However, there is an inherent trade-off between the context size and the speed of classifiers.","To address this issue, we propose a new method that employs a data selection strategy with sparse sampling across a wide field of view without image resampling.","This sparse sampling strategy makes it possible to classify voxels into multiple organs in real time without using accelerators.","Although our method is an independent classifier, it can generate full segmentation by querying grid locations at any resolution.","We have compared our method with existing segmentation techniques, demonstrating its potential for superior runtime in practical applications in medical imaging."],"url":"http://arxiv.org/abs/2404.18731v1"}
{"created":"2024-04-29 14:16:16","title":"CVTN: Cross Variable and Temporal Integration for Time Series Forecasting","abstract":"In multivariate time series forecasting, the Transformer architecture encounters two significant challenges: effectively mining features from historical sequences and avoiding overfitting during the learning of temporal dependencies. To tackle these challenges, this paper deconstructs time series forecasting into the learning of historical sequences and prediction sequences, introducing the Cross-Variable and Time Network (CVTN). This unique method divides multivariate time series forecasting into two phases: cross-variable learning for effectively mining fea tures from historical sequences, and cross-time learning to capture the temporal dependencies of prediction sequences. Separating these two phases helps avoid the impact of overfitting in cross-time learning on cross-variable learning. Exten sive experiments on various real-world datasets have confirmed its state-of-the-art (SOTA) performance. CVTN emphasizes three key dimensions in time series fore casting: the short-term and long-term nature of time series (locality and longevity), feature mining from both historical and prediction sequences, and the integration of cross-variable and cross-time learning. This approach not only advances the current state of time series forecasting but also provides a more comprehensive framework for future research in this field.","sentences":["In multivariate time series forecasting, the Transformer architecture encounters two significant challenges: effectively mining features from historical sequences and avoiding overfitting during the learning of temporal dependencies.","To tackle these challenges, this paper deconstructs time series forecasting into the learning of historical sequences and prediction sequences, introducing the Cross-Variable and Time Network (CVTN).","This unique method divides multivariate time series forecasting into two phases: cross-variable learning for effectively mining fea tures from historical sequences, and cross-time learning to capture the temporal dependencies of prediction sequences.","Separating these two phases helps avoid the impact of overfitting in cross-time learning on cross-variable learning.","Exten sive experiments on various real-world datasets have confirmed its state-of-the-art (SOTA) performance.","CVTN emphasizes three key dimensions in time series fore casting: the short-term and long-term nature of time series (locality and longevity), feature mining from both historical and prediction sequences, and the integration of cross-variable and cross-time learning.","This approach not only advances the current state of time series forecasting but also provides a more comprehensive framework for future research in this field."],"url":"http://arxiv.org/abs/2404.18730v1"}
{"created":"2024-04-29 14:16:08","title":"Fast Swarming of UAVs in GNSS-denied Feature-poor Environments without Explicit Communication","abstract":"A decentralized swarm approach for the fast cooperative flight of Unmanned Aerial Vehicles (UAVs) in feature-poor environments without any external localization and communication is introduced in this paper.   A novel model of a UAV neighborhood is proposed to achieve robust onboard mutual perception and flocking state feedback control, which is designed to decrease the inter-agent oscillations common in standard reactive swarm models employed in fast collective motion.   The novel swarming methodology is supplemented with an enhanced Multi-Robot State Estimation (MRSE) strategy to increase the reliability of the purely onboard localization, which may be unreliable in real environments.   Although MRSE and the neighborhood model may rely on information exchange between agents, we introduce a communication-less version of the swarming framework based on estimating communicated states to decrease dependence on the often unreliable communication networks of large swarms.   The proposed solution has been verified by a set of complex real-world experiments to demonstrate its overall capability in different conditions, including a UAV interception-motivated task with a group velocity reaching the physical limits of the individual hardware platforms.","sentences":["A decentralized swarm approach for the fast cooperative flight of Unmanned Aerial Vehicles (UAVs) in feature-poor environments without any external localization and communication is introduced in this paper.   ","A novel model of a UAV neighborhood is proposed to achieve robust onboard mutual perception and flocking state feedback control, which is designed to decrease the inter-agent oscillations common in standard reactive swarm models employed in fast collective motion.   ","The novel swarming methodology is supplemented with an enhanced Multi-Robot State Estimation (MRSE) strategy to increase the reliability of the purely onboard localization, which may be unreliable in real environments.   ","Although MRSE and the neighborhood model may rely on information exchange between agents, we introduce a communication-less version of the swarming framework based on estimating communicated states to decrease dependence on the often unreliable communication networks of large swarms.   ","The proposed solution has been verified by a set of complex real-world experiments to demonstrate its overall capability in different conditions, including a UAV interception-motivated task with a group velocity reaching the physical limits of the individual hardware platforms."],"url":"http://arxiv.org/abs/2404.18729v1"}
{"created":"2024-04-29 14:14:33","title":"The Constant in HATE: Analyzing Toxicity in Reddit across Topics and Languages","abstract":"Toxic language remains an ongoing challenge on social media platforms, presenting significant issues for users and communities. This paper provides a cross-topic and cross-lingual analysis of toxicity in Reddit conversations. We collect 1.5 million comment threads from 481 communities in six languages: English, German, Spanish, Turkish,Arabic, and Dutch, covering 80 topics such as Culture, Politics, and News. We thoroughly analyze how toxicity spikes within different communities in relation to specific topics. We observe consistent patterns of increased toxicity across languages for certain topics, while also noting significant variations within specific language communities.","sentences":["Toxic language remains an ongoing challenge on social media platforms, presenting significant issues for users and communities.","This paper provides a cross-topic and cross-lingual analysis of toxicity in Reddit conversations.","We collect 1.5 million comment threads from 481 communities in six languages: English, German, Spanish, Turkish,Arabic, and Dutch, covering 80 topics such as Culture, Politics, and News.","We thoroughly analyze how toxicity spikes within different communities in relation to specific topics.","We observe consistent patterns of increased toxicity across languages for certain topics, while also noting significant variations within specific language communities."],"url":"http://arxiv.org/abs/2404.18726v1"}
