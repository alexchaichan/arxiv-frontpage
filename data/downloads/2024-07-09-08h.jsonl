{"created":"2024-07-08 17:59:57","title":"Multi-Object Hallucination in Vision-Language Models","abstract":"Large vision language models (LVLMs) often suffer from object hallucination, producing objects not present in the given images. While current benchmarks for object hallucination primarily concentrate on the presence of a single object class rather than individual entities, this work systematically investigates multi-object hallucination, examining how models misperceive (e.g., invent nonexistent objects or become distracted) when tasked with focusing on multiple objects simultaneously. We introduce Recognition-based Object Probing Evaluation (ROPE), an automated evaluation protocol that considers the distribution of object classes within a single image during testing and uses visual referring prompts to eliminate ambiguity. With comprehensive empirical studies and analysis of potential factors leading to multi-object hallucination, we found that (1) LVLMs suffer more hallucinations when focusing on multiple objects compared to a single object. (2) The tested object class distribution affects hallucination behaviors, indicating that LVLMs may follow shortcuts and spurious correlations.(3) Hallucinatory behaviors are influenced by data-specific factors, salience and frequency, and model intrinsic behaviors. We hope to enable LVLMs to recognize and reason about multiple objects that often occur in realistic visual scenes, provide insights, and quantify our progress towards mitigating the issues.","sentences":["Large vision language models (LVLMs) often suffer from object hallucination, producing objects not present in the given images.","While current benchmarks for object hallucination primarily concentrate on the presence of a single object class rather than individual entities, this work systematically investigates multi-object hallucination, examining how models misperceive (e.g., invent nonexistent objects or become distracted) when tasked with focusing on multiple objects simultaneously.","We introduce Recognition-based Object Probing Evaluation (ROPE), an automated evaluation protocol that considers the distribution of object classes within a single image during testing and uses visual referring prompts to eliminate ambiguity.","With comprehensive empirical studies and analysis of potential factors leading to multi-object hallucination, we found that (1) LVLMs suffer more hallucinations when focusing on multiple objects compared to a single object.","(2) The tested object class distribution affects hallucination behaviors, indicating that LVLMs may follow shortcuts and spurious correlations.(3)","Hallucinatory behaviors are influenced by data-specific factors, salience and frequency, and model intrinsic behaviors.","We hope to enable LVLMs to recognize and reason about multiple objects that often occur in realistic visual scenes, provide insights, and quantify our progress towards mitigating the issues."],"url":"http://arxiv.org/abs/2407.06192v1"}
{"created":"2024-07-08 17:59:55","title":"Tailor3D: Customized 3D Assets Editing and Generation with Dual-Side Images","abstract":"Recent advances in 3D AIGC have shown promise in directly creating 3D objects from text and images, offering significant cost savings in animation and product design. However, detailed edit and customization of 3D assets remains a long-standing challenge. Specifically, 3D Generation methods lack the ability to follow finely detailed instructions as precisely as their 2D image creation counterparts. Imagine you can get a toy through 3D AIGC but with undesired accessories and dressing. To tackle this challenge, we propose a novel pipeline called Tailor3D, which swiftly creates customized 3D assets from editable dual-side images. We aim to emulate a tailor's ability to locally change objects or perform overall style transfer. Unlike creating 3D assets from multiple views, using dual-side images eliminates conflicts on overlapping areas that occur when editing individual views. Specifically, it begins by editing the front view, then generates the back view of the object through multi-view diffusion. Afterward, it proceeds to edit the back views. Finally, a Dual-sided LRM is proposed to seamlessly stitch together the front and back 3D features, akin to a tailor sewing together the front and back of a garment. The Dual-sided LRM rectifies imperfect consistencies between the front and back views, enhancing editing capabilities and reducing memory burdens while seamlessly integrating them into a unified 3D representation with the LoRA Triplane Transformer. Experimental results demonstrate Tailor3D's effectiveness across various 3D generation and editing tasks, including 3D generative fill and style transfer. It provides a user-friendly, efficient solution for editing 3D assets, with each editing step taking only seconds to complete.","sentences":["Recent advances in 3D AIGC have shown promise in directly creating 3D objects from text and images, offering significant cost savings in animation and product design.","However, detailed edit and customization of 3D assets remains a long-standing challenge.","Specifically, 3D Generation methods lack the ability to follow finely detailed instructions as precisely as their 2D image creation counterparts.","Imagine you can get a toy through 3D AIGC but with undesired accessories and dressing.","To tackle this challenge, we propose a novel pipeline called Tailor3D, which swiftly creates customized 3D assets from editable dual-side images.","We aim to emulate a tailor's ability to locally change objects or perform overall style transfer.","Unlike creating 3D assets from multiple views, using dual-side images eliminates conflicts on overlapping areas that occur when editing individual views.","Specifically, it begins by editing the front view, then generates the back view of the object through multi-view diffusion.","Afterward, it proceeds to edit the back views.","Finally, a Dual-sided LRM is proposed to seamlessly stitch together the front and back 3D features, akin to a tailor sewing together the front and back of a garment.","The Dual-sided LRM rectifies imperfect consistencies between the front and back views, enhancing editing capabilities and reducing memory burdens while seamlessly integrating them into a unified 3D representation with the LoRA Triplane Transformer.","Experimental results demonstrate Tailor3D's effectiveness across various 3D generation and editing tasks, including 3D generative fill and style transfer.","It provides a user-friendly, efficient solution for editing 3D assets, with each editing step taking only seconds to complete."],"url":"http://arxiv.org/abs/2407.06191v1"}
{"created":"2024-07-08 17:59:54","title":"4D Contrastive Superflows are Dense 3D Representation Learners","abstract":"In the realm of autonomous driving, accurate 3D perception is the foundation. However, developing such models relies on extensive human annotations -- a process that is both costly and labor-intensive. To address this challenge from a data representation learning perspective, we introduce SuperFlow, a novel framework designed to harness consecutive LiDAR-camera pairs for establishing spatiotemporal pretraining objectives. SuperFlow stands out by integrating two key designs: 1) a dense-to-sparse consistency regularization, which promotes insensitivity to point cloud density variations during feature learning, and 2) a flow-based contrastive learning module, carefully crafted to extract meaningful temporal cues from readily available sensor calibrations. To further boost learning efficiency, we incorporate a plug-and-play view consistency module that enhances the alignment of the knowledge distilled from camera views. Extensive comparative and ablation studies across 11 heterogeneous LiDAR datasets validate our effectiveness and superiority. Additionally, we observe several interesting emerging properties by scaling up the 2D and 3D backbones during pretraining, shedding light on the future research of 3D foundation models for LiDAR-based perception.","sentences":["In the realm of autonomous driving, accurate 3D perception is the foundation.","However, developing such models relies on extensive human annotations -- a process that is both costly and labor-intensive.","To address this challenge from a data representation learning perspective, we introduce SuperFlow, a novel framework designed to harness consecutive LiDAR-camera pairs for establishing spatiotemporal pretraining objectives.","SuperFlow stands out by integrating two key designs: 1) a dense-to-sparse consistency regularization, which promotes insensitivity to point cloud density variations during feature learning, and 2) a flow-based contrastive learning module, carefully crafted to extract meaningful temporal cues from readily available sensor calibrations.","To further boost learning efficiency, we incorporate a plug-and-play view consistency module that enhances the alignment of the knowledge distilled from camera views.","Extensive comparative and ablation studies across 11 heterogeneous LiDAR datasets validate our effectiveness and superiority.","Additionally, we observe several interesting emerging properties by scaling up the 2D and 3D backbones during pretraining, shedding light on the future research of 3D foundation models for LiDAR-based perception."],"url":"http://arxiv.org/abs/2407.06190v1"}
{"created":"2024-07-08 17:59:42","title":"Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision","abstract":"The performance of Large Vision Language Models (LVLMs) is dependent on the size and quality of their training datasets. Existing video instruction tuning datasets lack diversity as they are derived by prompting large language models with video captions to generate question-answer pairs, and are therefore mostly descriptive. Meanwhile, many labeled video datasets with diverse labels and supervision exist - however, we find that their integration into LVLMs is non-trivial. Herein, we present Video Self-Training with augmented Reasoning (Video-STaR), the first video self-training approach. Video-STaR allows the utilization of any labeled video dataset for video instruction tuning. In Video-STaR, an LVLM cycles between instruction generation and finetuning, which we show (I) improves general video understanding and (II) adapts LVLMs to novel downstream tasks with existing supervision. During generation, an LVLM is prompted to propose an answer. The answers are then filtered only to those that contain the original video labels, and the LVLM is then re-trained on the generated dataset. By only training on generated answers that contain the correct video labels, Video-STaR utilizes these existing video labels as weak supervision for video instruction tuning. Our results demonstrate that Video-STaR-enhanced LVLMs exhibit improved performance in (I) general video QA, where TempCompass performance improved by 10%, and (II) on downstream tasks, where Video-STaR improved Kinetics700-QA accuracy by 20% and action quality assessment on FineDiving by 15%.","sentences":["The performance of Large Vision Language Models (LVLMs) is dependent on the size and quality of their training datasets.","Existing video instruction tuning datasets lack diversity as they are derived by prompting large language models with video captions to generate question-answer pairs, and are therefore mostly descriptive.","Meanwhile, many labeled video datasets with diverse labels and supervision exist - however, we find that their integration into LVLMs is non-trivial.","Herein, we present Video Self-Training with augmented Reasoning (Video-STaR), the first video self-training approach.","Video-STaR allows the utilization of any labeled video dataset for video instruction tuning.","In Video-STaR, an LVLM cycles between instruction generation and finetuning, which we show (I) improves general video understanding and (II) adapts LVLMs to novel downstream tasks with existing supervision.","During generation, an LVLM is prompted to propose an answer.","The answers are then filtered only to those that contain the original video labels, and the LVLM is then re-trained on the generated dataset.","By only training on generated answers that contain the correct video labels, Video-STaR utilizes these existing video labels as weak supervision for video instruction tuning.","Our results demonstrate that Video-STaR-enhanced LVLMs exhibit improved performance in (I) general video QA, where TempCompass performance improved by 10%, and (II) on downstream tasks, where Video-STaR improved Kinetics700-QA accuracy by 20% and action quality assessment on FineDiving by 15%."],"url":"http://arxiv.org/abs/2407.06189v1"}
{"created":"2024-07-08 17:59:36","title":"CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation","abstract":"Crowd Motion Generation is essential in entertainment industries such as animation and games as well as in strategic fields like urban simulation and planning. This new task requires an intricate integration of control and generation to realistically synthesize crowd dynamics under specific spatial and semantic constraints, whose challenges are yet to be fully explored. On the one hand, existing human motion generation models typically focus on individual behaviors, neglecting the complexities of collective behaviors. On the other hand, recent methods for multi-person motion generation depend heavily on pre-defined scenarios and are limited to a fixed, small number of inter-person interactions, thus hampering their practicality. To overcome these challenges, we introduce CrowdMoGen, a zero-shot text-driven framework that harnesses the power of Large Language Model (LLM) to incorporate the collective intelligence into the motion generation framework as guidance, thereby enabling generalizable planning and generation of crowd motions without paired training data. Our framework consists of two key components: 1) Crowd Scene Planner that learns to coordinate motions and dynamics according to specific scene contexts or introduced perturbations, and 2) Collective Motion Generator that efficiently synthesizes the required collective motions based on the holistic plans. Extensive quantitative and qualitative experiments have validated the effectiveness of our framework, which not only fills a critical gap by providing scalable and generalizable solutions for Crowd Motion Generation task but also achieves high levels of realism and flexibility.","sentences":["Crowd Motion Generation is essential in entertainment industries such as animation and games as well as in strategic fields like urban simulation and planning.","This new task requires an intricate integration of control and generation to realistically synthesize crowd dynamics under specific spatial and semantic constraints, whose challenges are yet to be fully explored.","On the one hand, existing human motion generation models typically focus on individual behaviors, neglecting the complexities of collective behaviors.","On the other hand, recent methods for multi-person motion generation depend heavily on pre-defined scenarios and are limited to a fixed, small number of inter-person interactions, thus hampering their practicality.","To overcome these challenges, we introduce CrowdMoGen, a zero-shot text-driven framework that harnesses the power of Large Language Model (LLM) to incorporate the collective intelligence into the motion generation framework as guidance, thereby enabling generalizable planning and generation of crowd motions without paired training data.","Our framework consists of two key components: 1) Crowd Scene Planner that learns to coordinate motions and dynamics according to specific scene contexts or introduced perturbations, and 2) Collective Motion Generator that efficiently synthesizes the required collective motions based on the holistic plans.","Extensive quantitative and qualitative experiments have validated the effectiveness of our framework, which not only fills a critical gap by providing scalable and generalizable solutions for Crowd Motion Generation task but also achieves high levels of realism and flexibility."],"url":"http://arxiv.org/abs/2407.06188v1"}
{"created":"2024-07-08 17:59:02","title":"JeDi: Joint-Image Diffusion Models for Finetuning-Free Personalized Text-to-Image Generation","abstract":"Personalized text-to-image generation models enable users to create images that depict their individual possessions in diverse scenes, finding applications in various domains. To achieve the personalization capability, existing methods rely on finetuning a text-to-image foundation model on a user's custom dataset, which can be non-trivial for general users, resource-intensive, and time-consuming. Despite attempts to develop finetuning-free methods, their generation quality is much lower compared to their finetuning counterparts. In this paper, we propose Joint-Image Diffusion (\\jedi), an effective technique for learning a finetuning-free personalization model. Our key idea is to learn the joint distribution of multiple related text-image pairs that share a common subject. To facilitate learning, we propose a scalable synthetic dataset generation technique. Once trained, our model enables fast and easy personalization at test time by simply using reference images as input during the sampling process. Our approach does not require any expensive optimization process or additional modules and can faithfully preserve the identity represented by any number of reference images. Experimental results show that our model achieves state-of-the-art generation quality, both quantitatively and qualitatively, significantly outperforming both the prior finetuning-based and finetuning-free personalization baselines.","sentences":["Personalized text-to-image generation models enable users to create images that depict their individual possessions in diverse scenes, finding applications in various domains.","To achieve the personalization capability, existing methods rely on finetuning a text-to-image foundation model on a user's custom dataset, which can be non-trivial for general users, resource-intensive, and time-consuming.","Despite attempts to develop finetuning-free methods, their generation quality is much lower compared to their finetuning counterparts.","In this paper, we propose Joint-Image Diffusion (\\jedi), an effective technique for learning a finetuning-free personalization model.","Our key idea is to learn the joint distribution of multiple related text-image pairs that share a common subject.","To facilitate learning, we propose a scalable synthetic dataset generation technique.","Once trained, our model enables fast and easy personalization at test time by simply using reference images as input during the sampling process.","Our approach does not require any expensive optimization process or additional modules and can faithfully preserve the identity represented by any number of reference images.","Experimental results show that our model achieves state-of-the-art generation quality, both quantitatively and qualitatively, significantly outperforming both the prior finetuning-based and finetuning-free personalization baselines."],"url":"http://arxiv.org/abs/2407.06187v1"}
{"created":"2024-07-08 17:56:00","title":"Stepping on the Edge: Curvature Aware Learning Rate Tuners","abstract":"Curvature information -- particularly, the largest eigenvalue of the loss Hessian, known as the sharpness -- often forms the basis for learning rate tuners. However, recent work has shown that the curvature information undergoes complex dynamics during training, going from a phase of increasing sharpness to eventual stabilization. We analyze the closed-loop feedback effect between learning rate tuning and curvature. We find that classical learning rate tuners may yield greater one-step loss reduction, yet they ultimately underperform in the long term when compared to constant learning rates in the full batch regime. These models break the stabilization of the sharpness, which we explain using a simplified model of the joint dynamics of the learning rate and the curvature. To further investigate these effects, we introduce a new learning rate tuning method, Curvature Dynamics Aware Tuning (CDAT), which prioritizes long term curvature stabilization over instantaneous progress on the objective. In the full batch regime, CDAT shows behavior akin to prefixed warm-up schedules on deep learning objectives, outperforming tuned constant learning rates. In the mini batch regime, we observe that stochasticity introduces confounding effects that explain the previous success of some learning rate tuners at appropriate batch sizes. Our findings highlight the critical role of understanding the joint dynamics of the learning rate and curvature, beyond greedy minimization, to diagnose failures and design effective adaptive learning rate tuners.","sentences":["Curvature information -- particularly, the largest eigenvalue of the loss Hessian, known as the sharpness -- often forms the basis for learning rate tuners.","However, recent work has shown that the curvature information undergoes complex dynamics during training, going from a phase of increasing sharpness to eventual stabilization.","We analyze the closed-loop feedback effect between learning rate tuning and curvature.","We find that classical learning rate tuners may yield greater one-step loss reduction, yet they ultimately underperform in the long term when compared to constant learning rates in the full batch regime.","These models break the stabilization of the sharpness, which we explain using a simplified model of the joint dynamics of the learning rate and the curvature.","To further investigate these effects, we introduce a new learning rate tuning method, Curvature Dynamics Aware Tuning (CDAT), which prioritizes long term curvature stabilization over instantaneous progress on the objective.","In the full batch regime, CDAT shows behavior akin to prefixed warm-up schedules on deep learning objectives, outperforming tuned constant learning rates.","In the mini batch regime, we observe that stochasticity introduces confounding effects that explain the previous success of some learning rate tuners at appropriate batch sizes.","Our findings highlight the critical role of understanding the joint dynamics of the learning rate and curvature, beyond greedy minimization, to diagnose failures and design effective adaptive learning rate tuners."],"url":"http://arxiv.org/abs/2407.06183v1"}
{"created":"2024-07-08 17:54:43","title":"Left-Linear Rewriting in Adhesive Categories","abstract":"When can two sequential steps performed by a computing device be considered (causally) independent? This is a relevant question for concurrent and distributed systems, since independence means that they could be executed in any order, and potentially in parallel. Equivalences identifying rewriting sequences which differ only for independent steps are at the core of the theory of concurrency of many formalisms. We investigate the issue in the context of the double pushout approach to rewriting in the general setting of adhesive categories. While a consolidated theory exists for linear rules,which can consume, preserve and generate entities, this paper focuses on left-linear rules which may also \"merge\" parts of the state. This is an apparently minimal, yet technically hard enhancement,since a standard characterisation of independence that - in the linear case - allows one to derive a number of properties, essential in the development of a theory of concurrency, no longer holds. The paper performs an in-depth study of the notion of independence for left-linear rules: it introduces a novel characterisation of independence, identifies well-behaved classes of left-linear rewriting systems,and provides some fundamental results including a Church-Rosser property and the existence of canonical equivalence proofs for concurrent computations. These results properly extends the class of formalisms that can be modelled in the adhesive framework","sentences":["When can two sequential steps performed by a computing device be considered (causally) independent?","This is a relevant question for concurrent and distributed systems, since independence means that they could be executed in any order, and potentially in parallel.","Equivalences identifying rewriting sequences which differ only for independent steps are at the core of the theory of concurrency of many formalisms.","We investigate the issue in the context of the double pushout approach to rewriting in the general setting of adhesive categories.","While a consolidated theory exists for linear rules,which can consume, preserve and generate entities, this paper focuses on left-linear rules which may also \"merge\" parts of the state.","This is an apparently minimal, yet technically hard enhancement,since a standard characterisation of independence that - in the linear case - allows one to derive a number of properties, essential in the development of a theory of concurrency, no longer holds.","The paper performs an in-depth study of the notion of independence for left-linear rules: it introduces a novel characterisation of independence, identifies well-behaved classes of left-linear rewriting systems,and provides some fundamental results including a Church-Rosser property and the existence of canonical equivalence proofs for concurrent computations.","These results properly extends the class of formalisms that can be modelled in the adhesive framework"],"url":"http://arxiv.org/abs/2407.06181v1"}
{"created":"2024-07-08 17:52:23","title":"Transfer Learning with Self-Supervised Vision Transformers for Snake Identification","abstract":"We present our approach for the SnakeCLEF 2024 competition to predict snake species from images. We explore and use Meta's DINOv2 vision transformer model for feature extraction to tackle species' high variability and visual similarity in a dataset of 182,261 images. We perform exploratory analysis on embeddings to understand their structure, and train a linear classifier on the embeddings to predict species. Despite achieving a score of 39.69, our results show promise for DINOv2 embeddings in snake identification. All code for this project is available at https://github.com/dsgt-kaggle-clef/snakeclef-2024.","sentences":["We present our approach for the SnakeCLEF 2024 competition to predict snake species from images.","We explore and use Meta's DINOv2 vision transformer model for feature extraction to tackle species' high variability and visual similarity in a dataset of 182,261 images.","We perform exploratory analysis on embeddings to understand their structure, and train a linear classifier on the embeddings to predict species.","Despite achieving a score of 39.69, our results show promise for DINOv2 embeddings in snake identification.","All code for this project is available at https://github.com/dsgt-kaggle-clef/snakeclef-2024."],"url":"http://arxiv.org/abs/2407.06178v1"}
{"created":"2024-07-08 17:50:00","title":"Vision-Language Models under Cultural and Inclusive Considerations","abstract":"Large vision-language models (VLMs) can assist visually impaired people by describing images from their daily lives. Current evaluation datasets may not reflect diverse cultural user backgrounds or the situational context of this use case. To address this problem, we create a survey to determine caption preferences and propose a culture-centric evaluation benchmark by filtering VizWiz, an existing dataset with images taken by people who are blind. We then evaluate several VLMs, investigating their reliability as visual assistants in a culturally diverse setting. While our results for state-of-the-art models are promising, we identify challenges such as hallucination and misalignment of automatic evaluation metrics with human judgment. We make our survey, data, code, and model outputs publicly available.","sentences":["Large vision-language models (VLMs) can assist visually impaired people by describing images from their daily lives.","Current evaluation datasets may not reflect diverse cultural user backgrounds or the situational context of this use case.","To address this problem, we create a survey to determine caption preferences and propose a culture-centric evaluation benchmark by filtering VizWiz, an existing dataset with images taken by people who are blind.","We then evaluate several VLMs, investigating their reliability as visual assistants in a culturally diverse setting.","While our results for state-of-the-art models are promising, we identify challenges such as hallucination and misalignment of automatic evaluation metrics with human judgment.","We make our survey, data, code, and model outputs publicly available."],"url":"http://arxiv.org/abs/2407.06177v1"}
{"created":"2024-07-08 17:49:41","title":"The Tug-of-War Between Deepfake Generation and Detection","abstract":"Multimodal generative models are rapidly evolving, leading to a surge in the generation of realistic video and audio that offers exciting possibilities but also serious risks. Deepfake videos, which can convincingly impersonate individuals, have particularly garnered attention due to their potential misuse in spreading misinformation and creating fraudulent content. This survey paper examines the dual landscape of deepfake video generation and detection, emphasizing the need for effective countermeasures against potential abuses. We provide a comprehensive overview of current deepfake generation techniques, including face swapping, reenactment, and audio-driven animation, which leverage cutting-edge technologies like generative adversarial networks and diffusion models to produce highly realistic fake videos. Additionally, we analyze various detection approaches designed to differentiate authentic from altered videos, from detecting visual artifacts to deploying advanced algorithms that pinpoint inconsistencies across video and audio signals.   The effectiveness of these detection methods heavily relies on the diversity and quality of datasets used for training and evaluation. We discuss the evolution of deepfake datasets, highlighting the importance of robust, diverse, and frequently updated collections to enhance the detection accuracy and generalizability. As deepfakes become increasingly indistinguishable from authentic content, developing advanced detection techniques that can keep pace with generation technologies is crucial. We advocate for a proactive approach in the \"tug-of-war\" between deepfake creators and detectors, emphasizing the need for continuous research collaboration, standardization of evaluation metrics, and the creation of comprehensive benchmarks.","sentences":["Multimodal generative models are rapidly evolving, leading to a surge in the generation of realistic video and audio that offers exciting possibilities but also serious risks.","Deepfake videos, which can convincingly impersonate individuals, have particularly garnered attention due to their potential misuse in spreading misinformation and creating fraudulent content.","This survey paper examines the dual landscape of deepfake video generation and detection, emphasizing the need for effective countermeasures against potential abuses.","We provide a comprehensive overview of current deepfake generation techniques, including face swapping, reenactment, and audio-driven animation, which leverage cutting-edge technologies like generative adversarial networks and diffusion models to produce highly realistic fake videos.","Additionally, we analyze various detection approaches designed to differentiate authentic from altered videos, from detecting visual artifacts to deploying advanced algorithms that pinpoint inconsistencies across video and audio signals.   ","The effectiveness of these detection methods heavily relies on the diversity and quality of datasets used for training and evaluation.","We discuss the evolution of deepfake datasets, highlighting the importance of robust, diverse, and frequently updated collections to enhance the detection accuracy and generalizability.","As deepfakes become increasingly indistinguishable from authentic content, developing advanced detection techniques that can keep pace with generation technologies is crucial.","We advocate for a proactive approach in the \"tug-of-war\" between deepfake creators and detectors, emphasizing the need for continuous research collaboration, standardization of evaluation metrics, and the creation of comprehensive benchmarks."],"url":"http://arxiv.org/abs/2407.06174v1"}
{"created":"2024-07-08 17:48:42","title":"On Speeding Up Language Model Evaluation","abstract":"Large language models (LLMs) currently dominate the field of natural language processing (NLP), representing the state-of-the-art across a diverse array of tasks. Developing a model of this nature, from training to inference, requires making numerous decisions which define a combinatorial search problem. For example, selecting the optimal pre-trained LLM, prompt, or hyperparameters to attain the best performance for a task often requires evaluating multiple candidates on an entire test set. This exhaustive evaluation can be time-consuming and costly, as both inference and metric computation with LLMs are resource-intensive. In this paper, we address the challenge of identifying the best method within a limited budget for evaluating methods on test examples. By leveraging the well-studied multi-armed bandit framework, which sequentially selects the next method-example pair to evaluate, our approach, combining multi-armed bandit algorithms with low-rank factorization, significantly reduces the required resources. Experiments show that our algorithms can identify the top-performing method using only 5-15\\% of the typically needed resources, resulting in an 85-95\\% reduction in cost.","sentences":["Large language models (LLMs) currently dominate the field of natural language processing (NLP), representing the state-of-the-art across a diverse array of tasks.","Developing a model of this nature, from training to inference, requires making numerous decisions which define a combinatorial search problem.","For example, selecting the optimal pre-trained LLM, prompt, or hyperparameters to attain the best performance for a task often requires evaluating multiple candidates on an entire test set.","This exhaustive evaluation can be time-consuming and costly, as both inference and metric computation with LLMs are resource-intensive.","In this paper, we address the challenge of identifying the best method within a limited budget for evaluating methods on test examples.","By leveraging the well-studied multi-armed bandit framework, which sequentially selects the next method-example pair to evaluate, our approach, combining multi-armed bandit algorithms with low-rank factorization, significantly reduces the required resources.","Experiments show that our algorithms can identify the top-performing method using only 5-15\\% of the typically needed resources, resulting in an 85-95\\% reduction in cost."],"url":"http://arxiv.org/abs/2407.06172v1"}
{"created":"2024-07-08 17:48:39","title":"Potential Based Diffusion Motion Planning","abstract":"Effective motion planning in high dimensional spaces is a long-standing open problem in robotics. One class of traditional motion planning algorithms corresponds to potential-based motion planning. An advantage of potential based motion planning is composability -- different motion constraints can be easily combined by adding corresponding potentials. However, constructing motion paths from potentials requires solving a global optimization across configuration space potential landscape, which is often prone to local minima. We propose a new approach towards learning potential based motion planning, where we train a neural network to capture and learn an easily optimizable potentials over motion planning trajectories. We illustrate the effectiveness of such approach, significantly outperforming both classical and recent learned motion planning approaches and avoiding issues with local minima. We further illustrate its inherent composability, enabling us to generalize to a multitude of different motion constraints.","sentences":["Effective motion planning in high dimensional spaces is a long-standing open problem in robotics.","One class of traditional motion planning algorithms corresponds to potential-based motion planning.","An advantage of potential based motion planning is composability -- different motion constraints can be easily combined by adding corresponding potentials.","However, constructing motion paths from potentials requires solving a global optimization across configuration space potential landscape, which is often prone to local minima.","We propose a new approach towards learning potential based motion planning, where we train a neural network to capture and learn an easily optimizable potentials over motion planning trajectories.","We illustrate the effectiveness of such approach, significantly outperforming both classical and recent learned motion planning approaches and avoiding issues with local minima.","We further illustrate its inherent composability, enabling us to generalize to a multitude of different motion constraints."],"url":"http://arxiv.org/abs/2407.06169v1"}
{"created":"2024-07-08 17:47:45","title":"TARGO: Benchmarking Target-driven Object Grasping under Occlusions","abstract":"Recent advances in predicting 6D grasp poses from a single depth image have led to promising performance in robotic grasping. However, previous grasping models face challenges in cluttered environments where nearby objects impact the target object's grasp. In this paper, we first establish a new benchmark dataset for TARget-driven Grasping under Occlusions, named TARGO. We make the following contributions: 1) We are the first to study the occlusion level of grasping. 2) We set up an evaluation benchmark consisting of large-scale synthetic data and part of real-world data, and we evaluated five grasp models and found that even the current SOTA model suffers when the occlusion level increases, leaving grasping under occlusion still a challenge. 3) We also generate a large-scale training dataset via a scalable pipeline, which can be used to boost the performance of grasping under occlusion and generalized to the real world. 4) We further propose a transformer-based grasping model involving a shape completion module, termed TARGO-Net, which performs most robustly as occlusion increases. Our benchmark dataset can be found at https://TARGO-benchmark.github.io/.","sentences":["Recent advances in predicting 6D grasp poses from a single depth image have led to promising performance in robotic grasping.","However, previous grasping models face challenges in cluttered environments where nearby objects impact the target object's grasp.","In this paper, we first establish a new benchmark dataset for TARget-driven Grasping under Occlusions, named TARGO.","We make the following contributions: 1) We are the first to study the occlusion level of grasping.","2) We set up an evaluation benchmark consisting of large-scale synthetic data and part of real-world data, and we evaluated five grasp models and found that even the current SOTA model suffers when the occlusion level increases, leaving grasping under occlusion still a challenge.","3) We also generate a large-scale training dataset via a scalable pipeline, which can be used to boost the performance of grasping under occlusion and generalized to the real world.","4) We further propose a transformer-based grasping model involving a shape completion module, termed TARGO-Net, which performs most robustly as occlusion increases.","Our benchmark dataset can be found at https://TARGO-benchmark.github.io/."],"url":"http://arxiv.org/abs/2407.06168v1"}
{"created":"2024-07-08 17:45:40","title":"D\u03b5pS: Delayed \u03b5-Shrinking for Faster Once-For-All Training","abstract":"CNNs are increasingly deployed across different hardware, dynamic environments, and low-power embedded devices. This has led to the design and training of CNN architectures with the goal of maximizing accuracy subject to such variable deployment constraints. As the number of deployment scenarios grows, there is a need to find scalable solutions to design and train specialized CNNs. Once-for-all training has emerged as a scalable approach that jointly co-trains many models (subnets) at once with a constant training cost and finds specialized CNNs later. The scalability is achieved by training the full model and simultaneously reducing it to smaller subnets that share model weights (weight-shared shrinking). However, existing once-for-all training approaches incur huge training costs reaching 1200 GPU hours. We argue this is because they either start the process of shrinking the full model too early or too late. Hence, we propose Delayed $\\epsilon$-Shrinking (D$\\epsilon$pS) that starts the process of shrinking the full model when it is partially trained (~50%) which leads to training cost improvement and better in-place knowledge distillation to smaller models. The proposed approach also consists of novel heuristics that dynamically adjust subnet learning rates incrementally (E), leading to improved weight-shared knowledge distillation from larger to smaller subnets as well. As a result, DEpS outperforms state-of-the-art once-for-all training techniques across different datasets including CIFAR10/100, ImageNet-100, and ImageNet-1k on accuracy and cost. It achieves 1.83% higher ImageNet-1k top1 accuracy or the same accuracy with 1.3x reduction in FLOPs and 2.5x drop in training cost (GPU*hrs)","sentences":["CNNs are increasingly deployed across different hardware, dynamic environments, and low-power embedded devices.","This has led to the design and training of CNN architectures with the goal of maximizing accuracy subject to such variable deployment constraints.","As the number of deployment scenarios grows, there is a need to find scalable solutions to design and train specialized CNNs.","Once-for-all training has emerged as a scalable approach that jointly co-trains many models (subnets) at once with a constant training cost and finds specialized CNNs later.","The scalability is achieved by training the full model and simultaneously reducing it to smaller subnets that share model weights (weight-shared shrinking).","However, existing once-for-all training approaches incur huge training costs reaching 1200 GPU hours.","We argue this is because they either start the process of shrinking the full model too early or too late.","Hence, we propose Delayed $\\epsilon$-Shrinking (D$\\epsilon$pS) that starts the process of shrinking the full model when it is partially trained (~50%) which leads to training cost improvement and better in-place knowledge distillation to smaller models.","The proposed approach also consists of novel heuristics that dynamically adjust subnet learning rates incrementally (E), leading to improved weight-shared knowledge distillation from larger to smaller subnets as well.","As a result, DEpS outperforms state-of-the-art once-for-all training techniques across different datasets including CIFAR10/100, ImageNet-100, and ImageNet-1k on accuracy and cost.","It achieves 1.83% higher ImageNet-1k top1 accuracy or the same accuracy with 1.3x reduction in FLOPs and 2.5x drop in training cost (GPU*hrs)"],"url":"http://arxiv.org/abs/2407.06167v1"}
{"created":"2024-07-08 17:28:16","title":"Enhancing Robotic Arm Activity Recognition with Vision Transformers and Wavelet-Transformed Channel State Information","abstract":"Vision-based methods are commonly used in robotic arm activity recognition. These approaches typically rely on line-of-sight (LoS) and raise privacy concerns, particularly in smart home applications. Passive Wi-Fi sensing represents a new paradigm for recognizing human and robotic arm activities, utilizing channel state information (CSI) measurements to identify activities in indoor environments. In this paper, a novel machine learning approach based on discrete wavelet transform and vision transformers for robotic arm activity recognition from CSI measurements in indoor settings is proposed. This method outperforms convolutional neural network (CNN) and long short-term memory (LSTM) models in robotic arm activity recognition, particularly when LoS is obstructed by barriers, without relying on external or internal sensors or visual aids. Experiments are conducted using four different data collection scenarios and four different robotic arm activities. Performance results demonstrate that wavelet transform can significantly enhance the accuracy of visual transformer networks in robotic arms activity recognition.","sentences":["Vision-based methods are commonly used in robotic arm activity recognition.","These approaches typically rely on line-of-sight (LoS) and raise privacy concerns, particularly in smart home applications.","Passive Wi-Fi sensing represents a new paradigm for recognizing human and robotic arm activities, utilizing channel state information (CSI) measurements to identify activities in indoor environments.","In this paper, a novel machine learning approach based on discrete wavelet transform and vision transformers for robotic arm activity recognition from CSI measurements in indoor settings is proposed.","This method outperforms convolutional neural network (CNN) and long short-term memory (LSTM) models in robotic arm activity recognition, particularly when LoS is obstructed by barriers, without relying on external or internal sensors or visual aids.","Experiments are conducted using four different data collection scenarios and four different robotic arm activities.","Performance results demonstrate that wavelet transform can significantly enhance the accuracy of visual transformer networks in robotic arms activity recognition."],"url":"http://arxiv.org/abs/2407.06154v1"}
{"created":"2024-07-08 17:27:17","title":"What's Wrong with Your Code Generated by Large Language Models? An Extensive Study","abstract":"The increasing development of large language models (LLMs) in code generation has drawn significant attention among researchers. To enhance LLM-based code generation ability, current efforts are predominantly directed towards collecting high-quality datasets and leveraging diverse training technologies. However, there is a notable lack of comprehensive studies examining the limitations and boundaries of these existing methods. To bridge this gap, we conducted an extensive empirical study evaluating the performance of three leading closed-source LLMs and four popular open-source LLMs on three commonly used benchmarks. Our investigation, which evaluated the length, cyclomatic complexity and API number of the generated code, revealed that these LLMs face challenges in generating successful code for more complex problems, and tend to produce code that is shorter yet more complicated as compared to canonical solutions. Additionally, we developed a taxonomy of bugs for incorrect codes that includes three categories and 12 sub-categories, and analyze the root cause for common bug types. Furthermore, to better understand the performance of LLMs in real-world projects, we manually created a real-world benchmark comprising 140 code generation tasks. Our analysis highlights distinct differences in bug distributions between actual scenarios and existing benchmarks. Finally, we propose a novel training-free iterative method that introduces self-critique, enabling LLMs to critique and correct their generated code based on bug types and compiler feedback. Experimental results demonstrate that our approach can significantly mitigate bugs and increase the passing rate by 29.2% after two iterations, indicating substantial potential for LLMs to handle more complex problems.","sentences":["The increasing development of large language models (LLMs) in code generation has drawn significant attention among researchers.","To enhance LLM-based code generation ability, current efforts are predominantly directed towards collecting high-quality datasets and leveraging diverse training technologies.","However, there is a notable lack of comprehensive studies examining the limitations and boundaries of these existing methods.","To bridge this gap, we conducted an extensive empirical study evaluating the performance of three leading closed-source LLMs and four popular open-source LLMs on three commonly used benchmarks.","Our investigation, which evaluated the length, cyclomatic complexity and API number of the generated code, revealed that these LLMs face challenges in generating successful code for more complex problems, and tend to produce code that is shorter yet more complicated as compared to canonical solutions.","Additionally, we developed a taxonomy of bugs for incorrect codes that includes three categories and 12 sub-categories, and analyze the root cause for common bug types.","Furthermore, to better understand the performance of LLMs in real-world projects, we manually created a real-world benchmark comprising 140 code generation tasks.","Our analysis highlights distinct differences in bug distributions between actual scenarios and existing benchmarks.","Finally, we propose a novel training-free iterative method that introduces self-critique, enabling LLMs to critique and correct their generated code based on bug types and compiler feedback.","Experimental results demonstrate that our approach can significantly mitigate bugs and increase the passing rate by 29.2% after two iterations, indicating substantial potential for LLMs to handle more complex problems."],"url":"http://arxiv.org/abs/2407.06153v1"}
{"created":"2024-07-08 17:24:08","title":"Auto-PICNN: Automated machine learning for physics-informed convolutional neural networks","abstract":"Recent advances in deep learning for solving partial differential equations (PDEs) have introduced physics-informed neural networks (PINNs), which integrate machine learning with physical laws. Physics-informed convolutional neural networks (PICNNs) extend PINNs by leveraging CNNs for enhanced generalization and efficiency. However, current PICNNs depend on manual design, and inappropriate designs may not effectively solve PDEs. Furthermore, due to the diversity of physical problems, the ideal network architectures and loss functions vary across different PDEs. It is impractical to find the optimal PICNN architecture and loss function for each specific physical problem through extensive manual experimentation. To surmount these challenges, this paper uses automated machine learning (AutoML) to automatically and efficiently search for the loss functions and network architectures of PICNNs. We introduce novel search spaces for loss functions and network architectures and propose a two-stage search strategy. The first stage focuses on searching for factors and residual adjustment operations that influence the loss function, while the second stage aims to find the best CNN architecture. Experimental results show that our automatic searching method significantly outperforms the manually-designed model on multiple datasets.","sentences":["Recent advances in deep learning for solving partial differential equations (PDEs) have introduced physics-informed neural networks (PINNs), which integrate machine learning with physical laws.","Physics-informed convolutional neural networks (PICNNs) extend PINNs by leveraging CNNs for enhanced generalization and efficiency.","However, current PICNNs depend on manual design, and inappropriate designs may not effectively solve PDEs.","Furthermore, due to the diversity of physical problems, the ideal network architectures and loss functions vary across different PDEs.","It is impractical to find the optimal PICNN architecture and loss function for each specific physical problem through extensive manual experimentation.","To surmount these challenges, this paper uses automated machine learning (AutoML) to automatically and efficiently search for the loss functions and network architectures of PICNNs.","We introduce novel search spaces for loss functions and network architectures and propose a two-stage search strategy.","The first stage focuses on searching for factors and residual adjustment operations that influence the loss function, while the second stage aims to find the best CNN architecture.","Experimental results show that our automatic searching method significantly outperforms the manually-designed model on multiple datasets."],"url":"http://arxiv.org/abs/2407.06151v1"}
{"created":"2024-07-08 17:22:27","title":"PanDORA: Casual HDR Radiance Acquisition for Indoor Scenes","abstract":"Most novel view synthesis methods such as NeRF are unable to capture the true high dynamic range (HDR) radiance of scenes since they are typically trained on photos captured with standard low dynamic range (LDR) cameras. While the traditional exposure bracketing approach which captures several images at different exposures has recently been adapted to the multi-view case, we find such methods to fall short of capturing the full dynamic range of indoor scenes, which includes very bright light sources. In this paper, we present PanDORA: a PANoramic Dual-Observer Radiance Acquisition system for the casual capture of indoor scenes in high dynamic range. Our proposed system comprises two 360{\\deg} cameras rigidly attached to a portable tripod. The cameras simultaneously acquire two 360{\\deg} videos: one at a regular exposure and the other at a very fast exposure, allowing a user to simply wave the apparatus casually around the scene in a matter of minutes. The resulting images are fed to a NeRF-based algorithm that reconstructs the scene's full high dynamic range. Compared to HDR baselines from previous work, our approach reconstructs the full HDR radiance of indoor scenes without sacrificing the visual quality while retaining the ease of capture from recent NeRF-like approaches.","sentences":["Most novel view synthesis methods such as NeRF are unable to capture the true high dynamic range (HDR) radiance of scenes since they are typically trained on photos captured with standard low dynamic range (LDR) cameras.","While the traditional exposure bracketing approach which captures several images at different exposures has recently been adapted to the multi-view case, we find such methods to fall short of capturing the full dynamic range of indoor scenes, which includes very bright light sources.","In this paper, we present PanDORA: a PANoramic Dual-Observer Radiance Acquisition system for the casual capture of indoor scenes in high dynamic range.","Our proposed system comprises two 360{\\deg} cameras rigidly attached to a portable tripod.","The cameras simultaneously acquire two 360{\\deg} videos: one at a regular exposure and the other at a very fast exposure, allowing a user to simply wave the apparatus casually around the scene in a matter of minutes.","The resulting images are fed to a NeRF-based algorithm that reconstructs the scene's full high dynamic range.","Compared to HDR baselines from previous work, our approach reconstructs the full HDR radiance of indoor scenes without sacrificing the visual quality while retaining the ease of capture from recent NeRF-like approaches."],"url":"http://arxiv.org/abs/2407.06150v1"}
{"created":"2024-07-08 17:21:31","title":"WIBACong: An Argument-centric Framework for Understanding US Congressional Hearings","abstract":"How can we utilize state-of-the-art NLP tools to better understand legislative deliberation? Committee hearings are a core feature of any legislature, and they create an institutional setting to promote the exchange of arguments and reasoning that directly impact and shape legislation. We develop WIBACong, which is an application of the WIBA NLP framework for quantifying and qualifying the deliberation dynamics that we previously developed, applied to US Congressional Hearings. WIBA is a pipeline for extracting and analyzing argumentation communicated within text corpora, enabling a focused attention on the dynamics of debates occurring in democratic settings. With our framework, we are able to uncover the nuances of how deliberative discourse actually is. In WIBACong, we propose a variety of summary statistics and useful visualizations to the WIBA output in order to analyze argumentation in U.S. committee hearing testimony, and in so doing we reveal potential biases in the committee system, and how political parties control the flow of information in 'hot topic' hearings.","sentences":["How can we utilize state-of-the-art NLP tools to better understand legislative deliberation?","Committee hearings are a core feature of any legislature, and they create an institutional setting to promote the exchange of arguments and reasoning that directly impact and shape legislation.","We develop WIBACong, which is an application of the WIBA NLP framework for quantifying and qualifying the deliberation dynamics that we previously developed, applied to US Congressional Hearings.","WIBA is a pipeline for extracting and analyzing argumentation communicated within text corpora, enabling a focused attention on the dynamics of debates occurring in democratic settings.","With our framework, we are able to uncover the nuances of how deliberative discourse actually is.","In WIBACong, we propose a variety of summary statistics and useful visualizations to the WIBA output in order to analyze argumentation in U.S. committee hearing testimony, and in so doing we reveal potential biases in the committee system, and how political parties control the flow of information in 'hot topic' hearings."],"url":"http://arxiv.org/abs/2407.06149v1"}
{"created":"2024-07-08 17:19:59","title":"Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks","abstract":"We present and evaluate a method called grammar masking, which is used to guide large language models (LLMs) toward producing syntactically correct models for a given context-free grammar. Prompt engineering methods such as few-shot learning or priming can be used to improve the chances of an LLM producing correct syntax, but the more complex the grammar, the more time-consuming and less promising these methods become. Previous work is focused primarily on the usage of either language model training or prompt engineering. In this work, a method is presented that restricts the output to a given grammar using constrained decoding to ensure the output adheres to a valid syntax. We use several DSLs built with MontiCore and task multiple LLMs to produce models with and without constrained decoding. A corresponding parser is used to confirm the syntactic correctness of each model. We show that grammar masking can dramatically improve the modeling capabilities of several LLMs, reducing the need for well-refined prompting while increasing the chance of producing correct models.","sentences":["We present and evaluate a method called grammar masking, which is used to guide large language models (LLMs) toward producing syntactically correct models for a given context-free grammar.","Prompt engineering methods such as few-shot learning or priming can be used to improve the chances of an LLM producing correct syntax, but the more complex the grammar, the more time-consuming and less promising these methods become.","Previous work is focused primarily on the usage of either language model training or prompt engineering.","In this work, a method is presented that restricts the output to a given grammar using constrained decoding to ensure the output adheres to a valid syntax.","We use several DSLs built with MontiCore and task multiple LLMs to produce models with and without constrained decoding.","A corresponding parser is used to confirm the syntactic correctness of each model.","We show that grammar masking can dramatically improve the modeling capabilities of several LLMs, reducing the need for well-refined prompting while increasing the chance of producing correct models."],"url":"http://arxiv.org/abs/2407.06146v1"}
{"created":"2024-07-08 17:17:29","title":"Delay-Aware Robust Edge Network Hardening Under Decision-Dependent Uncertainty","abstract":"Edge computing promises to offer low-latency and ubiquitous computation to numerous devices at the network edge. For delay-sensitive applications, link delays can have a direct impact on service quality. These delays can fluctuate drastically over time due to various factors such as network congestion, changing traffic conditions, cyberattacks, component failures, and natural disasters. Thus, it is crucial to efficiently harden the edge network to mitigate link delay variation as well as ensure a stable and improved user experience. To this end, we propose a novel robust model for optimal edge network hardening, considering the link delay uncertainty. Departing from the existing literature that treats uncertainties as exogenous, our model incorporates an endogenous uncertainty set to properly capture the impact of hardening and workload allocation decisions on link delays. However, the endogenous set introduces additional complexity to the problem due to the interdependence between decisions and uncertainties. We present two efficient methods to transform the problem into a solvable form. Extensive numerical results are shown to demonstrate the effectiveness of the proposed approach.","sentences":["Edge computing promises to offer low-latency and ubiquitous computation to numerous devices at the network edge.","For delay-sensitive applications, link delays can have a direct impact on service quality.","These delays can fluctuate drastically over time due to various factors such as network congestion, changing traffic conditions, cyberattacks, component failures, and natural disasters.","Thus, it is crucial to efficiently harden the edge network to mitigate link delay variation as well as ensure a stable and improved user experience.","To this end, we propose a novel robust model for optimal edge network hardening, considering the link delay uncertainty.","Departing from the existing literature that treats uncertainties as exogenous, our model incorporates an endogenous uncertainty set to properly capture the impact of hardening and workload allocation decisions on link delays.","However, the endogenous set introduces additional complexity to the problem due to the interdependence between decisions and uncertainties.","We present two efficient methods to transform the problem into a solvable form.","Extensive numerical results are shown to demonstrate the effectiveness of the proposed approach."],"url":"http://arxiv.org/abs/2407.06142v1"}
{"created":"2024-07-08 17:09:39","title":"Mamba-FSCIL: Dynamic Adaptation with Selective State Space Model for Few-Shot Class-Incremental Learning","abstract":"Few-shot class-incremental learning (FSCIL) confronts the challenge of integrating new classes into a model with minimal training samples while preserving the knowledge of previously learned classes. Traditional methods widely adopt static adaptation relying on a fixed parameter space to learn from data that arrive sequentially, prone to overfitting to the current session. Existing dynamic strategies require the expansion of the parameter space continually, leading to increased complexity. To address these challenges, we integrate the recently proposed selective state space model (SSM) into FSCIL. Concretely, we propose a dual selective SSM projector that dynamically adjusts the projection parameters based on the intermediate features for dynamic adaptation. The dual design enables the model to maintain the robust features of base classes, while adaptively learning distinctive feature shifts for novel classes. Additionally, we develop a class-sensitive selective scan mechanism to guide dynamic adaptation. It minimizes the disruption to base-class representations caused by training on novel data, and meanwhile, forces the selective scan to perform in distinct patterns between base and novel classes. Experiments on miniImageNet, CUB-200, and CIFAR-100 demonstrate that our framework outperforms the existing state-of-the-art methods. The code is available at https://github.com/xiaojieli0903/Mamba-FSCIL.","sentences":["Few-shot class-incremental learning (FSCIL) confronts the challenge of integrating new classes into a model with minimal training samples while preserving the knowledge of previously learned classes.","Traditional methods widely adopt static adaptation relying on a fixed parameter space to learn from data that arrive sequentially, prone to overfitting to the current session.","Existing dynamic strategies require the expansion of the parameter space continually, leading to increased complexity.","To address these challenges, we integrate the recently proposed selective state space model (SSM) into FSCIL.","Concretely, we propose a dual selective SSM projector that dynamically adjusts the projection parameters based on the intermediate features for dynamic adaptation.","The dual design enables the model to maintain the robust features of base classes, while adaptively learning distinctive feature shifts for novel classes.","Additionally, we develop a class-sensitive selective scan mechanism to guide dynamic adaptation.","It minimizes the disruption to base-class representations caused by training on novel data, and meanwhile, forces the selective scan to perform in distinct patterns between base and novel classes.","Experiments on miniImageNet, CUB-200, and CIFAR-100 demonstrate that our framework outperforms the existing state-of-the-art methods.","The code is available at https://github.com/xiaojieli0903/Mamba-FSCIL."],"url":"http://arxiv.org/abs/2407.06136v1"}
{"created":"2024-07-08 17:08:02","title":"ANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation","abstract":"Previous open-source large multimodal models (LMMs) have faced several limitations: (1) they often lack native integration, requiring adapters to align visual representations with pre-trained large language models (LLMs); (2) many are restricted to single-modal generation; (3) while some support multimodal generation, they rely on separate diffusion models for visual modeling and generation. To mitigate these limitations, we present Anole, an open, autoregressive, native large multimodal model for interleaved image-text generation. We build Anole from Meta AI's Chameleon, adopting an innovative fine-tuning strategy that is both data-efficient and parameter-efficient. Anole demonstrates high-quality, coherent multimodal generation capabilities. We have open-sourced our model, training framework, and instruction tuning data.","sentences":["Previous open-source large multimodal models (LMMs) have faced several limitations: (1) they often lack native integration, requiring adapters to align visual representations with pre-trained large language models (LLMs); (2) many are restricted to single-modal generation; (3) while some support multimodal generation, they rely on separate diffusion models for visual modeling and generation.","To mitigate these limitations, we present Anole, an open, autoregressive, native large multimodal model for interleaved image-text generation.","We build Anole from Meta AI's Chameleon, adopting an innovative fine-tuning strategy that is both data-efficient and parameter-efficient.","Anole demonstrates high-quality, coherent multimodal generation capabilities.","We have open-sourced our model, training framework, and instruction tuning data."],"url":"http://arxiv.org/abs/2407.06135v1"}
{"created":"2024-07-08 17:07:04","title":"Scaling Analog Photonic Accelerators for Byte-Size, Integer General Matrix Multiply (GEMM) Kernels","abstract":"Deep Neural Networks (DNNs) predominantly rely on General Matrix Multiply (GEMM) kernels, which are often accelerated using specialized hardware architectures. Recently, analog photonic GEMM accelerators have emerged as a promising alternative, offering vastly superior speed and energy efficiency compared to traditional electronic accelerators. However, these photonic cannot support wider than 4-bit integer operands due to their inherent trade-offs between analog dynamic range and parallelism. This is often inadequate for DNN training as at least 8-bit wide operands are deemed necessary to prevent significant accuracy drops. To address these limitations, we introduce a scalable photonic GEMM accelerator named SPOGA. SPOGA utilizes enhanced features such as analog summation of homodyne optical signals and in-transduction positional weighting of operands. By employing an extended optical-analog dataflow that minimizes overheads associated with bit-sliced integer arithmetic, SPOGA supports byte-size integer GEMM kernels, achieving significant improvements in throughput, latency, and energy efficiency. Specifically, SPOGA demonstrates up to 14.4$\\times$, 2$\\times$, and 28.5$\\times$ improvements in frames-per-second (FPS), FPS/Watt, and FPS/Watt/mm$^2$ respectively, compared to existing state-of-the-art photonic solutions.","sentences":["Deep Neural Networks (DNNs) predominantly rely on General Matrix Multiply (GEMM) kernels, which are often accelerated using specialized hardware architectures.","Recently, analog photonic GEMM accelerators have emerged as a promising alternative, offering vastly superior speed and energy efficiency compared to traditional electronic accelerators.","However, these photonic cannot support wider than 4-bit integer operands due to their inherent trade-offs between analog dynamic range and parallelism.","This is often inadequate for DNN training as at least 8-bit wide operands are deemed necessary to prevent significant accuracy drops.","To address these limitations, we introduce a scalable photonic GEMM accelerator named SPOGA.","SPOGA utilizes enhanced features such as analog summation of homodyne optical signals and in-transduction positional weighting of operands.","By employing an extended optical-analog dataflow that minimizes overheads associated with bit-sliced integer arithmetic, SPOGA supports byte-size integer GEMM kernels, achieving significant improvements in throughput, latency, and energy efficiency.","Specifically, SPOGA demonstrates up to 14.4$\\times$, 2$\\times$, and 28.5$\\times$ improvements in frames-per-second (FPS), FPS/Watt, and FPS/Watt/mm$^2$ respectively, compared to existing state-of-the-art photonic solutions."],"url":"http://arxiv.org/abs/2407.06134v1"}
{"created":"2024-07-08 17:06:29","title":"R\u00e9nyi Common Information for Doubly Symmetric Binary Sources","abstract":"In this note, we provide analytic expressions for the R\\'enyi common information of orders in $(1,\\infty)$ for the doubly symmetric binary source (DSBS). Until now, analytic expressions for the R\\'enyi common information of all orders in $[0,\\infty]$ have been completely known for this source. We also consider the R\\'enyi common information of all orders in $[-\\infty,0)$ and evaluate it for the DSBS. We provide a sufficient condition under which the R\\'enyi common information of such orders coincides with Wyner's common information for the DSBS. Based on numerical analysis, we conjecture that there is a certain phase transition as the crossover probability increasing for the R\\'enyi common information of negative orders for the DSBS. Our proofs are based on a lemma on splitting of the entropy and the analytic expression of relaxed Wyner's common information.","sentences":["In this note, we provide analytic expressions for the R\\'enyi common information of orders in $(1,\\infty)$ for the doubly symmetric binary source (DSBS).","Until now, analytic expressions for the R\\'enyi common information of all orders in $[0,\\infty]$ have been completely known for this source.","We also consider the R\\'enyi common information of all orders in $[-\\infty,0)$ and evaluate it for the DSBS.","We provide a sufficient condition under which the R\\'enyi common information of such orders coincides with Wyner's common information for the DSBS.","Based on numerical analysis, we conjecture that there is a certain phase transition as the crossover probability increasing for the R\\'enyi common information of negative orders for the DSBS.","Our proofs are based on a lemma on splitting of the entropy and the analytic expression of relaxed Wyner's common information."],"url":"http://arxiv.org/abs/2407.06132v1"}
{"created":"2024-07-08 17:05:25","title":"Connected Matchings","abstract":"We show that each set of $n\\ge 2$ points in the plane in general position has a straight-line matching with at least $(5n+1)/27$ edges whose segments form a connected set, and such a matching can be computed in $O(n \\log n)$ time. As an upper bound, we show that for some planar point sets in general position the largest matching whose segments form a connected set has $\\lceil \\frac{n-1}{3}\\rceil$ edges. We also consider a colored version, where each edge of the matching should connect points with different colors.","sentences":["We show that each set of $n\\ge 2$ points in the plane in general position has a straight-line matching with at least $(5n+1)/27$ edges whose segments form a connected set, and such a matching can be computed in $O(n \\log","n)$ time.","As an upper bound, we show that for some planar point sets in general position the largest matching whose segments form a connected set has $\\lceil \\frac{n-1}{3}\\rceil$ edges.","We also consider a colored version, where each edge of the matching should connect points with different colors."],"url":"http://arxiv.org/abs/2407.06131v1"}
{"created":"2024-07-08 17:04:31","title":"Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization","abstract":"Automatically generating data visualizations in response to human utterances on datasets necessitates a deep semantic understanding of the data utterance, including implicit and explicit references to data attributes, visualization tasks, and necessary data preparation steps. Natural Language Interfaces (NLIs) for data visualization have explored ways to infer such information, yet challenges persist due to inherent uncertainty in human speech. Recent advances in Large Language Models (LLMs) provide an avenue to address these challenges, but their ability to extract the relevant semantic information remains unexplored. In this study, we evaluate four publicly available LLMs (GPT-4, Gemini-Pro, Llama3, and Mixtral), investigating their ability to comprehend utterances even in the presence of uncertainty and identify the relevant data context and visual tasks. Our findings reveal that LLMs are sensitive to uncertainties in utterances. Despite this sensitivity, they are able to extract the relevant data context. However, LLMs struggle with inferring visualization tasks. Based on these results, we highlight future research directions on using LLMs for visualization generation.","sentences":["Automatically generating data visualizations in response to human utterances on datasets necessitates a deep semantic understanding of the data utterance, including implicit and explicit references to data attributes, visualization tasks, and necessary data preparation steps.","Natural Language Interfaces (NLIs) for data visualization have explored ways to infer such information, yet challenges persist due to inherent uncertainty in human speech.","Recent advances in Large Language Models (LLMs) provide an avenue to address these challenges, but their ability to extract the relevant semantic information remains unexplored.","In this study, we evaluate four publicly available LLMs (GPT-4, Gemini-Pro, Llama3, and Mixtral), investigating their ability to comprehend utterances even in the presence of uncertainty and identify the relevant data context and visual tasks.","Our findings reveal that LLMs are sensitive to uncertainties in utterances.","Despite this sensitivity, they are able to extract the relevant data context.","However, LLMs struggle with inferring visualization tasks.","Based on these results, we highlight future research directions on using LLMs for visualization generation."],"url":"http://arxiv.org/abs/2407.06129v1"}
{"created":"2024-07-08 17:00:51","title":"Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities","abstract":"Depression has proven to be a significant public health issue, profoundly affecting the psychological well-being of individuals. If it remains undiagnosed, depression can lead to severe health issues, which can manifest physically and even lead to suicide. Generally, Diagnosing depression or any other mental disorder involves conducting semi-structured interviews alongside supplementary questionnaires, including variants of the Patient Health Questionnaire (PHQ) by Clinicians and mental health professionals. This approach places significant reliance on the experience and judgment of trained physicians, making the diagnosis susceptible to personal biases. Given that the underlying mechanisms causing depression are still being actively researched, physicians often face challenges in diagnosing and treating the condition, particularly in its early stages of clinical presentation. Recently, significant strides have been made in Artificial neural computing to solve problems involving text, image, and speech in various domains. Our analysis has aimed to leverage these state-of-the-art (SOTA) models in our experiments to achieve optimal outcomes leveraging multiple modalities. The experiments were performed on the Extended Distress Analysis Interview Corpus Wizard of Oz dataset (E-DAIC) corpus presented in the Audio/Visual Emotion Challenge (AVEC) 2019 Challenge. The proposed solutions demonstrate better results achieved by Proprietary and Open-source Large Language Models (LLMs), which achieved a Root Mean Square Error (RMSE) score of 3.98 on Textual Modality, beating the AVEC 2019 challenge baseline results and current SOTA regression analysis architectures. Additionally, the proposed solution achieved an accuracy of 71.43% in the classification task. The paper also includes a novel audio-visual multi-modal network that predicts PHQ-8 scores with an RMSE of 6.51.","sentences":["Depression has proven to be a significant public health issue, profoundly affecting the psychological well-being of individuals.","If it remains undiagnosed, depression can lead to severe health issues, which can manifest physically and even lead to suicide.","Generally, Diagnosing depression or any other mental disorder involves conducting semi-structured interviews alongside supplementary questionnaires, including variants of the Patient Health Questionnaire (PHQ) by Clinicians and mental health professionals.","This approach places significant reliance on the experience and judgment of trained physicians, making the diagnosis susceptible to personal biases.","Given that the underlying mechanisms causing depression are still being actively researched, physicians often face challenges in diagnosing and treating the condition, particularly in its early stages of clinical presentation.","Recently, significant strides have been made in Artificial neural computing to solve problems involving text, image, and speech in various domains.","Our analysis has aimed to leverage these state-of-the-art (SOTA) models in our experiments to achieve optimal outcomes leveraging multiple modalities.","The experiments were performed on the Extended Distress Analysis Interview Corpus Wizard of Oz dataset (E-DAIC) corpus presented in the Audio/Visual Emotion Challenge (AVEC) 2019 Challenge.","The proposed solutions demonstrate better results achieved by Proprietary and Open-source Large Language Models (LLMs), which achieved a Root Mean Square Error (RMSE) score of 3.98 on Textual Modality, beating the AVEC 2019 challenge baseline results and current SOTA regression analysis architectures.","Additionally, the proposed solution achieved an accuracy of 71.43% in the classification task.","The paper also includes a novel audio-visual multi-modal network that predicts PHQ-8 scores with an RMSE of 6.51."],"url":"http://arxiv.org/abs/2407.06125v1"}
{"created":"2024-07-08 17:00:28","title":"Structured Generations: Using Hierarchical Clusters to guide Diffusion Models","abstract":"This paper introduces Diffuse-TreeVAE, a deep generative model that integrates hierarchical clustering into the framework of Denoising Diffusion Probabilistic Models (DDPMs). The proposed approach generates new images by sampling from a root embedding of a learned latent tree VAE-based structure, it then propagates through hierarchical paths, and utilizes a second-stage DDPM to refine and generate distinct, high-quality images for each data cluster. The result is a model that not only improves image clarity but also ensures that the generated samples are representative of their respective clusters, addressing the limitations of previous VAE-based methods and advancing the state of clustering-based generative modeling.","sentences":["This paper introduces Diffuse-TreeVAE, a deep generative model that integrates hierarchical clustering into the framework of Denoising Diffusion Probabilistic Models (DDPMs).","The proposed approach generates new images by sampling from a root embedding of a learned latent tree VAE-based structure, it then propagates through hierarchical paths, and utilizes a second-stage DDPM to refine and generate distinct, high-quality images for each data cluster.","The result is a model that not only improves image clarity but also ensures that the generated samples are representative of their respective clusters, addressing the limitations of previous VAE-based methods and advancing the state of clustering-based generative modeling."],"url":"http://arxiv.org/abs/2407.06124v1"}
{"created":"2024-07-08 16:59:50","title":"Investigating User Perceptions of Collaborative Agenda Setting in Virtual Health Counseling Session","abstract":"Virtual health counselors offer the potential to provide users with information and counseling in complex areas such as disease management and health education. However, ensuring user engagement is challenging, particularly when the volume of information and length of counseling sessions increase. Agenda setting a clinical counseling technique where a patient and clinician collaboratively decide on session topics is an effective approach to tailoring discussions for individual patient needs and sustaining engagement. We explore the effectiveness of agenda setting in a virtual counselor system designed to counsel women for breast cancer genetic testing. In a between subjects study, we assessed three versions of the system with varying levels of user control in the system's agenda setting approach. We found that participants' knowledge improved across all conditions. Although our results showed that any type of agenda setting was perceived as useful, regardless of user control, interviews revealed a preference for more collaboration and user involvement in the agenda setting process. Our study highlights the importance of using patient-centered approaches, such as tailored discussions, when using virtual counselors in healthcare.","sentences":["Virtual health counselors offer the potential to provide users with information and counseling in complex areas such as disease management and health education.","However, ensuring user engagement is challenging, particularly when the volume of information and length of counseling sessions increase.","Agenda setting a clinical counseling technique where a patient and clinician collaboratively decide on session topics is an effective approach to tailoring discussions for individual patient needs and sustaining engagement.","We explore the effectiveness of agenda setting in a virtual counselor system designed to counsel women for breast cancer genetic testing.","In a between subjects study, we assessed three versions of the system with varying levels of user control in the system's agenda setting approach.","We found that participants' knowledge improved across all conditions.","Although our results showed that any type of agenda setting was perceived as useful, regardless of user control, interviews revealed a preference for more collaboration and user involvement in the agenda setting process.","Our study highlights the importance of using patient-centered approaches, such as tailored discussions, when using virtual counselors in healthcare."],"url":"http://arxiv.org/abs/2407.06123v1"}
{"created":"2024-07-08 16:58:57","title":"Periodic agent-state based Q-learning for POMDPs","abstract":"The standard approach for Partially Observable Markov Decision Processes (POMDPs) is to convert them to a fully observed belief-state MDP. However, the belief state depends on the system model and is therefore not viable in reinforcement learning (RL) settings. A widely used alternative is to use an agent state, which is a model-free, recursively updateable function of the observation history. Examples include frame stacking and recurrent neural networks. Since the agent state is model-free, it is used to adapt standard RL algorithms to POMDPs. However, standard RL algorithms like Q-learning learn a stationary policy. Our main thesis that we illustrate via examples is that because the agent state does not satisfy the Markov property, non-stationary agent-state based policies can outperform stationary ones. To leverage this feature, we propose PASQL (periodic agent-state based Q-learning), which is a variant of agent-state-based Q-learning that learns periodic policies. By combining ideas from periodic Markov chains and stochastic approximation, we rigorously establish that PASQL converges to a cyclic limit and characterize the approximation error of the converged periodic policy. Finally, we present a numerical experiment to highlight the salient features of PASQL and demonstrate the benefit of learning periodic policies over stationary policies.","sentences":["The standard approach for Partially Observable Markov Decision Processes (POMDPs) is to convert them to a fully observed belief-state MDP.","However, the belief state depends on the system model and is therefore not viable in reinforcement learning (RL) settings.","A widely used alternative is to use an agent state, which is a model-free, recursively updateable function of the observation history.","Examples include frame stacking and recurrent neural networks.","Since the agent state is model-free, it is used to adapt standard RL algorithms to POMDPs.","However, standard RL algorithms like Q-learning learn a stationary policy.","Our main thesis that we illustrate via examples is that because the agent state does not satisfy the Markov property, non-stationary agent-state based policies can outperform stationary ones.","To leverage this feature, we propose PASQL (periodic agent-state based Q-learning), which is a variant of agent-state-based Q-learning that learns periodic policies.","By combining ideas from periodic Markov chains and stochastic approximation, we rigorously establish that PASQL converges to a cyclic limit and characterize the approximation error of the converged periodic policy.","Finally, we present a numerical experiment to highlight the salient features of PASQL and demonstrate the benefit of learning periodic policies over stationary policies."],"url":"http://arxiv.org/abs/2407.06121v1"}
{"created":"2024-07-08 16:57:26","title":"Sketchy Moment Matching: Toward Fast and Provable Data Selection for Finetuning","abstract":"We revisit data selection in a modern context of finetuning from a fundamental perspective. Extending the classical wisdom of variance minimization in low dimensions to high-dimensional finetuning, our generalization analysis unveils the importance of additionally reducing bias induced by low-rank approximation. Inspired by the variance-bias tradeoff in high dimensions from the theory, we introduce Sketchy Moment Matching (SkMM), a scalable data selection scheme with two stages. (i) First, the bias is controlled using gradient sketching that explores the finetuning parameter space for an informative low-dimensional subspace $\\mathcal{S}$; (ii) then the variance is reduced over $\\mathcal{S}$ via moment matching between the original and selected datasets. Theoretically, we show that gradient sketching is fast and provably accurate: selecting $n$ samples by reducing variance over $\\mathcal{S}$ preserves the fast-rate generalization $O(\\dim(\\mathcal{S})/n)$, independent of the parameter dimension. Empirically, we concretize the variance-bias balance via synthetic experiments and demonstrate the effectiveness of SkMM for finetuning in real vision tasks.","sentences":["We revisit data selection in a modern context of finetuning from a fundamental perspective.","Extending the classical wisdom of variance minimization in low dimensions to high-dimensional finetuning, our generalization analysis unveils the importance of additionally reducing bias induced by low-rank approximation.","Inspired by the variance-bias tradeoff in high dimensions from the theory, we introduce Sketchy Moment Matching (SkMM), a scalable data selection scheme with two stages.","(i) First, the bias is controlled using gradient sketching that explores the finetuning parameter space for an informative low-dimensional subspace $\\mathcal{S}$; (ii) then the variance is reduced over $\\mathcal{S}$ via moment matching between the original and selected datasets.","Theoretically, we show that gradient sketching is fast and provably accurate: selecting $n$ samples by reducing variance over $\\mathcal{S}$ preserves the fast-rate generalization $O(\\dim(\\mathcal{S})/n)$, independent of the parameter dimension.","Empirically, we concretize the variance-bias balance via synthetic experiments and demonstrate the effectiveness of SkMM for finetuning in real vision tasks."],"url":"http://arxiv.org/abs/2407.06120v1"}
{"created":"2024-07-08 16:57:03","title":"Report on the NSF Workshop on Sustainable Computing for Sustainability (NSF WSCS 2024)","abstract":"This report documents the process that led to the NSF Workshop on \"Sustainable Computing for Sustainability\" held in April 2024 at NSF in Alexandria, VA, and reports on its findings. The workshop's primary goals were to (i) advance the development of research initiatives along the themes of both sustainable computing and computing for sustainability, while also (ii) helping develop and sustain the interdisciplinary teams those initiatives would need. The workshop's findings are in the form of recommendations grouped in three categories: General recommendations that cut across both themes of sustainable computing and computing for sustainability, and recommendations that are specific to sustainable computing and computing for sustainability, respectively.","sentences":["This report documents the process that led to the NSF Workshop on \"Sustainable Computing for Sustainability\" held in April 2024 at NSF in Alexandria, VA, and reports on its findings.","The workshop's primary goals were to (i) advance the development of research initiatives along the themes of both sustainable computing and computing for sustainability, while also (ii) helping develop and sustain the interdisciplinary teams those initiatives would need.","The workshop's findings are in the form of recommendations grouped in three categories: General recommendations that cut across both themes of sustainable computing and computing for sustainability, and recommendations that are specific to sustainable computing and computing for sustainability, respectively."],"url":"http://arxiv.org/abs/2407.06119v1"}
{"created":"2024-07-08 16:56:37","title":"Autonomous Mobile Robot Navigation: Tracking problem","abstract":"This paper presents a study on autonomous robot navigation, focusing on three key behaviors: Odometry, Target Tracking, and Obstacle Avoidance. Each behavior is described in detail, along with experimental setups for simulated and real-world environments. Odometry utilizes wheel encoder data for precise navigation along predefined paths, validated through experiments with a Pioneer robot. Target Tracking employs vision-based techniques for pursuing designated targets while avoiding obstacles, demonstrated on the same platform. Obstacle Avoidance utilizes ultrasonic sensors to navigate cluttered environments safely, validated in both simulated and real-world scenarios. Additionally, the paper extends the project to include an Elegoo robot car, leveraging its features for enhanced experimentation. Through advanced algorithms and experimental validations, this study provides insights into developing robust navigation systems for autonomous robots.","sentences":["This paper presents a study on autonomous robot navigation, focusing on three key behaviors: Odometry, Target Tracking, and Obstacle Avoidance.","Each behavior is described in detail, along with experimental setups for simulated and real-world environments.","Odometry utilizes wheel encoder data for precise navigation along predefined paths, validated through experiments with a Pioneer robot.","Target Tracking employs vision-based techniques for pursuing designated targets while avoiding obstacles, demonstrated on the same platform.","Obstacle Avoidance utilizes ultrasonic sensors to navigate cluttered environments safely, validated in both simulated and real-world scenarios.","Additionally, the paper extends the project to include an Elegoo robot car, leveraging its features for enhanced experimentation.","Through advanced algorithms and experimental validations, this study provides insights into developing robust navigation systems for autonomous robots."],"url":"http://arxiv.org/abs/2407.06118v1"}
{"created":"2024-07-08 16:49:01","title":"C2C: Component-to-Composition Learning for Zero-Shot Compositional Action Recognition","abstract":"Compositional actions consist of dynamic (verbs) and static (objects) concepts. Humans can easily recognize unseen compositions using the learned concepts. For machines, solving such a problem requires a model to recognize unseen actions composed of previously observed verbs and objects, thus requiring, so-called, compositional generalization ability. To facilitate this research, we propose a novel Zero-Shot Compositional Action Recognition (ZS-CAR) task. For evaluating the task, we construct a new benchmark, Something-composition (Sth-com), based on the widely used Something-Something V2 dataset. We also propose a novel Component-to-Composition (C2C) learning method to solve the new ZS-CAR task. C2C includes an independent component learning module and a composition inference module. Last, we devise an enhanced training strategy to address the challenges of component variation between seen and unseen compositions and to handle the subtle balance between learning seen and unseen actions. The experimental results demonstrate that the proposed framework significantly surpasses the existing compositional generalization methods and sets a new state-of-the-art. The new Sth-com benchmark and code are available at https://github.com/RongchangLi/ZSCAR_C2C.","sentences":["Compositional actions consist of dynamic (verbs) and static (objects) concepts.","Humans can easily recognize unseen compositions using the learned concepts.","For machines, solving such a problem requires a model to recognize unseen actions composed of previously observed verbs and objects, thus requiring, so-called, compositional generalization ability.","To facilitate this research, we propose a novel Zero-Shot Compositional Action Recognition (ZS-CAR) task.","For evaluating the task, we construct a new benchmark, Something-composition (Sth-com), based on the widely used Something-Something V2 dataset.","We also propose a novel Component-to-Composition (C2C) learning method to solve the new ZS-CAR task.","C2C includes an independent component learning module and a composition inference module.","Last, we devise an enhanced training strategy to address the challenges of component variation between seen and unseen compositions and to handle the subtle balance between learning seen and unseen actions.","The experimental results demonstrate that the proposed framework significantly surpasses the existing compositional generalization methods and sets a new state-of-the-art.","The new Sth-com benchmark and code are available at https://github.com/RongchangLi/ZSCAR_C2C."],"url":"http://arxiv.org/abs/2407.06113v1"}
{"created":"2024-07-08 16:48:48","title":"Enhancing Language Model Rationality with Bi-Directional Deliberation Reasoning","abstract":"This paper introduces BI-Directional DEliberation Reasoning (BIDDER), a novel reasoning approach to enhance the decision rationality of language models. Traditional reasoning methods typically rely on historical information and employ uni-directional (left-to-right) reasoning strategy. This lack of bi-directional deliberation reasoning results in limited awareness of potential future outcomes and insufficient integration of historical context, leading to suboptimal decisions. BIDDER addresses this gap by incorporating principles of rational decision-making, specifically managing uncertainty and predicting expected utility. Our approach involves three key processes: Inferring hidden states to represent uncertain information in the decision-making process from historical data; Using these hidden states to predict future potential states and potential outcomes; Integrating historical information (past contexts) and long-term outcomes (future contexts) to inform reasoning. By leveraging bi-directional reasoning, BIDDER ensures thorough exploration of both past and future contexts, leading to more informed and rational decisions. We tested BIDDER's effectiveness in two well-defined scenarios: Poker (Limit Texas Hold'em) and Negotiation. Our experiments demonstrate that BIDDER significantly improves the decision-making capabilities of LLMs and LLM agents.","sentences":["This paper introduces BI-Directional DEliberation Reasoning (BIDDER), a novel reasoning approach to enhance the decision rationality of language models.","Traditional reasoning methods typically rely on historical information and employ uni-directional (left-to-right) reasoning strategy.","This lack of bi-directional deliberation reasoning results in limited awareness of potential future outcomes and insufficient integration of historical context, leading to suboptimal decisions.","BIDDER addresses this gap by incorporating principles of rational decision-making, specifically managing uncertainty and predicting expected utility.","Our approach involves three key processes: Inferring hidden states to represent uncertain information in the decision-making process from historical data; Using these hidden states to predict future potential states and potential outcomes; Integrating historical information (past contexts) and long-term outcomes (future contexts) to inform reasoning.","By leveraging bi-directional reasoning, BIDDER ensures thorough exploration of both past and future contexts, leading to more informed and rational decisions.","We tested BIDDER's effectiveness in two well-defined scenarios: Poker (Limit Texas Hold'em) and Negotiation.","Our experiments demonstrate that BIDDER significantly improves the decision-making capabilities of LLMs and LLM agents."],"url":"http://arxiv.org/abs/2407.06112v1"}
{"created":"2024-07-08 16:47:19","title":"FGA: Fourier-Guided Attention Network for Crowd Count Estimation","abstract":"Crowd counting is gaining societal relevance, particularly in domains of Urban Planning, Crowd Management, and Public Safety. This paper introduces Fourier-guided attention (FGA), a novel attention mechanism for crowd count estimation designed to address the inefficient full-scale global pattern capture in existing works on convolution-based attention networks. FGA efficiently captures multi-scale information, including full-scale global patterns, by utilizing Fast-Fourier Transformations (FFT) along with spatial attention for global features and convolutions with channel-wise attention for semi-global and local features. The architecture of FGA involves a dual-path approach: (1) a path for processing full-scale global features through FFT, allowing for efficient extraction of information in the frequency domain, and (2) a path for processing remaining feature maps for semi-global and local features using traditional convolutions and channel-wise attention. This dual-path architecture enables FGA to seamlessly integrate frequency and spatial information, enhancing its ability to capture diverse crowd patterns. We apply FGA in the last layers of two popular crowd-counting works, CSRNet and CANNet, to evaluate the module's performance on benchmark datasets such as ShanghaiTech-A, ShanghaiTech-B, UCF-CC-50, and JHU++ crowd. The experiments demonstrate a notable improvement across all datasets based on Mean-Squared-Error (MSE) and Mean-Absolute-Error (MAE) metrics, showing comparable performance to recent state-of-the-art methods. Additionally, we illustrate the interpretability using qualitative analysis, leveraging Grad-CAM heatmaps, to show the effectiveness of FGA in capturing crowd patterns.","sentences":["Crowd counting is gaining societal relevance, particularly in domains of Urban Planning, Crowd Management, and Public Safety.","This paper introduces Fourier-guided attention (FGA), a novel attention mechanism for crowd count estimation designed to address the inefficient full-scale global pattern capture in existing works on convolution-based attention networks.","FGA efficiently captures multi-scale information, including full-scale global patterns, by utilizing Fast-Fourier Transformations (FFT) along with spatial attention for global features and convolutions with channel-wise attention for semi-global and local features.","The architecture of FGA involves a dual-path approach: (1) a path for processing full-scale global features through FFT, allowing for efficient extraction of information in the frequency domain, and (2) a path for processing remaining feature maps for semi-global and local features using traditional convolutions and channel-wise attention.","This dual-path architecture enables FGA to seamlessly integrate frequency and spatial information, enhancing its ability to capture diverse crowd patterns.","We apply FGA in the last layers of two popular crowd-counting works, CSRNet and CANNet, to evaluate the module's performance on benchmark datasets such as ShanghaiTech-A, ShanghaiTech-B, UCF-CC-50, and JHU++ crowd.","The experiments demonstrate a notable improvement across all datasets based on Mean-Squared-Error (MSE) and Mean-Absolute-Error (MAE) metrics, showing comparable performance to recent state-of-the-art methods.","Additionally, we illustrate the interpretability using qualitative analysis, leveraging Grad-CAM heatmaps, to show the effectiveness of FGA in capturing crowd patterns."],"url":"http://arxiv.org/abs/2407.06110v1"}
{"created":"2024-07-08 16:46:47","title":"PerlDiff: Controllable Street View Synthesis Using Perspective-Layout Diffusion Models","abstract":"Controllable generation is considered a potentially vital approach to address the challenge of annotating 3D data, and the precision of such controllable generation becomes particularly imperative in the context of data production for autonomous driving. Existing methods focus on the integration of diverse generative information into controlling inputs, utilizing frameworks such as GLIGEN or ControlNet, to produce commendable outcomes in controllable generation. However, such approaches intrinsically restrict generation performance to the learning capacities of predefined network architectures. In this paper, we explore the integration of controlling information and introduce PerlDiff (Perspective-Layout Diffusion Models), a method for effective street view image generation that fully leverages perspective 3D geometric information. Our PerlDiff employs 3D geometric priors to guide the generation of street view images with precise object-level control within the network learning process, resulting in a more robust and controllable output. Moreover, it demonstrates superior controllability compared to alternative layout control methods. Empirical results justify that our PerlDiff markedly enhances the precision of generation on the NuScenes and KITTI datasets. Our codes and models are publicly available at https://github.com/LabShuHangGU/PerlDiff.","sentences":["Controllable generation is considered a potentially vital approach to address the challenge of annotating 3D data, and the precision of such controllable generation becomes particularly imperative in the context of data production for autonomous driving.","Existing methods focus on the integration of diverse generative information into controlling inputs, utilizing frameworks such as GLIGEN or ControlNet, to produce commendable outcomes in controllable generation.","However, such approaches intrinsically restrict generation performance to the learning capacities of predefined network architectures.","In this paper, we explore the integration of controlling information and introduce PerlDiff (Perspective-Layout Diffusion Models), a method for effective street view image generation that fully leverages perspective 3D geometric information.","Our PerlDiff employs 3D geometric priors to guide the generation of street view images with precise object-level control within the network learning process, resulting in a more robust and controllable output.","Moreover, it demonstrates superior controllability compared to alternative layout control methods.","Empirical results justify that our PerlDiff markedly enhances the precision of generation on the NuScenes and KITTI datasets.","Our codes and models are publicly available at https://github.com/LabShuHangGU/PerlDiff."],"url":"http://arxiv.org/abs/2407.06109v1"}
{"created":"2024-07-08 16:44:36","title":"Bridging abstract dialectical argumentation and Boolean gene regulation","abstract":"This paper leans on two similar areas so far detached from each other. On the one hand, Dung's pioneering contributions to abstract argumentation, almost thirty years ago, gave rise to a plethora of successors, including abstract dialectical frameworks (ADFs). On the other hand, Boolean networks (BNs), devised as models of gene regulation, have been successful for studying the behavior of molecular processes within cells. ADFs and BNs are similar to each other: both can be viewed as functions from vectors of bits to vectors of bits. As soon as similarities emerge between these two formalisms, however, differences appear. For example, conflict-freedom is prominent in argumentation (where we are interested in a self-consistent, i.e., conflict-free, set of beliefs) but absent in BNs. By contrast, asynchrony (where only one gene is updated at a time) is conspicuous in BNs and lacking in argumentation. Finally, while a monotonicity-based notion occurs in signed reasoning of both argumentation and gene regulation, a different, derivative-based notion only appears in the BN literature. To identify common mathematical structure between both formalisms, these differences need clarification. This contribution is a partial review of both these areas, where we cover enough ground to exhibit their more evident similarities, to then reconcile some of their apparent differences. We highlight a range of avenues of research resulting from ironing out discrepancies between these two fields. Unveiling their common concerns should enable these two areas to cross-fertilize so as to transfer ideas and results between each other.","sentences":["This paper leans on two similar areas so far detached from each other.","On the one hand, Dung's pioneering contributions to abstract argumentation, almost thirty years ago, gave rise to a plethora of successors, including abstract dialectical frameworks (ADFs).","On the other hand, Boolean networks (BNs), devised as models of gene regulation, have been successful for studying the behavior of molecular processes within cells.","ADFs and BNs are similar to each other: both can be viewed as functions from vectors of bits to vectors of bits.","As soon as similarities emerge between these two formalisms, however, differences appear.","For example, conflict-freedom is prominent in argumentation (where we are interested in a self-consistent, i.e., conflict-free, set of beliefs) but absent in BNs.","By contrast, asynchrony (where only one gene is updated at a time) is conspicuous in BNs and lacking in argumentation.","Finally, while a monotonicity-based notion occurs in signed reasoning of both argumentation and gene regulation, a different, derivative-based notion only appears in the BN literature.","To identify common mathematical structure between both formalisms, these differences need clarification.","This contribution is a partial review of both these areas, where we cover enough ground to exhibit their more evident similarities, to then reconcile some of their apparent differences.","We highlight a range of avenues of research resulting from ironing out discrepancies between these two fields.","Unveiling their common concerns should enable these two areas to cross-fertilize so as to transfer ideas and results between each other."],"url":"http://arxiv.org/abs/2407.06106v1"}
{"created":"2024-07-08 16:38:52","title":"Physics-Informed Machine Learning Towards A Real-Time Spacecraft Thermal Simulator","abstract":"Modeling thermal states for complex space missions, such as the surface exploration of airless bodies, requires high computation, whether used in ground-based analysis for spacecraft design or during onboard reasoning for autonomous operations. For example, a finite-element thermal model with hundreds of elements can take significant time to simulate, which makes it unsuitable for onboard reasoning during time-sensitive scenarios such as descent and landing, proximity operations, or in-space assembly. Further, the lack of fast and accurate thermal modeling drives thermal designs to be more conservative and leads to spacecraft with larger mass and higher power budgets. The emerging paradigm of physics-informed machine learning (PIML) presents a class of hybrid modeling architectures that address this challenge by combining simplified physics models with machine learning (ML) models resulting in models which maintain both interpretability and robustness. Such techniques enable designs with reduced mass and power through onboard thermal-state estimation and control and may lead to improved onboard handling of off-nominal states, including unplanned down-time. The PIML model or hybrid model presented here consists of a neural network which predicts reduced nodalizations (distribution and size of coarse mesh) given on-orbit thermal load conditions, and subsequently a (relatively coarse) finite-difference model operates on this mesh to predict thermal states. We compare the computational performance and accuracy of the hybrid model to a data-driven neural net model, and a high-fidelity finite-difference model of a prototype Earth-orbiting small spacecraft. The PIML based active nodalization approach provides significantly better generalization than the neural net model and coarse mesh model, while reducing computing cost by up to 1.7x compared to the high-fidelity model.","sentences":["Modeling thermal states for complex space missions, such as the surface exploration of airless bodies, requires high computation, whether used in ground-based analysis for spacecraft design or during onboard reasoning for autonomous operations.","For example, a finite-element thermal model with hundreds of elements can take significant time to simulate, which makes it unsuitable for onboard reasoning during time-sensitive scenarios such as descent and landing, proximity operations, or in-space assembly.","Further, the lack of fast and accurate thermal modeling drives thermal designs to be more conservative and leads to spacecraft with larger mass and higher power budgets.","The emerging paradigm of physics-informed machine learning (PIML) presents a class of hybrid modeling architectures that address this challenge by combining simplified physics models with machine learning (ML) models resulting in models which maintain both interpretability and robustness.","Such techniques enable designs with reduced mass and power through onboard thermal-state estimation and control and may lead to improved onboard handling of off-nominal states, including unplanned down-time.","The PIML model or hybrid model presented here consists of a neural network which predicts reduced nodalizations (distribution and size of coarse mesh) given on-orbit thermal load conditions, and subsequently a (relatively coarse) finite-difference model operates on this mesh to predict thermal states.","We compare the computational performance and accuracy of the hybrid model to a data-driven neural net model, and a high-fidelity finite-difference model of a prototype Earth-orbiting small spacecraft.","The PIML based active nodalization approach provides significantly better generalization than the neural net model and coarse mesh model, while reducing computing cost by up to 1.7x compared to the high-fidelity model."],"url":"http://arxiv.org/abs/2407.06099v1"}
{"created":"2024-07-08 16:38:31","title":"Epistemological Bias As a Means for the Automated Detection of Injustices in Text","abstract":"Injustice occurs when someone experiences unfair treatment or their rights are violated and is often due to the presence of implicit biases and prejudice such as stereotypes. The automated identification of injustice in text has received little attention, due in part to the fact that underlying implicit biases or stereotypes are rarely explicitly stated and that instances often occur unconsciously due to the pervasive nature of prejudice in society. Here, we describe a novel framework that combines the use of a fine-tuned BERT-based bias detection model, two stereotype detection models, and a lexicon-based approach to show that epistemological biases (i.e., words, which presupposes, entails, asserts, hedges, or boosts text to erode or assert a person's capacity as a knower) can assist with the automatic detection of injustice in text. The news media has many instances of injustice (i.e. discriminatory narratives), thus it is our use case here. We conduct and discuss an empirical qualitative research study which shows how the framework can be applied to detect injustices, even at higher volumes of data.","sentences":["Injustice occurs when someone experiences unfair treatment or their rights are violated and is often due to the presence of implicit biases and prejudice such as stereotypes.","The automated identification of injustice in text has received little attention, due in part to the fact that underlying implicit biases or stereotypes are rarely explicitly stated and that instances often occur unconsciously due to the pervasive nature of prejudice in society.","Here, we describe a novel framework that combines the use of a fine-tuned BERT-based bias detection model, two stereotype detection models, and a lexicon-based approach to show that epistemological biases (i.e., words, which presupposes, entails, asserts, hedges, or boosts text to erode or assert a person's capacity as a knower) can assist with the automatic detection of injustice in text.","The news media has many instances of injustice (i.e. discriminatory narratives), thus it is our use case here.","We conduct and discuss an empirical qualitative research study which shows how the framework can be applied to detect injustices, even at higher volumes of data."],"url":"http://arxiv.org/abs/2407.06098v1"}
{"created":"2024-07-08 16:36:55","title":"Muzzle-Based Cattle Identification System Using Artificial Intelligence (AI)","abstract":"Absence of tamper-proof cattle identification technology was a significant problem preventing insurance companies from providing livestock insurance. This lack of technology had devastating financial consequences for marginal farmers as they did not have the opportunity to claim compensation for any unexpected events such as the accidental death of cattle in Bangladesh. Using machine learning and deep learning algorithms, we have solved the bottleneck of cattle identification by developing and introducing a muzzle-based cattle identification system. The uniqueness of cattle muzzles has been scientifically established, which resembles human fingerprints. This is the fundamental premise that prompted us to develop a cattle identification system that extracts the uniqueness of cattle muzzles. For this purpose, we collected 32,374 images from 826 cattle. Contrast-limited adaptive histogram equalization (CLAHE) with sharpening filters was applied in the preprocessing steps to remove noise from images. We used the YOLO algorithm for cattle muzzle detection in the image and the FaceNet architecture to learn unified embeddings from muzzle images using squared $L_2$ distances. Our system performs with an accuracy of $96.489\\%$, $F_1$ score of $97.334\\%$, and a true positive rate (tpr) of $87.993\\%$ at a remarkably low false positive rate (fpr) of $0.098\\%$. This reliable and efficient system for identifying cattle can significantly advance livestock insurance and precision farming.","sentences":["Absence of tamper-proof cattle identification technology was a significant problem preventing insurance companies from providing livestock insurance.","This lack of technology had devastating financial consequences for marginal farmers as they did not have the opportunity to claim compensation for any unexpected events such as the accidental death of cattle in Bangladesh.","Using machine learning and deep learning algorithms, we have solved the bottleneck of cattle identification by developing and introducing a muzzle-based cattle identification system.","The uniqueness of cattle muzzles has been scientifically established, which resembles human fingerprints.","This is the fundamental premise that prompted us to develop a cattle identification system that extracts the uniqueness of cattle muzzles.","For this purpose, we collected 32,374 images from 826 cattle.","Contrast-limited adaptive histogram equalization (CLAHE) with sharpening filters was applied in the preprocessing steps to remove noise from images.","We used the YOLO algorithm for cattle muzzle detection in the image and the FaceNet architecture to learn unified embeddings from muzzle images using squared $L_2$ distances.","Our system performs with an accuracy of $96.489\\%$, $F_1$ score of $97.334\\%$, and a true positive rate (tpr) of $87.993\\%$ at a remarkably low false positive rate (fpr) of $0.098\\%$. This reliable and efficient system for identifying cattle can significantly advance livestock insurance and precision farming."],"url":"http://arxiv.org/abs/2407.06096v1"}
{"created":"2024-07-08 16:36:12","title":"Accelerating Diffusion for SAR-to-Optical Image Translation via Adversarial Consistency Distillation","abstract":"Synthetic Aperture Radar (SAR) provides all-weather, high-resolution imaging capabilities, but its unique imaging mechanism often requires expert interpretation, limiting its widespread applicability. Translating SAR images into more easily recognizable optical images using diffusion models helps address this challenge. However, diffusion models suffer from high latency due to numerous iterative inferences, while Generative Adversarial Networks (GANs) can achieve image translation with just a single iteration but often at the cost of image quality. To overcome these issues, we propose a new training framework for SAR-to-optical image translation that combines the strengths of both approaches. Our method employs consistency distillation to reduce iterative inference steps and integrates adversarial learning to ensure image clarity and minimize color shifts. Additionally, our approach allows for a trade-off between quality and speed, providing flexibility based on application requirements. We conducted experiments on SEN12 and GF3 datasets, performing quantitative evaluations using Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Frechet Inception Distance (FID), as well as calculating the inference latency. The results demonstrate that our approach significantly improves inference speed by 131 times while maintaining the visual quality of the generated images, thus offering a robust and efficient solution for SAR-to-optical image translation.","sentences":["Synthetic Aperture Radar (SAR) provides all-weather, high-resolution imaging capabilities, but its unique imaging mechanism often requires expert interpretation, limiting its widespread applicability.","Translating SAR images into more easily recognizable optical images using diffusion models helps address this challenge.","However, diffusion models suffer from high latency due to numerous iterative inferences, while Generative Adversarial Networks (GANs) can achieve image translation with just a single iteration but often at the cost of image quality.","To overcome these issues, we propose a new training framework for SAR-to-optical image translation that combines the strengths of both approaches.","Our method employs consistency distillation to reduce iterative inference steps and integrates adversarial learning to ensure image clarity and minimize color shifts.","Additionally, our approach allows for a trade-off between quality and speed, providing flexibility based on application requirements.","We conducted experiments on SEN12 and GF3 datasets, performing quantitative evaluations using Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Frechet Inception Distance (FID), as well as calculating the inference latency.","The results demonstrate that our approach significantly improves inference speed by 131 times while maintaining the visual quality of the generated images, thus offering a robust and efficient solution for SAR-to-optical image translation."],"url":"http://arxiv.org/abs/2407.06095v1"}
{"created":"2024-07-08 16:34:48","title":"ERR@HRI 2024 Challenge: Multimodal Detection of Errors and Failures in Human-Robot Interactions","abstract":"Despite the recent advancements in robotics and machine learning (ML), the deployment of autonomous robots in our everyday lives is still an open challenge. This is due to multiple reasons among which are their frequent mistakes, such as interrupting people or having delayed responses, as well as their limited ability to understand human speech, i.e., failure in tasks like transcribing speech to text. These mistakes may disrupt interactions and negatively influence human perception of these robots. To address this problem, robots need to have the ability to detect human-robot interaction (HRI) failures. The ERR@HRI 2024 challenge tackles this by offering a benchmark multimodal dataset of robot failures during human-robot interactions (HRI), encouraging researchers to develop and benchmark multimodal machine learning models to detect these failures. We created a dataset featuring multimodal non-verbal interaction data, including facial, speech, and pose features from video clips of interactions with a robotic coach, annotated with labels indicating the presence or absence of robot mistakes, user awkwardness, and interaction ruptures, allowing for the training and evaluation of predictive models. Challenge participants have been invited to submit their multimodal ML models for detection of robot errors and to be evaluated against various performance metrics such as accuracy, precision, recall, F1 score, with and without a margin of error reflecting the time-sensitivity of these metrics. The results of this challenge will help the research field in better understanding the robot failures in human-robot interactions and designing autonomous robots that can mitigate their own errors after successfully detecting them.","sentences":["Despite the recent advancements in robotics and machine learning (ML), the deployment of autonomous robots in our everyday lives is still an open challenge.","This is due to multiple reasons among which are their frequent mistakes, such as interrupting people or having delayed responses, as well as their limited ability to understand human speech, i.e., failure in tasks like transcribing speech to text.","These mistakes may disrupt interactions and negatively influence human perception of these robots.","To address this problem, robots need to have the ability to detect human-robot interaction (HRI) failures.","The ERR@HRI 2024 challenge tackles this by offering a benchmark multimodal dataset of robot failures during human-robot interactions (HRI), encouraging researchers to develop and benchmark multimodal machine learning models to detect these failures.","We created a dataset featuring multimodal non-verbal interaction data, including facial, speech, and pose features from video clips of interactions with a robotic coach, annotated with labels indicating the presence or absence of robot mistakes, user awkwardness, and interaction ruptures, allowing for the training and evaluation of predictive models.","Challenge participants have been invited to submit their multimodal ML models for detection of robot errors and to be evaluated against various performance metrics such as accuracy, precision, recall, F1 score, with and without a margin of error reflecting the time-sensitivity of these metrics.","The results of this challenge will help the research field in better understanding the robot failures in human-robot interactions and designing autonomous robots that can mitigate their own errors after successfully detecting them."],"url":"http://arxiv.org/abs/2407.06094v1"}
{"created":"2024-07-08 16:34:47","title":"Artificial Intuition: Efficient Classification of Scientific Abstracts","abstract":"It is desirable to coarsely classify short scientific texts, such as grant or publication abstracts, for strategic insight or research portfolio management. These texts efficiently transmit dense information to experts possessing a rich body of knowledge to aid interpretation. Yet this task is remarkably difficult to automate because of brevity and the absence of context. To address this gap, we have developed a novel approach to generate and appropriately assign coarse domain-specific labels. We show that a Large Language Model (LLM) can provide metadata essential to the task, in a process akin to the augmentation of supplemental knowledge representing human intuition, and propose a workflow. As a pilot study, we use a corpus of award abstracts from the National Aeronautics and Space Administration (NASA). We develop new assessment tools in concert with established performance metrics.","sentences":["It is desirable to coarsely classify short scientific texts, such as grant or publication abstracts, for strategic insight or research portfolio management.","These texts efficiently transmit dense information to experts possessing a rich body of knowledge to aid interpretation.","Yet this task is remarkably difficult to automate because of brevity and the absence of context.","To address this gap, we have developed a novel approach to generate and appropriately assign coarse domain-specific labels.","We show that a Large Language Model (LLM) can provide metadata essential to the task, in a process akin to the augmentation of supplemental knowledge representing human intuition, and propose a workflow.","As a pilot study, we use a corpus of award abstracts from the National Aeronautics and Space Administration (NASA).","We develop new assessment tools in concert with established performance metrics."],"url":"http://arxiv.org/abs/2407.06093v1"}
{"created":"2024-07-08 16:31:49","title":"Assessing Cardiomegaly in Dogs Using a Simple CNN Model","abstract":"This paper introduces DogHeart, a dataset comprising 1400 training, 200 validation, and 400 test images categorized as small, normal, and large based on VHS score. A custom CNN model is developed, featuring a straightforward architecture with 4 convolutional layers and 4 fully connected layers. Despite the absence of data augmentation, the model achieves a 72\\% accuracy in classifying cardiomegaly severity. The study contributes to automated assessment of cardiac conditions in dogs, highlighting the potential for early detection and intervention in veterinary care.","sentences":["This paper introduces DogHeart, a dataset comprising 1400 training, 200 validation, and 400 test images categorized as small, normal, and large based on VHS score.","A custom CNN model is developed, featuring a straightforward architecture with 4 convolutional layers and 4 fully connected layers.","Despite the absence of data augmentation, the model achieves a 72\\% accuracy in classifying cardiomegaly severity.","The study contributes to automated assessment of cardiac conditions in dogs, highlighting the potential for early detection and intervention in veterinary care."],"url":"http://arxiv.org/abs/2407.06092v1"}
{"created":"2024-07-08 16:29:08","title":"Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models","abstract":"The remarkable success of Large Language Models (LLMs) has ushered natural language processing (NLP) research into a new era. Despite their diverse capabilities, LLMs trained on different corpora exhibit varying strengths and weaknesses, leading to challenges in maximizing their overall efficiency and versatility. To address these challenges, recent studies have explored collaborative strategies for LLMs. This paper provides a comprehensive overview of this emerging research area, highlighting the motivation behind such collaborations. Specifically, we categorize collaborative strategies into three primary approaches: Merging, Ensemble, and Cooperation. Merging involves integrating multiple LLMs in the parameter space. Ensemble combines the outputs of various LLMs. Cooperation} leverages different LLMs to allow full play to their diverse capabilities for specific tasks. We provide in-depth introductions to these methods from different perspectives and discuss their potential applications. Additionally, we outline future research directions, hoping this work will catalyze further studies on LLM collaborations and paving the way for advanced NLP applications.","sentences":["The remarkable success of Large Language Models (LLMs) has ushered natural language processing (NLP) research into a new era.","Despite their diverse capabilities, LLMs trained on different corpora exhibit varying strengths and weaknesses, leading to challenges in maximizing their overall efficiency and versatility.","To address these challenges, recent studies have explored collaborative strategies for LLMs.","This paper provides a comprehensive overview of this emerging research area, highlighting the motivation behind such collaborations.","Specifically, we categorize collaborative strategies into three primary approaches: Merging, Ensemble, and Cooperation.","Merging involves integrating multiple LLMs in the parameter space.","Ensemble combines the outputs of various LLMs.","Cooperation} leverages different LLMs to allow full play to their diverse capabilities for specific tasks.","We provide in-depth introductions to these methods from different perspectives and discuss their potential applications.","Additionally, we outline future research directions, hoping this work will catalyze further studies on LLM collaborations and paving the way for advanced NLP applications."],"url":"http://arxiv.org/abs/2407.06089v1"}
{"created":"2024-07-08 16:28:38","title":"Qualitative Event Perception: Leveraging Spatiotemporal Episodic Memory for Learning Combat in a Strategy Game","abstract":"Event perception refers to people's ability to carve up continuous experience into meaningful discrete events. We speak of finishing our morning coffee, mowing the lawn, leaving work, etc. as singular occurrences that are localized in time and space. In this work, we analyze how spatiotemporal representations can be used to automatically segment continuous experience into structured episodes, and how these descriptions can be used for analogical learning. These representations are based on Hayes' notion of histories and build upon existing work on qualitative episodic memory. Our agent automatically generates event descriptions of military battles in a strategy game and improves its gameplay by learning from this experience. Episodes are segmented based on changing properties in the world and we show evidence that they facilitate learning because they capture event descriptions at a useful spatiotemporal grain size. This is evaluated through our agent's performance in the game. We also show empirical evidence that the perception of spatial extent of episodes affects both their temporal duration as well as the number of overall cases generated.","sentences":["Event perception refers to people's ability to carve up continuous experience into meaningful discrete events.","We speak of finishing our morning coffee, mowing the lawn, leaving work, etc. as singular occurrences that are localized in time and space.","In this work, we analyze how spatiotemporal representations can be used to automatically segment continuous experience into structured episodes, and how these descriptions can be used for analogical learning.","These representations are based on Hayes' notion of histories and build upon existing work on qualitative episodic memory.","Our agent automatically generates event descriptions of military battles in a strategy game and improves its gameplay by learning from this experience.","Episodes are segmented based on changing properties in the world and we show evidence that they facilitate learning because they capture event descriptions at a useful spatiotemporal grain size.","This is evaluated through our agent's performance in the game.","We also show empirical evidence that the perception of spatial extent of episodes affects both their temporal duration as well as the number of overall cases generated."],"url":"http://arxiv.org/abs/2407.06088v1"}
{"created":"2024-07-08 16:26:52","title":"3D Vision and Language Pretraining with Large-Scale Synthetic Data","abstract":"3D Vision-Language Pre-training (3D-VLP) aims to provide a pre-train model which can bridge 3D scenes with natural language, which is an important technique for embodied intelligence. However, current 3D-VLP datasets are hindered by limited scene-level diversity and insufficient fine-grained annotations (only 1.2K scenes and 280K textual annotations in ScanScribe), primarily due to the labor-intensive of collecting and annotating 3D scenes. To overcome these obstacles, we construct SynVL3D, a comprehensive synthetic scene-text corpus with 10K indoor scenes and 1M descriptions at object, view, and room levels, which has the advantages of diverse scene data, rich textual descriptions, multi-grained 3D-text associations, and low collection cost. Utilizing the rich annotations in SynVL3D, we pre-train a simple and unified Transformer for aligning 3D and language with multi-grained pretraining tasks. Moreover, we propose a synthetic-to-real domain adaptation in downstream task fine-tuning process to address the domain shift. Through extensive experiments, we verify the effectiveness of our model design by achieving state-of-the-art performance on downstream tasks including visual grounding, dense captioning, and question answering.","sentences":["3D Vision-Language Pre-training (3D-VLP) aims to provide a pre-train model which can bridge 3D scenes with natural language, which is an important technique for embodied intelligence.","However, current 3D-VLP datasets are hindered by limited scene-level diversity and insufficient fine-grained annotations (only 1.2K scenes and 280K textual annotations in ScanScribe), primarily due to the labor-intensive of collecting and annotating 3D scenes.","To overcome these obstacles, we construct SynVL3D, a comprehensive synthetic scene-text corpus with 10K indoor scenes and 1M descriptions at object, view, and room levels, which has the advantages of diverse scene data, rich textual descriptions, multi-grained 3D-text associations, and low collection cost.","Utilizing the rich annotations in SynVL3D, we pre-train a simple and unified Transformer for aligning 3D and language with multi-grained pretraining tasks.","Moreover, we propose a synthetic-to-real domain adaptation in downstream task fine-tuning process to address the domain shift.","Through extensive experiments, we verify the effectiveness of our model design by achieving state-of-the-art performance on downstream tasks including visual grounding, dense captioning, and question answering."],"url":"http://arxiv.org/abs/2407.06084v1"}
{"created":"2024-07-08 16:25:50","title":"Optimal Rank-Metric Codes with Rank-Locality from Drinfeld Modules","abstract":"We introduce a new technique to construct rank-metric codes using the arithmetic theory of Drinfeld modules over global fields, and Dirichlet Theorem on polynomial arithmetic progressions. Using our methods, we obtain a new infinite family of optimal rank-metric codes with rank-locality, i.e. every code in our family achieves the information theoretical bound for rank-metric codes with rank-locality.","sentences":["We introduce a new technique to construct rank-metric codes using the arithmetic theory of Drinfeld modules over global fields, and Dirichlet Theorem on polynomial arithmetic progressions.","Using our methods, we obtain a new infinite family of optimal rank-metric codes with rank-locality, i.e. every code in our family achieves the information theoretical bound for rank-metric codes with rank-locality."],"url":"http://arxiv.org/abs/2407.06081v1"}
{"created":"2024-07-08 16:25:34","title":"Layered Diffusion Model for One-Shot High Resolution Text-to-Image Synthesis","abstract":"We present a one-shot text-to-image diffusion model that can generate high-resolution images from natural language descriptions. Our model employs a layered U-Net architecture that simultaneously synthesizes images at multiple resolution scales. We show that this method outperforms the baseline of synthesizing images only at the target resolution, while reducing the computational cost per step. We demonstrate that higher resolution synthesis can be achieved by layering convolutions at additional resolution scales, in contrast to other methods which require additional models for super-resolution synthesis.","sentences":["We present a one-shot text-to-image diffusion model that can generate high-resolution images from natural language descriptions.","Our model employs a layered U-Net architecture that simultaneously synthesizes images at multiple resolution scales.","We show that this method outperforms the baseline of synthesizing images only at the target resolution, while reducing the computational cost per step.","We demonstrate that higher resolution synthesis can be achieved by layering convolutions at additional resolution scales, in contrast to other methods which require additional models for super-resolution synthesis."],"url":"http://arxiv.org/abs/2407.06079v1"}
{"created":"2024-07-08 16:25:01","title":"Object-Oriented Material Classification and 3D Clustering for Improved Semantic Perception and Mapping in Mobile Robots","abstract":"Classification of different object surface material types can play a significant role in the decision-making algorithms for mobile robots and autonomous vehicles. RGB-based scene-level semantic segmentation has been well-addressed in the literature. However, improving material recognition using the depth modality and its integration with SLAM algorithms for 3D semantic mapping could unlock new potential benefits in the robotics perception pipeline. To this end, we propose a complementarity-aware deep learning approach for RGB-D-based material classification built on top of an object-oriented pipeline. The approach further integrates the ORB-SLAM2 method for 3D scene mapping with multiscale clustering of the detected material semantics in the point cloud map generated by the visual SLAM algorithm. Extensive experimental results with existing public datasets and newly contributed real-world robot datasets demonstrate a significant improvement in material classification and 3D clustering accuracy compared to state-of-the-art approaches for 3D semantic scene mapping.","sentences":["Classification of different object surface material types can play a significant role in the decision-making algorithms for mobile robots and autonomous vehicles.","RGB-based scene-level semantic segmentation has been well-addressed in the literature.","However, improving material recognition using the depth modality and its integration with SLAM algorithms for 3D semantic mapping could unlock new potential benefits in the robotics perception pipeline.","To this end, we propose a complementarity-aware deep learning approach for RGB-D-based material classification built on top of an object-oriented pipeline.","The approach further integrates the ORB-SLAM2 method for 3D scene mapping with multiscale clustering of the detected material semantics in the point cloud map generated by the visual SLAM algorithm.","Extensive experimental results with existing public datasets and newly contributed real-world robot datasets demonstrate a significant improvement in material classification and 3D clustering accuracy compared to state-of-the-art approaches for 3D semantic scene mapping."],"url":"http://arxiv.org/abs/2407.06077v1"}
{"created":"2024-07-08 16:21:53","title":"Understanding Visual Feature Reliance through the Lens of Complexity","abstract":"Recent studies suggest that deep learning models inductive bias towards favoring simpler features may be one of the sources of shortcut learning. Yet, there has been limited focus on understanding the complexity of the myriad features that models learn. In this work, we introduce a new metric for quantifying feature complexity, based on $\\mathscr{V}$-information and capturing whether a feature requires complex computational transformations to be extracted. Using this $\\mathscr{V}$-information metric, we analyze the complexities of 10,000 features, represented as directions in the penultimate layer, that were extracted from a standard ImageNet-trained vision model. Our study addresses four key questions: First, we ask what features look like as a function of complexity and find a spectrum of simple to complex features present within the model. Second, we ask when features are learned during training. We find that simpler features dominate early in training, and more complex features emerge gradually. Third, we investigate where within the network simple and complex features flow, and find that simpler features tend to bypass the visual hierarchy via residual connections. Fourth, we explore the connection between features complexity and their importance in driving the networks decision. We find that complex features tend to be less important. Surprisingly, important features become accessible at earlier layers during training, like a sedimentation process, allowing the model to build upon these foundational elements.","sentences":["Recent studies suggest that deep learning models inductive bias towards favoring simpler features may be one of the sources of shortcut learning.","Yet, there has been limited focus on understanding the complexity of the myriad features that models learn.","In this work, we introduce a new metric for quantifying feature complexity, based on $\\mathscr{V}$-information and capturing whether a feature requires complex computational transformations to be extracted.","Using this $\\mathscr{V}$-information metric, we analyze the complexities of 10,000 features, represented as directions in the penultimate layer, that were extracted from a standard ImageNet-trained vision model.","Our study addresses four key questions:","First, we ask what features look like as a function of complexity and find a spectrum of simple to complex features present within the model.","Second, we ask when features are learned during training.","We find that simpler features dominate early in training, and more complex features emerge gradually.","Third, we investigate where within the network simple and complex features flow, and find that simpler features tend to bypass the visual hierarchy via residual connections.","Fourth, we explore the connection between features complexity and their importance in driving the networks decision.","We find that complex features tend to be less important.","Surprisingly, important features become accessible at earlier layers during training, like a sedimentation process, allowing the model to build upon these foundational elements."],"url":"http://arxiv.org/abs/2407.06076v1"}
{"created":"2024-07-08 16:13:42","title":"From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty","abstract":"Large language models (LLMs) often exhibit undesirable behaviors, such as hallucinations and sequence repetitions. We propose to view these behaviors as fallbacks that models exhibit under uncertainty, and investigate the connection between them. We categorize fallback behaviors -- sequence repetitions, degenerate text, and hallucinations -- and extensively analyze them in models from the same family that differ by the amount of pretraining tokens, parameter count, or the inclusion of instruction-following training. Our experiments reveal a clear and consistent ordering of fallback behaviors, across all these axes: the more advanced an LLM is (i.e., trained on more tokens, has more parameters, or instruction-tuned), its fallback behavior shifts from sequence repetitions, to degenerate text, and then to hallucinations. Moreover, the same ordering is observed throughout a single generation, even for the best-performing models; as uncertainty increases, models shift from generating hallucinations to producing degenerate text and then sequence repetitions. Lastly, we demonstrate that while common decoding techniques, such as random sampling, might alleviate some unwanted behaviors like sequence repetitions, they increase harder-to-detect hallucinations.","sentences":["Large language models (LLMs) often exhibit undesirable behaviors, such as hallucinations and sequence repetitions.","We propose to view these behaviors as fallbacks that models exhibit under uncertainty, and investigate the connection between them.","We categorize fallback behaviors -- sequence repetitions, degenerate text, and hallucinations -- and extensively analyze them in models from the same family that differ by the amount of pretraining tokens, parameter count, or the inclusion of instruction-following training.","Our experiments reveal a clear and consistent ordering of fallback behaviors, across all these axes: the more advanced an LLM is (i.e., trained on more tokens, has more parameters, or instruction-tuned), its fallback behavior shifts from sequence repetitions, to degenerate text, and then to hallucinations.","Moreover, the same ordering is observed throughout a single generation, even for the best-performing models; as uncertainty increases, models shift from generating hallucinations to producing degenerate text and then sequence repetitions.","Lastly, we demonstrate that while common decoding techniques, such as random sampling, might alleviate some unwanted behaviors like sequence repetitions, they increase harder-to-detect hallucinations."],"url":"http://arxiv.org/abs/2407.06071v1"}
{"created":"2024-07-08 16:01:04","title":"MERGE -- A Bimodal Dataset for Static Music Emotion Recognition","abstract":"The Music Emotion Recognition (MER) field has seen steady developments in recent years, with contributions from feature engineering, machine learning, and deep learning. The landscape has also shifted from audio-centric systems to bimodal ensembles that combine audio and lyrics. However, a severe lack of public and sizeable bimodal databases has hampered the development and improvement of bimodal audio-lyrics systems. This article proposes three new audio, lyrics, and bimodal MER research datasets, collectively called MERGE, created using a semi-automatic approach. To comprehensively assess the proposed datasets and establish a baseline for benchmarking, we conducted several experiments for each modality, using feature engineering, machine learning, and deep learning methodologies. In addition, we propose and validate fixed train-validate-test splits. The obtained results confirm the viability of the proposed datasets, achieving the best overall result of 79.21% F1-score for bimodal classification using a deep neural network.","sentences":["The Music Emotion Recognition (MER) field has seen steady developments in recent years, with contributions from feature engineering, machine learning, and deep learning.","The landscape has also shifted from audio-centric systems to bimodal ensembles that combine audio and lyrics.","However, a severe lack of public and sizeable bimodal databases has hampered the development and improvement of bimodal audio-lyrics systems.","This article proposes three new audio, lyrics, and bimodal MER research datasets, collectively called MERGE, created using a semi-automatic approach.","To comprehensively assess the proposed datasets and establish a baseline for benchmarking, we conducted several experiments for each modality, using feature engineering, machine learning, and deep learning methodologies.","In addition, we propose and validate fixed train-validate-test splits.","The obtained results confirm the viability of the proposed datasets, achieving the best overall result of 79.21% F1-score for bimodal classification using a deep neural network."],"url":"http://arxiv.org/abs/2407.06060v1"}
{"created":"2024-07-08 16:01:00","title":"LaFAM: Unsupervised Feature Attribution with Label-free Activation Maps","abstract":"Convolutional Neural Networks (CNNs) are known for their ability to learn hierarchical structures, naturally developing detectors for objects, and semantic concepts within their deeper layers. Activation maps (AMs) reveal these saliency regions, which are crucial for many Explainable AI (XAI) methods. However, the direct exploitation of raw AMs in CNNs for feature attribution remains underexplored in literature. This work revises Class Activation Map (CAM) methods by introducing the Label-free Activation Map (LaFAM), a streamlined approach utilizing raw AMs for feature attribution without reliance on labels. LaFAM presents an efficient alternative to conventional CAM methods, demonstrating particular effectiveness in saliency map generation for self-supervised learning while maintaining applicability in supervised learning scenarios.","sentences":["Convolutional Neural Networks (CNNs) are known for their ability to learn hierarchical structures, naturally developing detectors for objects, and semantic concepts within their deeper layers.","Activation maps (AMs) reveal these saliency regions, which are crucial for many Explainable AI (XAI) methods.","However, the direct exploitation of raw AMs in CNNs for feature attribution remains underexplored in literature.","This work revises Class Activation Map (CAM) methods by introducing the Label-free Activation Map (LaFAM), a streamlined approach utilizing raw AMs for feature attribution without reliance on labels.","LaFAM presents an efficient alternative to conventional CAM methods, demonstrating particular effectiveness in saliency map generation for self-supervised learning while maintaining applicability in supervised learning scenarios."],"url":"http://arxiv.org/abs/2407.06059v1"}
{"created":"2024-07-08 15:59:44","title":"Variational Best-of-N Alignment","abstract":"Best-of-N (BoN) is a popular and effective algorithm for aligning language models to human preferences. The algorithm works as follows: at inference time, N samples are drawn from the language model, and the sample with the highest reward, as judged by a reward model, is returned as the output. Despite its effectiveness, BoN is computationally expensive; it reduces sampling throughput by a factor of N. To make BoN more efficient at inference time, one strategy is to fine-tune the language model to mimic what BoN does during inference. To achieve this, we derive the distribution induced by the BoN algorithm. We then propose to fine-tune the language model to minimize backward KL divergence to the BoN distribution. Our approach is analogous to mean-field variational inference and, thus, we term it variational BoN (vBoN). To the extent this fine-tuning is successful and we end up with a good approximation, we have reduced the inference cost by a factor of N. Our experiments on a controlled generation task suggest that while variational BoN is not as effective as BoN in aligning language models, it is close to BoN performance as vBoN appears more often on the Pareto frontier of reward and KL divergence compared to models trained with KL-constrained RL objective.","sentences":["Best-of-N (BoN) is a popular and effective algorithm for aligning language models to human preferences.","The algorithm works as follows: at inference time, N samples are drawn from the language model, and the sample with the highest reward, as judged by a reward model, is returned as the output.","Despite its effectiveness, BoN is computationally expensive; it reduces sampling throughput by a factor of N. To make BoN more efficient at inference time, one strategy is to fine-tune the language model to mimic what BoN does during inference.","To achieve this, we derive the distribution induced by the BoN algorithm.","We then propose to fine-tune the language model to minimize backward KL divergence to the BoN distribution.","Our approach is analogous to mean-field variational inference and, thus, we term it variational BoN (vBoN).","To the extent this fine-tuning is successful and we end up with a good approximation, we have reduced the inference cost by a factor of N. Our experiments on a controlled generation task suggest that while variational BoN is not as effective as BoN in aligning language models, it is close to BoN performance as vBoN appears more often on the Pareto frontier of reward and KL divergence compared to models trained with KL-constrained RL objective."],"url":"http://arxiv.org/abs/2407.06057v1"}
{"created":"2024-07-08 15:58:33","title":"Stranger Danger! Identifying and Avoiding Unpredictable Pedestrians in RL-based Social Robot Navigation","abstract":"Reinforcement learning (RL) methods for social robot navigation show great success navigating robots through large crowds of people, but the performance of these learning-based methods tends to degrade in particularly challenging or unfamiliar situations due to the models' dependency on representative training data. To ensure human safety and comfort, it is critical that these algorithms handle uncommon cases appropriately, but the low frequency and wide diversity of such situations present a significant challenge for these data-driven methods. To overcome this challenge, we propose modifications to the learning process that encourage these RL policies to maintain additional caution in unfamiliar situations. Specifically, we improve the Socially Attentive Reinforcement Learning (SARL) policy by (1) modifying the training process to systematically introduce deviations into a pedestrian model, (2) updating the value network to estimate and utilize pedestrian-unpredictability features, and (3) implementing a reward function to learn an effective response to pedestrian unpredictability. Compared to the original SARL policy, our modified policy maintains similar navigation times and path lengths, while reducing the number of collisions by 82% and reducing the proportion of time spent in the pedestrians' personal space by up to 19 percentage points for the most difficult cases. We also describe how to apply these modifications to other RL policies and demonstrate that some key high-level behaviors of our approach transfer to a physical robot.","sentences":["Reinforcement learning (RL) methods for social robot navigation show great success navigating robots through large crowds of people, but the performance of these learning-based methods tends to degrade in particularly challenging or unfamiliar situations due to the models' dependency on representative training data.","To ensure human safety and comfort, it is critical that these algorithms handle uncommon cases appropriately, but the low frequency and wide diversity of such situations present a significant challenge for these data-driven methods.","To overcome this challenge, we propose modifications to the learning process that encourage these RL policies to maintain additional caution in unfamiliar situations.","Specifically, we improve the Socially Attentive Reinforcement Learning (SARL) policy by (1) modifying the training process to systematically introduce deviations into a pedestrian model, (2) updating the value network to estimate and utilize pedestrian-unpredictability features, and (3) implementing a reward function to learn an effective response to pedestrian unpredictability.","Compared to the original SARL policy, our modified policy maintains similar navigation times and path lengths, while reducing the number of collisions by 82% and reducing the proportion of time spent in the pedestrians' personal space by up to 19 percentage points for the most difficult cases.","We also describe how to apply these modifications to other RL policies and demonstrate that some key high-level behaviors of our approach transfer to a physical robot."],"url":"http://arxiv.org/abs/2407.06056v1"}
{"created":"2024-07-08 15:53:48","title":"Two-timescale weighted sum-rate maximization for large cellular and cell-free massive MIMO","abstract":"We reconsider the problem of joint power control and beamforming design to maximize the weighted sum rate in large and potentially cell-free massive MIMO networks. In contrast to the available short-term methods, where an iterative algorithm is run for every instantaneous channel realization, we derive an iterative algorithm that can be run only sporadically leveraging known channel statistics, with minor performance loss. In addition, our algorithm also applies to the design of non-trivial cooperative beamforming schemes subject to limited sharing of instantaneous channel state information. Furthermore, our algorithm generalizes and outperforms the competing long-term methods from the massive MIMO literature, which are restricted to long-term power control only or to long-term joint power control and large-scale fading decoding design.","sentences":["We reconsider the problem of joint power control and beamforming design to maximize the weighted sum rate in large and potentially cell-free massive MIMO networks.","In contrast to the available short-term methods, where an iterative algorithm is run for every instantaneous channel realization, we derive an iterative algorithm that can be run only sporadically leveraging known channel statistics, with minor performance loss.","In addition, our algorithm also applies to the design of non-trivial cooperative beamforming schemes subject to limited sharing of instantaneous channel state information.","Furthermore, our algorithm generalizes and outperforms the competing long-term methods from the massive MIMO literature, which are restricted to long-term power control only or to long-term joint power control and large-scale fading decoding design."],"url":"http://arxiv.org/abs/2407.06050v1"}
{"created":"2024-07-08 15:51:37","title":"Vision-Braille: An End-to-End Tool for Chinese Braille Image-to-Text Translation","abstract":"Visually impaired people are a large group who can only use braille for reading and writing. However, the lack of special educational resources is the bottleneck for educating them. Educational equity is a reflection of the level of social civilization, cultural equality, and individual dignity. Facilitating and improving lifelong learning channels for the visually impaired is of great significance. Their written braille homework or exam papers cannot be understood by sighted teachers, because of the lack of a highly accurate braille translation system, especially in Chinese which has tone marks. braille writers often omit tone marks to save space, leading to confusion when braille with the same consonants and vowels is translated into Chinese. Previous algorithms were insufficient in extracting contextual information, resulting in low accuracy of braille translations into Chinese. This project informatively fine-tuned the mT5 model with an Encoder-decoder architecture for braille to Chinese character conversion. This research created a training set of braille and corresponding Chinese text from the Leipzig Corpora. This project significantly reduced the confusion in braille, achieving $62.4$ and $62.3$ BLEU scores in the validation and test sets, with a curriculum learning fine-tuning method. By incorporating the braille recognition algorithm, this project is the first publicly available braille translation system and can benefit lots of visually impaired students and families who are preparing for the Chinese College Test and help to propel their college dreams in the future. There is a demo on our homepage\\footnote{\\url{https://vision-braille.com/}}.","sentences":["Visually impaired people are a large group who can only use braille for reading and writing.","However, the lack of special educational resources is the bottleneck for educating them.","Educational equity is a reflection of the level of social civilization, cultural equality, and individual dignity.","Facilitating and improving lifelong learning channels for the visually impaired is of great significance.","Their written braille homework or exam papers cannot be understood by sighted teachers, because of the lack of a highly accurate braille translation system, especially in Chinese which has tone marks.","braille writers often omit tone marks to save space, leading to confusion when braille with the same consonants and vowels is translated into Chinese.","Previous algorithms were insufficient in extracting contextual information, resulting in low accuracy of braille translations into Chinese.","This project informatively fine-tuned the mT5 model with an Encoder-decoder architecture for braille to Chinese character conversion.","This research created a training set of braille and corresponding Chinese text from the Leipzig Corpora.","This project significantly reduced the confusion in braille, achieving $62.4$ and $62.3$ BLEU scores in the validation and test sets, with a curriculum learning fine-tuning method.","By incorporating the braille recognition algorithm, this project is the first publicly available braille translation system and can benefit lots of visually impaired students and families who are preparing for the Chinese College Test and help to propel their college dreams in the future.","There is a demo on our homepage\\footnote{\\url{https://vision-braille.com/}}."],"url":"http://arxiv.org/abs/2407.06048v1"}
{"created":"2024-07-08 15:42:02","title":"OpenCIL: Benchmarking Out-of-Distribution Detection in Class-Incremental Learning","abstract":"Class incremental learning (CIL) aims to learn a model that can not only incrementally accommodate new classes, but also maintain the learned knowledge of old classes. Out-of-distribution (OOD) detection in CIL is to retain this incremental learning ability, while being able to reject unknown samples that are drawn from different distributions of the learned classes. This capability is crucial to the safety of deploying CIL models in open worlds. However, despite remarkable advancements in the respective CIL and OOD detection, there lacks a systematic and large-scale benchmark to assess the capability of advanced CIL models in detecting OOD samples. To fill this gap, in this study we design a comprehensive empirical study to establish such a benchmark, named $\\textbf{OpenCIL}$. To this end, we propose two principled frameworks for enabling four representative CIL models with 15 diverse OOD detection methods, resulting in 60 baseline models for OOD detection in CIL. The empirical evaluation is performed on two popular CIL datasets with six commonly-used OOD datasets. One key observation we find through our comprehensive evaluation is that the CIL models can be severely biased towards the OOD samples and newly added classes when they are exposed to open environments. Motivated by this, we further propose a new baseline for OOD detection in CIL, namely Bi-directional Energy Regularization ($\\textbf{BER}$), which is specially designed to mitigate these two biases in different CIL models by having energy regularization on both old and new classes. Its superior performance is justified in our experiments. All codes and datasets are open-source at $https://github.com/mala-lab/OpenCIL$.","sentences":["Class incremental learning (CIL) aims to learn a model that can not only incrementally accommodate new classes, but also maintain the learned knowledge of old classes.","Out-of-distribution (OOD) detection in CIL is to retain this incremental learning ability, while being able to reject unknown samples that are drawn from different distributions of the learned classes.","This capability is crucial to the safety of deploying CIL models in open worlds.","However, despite remarkable advancements in the respective CIL and OOD detection, there lacks a systematic and large-scale benchmark to assess the capability of advanced CIL models in detecting OOD samples.","To fill this gap, in this study we design a comprehensive empirical study to establish such a benchmark, named $\\textbf{OpenCIL}$. To this end, we propose two principled frameworks for enabling four representative CIL models with 15 diverse OOD detection methods, resulting in 60 baseline models for OOD detection in CIL.","The empirical evaluation is performed on two popular CIL datasets with six commonly-used OOD datasets.","One key observation we find through our comprehensive evaluation is that the CIL models can be severely biased towards the OOD samples and newly added classes when they are exposed to open environments.","Motivated by this, we further propose a new baseline for OOD detection in CIL, namely Bi-directional Energy Regularization ($\\textbf{BER}$), which is specially designed to mitigate these two biases in different CIL models by having energy regularization on both old and new classes.","Its superior performance is justified in our experiments.","All codes and datasets are open-source at $https://github.com/mala-lab/OpenCIL$."],"url":"http://arxiv.org/abs/2407.06045v1"}
{"created":"2024-07-08 15:40:28","title":"Test-time adaptation for geospatial point cloud semantic segmentation with distinct domain shifts","abstract":"Domain adaptation (DA) techniques help deep learning models generalize across data shifts for point cloud semantic segmentation (PCSS). Test-time adaptation (TTA) allows direct adaptation of a pre-trained model to unlabeled data during inference stage without access to source data or additional training, avoiding privacy issues and large computational resources. We address TTA for geospatial PCSS by introducing three domain shift paradigms: photogrammetric to airborne LiDAR, airborne to mobile LiDAR, and synthetic to mobile laser scanning. We propose a TTA method that progressively updates batch normalization (BN) statistics with each testing batch. Additionally, a self-supervised learning module optimizes learnable BN affine parameters. Information maximization and reliability-constrained pseudo-labeling improve prediction confidence and supply supervisory signals. Experimental results show our method improves classification accuracy by up to 20\\% mIoU, outperforming other methods. For photogrammetric (SensatUrban) to airborne (Hessigheim 3D) adaptation at the inference stage, our method achieves 59.46\\% mIoU and 85.97\\% OA without retraining or fine-turning.","sentences":["Domain adaptation (DA) techniques help deep learning models generalize across data shifts for point cloud semantic segmentation (PCSS).","Test-time adaptation (TTA) allows direct adaptation of a pre-trained model to unlabeled data during inference stage without access to source data or additional training, avoiding privacy issues and large computational resources.","We address TTA for geospatial PCSS by introducing three domain shift paradigms: photogrammetric to airborne LiDAR, airborne to mobile LiDAR, and synthetic to mobile laser scanning.","We propose a TTA method that progressively updates batch normalization (BN) statistics with each testing batch.","Additionally, a self-supervised learning module optimizes learnable BN affine parameters.","Information maximization and reliability-constrained pseudo-labeling improve prediction confidence and supply supervisory signals.","Experimental results show our method improves classification accuracy by up to 20\\% mIoU, outperforming other methods.","For photogrammetric (SensatUrban) to airborne (Hessigheim 3D) adaptation at the inference stage, our method achieves 59.46\\% mIoU and 85.97\\% OA without retraining or fine-turning."],"url":"http://arxiv.org/abs/2407.06043v1"}
{"created":"2024-07-08 15:37:51","title":"MST5 -- Multilingual Question Answering over Knowledge Graphs","abstract":"Knowledge Graph Question Answering (KGQA) simplifies querying vast amounts of knowledge stored in a graph-based model using natural language. However, the research has largely concentrated on English, putting non-English speakers at a disadvantage. Meanwhile, existing multilingual KGQA systems face challenges in achieving performance comparable to English systems, highlighting the difficulty of generating SPARQL queries from diverse languages. In this research, we propose a simplified approach to enhance multilingual KGQA systems by incorporating linguistic context and entity information directly into the processing pipeline of a language model. Unlike existing methods that rely on separate encoders for integrating auxiliary information, our strategy leverages a single, pretrained multilingual transformer-based language model to manage both the primary input and the auxiliary data. Our methodology significantly improves the language model's ability to accurately convert a natural language query into a relevant SPARQL query. It demonstrates promising results on the most recent QALD datasets, namely QALD-9-Plus and QALD-10. Furthermore, we introduce and evaluate our approach on Chinese and Japanese, thereby expanding the language diversity of the existing datasets.","sentences":["Knowledge Graph Question Answering (KGQA) simplifies querying vast amounts of knowledge stored in a graph-based model using natural language.","However, the research has largely concentrated on English, putting non-English speakers at a disadvantage.","Meanwhile, existing multilingual KGQA systems face challenges in achieving performance comparable to English systems, highlighting the difficulty of generating SPARQL queries from diverse languages.","In this research, we propose a simplified approach to enhance multilingual KGQA systems by incorporating linguistic context and entity information directly into the processing pipeline of a language model.","Unlike existing methods that rely on separate encoders for integrating auxiliary information, our strategy leverages a single, pretrained multilingual transformer-based language model to manage both the primary input and the auxiliary data.","Our methodology significantly improves the language model's ability to accurately convert a natural language query into a relevant SPARQL query.","It demonstrates promising results on the most recent QALD datasets, namely QALD-9-Plus and QALD-10.","Furthermore, we introduce and evaluate our approach on Chinese and Japanese, thereby expanding the language diversity of the existing datasets."],"url":"http://arxiv.org/abs/2407.06041v1"}
{"created":"2024-07-08 15:36:30","title":"Enabling Performant and Secure EDA as a Service in Public Clouds Using Confidential Containers","abstract":"Increasingly, business opportunities available to fabless design teams in the semiconductor industry far exceed those addressable with on-prem compute resources. An attractive option to capture these electronic design automation (EDA) design opportunities is through public cloud bursting. However, security concerns with public cloud bursting arise from having to protect process design kits, third party intellectual property, and new design data for semiconductor devices and chips. One way to address security concerns for public cloud bursting is to leverage confidential containers for EDA workloads. Confidential containers add zero trust computing elements to significantly reduce the probability of intellectual property escapes. A key concern that often follows security discussions is whether EDA workload performance will suffer with confidential computing. In this work we demonstrate a full set of EDA confidential containers and their deployment and characterize performance impacts of confidential elements of the flow including storage and networking. A complete end-to-end confidential container-based EDA workload exhibits 7.13% and 2.05% performance overheads over bare-metal container and VM based solutions, respectively.","sentences":["Increasingly, business opportunities available to fabless design teams in the semiconductor industry far exceed those addressable with on-prem compute resources.","An attractive option to capture these electronic design automation (EDA) design opportunities is through public cloud bursting.","However, security concerns with public cloud bursting arise from having to protect process design kits, third party intellectual property, and new design data for semiconductor devices and chips.","One way to address security concerns for public cloud bursting is to leverage confidential containers for EDA workloads.","Confidential containers add zero trust computing elements to significantly reduce the probability of intellectual property escapes.","A key concern that often follows security discussions is whether EDA workload performance will suffer with confidential computing.","In this work we demonstrate a full set of EDA confidential containers and their deployment and characterize performance impacts of confidential elements of the flow including storage and networking.","A complete end-to-end confidential container-based EDA workload exhibits 7.13% and 2.05% performance overheads over bare-metal container and VM based solutions, respectively."],"url":"http://arxiv.org/abs/2407.06040v1"}
{"created":"2024-07-08 15:31:20","title":"Kratos: An FPGA Benchmark for Unrolled DNNs with Fine-Grained Sparsity and Mixed Precision","abstract":"FPGAs offer a flexible platform for accelerating deep neural network (DNN) inference, particularly for non-uniform workloads featuring fine-grained unstructured sparsity and mixed arithmetic precision. To leverage these redundancies, an emerging approach involves partially or fully unrolling computations for each DNN layer. That way, parameter-level and bit-level ineffectual operations can be completely skipped, thus saving the associated area and power. Regardless, unrolled implementations scale poorly and limit the size of a DNN that can be unrolled on an FPGA. This motivates the investigation of new reconfigurable architectures to improve the efficiency of unrolled DNNs, while taking advantage of sparsity and mixed precision. To enable this, we present Kratos: a focused FPGA benchmark of unrolled DNN primitives with varying levels of sparsity and different arithmetic precisions. Our analysis reveals that unrolled DNNs can operate at very high frequencies, reaching the maximum frequency limit of an Arria 10 device. Additionally, we found that substantial area reductions can be achieved through fine-grained sparsity and low bit-width. We build on those results to tailor the FPGA fabric for unrolled DNNs through an architectural case study demonstrating $\\sim$2$\\times$ area reduction when using smaller LUT sizes within current FPGAs. This paves the way for further exploration of new programmable architectures that are purpose-built for sparse and low-precision unrolled DNNs. Our source code and benchmark are available on github.com/abdelfattah-lab/Kratos-benchmark.","sentences":["FPGAs offer a flexible platform for accelerating deep neural network (DNN) inference, particularly for non-uniform workloads featuring fine-grained unstructured sparsity and mixed arithmetic precision.","To leverage these redundancies, an emerging approach involves partially or fully unrolling computations for each DNN layer.","That way, parameter-level and bit-level ineffectual operations can be completely skipped, thus saving the associated area and power.","Regardless, unrolled implementations scale poorly and limit the size of a DNN that can be unrolled on an FPGA.","This motivates the investigation of new reconfigurable architectures to improve the efficiency of unrolled DNNs, while taking advantage of sparsity and mixed precision.","To enable this, we present Kratos: a focused FPGA benchmark of unrolled DNN primitives with varying levels of sparsity and different arithmetic precisions.","Our analysis reveals that unrolled DNNs can operate at very high frequencies, reaching the maximum frequency limit of an Arria 10 device.","Additionally, we found that substantial area reductions can be achieved through fine-grained sparsity and low bit-width.","We build on those results to tailor the FPGA fabric for unrolled DNNs through an architectural case study demonstrating $\\sim$2$\\times$ area reduction when using smaller LUT sizes within current FPGAs.","This paves the way for further exploration of new programmable architectures that are purpose-built for sparse and low-precision unrolled DNNs.","Our source code and benchmark are available on github.com/abdelfattah-lab/Kratos-benchmark."],"url":"http://arxiv.org/abs/2407.06033v1"}
{"created":"2024-07-08 15:25:33","title":"PAS: Data-Efficient Plug-and-Play Prompt Augmentation System","abstract":"In recent years, the rise of Large Language Models (LLMs) has spurred a growing demand for plug-and-play AI systems. Among the various AI techniques, prompt engineering stands out as particularly significant. However, users often face challenges in writing prompts due to the steep learning curve and significant time investment, and existing automatic prompt engineering (APE) models can be difficult to use. To address this issue, we propose PAS, an LLM-based plug-and-play APE system. PAS utilizes LLMs trained on high-quality, automatically generated prompt complementary datasets, resulting in exceptional performance. In comprehensive benchmarks, PAS achieves state-of-the-art (SoTA) results compared to previous APE models, with an average improvement of 6.09 points. Moreover, PAS is highly efficient, achieving SoTA performance with only 9000 data points. Additionally, PAS can autonomously generate prompt augmentation data without requiring additional human labor. Its flexibility also allows it to be compatible with all existing LLMs and applicable to a wide range of tasks. PAS excels in human evaluations, underscoring its suitability as a plug-in for users. This combination of high performance, efficiency, and flexibility makes PAS a valuable system for enhancing the usability and effectiveness of LLMs through improved prompt engineering.","sentences":["In recent years, the rise of Large Language Models (LLMs) has spurred a growing demand for plug-and-play AI systems.","Among the various AI techniques, prompt engineering stands out as particularly significant.","However, users often face challenges in writing prompts due to the steep learning curve and significant time investment, and existing automatic prompt engineering (APE) models can be difficult to use.","To address this issue, we propose PAS, an LLM-based plug-and-play APE system.","PAS utilizes LLMs trained on high-quality, automatically generated prompt complementary datasets, resulting in exceptional performance.","In comprehensive benchmarks, PAS achieves state-of-the-art (SoTA) results compared to previous APE models, with an average improvement of 6.09 points.","Moreover, PAS is highly efficient, achieving SoTA performance with only 9000 data points.","Additionally, PAS can autonomously generate prompt augmentation data without requiring additional human labor.","Its flexibility also allows it to be compatible with all existing LLMs and applicable to a wide range of tasks.","PAS excels in human evaluations, underscoring its suitability as a plug-in for users.","This combination of high performance, efficiency, and flexibility makes PAS a valuable system for enhancing the usability and effectiveness of LLMs through improved prompt engineering."],"url":"http://arxiv.org/abs/2407.06027v1"}
{"created":"2024-07-08 15:22:49","title":"iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement","abstract":"Urban congestion remains a critical challenge, with traffic signal control (TSC) emerging as a potent solution. TSC is often modeled as a Markov Decision Process problem and then solved using reinforcement learning (RL), which has proven effective. However, the existing RL-based TSC system often overlooks imperfect observations caused by degraded communication, such as packet loss, delays, and noise, as well as rare real-life events not included in the reward function, such as unconsidered emergency vehicles. To address these limitations, we introduce a novel integration framework that combines a large language model (LLM) with RL. This framework is designed to manage overlooked elements in the reward function and gaps in state information, thereby enhancing the policies of RL agents. In our approach, RL initially makes decisions based on observed data. Subsequently, LLMs evaluate these decisions to verify their reasonableness. If a decision is found to be unreasonable, it is adjusted accordingly. Additionally, this integration approach can be seamlessly integrated with existing RL-based TSC systems without necessitating modifications. Extensive testing confirms that our approach reduces the average waiting time by $17.5\\%$ in degraded communication conditions as compared to traditional RL methods, underscoring its potential to advance practical RL applications in intelligent transportation systems. The related code can be found at \\url{https://github.com/Traffic-Alpha/iLLM-TSC}.","sentences":["Urban congestion remains a critical challenge, with traffic signal control (TSC) emerging as a potent solution.","TSC is often modeled as a Markov Decision Process problem and then solved using reinforcement learning (RL), which has proven effective.","However, the existing RL-based TSC system often overlooks imperfect observations caused by degraded communication, such as packet loss, delays, and noise, as well as rare real-life events not included in the reward function, such as unconsidered emergency vehicles.","To address these limitations, we introduce a novel integration framework that combines a large language model (LLM) with RL.","This framework is designed to manage overlooked elements in the reward function and gaps in state information, thereby enhancing the policies of RL agents.","In our approach, RL initially makes decisions based on observed data.","Subsequently, LLMs evaluate these decisions to verify their reasonableness.","If a decision is found to be unreasonable, it is adjusted accordingly.","Additionally, this integration approach can be seamlessly integrated with existing RL-based TSC systems without necessitating modifications.","Extensive testing confirms that our approach reduces the average waiting time by $17.5\\%$ in degraded communication conditions as compared to traditional RL methods, underscoring its potential to advance practical RL applications in intelligent transportation systems.","The related code can be found at \\url{https://github.com/Traffic-Alpha/iLLM-TSC}."],"url":"http://arxiv.org/abs/2407.06025v1"}
{"created":"2024-07-08 15:17:46","title":"Distilling System 2 into System 1","abstract":"Large language models (LLMs) can spend extra compute during inference to generate intermediate thoughts, which helps to produce better final responses. Since Chain-of-Thought (Wei et al., 2022), many such System 2 techniques have been proposed such as Rephrase and Respond (Deng et al., 2023a), System 2 Attention (Weston and Sukhbaatar, 2023) and Branch-Solve-Merge (Saha et al., 2023). In this work we investigate self-supervised methods to ``compile'' (distill) higher quality outputs from System 2 techniques back into LLM generations without intermediate reasoning token sequences, as this reasoning has been distilled into System 1. We show that several such techniques can be successfully distilled, resulting in improved results compared to the original System 1 performance, and with less inference cost than System 2. We posit that such System 2 distillation will be an important feature of future continually learning AI systems, enabling them to focus System 2 capabilities on the reasoning tasks that they cannot yet do well.","sentences":["Large language models (LLMs) can spend extra compute during inference to generate intermediate thoughts, which helps to produce better final responses.","Since Chain-of-Thought (Wei et al., 2022), many such System 2 techniques have been proposed such as Rephrase and Respond (Deng et al., 2023a), System 2 Attention (Weston and Sukhbaatar, 2023) and Branch-Solve-Merge (Saha et al., 2023).","In this work we investigate self-supervised methods to ``compile'' (distill) higher quality outputs from System 2 techniques back into LLM generations without intermediate reasoning token sequences, as this reasoning has been distilled into System 1.","We show that several such techniques can be successfully distilled, resulting in improved results compared to the original System 1 performance, and with less inference cost than System 2.","We posit that such System 2 distillation will be an important feature of future continually learning AI systems, enabling them to focus System 2 capabilities on the reasoning tasks that they cannot yet do well."],"url":"http://arxiv.org/abs/2407.06023v1"}
{"created":"2024-07-08 15:08:41","title":"Leveraging Transformers for Weakly Supervised Object Localization in Unconstrained Videos","abstract":"Weakly-Supervised Video Object Localization (WSVOL) involves localizing an object in videos using only video-level labels, also referred to as tags. State-of-the-art WSVOL methods like Temporal CAM (TCAM) rely on class activation mapping (CAM) and typically require a pre-trained CNN classifier. However, their localization accuracy is affected by their tendency to minimize the mutual information between different instances of a class and exploit temporal information during training for downstream tasks, e.g., detection and tracking. In the absence of bounding box annotation, it is challenging to exploit precise information about objects from temporal cues because the model struggles to locate objects over time. To address these issues, a novel method called transformer based CAM for videos (TrCAM-V), is proposed for WSVOL. It consists of a DeiT backbone with two heads for classification and localization. The classification head is trained using standard classification loss (CL), while the localization head is trained using pseudo-labels that are extracted using a pre-trained CLIP model. From these pseudo-labels, the high and low activation values are considered to be foreground and background regions, respectively. Our TrCAM-V method allows training a localization network by sampling pseudo-pixels on the fly from these regions. Additionally, a conditional random field (CRF) loss is employed to align the object boundaries with the foreground map. During inference, the model can process individual frames for real-time localization applications. Extensive experiments on challenging YouTube-Objects unconstrained video datasets show that our TrCAM-V method achieves new state-of-the-art performance in terms of classification and localization accuracy.","sentences":["Weakly-Supervised Video Object Localization (WSVOL) involves localizing an object in videos using only video-level labels, also referred to as tags.","State-of-the-art WSVOL methods like Temporal CAM (TCAM) rely on class activation mapping (CAM) and typically require a pre-trained CNN classifier.","However, their localization accuracy is affected by their tendency to minimize the mutual information between different instances of a class and exploit temporal information during training for downstream tasks, e.g., detection and tracking.","In the absence of bounding box annotation, it is challenging to exploit precise information about objects from temporal cues because the model struggles to locate objects over time.","To address these issues, a novel method called transformer based CAM for videos (TrCAM-V), is proposed for WSVOL.","It consists of a DeiT backbone with two heads for classification and localization.","The classification head is trained using standard classification loss (CL), while the localization head is trained using pseudo-labels that are extracted using a pre-trained CLIP model.","From these pseudo-labels, the high and low activation values are considered to be foreground and background regions, respectively.","Our TrCAM-V method allows training a localization network by sampling pseudo-pixels on the fly from these regions.","Additionally, a conditional random field (CRF) loss is employed to align the object boundaries with the foreground map.","During inference, the model can process individual frames for real-time localization applications.","Extensive experiments on challenging YouTube-Objects unconstrained video datasets show that our TrCAM-V method achieves new state-of-the-art performance in terms of classification and localization accuracy."],"url":"http://arxiv.org/abs/2407.06018v1"}
{"created":"2024-07-08 15:07:09","title":"RHRSegNet: Relighting High-Resolution Night-Time Semantic Segmentation","abstract":"Night time semantic segmentation is a crucial task in computer vision, focusing on accurately classifying and segmenting objects in low-light conditions. Unlike daytime techniques, which often perform worse in nighttime scenes, it is essential for autonomous driving due to insufficient lighting, low illumination, dynamic lighting, shadow effects, and reduced contrast. We propose RHRSegNet, implementing a relighting model over a High-Resolution Network for semantic segmentation. RHRSegNet implements residual convolutional feature learning to handle complex lighting conditions. Our model then feeds the lightened scene feature maps into a high-resolution network for scene segmentation. The network consists of a convolutional producing feature maps with varying resolutions, achieving different levels of resolution through down-sampling and up-sampling. Large nighttime datasets are used for training and evaluation, such as NightCity, City-Scape, and Dark-Zurich datasets. Our proposed model increases the HRnet segmentation performance by 5% in low-light or nighttime images.","sentences":["Night time semantic segmentation is a crucial task in computer vision, focusing on accurately classifying and segmenting objects in low-light conditions.","Unlike daytime techniques, which often perform worse in nighttime scenes, it is essential for autonomous driving due to insufficient lighting, low illumination, dynamic lighting, shadow effects, and reduced contrast.","We propose RHRSegNet, implementing a relighting model over a High-Resolution Network for semantic segmentation.","RHRSegNet implements residual convolutional feature learning to handle complex lighting conditions.","Our model then feeds the lightened scene feature maps into a high-resolution network for scene segmentation.","The network consists of a convolutional producing feature maps with varying resolutions, achieving different levels of resolution through down-sampling and up-sampling.","Large nighttime datasets are used for training and evaluation, such as NightCity, City-Scape, and Dark-Zurich datasets.","Our proposed model increases the HRnet segmentation performance by 5% in low-light or nighttime images."],"url":"http://arxiv.org/abs/2407.06016v1"}
{"created":"2024-07-08 15:05:59","title":"Evaluating Predictive Models in Cybersecurity: A Comparative Analysis of Machine and Deep Learning Techniques for Threat Detection","abstract":"As these attacks become more and more difficult to see, the need for the great hi-tech models that detect them is undeniable. This paper examines and compares various machine learning as well as deep learning models to choose the most suitable ones for detecting and fighting against cybersecurity risks. The two datasets are used in the study to assess models like Naive Bayes, SVM, Random Forest, and deep learning architectures, i.e., VGG16, in the context of accuracy, precision, recall, and F1-score. Analysis shows that Random Forest and Extra Trees do better in terms of accuracy though in different aspects of the dataset characteristics and types of threat. This research not only emphasizes the strengths and weaknesses of each predictive model but also addresses the difficulties associated with deploying such technologies in the real-world environment, such as data dependency and computational demands. The research findings are targeted at cybersecurity professionals to help them select appropriate predictive models and configure them to strengthen the security measures against cyber threats completely.","sentences":["As these attacks become more and more difficult to see, the need for the great hi-tech models that detect them is undeniable.","This paper examines and compares various machine learning as well as deep learning models to choose the most suitable ones for detecting and fighting against cybersecurity risks.","The two datasets are used in the study to assess models like Naive Bayes, SVM, Random Forest, and deep learning architectures, i.e., VGG16, in the context of accuracy, precision, recall, and F1-score.","Analysis shows that Random Forest and Extra Trees do better in terms of accuracy though in different aspects of the dataset characteristics and types of threat.","This research not only emphasizes the strengths and weaknesses of each predictive model but also addresses the difficulties associated with deploying such technologies in the real-world environment, such as data dependency and computational demands.","The research findings are targeted at cybersecurity professionals to help them select appropriate predictive models and configure them to strengthen the security measures against cyber threats completely."],"url":"http://arxiv.org/abs/2407.06014v1"}
{"created":"2024-07-08 15:05:53","title":"Revisit the Arimoto-Blahut algorithm: New Analysis with Approximation","abstract":"By the seminal paper of Claude Shannon \\cite{Shannon48}, the computation of the capacity of a discrete memoryless channel has been considered as one of the most important and fundamental problems in Information Theory. Nearly 50 years ago, Arimoto and Blahut independently proposed identical algorithms to solve this problem in their seminal papers \\cite{Arimoto1972AnAF, Blahut1972ComputationOC}. The Arimoto-Blahut algorithm was proven to converge to the capacity of the channel as $t \\to \\infty$ with the convergence rate upper bounded by $O\\left(\\log(m)/t\\right)$, where $m$ is the size of the input distribution, and being inverse exponential when there is a unique solution in the interior of the input probability simplex \\cite{Arimoto1972AnAF}. Recently it was proved, in \\cite{Nakagawa2020AnalysisOT}, that the convergence rate is at worst inverse linear $O(1/t)$ in some specific cases.   In this paper, we revisit this fundamental algorithm looking at the rate of convergence to the capacity and the time complexity, given $m,n$, where $n$ is size of the output of the channel, focusing on the approximation of the capacity. We prove that the rate of convergence to an $\\varepsilon$-optimal solution, for any constant $\\varepsilon > 0$, is inverse exponential $O\\left(\\log(m)/c^t\\right)$, for a constant $c > 1$ and $O\\left(\\log \\left(\\log (m)/\\varepsilon\\right)\\right)$ at most iterations, implying $O\\left(m n\\log \\left(\\log (m)/\\varepsilon\\right)\\right)$ total complexity of the algorithm.","sentences":["By the seminal paper of Claude Shannon \\cite{Shannon48}, the computation of the capacity of a discrete memoryless channel has been considered as one of the most important and fundamental problems in Information Theory.","Nearly 50 years ago, Arimoto and Blahut independently proposed identical algorithms to solve this problem in their seminal papers \\cite{Arimoto1972AnAF, Blahut1972ComputationOC}.","The Arimoto-Blahut algorithm was proven to converge to the capacity of the channel as $t \\to \\infty$ with the convergence rate upper bounded by $O\\left(\\log(m)/t\\right)$, where $m$ is the size of the input distribution, and being inverse exponential when there is a unique solution in the interior of the input probability simplex \\cite{Arimoto1972AnAF}.","Recently it was proved, in \\cite{Nakagawa2020AnalysisOT}, that the convergence rate is at worst inverse linear $O(1/t)$ in some specific cases.   ","In this paper, we revisit this fundamental algorithm looking at the rate of convergence to the capacity and the time complexity, given $m,n$, where $n$ is size of the output of the channel, focusing on the approximation of the capacity.","We prove that the rate of convergence to an $\\varepsilon$-optimal solution, for any constant $\\varepsilon > 0$, is inverse exponential $O\\left(\\log(m)/c^t\\right)$, for a constant $c > 1$ and $O\\left(\\log \\left(\\log (m)/\\varepsilon\\right)\\right)$ at most iterations, implying $O\\left(m n\\log \\left(\\log (m)/\\varepsilon\\right)\\right)$ total complexity of the algorithm."],"url":"http://arxiv.org/abs/2407.06013v1"}
{"created":"2024-07-08 15:04:21","title":"Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian","abstract":"The development of domain-specific language models has significantly advanced natural language processing applications in various specialized fields, particularly in biomedicine. However, the focus has largely been on English-language models, leaving a gap for less-resourced languages such as Italian. This paper introduces Igea, the first decoder-only language model designed explicitly for biomedical text generation in Italian. Built on the Minerva model and continually pretrained on a diverse corpus of Italian medical texts, Igea is available in three model sizes: 350 million, 1 billion, and 3 billion parameters. The models aim to balance computational efficiency and performance, addressing the challenges of managing the peculiarities of medical terminology in Italian. We evaluate Igea using a mix of in-domain biomedical corpora and general-purpose benchmarks, highlighting its efficacy and retention of general knowledge even after the domain-specific training. This paper discusses the model's development and evaluation, providing a foundation for future advancements in Italian biomedical NLP.","sentences":["The development of domain-specific language models has significantly advanced natural language processing applications in various specialized fields, particularly in biomedicine.","However, the focus has largely been on English-language models, leaving a gap for less-resourced languages such as Italian.","This paper introduces Igea, the first decoder-only language model designed explicitly for biomedical text generation in Italian.","Built on the Minerva model and continually pretrained on a diverse corpus of Italian medical texts, Igea is available in three model sizes: 350 million, 1 billion, and 3 billion parameters.","The models aim to balance computational efficiency and performance, addressing the challenges of managing the peculiarities of medical terminology in Italian.","We evaluate Igea using a mix of in-domain biomedical corpora and general-purpose benchmarks, highlighting its efficacy and retention of general knowledge even after the domain-specific training.","This paper discusses the model's development and evaluation, providing a foundation for future advancements in Italian biomedical NLP."],"url":"http://arxiv.org/abs/2407.06011v1"}
{"created":"2024-07-08 14:59:10","title":"Advancing Automated Deception Detection: A Multimodal Approach to Feature Extraction and Analysis","abstract":"With the exponential increase in video content, the need for accurate deception detection in human-centric video analysis has become paramount. This research focuses on the extraction and combination of various features to enhance the accuracy of deception detection models. By systematically extracting features from visual, audio, and text data, and experimenting with different combinations, we developed a robust model that achieved an impressive 99% accuracy. Our methodology emphasizes the significance of feature engineering in deception detection, providing a clear and interpretable framework. We trained various machine learning models, including LSTM, BiLSTM, and pre-trained CNNs, using both single and multi-modal approaches. The results demonstrated that combining multiple modalities significantly enhances detection performance compared to single modality training. This study highlights the potential of strategic feature extraction and combination in developing reliable and transparent automated deception detection systems in video analysis, paving the way for more advanced and accurate detection methodologies in future research.","sentences":["With the exponential increase in video content, the need for accurate deception detection in human-centric video analysis has become paramount.","This research focuses on the extraction and combination of various features to enhance the accuracy of deception detection models.","By systematically extracting features from visual, audio, and text data, and experimenting with different combinations, we developed a robust model that achieved an impressive 99% accuracy.","Our methodology emphasizes the significance of feature engineering in deception detection, providing a clear and interpretable framework.","We trained various machine learning models, including LSTM, BiLSTM, and pre-trained CNNs, using both single and multi-modal approaches.","The results demonstrated that combining multiple modalities significantly enhances detection performance compared to single modality training.","This study highlights the potential of strategic feature extraction and combination in developing reliable and transparent automated deception detection systems in video analysis, paving the way for more advanced and accurate detection methodologies in future research."],"url":"http://arxiv.org/abs/2407.06005v1"}
{"created":"2024-07-08 14:58:29","title":"Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models","abstract":"While humans naturally develop theory of mind (ToM), the capability to understand other people's mental states and beliefs, state-of-the-art large language models (LLMs) underperform on simple ToM benchmarks. We posit that we can extend our understanding of LLMs' ToM abilities by evaluating key human ToM precursors -- perception inference and perception-to-belief inference -- in LLMs. We introduce two datasets, Percept-ToMi and Percept-FANToM, to evaluate these precursory inferences for ToM in LLMs by annotating characters' perceptions on ToMi and FANToM, respectively. Our evaluation of eight state-of-the-art LLMs reveals that the models generally perform well in perception inference while exhibiting limited capability in perception-to-belief inference (e.g., lack of inhibitory control). Based on these results, we present PercepToM, a novel ToM method leveraging LLMs' strong perception inference capability while supplementing their limited perception-to-belief inference. Experimental results demonstrate that PercepToM significantly enhances LLM's performance, especially in false belief scenarios.","sentences":["While humans naturally develop theory of mind (ToM), the capability to understand other people's mental states and beliefs, state-of-the-art large language models (LLMs) underperform on simple ToM benchmarks.","We posit that we can extend our understanding of LLMs' ToM abilities by evaluating key human ToM precursors -- perception inference and perception-to-belief inference -- in LLMs.","We introduce two datasets, Percept-ToMi and Percept-FANToM, to evaluate these precursory inferences for ToM in LLMs by annotating characters' perceptions on ToMi and FANToM, respectively.","Our evaluation of eight state-of-the-art LLMs reveals that the models generally perform well in perception inference while exhibiting limited capability in perception-to-belief inference (e.g., lack of inhibitory control).","Based on these results, we present PercepToM, a novel ToM method leveraging LLMs' strong perception inference capability while supplementing their limited perception-to-belief inference.","Experimental results demonstrate that PercepToM significantly enhances LLM's performance, especially in false belief scenarios."],"url":"http://arxiv.org/abs/2407.06004v1"}
{"created":"2024-07-08 14:57:02","title":"Surprising gender biases in GPT","abstract":"We present seven experiments exploring gender biases in GPT. Initially, GPT was asked to generate demographics of a potential writer of twenty phrases containing feminine stereotypes and twenty with masculine stereotypes. Results show a strong asymmetry, with stereotypically masculine sentences attributed to a female more often than vice versa. For example, the sentence \"I love playing fotbal! Im practicing with my cosin Michael\" was constantly assigned by ChatGPT to a female writer. This phenomenon likely reflects that while initiatives to integrate women in traditionally masculine roles have gained momentum, the reverse movement remains relatively underdeveloped. Subsequent experiments investigate the same issue in high-stakes moral dilemmas. GPT-4 finds it more appropriate to abuse a man to prevent a nuclear apocalypse than to abuse a woman. This bias extends to other forms of violence central to the gender parity debate (abuse), but not to those less central (torture). Moreover, this bias increases in cases of mixed-sex violence for the greater good: GPT-4 agrees with a woman using violence against a man to prevent a nuclear apocalypse but disagrees with a man using violence against a woman for the same purpose. Finally, these biases are implicit, as they do not emerge when GPT-4 is directly asked to rank moral violations. These results highlight the necessity of carefully managing inclusivity efforts to prevent unintended discrimination.","sentences":["We present seven experiments exploring gender biases in GPT.","Initially, GPT was asked to generate demographics of a potential writer of twenty phrases containing feminine stereotypes and twenty with masculine stereotypes.","Results show a strong asymmetry, with stereotypically masculine sentences attributed to a female more often than vice versa.","For example, the sentence \"I love playing fotbal!","Im practicing with my cosin Michael\" was constantly assigned by ChatGPT to a female writer.","This phenomenon likely reflects that while initiatives to integrate women in traditionally masculine roles have gained momentum, the reverse movement remains relatively underdeveloped.","Subsequent experiments investigate the same issue in high-stakes moral dilemmas.","GPT-4 finds it more appropriate to abuse a man to prevent a nuclear apocalypse than to abuse a woman.","This bias extends to other forms of violence central to the gender parity debate (abuse), but not to those less central (torture).","Moreover, this bias increases in cases of mixed-sex violence for the greater good: GPT-4 agrees with a woman using violence against a man to prevent a nuclear apocalypse but disagrees with a man using violence against a woman for the same purpose.","Finally, these biases are implicit, as they do not emerge when GPT-4 is directly asked to rank moral violations.","These results highlight the necessity of carefully managing inclusivity efforts to prevent unintended discrimination."],"url":"http://arxiv.org/abs/2407.06003v1"}
{"created":"2024-07-08 14:53:07","title":"Pseudo-triplet Guided Few-shot Composed Image Retrieval","abstract":"Composed Image Retrieval (CIR) is a challenging task that aims to retrieve the target image based on a multimodal query, i.e., a reference image and its corresponding modification text. While previous supervised or zero-shot learning paradigms all fail to strike a good trade-off between time-consuming annotation cost and retrieval performance, recent researchers introduced the task of few-shot CIR (FS-CIR) and proposed a textual inversion-based network based on pretrained CLIP model to realize it. Despite its promising performance, the approach suffers from two key limitations: insufficient multimodal query composition training and indiscriminative training triplet selection. To address these two limitations, in this work, we propose a novel two-stage pseudo triplet guided few-shot CIR scheme, dubbed PTG-FSCIR. In the first stage, we employ a masked training strategy and advanced image caption generator to construct pseudo triplets from pure image data to enable the model to acquire primary knowledge related to multimodal query composition. In the second stage, based on active learning, we design a pseudo modification text-based query-target distance metric to evaluate the challenging score for each unlabeled sample. Meanwhile, we propose a robust top range-based random sampling strategy according to the 3-$\\sigma$ rule in statistics, to sample the challenging samples for fine-tuning the pretrained model. Notably, our scheme is plug-and-play and compatible with any existing supervised CIR models. We tested our scheme across three backbones on three public datasets (i.e., FashionIQ, CIRR, and Birds-to-Words), achieving maximum improvements of 26.4%, 25.5% and 21.6% respectively, demonstrating our scheme's effectiveness.","sentences":["Composed Image Retrieval (CIR) is a challenging task that aims to retrieve the target image based on a multimodal query, i.e., a reference image and its corresponding modification text.","While previous supervised or zero-shot learning paradigms all fail to strike a good trade-off between time-consuming annotation cost and retrieval performance, recent researchers introduced the task of few-shot CIR (FS-CIR) and proposed a textual inversion-based network based on pretrained CLIP model to realize it.","Despite its promising performance, the approach suffers from two key limitations: insufficient multimodal query composition training and indiscriminative training triplet selection.","To address these two limitations, in this work, we propose a novel two-stage pseudo triplet guided few-shot CIR scheme, dubbed PTG-FSCIR.","In the first stage, we employ a masked training strategy and advanced image caption generator to construct pseudo triplets from pure image data to enable the model to acquire primary knowledge related to multimodal query composition.","In the second stage, based on active learning, we design a pseudo modification text-based query-target distance metric to evaluate the challenging score for each unlabeled sample.","Meanwhile, we propose a robust top range-based random sampling strategy according to the 3-$\\sigma$ rule in statistics, to sample the challenging samples for fine-tuning the pretrained model.","Notably, our scheme is plug-and-play and compatible with any existing supervised CIR models.","We tested our scheme across three backbones on three public datasets (i.e., FashionIQ, CIRR, and Birds-to-Words), achieving maximum improvements of 26.4%, 25.5% and 21.6% respectively, demonstrating our scheme's effectiveness."],"url":"http://arxiv.org/abs/2407.06001v1"}
{"created":"2024-07-08 14:52:03","title":"Bounding Boxes and Probabilistic Graphical Models: Video Anomaly Detection Simplified","abstract":"In this study, we formulate the task of Video Anomaly Detection as a probabilistic analysis of object bounding boxes. We hypothesize that the representation of objects via their bounding boxes only, can be sufficient to successfully identify anomalous events in a scene. The implied value of this approach is increased object anonymization, faster model training and fewer computational resources. This can particularly benefit applications within video surveillance running on edge devices such as cameras. We design our model based on human reasoning which lends itself to explaining model output in human-understandable terms. Meanwhile, the slowest model trains within less than 7 seconds on a 11th Generation Intel Core i9 Processor. While our approach constitutes a drastic reduction of problem feature space in comparison with prior art, we show that this does not result in a reduction in performance: the results we report are highly competitive on the benchmark datasets CUHK Avenue and ShanghaiTech, and significantly exceed on the latest State-of-the-Art results on StreetScene, which has so far proven to be the most challenging VAD dataset.","sentences":["In this study, we formulate the task of Video Anomaly Detection as a probabilistic analysis of object bounding boxes.","We hypothesize that the representation of objects via their bounding boxes only, can be sufficient to successfully identify anomalous events in a scene.","The implied value of this approach is increased object anonymization, faster model training and fewer computational resources.","This can particularly benefit applications within video surveillance running on edge devices such as cameras.","We design our model based on human reasoning which lends itself to explaining model output in human-understandable terms.","Meanwhile, the slowest model trains within less than 7 seconds on a 11th Generation Intel Core i9 Processor.","While our approach constitutes a drastic reduction of problem feature space in comparison with prior art, we show that this does not result in a reduction in performance: the results we report are highly competitive on the benchmark datasets CUHK Avenue and ShanghaiTech, and significantly exceed on the latest State-of-the-Art results on StreetScene, which has so far proven to be the most challenging VAD dataset."],"url":"http://arxiv.org/abs/2407.06000v1"}
{"created":"2024-07-08 14:46:44","title":"Multimodal Diffusion Transformer: Learning Versatile Behavior from Multimodal Goals","abstract":"This work introduces the Multimodal Diffusion Transformer (MDT), a novel diffusion policy framework, that excels at learning versatile behavior from multimodal goal specifications with few language annotations. MDT leverages a diffusion-based multimodal transformer backbone and two self-supervised auxiliary objectives to master long-horizon manipulation tasks based on multimodal goals. The vast majority of imitation learning methods only learn from individual goal modalities, e.g. either language or goal images. However, existing large-scale imitation learning datasets are only partially labeled with language annotations, which prohibits current methods from learning language conditioned behavior from these datasets. MDT addresses this challenge by introducing a latent goal-conditioned state representation that is simultaneously trained on multimodal goal instructions. This state representation aligns image and language based goal embeddings and encodes sufficient information to predict future states. The representation is trained via two self-supervised auxiliary objectives, enhancing the performance of the presented transformer backbone. MDT shows exceptional performance on 164 tasks provided by the challenging CALVIN and LIBERO benchmarks, including a LIBERO version that contains less than $2\\%$ language annotations. Furthermore, MDT establishes a new record on the CALVIN manipulation challenge, demonstrating an absolute performance improvement of $15\\%$ over prior state-of-the-art methods that require large-scale pretraining and contain $10\\times$ more learnable parameters. MDT shows its ability to solve long-horizon manipulation from sparsely annotated data in both simulated and real-world environments. Demonstrations and Code are available at https://intuitive-robots.github.io/mdt_policy/.","sentences":["This work introduces the Multimodal Diffusion Transformer (MDT), a novel diffusion policy framework, that excels at learning versatile behavior from multimodal goal specifications with few language annotations.","MDT leverages a diffusion-based multimodal transformer backbone and two self-supervised auxiliary objectives to master long-horizon manipulation tasks based on multimodal goals.","The vast majority of imitation learning methods only learn from individual goal modalities, e.g. either language or goal images.","However, existing large-scale imitation learning datasets are only partially labeled with language annotations, which prohibits current methods from learning language conditioned behavior from these datasets.","MDT addresses this challenge by introducing a latent goal-conditioned state representation that is simultaneously trained on multimodal goal instructions.","This state representation aligns image and language based goal embeddings and encodes sufficient information to predict future states.","The representation is trained via two self-supervised auxiliary objectives, enhancing the performance of the presented transformer backbone.","MDT shows exceptional performance on 164 tasks provided by the challenging CALVIN and LIBERO benchmarks, including a LIBERO version that contains less than $2\\%$ language annotations.","Furthermore, MDT establishes a new record on the CALVIN manipulation challenge, demonstrating an absolute performance improvement of $15\\%$ over prior state-of-the-art methods that require large-scale pretraining and contain $10\\times$ more learnable parameters.","MDT shows its ability to solve long-horizon manipulation from sparsely annotated data in both simulated and real-world environments.","Demonstrations and Code are available at https://intuitive-robots.github.io/mdt_policy/."],"url":"http://arxiv.org/abs/2407.05996v1"}
{"created":"2024-07-08 14:41:53","title":"Self-Prior Guided Mamba-UNet Networks for Medical Image Super-Resolution","abstract":"In this paper, we propose a self-prior guided Mamba-UNet network (SMamba-UNet) for medical image super-resolution. Existing methods are primarily based on convolutional neural networks (CNNs) or Transformers. CNNs-based methods fail to capture long-range dependencies, while Transformer-based approaches face heavy calculation challenges due to their quadratic computational complexity. Recently, State Space Models (SSMs) especially Mamba have emerged, capable of modeling long-range dependencies with linear computational complexity. Inspired by Mamba, our approach aims to learn the self-prior multi-scale contextual features under Mamba-UNet networks, which may help to super-resolve low-resolution medical images in an efficient way. Specifically, we obtain self-priors by perturbing the brightness inpainting of the input image during network training, which can learn detailed texture and brightness information that is beneficial for super-resolution. Furthermore, we combine Mamba with Unet network to mine global features at different levels. We also design an improved 2D-Selective-Scan (ISS2D) module to divide image features into different directional sequences to learn long-range dependencies in multiple directions, and adaptively fuse sequence information to enhance super-resolved feature representation. Both qualitative and quantitative experimental results demonstrate that our approach outperforms current state-of-the-art methods on two public medical datasets: the IXI and fastMRI.","sentences":["In this paper, we propose a self-prior guided Mamba-UNet network (SMamba-UNet) for medical image super-resolution.","Existing methods are primarily based on convolutional neural networks (CNNs) or Transformers.","CNNs-based methods fail to capture long-range dependencies, while Transformer-based approaches face heavy calculation challenges due to their quadratic computational complexity.","Recently, State Space Models (SSMs) especially Mamba have emerged, capable of modeling long-range dependencies with linear computational complexity.","Inspired by Mamba, our approach aims to learn the self-prior multi-scale contextual features under Mamba-UNet networks, which may help to super-resolve low-resolution medical images in an efficient way.","Specifically, we obtain self-priors by perturbing the brightness inpainting of the input image during network training, which can learn detailed texture and brightness information that is beneficial for super-resolution.","Furthermore, we combine Mamba with Unet network to mine global features at different levels.","We also design an improved 2D-Selective-Scan (ISS2D) module to divide image features into different directional sequences to learn long-range dependencies in multiple directions, and adaptively fuse sequence information to enhance super-resolved feature representation.","Both qualitative and quantitative experimental results demonstrate that our approach outperforms current state-of-the-art methods on two public medical datasets: the IXI and fastMRI."],"url":"http://arxiv.org/abs/2407.05993v1"}
{"created":"2024-07-08 14:36:20","title":"Multi-Texture Synthesis through Signal Responsive Neural Cellular Automata","abstract":"Neural Cellular Automata (NCA) have proven to be effective in a variety of fields, with numerous biologically inspired applications. One of the fields, in which NCAs perform well is the generation of textures, modelling global patterns from local interactions governed by uniform and coherent rules. This paper aims to enhance the usability of NCAs in texture synthesis by addressing a shortcoming of current NCA architectures for texture generation, which requires separately trained NCA for each individual texture. In this work, we train a single NCA for the evolution of multiple textures, based on individual examples. Our solution provides texture information in the state of each cell, in the form of an internally coded genomic signal, which enables the NCA to generate the expected texture. Such a neural cellular automaton not only maintains its regenerative capability but also allows for interpolation between learned textures and supports grafting techniques. This demonstrates the ability to edit generated textures and the potential for them to merge and coexist within the same automaton. We also address questions related to the influence of the genomic information and the cost function on the evolution of the NCA.","sentences":["Neural Cellular Automata (NCA) have proven to be effective in a variety of fields, with numerous biologically inspired applications.","One of the fields, in which NCAs perform well is the generation of textures, modelling global patterns from local interactions governed by uniform and coherent rules.","This paper aims to enhance the usability of NCAs in texture synthesis by addressing a shortcoming of current NCA architectures for texture generation, which requires separately trained NCA for each individual texture.","In this work, we train a single NCA for the evolution of multiple textures, based on individual examples.","Our solution provides texture information in the state of each cell, in the form of an internally coded genomic signal, which enables the NCA to generate the expected texture.","Such a neural cellular automaton not only maintains its regenerative capability but also allows for interpolation between learned textures and supports grafting techniques.","This demonstrates the ability to edit generated textures and the potential for them to merge and coexist within the same automaton.","We also address questions related to the influence of the genomic information and the cost function on the evolution of the NCA."],"url":"http://arxiv.org/abs/2407.05991v1"}
{"created":"2024-07-08 14:28:53","title":"Time-Sensitive Networking over 5G: Experimental Evaluation of a Hybrid 5G and TSN System with IEEE 802.1Qbv Traffic","abstract":"Underpinned by the IEEE 802.1 standards, Time-sensitive networking (TSN) empowers standard Ethernet to handle stringent real-time requirements of industrial networking. TSN and private 5G will co-exist in industrial systems; hence, converged operation of the two is crucial to achieving end-to-end deterministic performance. This work conducts a testbed-based evaluation of a hybrid 5G and TSN system with over-the-air transmission of scheduled real-time TSN traffic (based on IEEE 802.1Qbv standard). The main objective is to bring the dynamics of hybrid 5G and TSN deployments to spotlight. The testbed comprises off-the-shelf TSN and 5G devices and a near product-grade 5G system. The results show the impact of 802.1Qbv parameters and 5G system capabilities on end-to-end deterministic performance. The findings of this study have significance for design and optimization of 3GPP-defined bridge model (black box model) for 5G/TSN integration.","sentences":["Underpinned by the IEEE 802.1 standards, Time-sensitive networking (TSN) empowers standard Ethernet to handle stringent real-time requirements of industrial networking.","TSN and private 5G will co-exist in industrial systems; hence, converged operation of the two is crucial to achieving end-to-end deterministic performance.","This work conducts a testbed-based evaluation of a hybrid 5G and TSN system with over-the-air transmission of scheduled real-time TSN traffic (based on IEEE 802.1Qbv standard).","The main objective is to bring the dynamics of hybrid 5G and TSN deployments to spotlight.","The testbed comprises off-the-shelf TSN and 5G devices and a near product-grade 5G system.","The results show the impact of 802.1Qbv parameters and 5G system capabilities on end-to-end deterministic performance.","The findings of this study have significance for design and optimization of 3GPP-defined bridge model (black box model) for 5G/TSN integration."],"url":"http://arxiv.org/abs/2407.05989v1"}
{"created":"2024-07-08 14:26:30","title":"KidSat: satellite imagery to map childhood poverty dataset and benchmark","abstract":"Satellite imagery has emerged as an important tool to analyse demographic, health, and development indicators. While various deep learning models have been built for these tasks, each is specific to a particular problem, with few standard benchmarks available. We propose a new dataset pairing satellite imagery and high-quality survey data on child poverty to benchmark satellite feature representations. Our dataset consists of 33,608 images, each 10 km $\\times$ 10 km, from 19 countries in Eastern and Southern Africa in the time period 1997-2022. As defined by UNICEF, multidimensional child poverty covers six dimensions and it can be calculated from the face-to-face Demographic and Health Surveys (DHS) Program . As part of the benchmark, we test spatial as well as temporal generalization, by testing on unseen locations, and on data after the training years. Using our dataset we benchmark multiple models, from low-level satellite imagery models such as MOSAIKS , to deep learning foundation models, which include both generic vision models such as Self-Distillation with no Labels (DINOv2) models and specific satellite imagery models such as SatMAE. We provide open source code for building the satellite dataset, obtaining ground truth data from DHS and running various models assessed in our work.","sentences":["Satellite imagery has emerged as an important tool to analyse demographic, health, and development indicators.","While various deep learning models have been built for these tasks, each is specific to a particular problem, with few standard benchmarks available.","We propose a new dataset pairing satellite imagery and high-quality survey data on child poverty to benchmark satellite feature representations.","Our dataset consists of 33,608 images, each 10 km $\\times$ 10 km, from 19 countries in Eastern and Southern Africa in the time period 1997-2022.","As defined by UNICEF, multidimensional child poverty covers six dimensions and it can be calculated from the face-to-face Demographic and Health Surveys (DHS) Program .","As part of the benchmark, we test spatial as well as temporal generalization, by testing on unseen locations, and on data after the training years.","Using our dataset we benchmark multiple models, from low-level satellite imagery models such as MOSAIKS , to deep learning foundation models, which include both generic vision models such as Self-Distillation with no Labels (DINOv2) models and specific satellite imagery models such as SatMAE.","We provide open source code for building the satellite dataset, obtaining ground truth data from DHS and running various models assessed in our work."],"url":"http://arxiv.org/abs/2407.05986v1"}
{"created":"2024-07-08 14:25:46","title":"Towards A Comprehensive Visual Saliency Explanation Framework for AI-based Face Recognition Systems","abstract":"Over recent years, deep convolutional neural networks have significantly advanced the field of face recognition techniques for both verification and identification purposes. Despite the impressive accuracy, these neural networks are often criticized for lacking explainability. There is a growing demand for understanding the decision-making process of AI-based face recognition systems. Some studies have investigated the use of visual saliency maps as explanations, but they have predominantly focused on the specific face verification case. The discussion on more general face recognition scenarios and the corresponding evaluation methodology for these explanations have long been absent in current research. Therefore, this manuscript conceives a comprehensive explanation framework for face recognition tasks. Firstly, an exhaustive definition of visual saliency map-based explanations for AI-based face recognition systems is provided, taking into account the two most common recognition situations individually, i.e., face verification and identification. Secondly, a new model-agnostic explanation method named CorrRISE is proposed to produce saliency maps, which reveal both the similar and dissimilar regions between any given face images. Subsequently, the explanation framework conceives a new evaluation methodology that offers quantitative measurement and comparison of the performance of general visual saliency explanation methods in face recognition. Consequently, extensive experiments are carried out on multiple verification and identification scenarios. The results showcase that CorrRISE generates insightful saliency maps and demonstrates superior performance, particularly in similarity maps in comparison with the state-of-the-art explanation approaches.","sentences":["Over recent years, deep convolutional neural networks have significantly advanced the field of face recognition techniques for both verification and identification purposes.","Despite the impressive accuracy, these neural networks are often criticized for lacking explainability.","There is a growing demand for understanding the decision-making process of AI-based face recognition systems.","Some studies have investigated the use of visual saliency maps as explanations, but they have predominantly focused on the specific face verification case.","The discussion on more general face recognition scenarios and the corresponding evaluation methodology for these explanations have long been absent in current research.","Therefore, this manuscript conceives a comprehensive explanation framework for face recognition tasks.","Firstly, an exhaustive definition of visual saliency map-based explanations for AI-based face recognition systems is provided, taking into account the two most common recognition situations individually, i.e., face verification and identification.","Secondly, a new model-agnostic explanation method named CorrRISE is proposed to produce saliency maps, which reveal both the similar and dissimilar regions between any given face images.","Subsequently, the explanation framework conceives a new evaluation methodology that offers quantitative measurement and comparison of the performance of general visual saliency explanation methods in face recognition.","Consequently, extensive experiments are carried out on multiple verification and identification scenarios.","The results showcase that CorrRISE generates insightful saliency maps and demonstrates superior performance, particularly in similarity maps in comparison with the state-of-the-art explanation approaches."],"url":"http://arxiv.org/abs/2407.05983v1"}
{"created":"2024-07-08 14:25:39","title":"MTL-Split: Multi-Task Learning for Edge Devices using Split Computing","abstract":"Split Computing (SC), where a Deep Neural Network (DNN) is intelligently split with a part of it deployed on an edge device and the rest on a remote server is emerging as a promising approach. It allows the power of DNNs to be leveraged for latency-sensitive applications that do not allow the entire DNN to be deployed remotely, while not having sufficient computation bandwidth available locally. In many such embedded systems scenarios, such as those in the automotive domain, computational resource constraints also necessitate Multi-Task Learning (MTL), where the same DNN is used for multiple inference tasks instead of having dedicated DNNs for each task, which would need more computing bandwidth. However, how to partition such a multi-tasking DNN to be deployed within a SC framework has not been sufficiently studied. This paper studies this problem, and MTL-Split, our novel proposed architecture, shows encouraging results on both synthetic and real-world data. The source code is available at https://github.com/intelligolabs/MTL-Split.","sentences":["Split Computing (SC), where a Deep Neural Network (DNN) is intelligently split with a part of it deployed on an edge device and the rest on a remote server is emerging as a promising approach.","It allows the power of DNNs to be leveraged for latency-sensitive applications that do not allow the entire DNN to be deployed remotely, while not having sufficient computation bandwidth available locally.","In many such embedded systems scenarios, such as those in the automotive domain, computational resource constraints also necessitate Multi-Task Learning (MTL), where the same DNN is used for multiple inference tasks instead of having dedicated DNNs for each task, which would need more computing bandwidth.","However, how to partition such a multi-tasking DNN to be deployed within a SC framework has not been sufficiently studied.","This paper studies this problem, and MTL-Split, our novel proposed architecture, shows encouraging results on both synthetic and real-world data.","The source code is available at https://github.com/intelligolabs/MTL-Split."],"url":"http://arxiv.org/abs/2407.05982v1"}
{"created":"2024-07-08 14:22:50","title":"Towards Understanding the Bugs in Solidity Compiler","abstract":"Solidity compiler plays a key role in enabling the development of smart contract applications on Ethereum by governing the syntax of a domain-specific language called Solidity and performing compilation and optimization of Solidity code. The correctness of Solidity compiler is critical in fostering transparency, efficiency, and trust in industries reliant on smart contracts. However, like other software systems, Solidity compiler is prone to bugs, which may produce incorrect bytecodes on blockchain platforms, resulting in severe security concerns. As a domain-specific compiler for smart contracts, Solidity compiler differs from other compilers in many perspectives, posing unique challenges to detect its bugs. To understand the bugs in Solidity compiler and benefit future research, in this paper, we present the first systematic study on 533 Solidity compiler bugs. We carefully examined their characteristics (including symptoms, root causes, and distribution), and their triggering test cases. Our study leads to seven bug-revealing takeaways for Solidity compiler. Moreover, to study the limitations of Solidity compiler fuzzers and bring our findings into practical scenarios, we evaluate three Solidity compiler fuzzers on our constructed benchmark. The results show that these fuzzers are inefficient in detecting Solidity compiler bugs. The inefficiency arises from their failure to consider the interesting bug-inducing features, bug-related compilation flags, and test oracles","sentences":["Solidity compiler plays a key role in enabling the development of smart contract applications on Ethereum by governing the syntax of a domain-specific language called Solidity and performing compilation and optimization of Solidity code.","The correctness of Solidity compiler is critical in fostering transparency, efficiency, and trust in industries reliant on smart contracts.","However, like other software systems, Solidity compiler is prone to bugs, which may produce incorrect bytecodes on blockchain platforms, resulting in severe security concerns.","As a domain-specific compiler for smart contracts, Solidity compiler differs from other compilers in many perspectives, posing unique challenges to detect its bugs.","To understand the bugs in Solidity compiler and benefit future research, in this paper, we present the first systematic study on 533 Solidity compiler bugs.","We carefully examined their characteristics (including symptoms, root causes, and distribution), and their triggering test cases.","Our study leads to seven bug-revealing takeaways for Solidity compiler.","Moreover, to study the limitations of Solidity compiler fuzzers and bring our findings into practical scenarios, we evaluate three Solidity compiler fuzzers on our constructed benchmark.","The results show that these fuzzers are inefficient in detecting Solidity compiler bugs.","The inefficiency arises from their failure to consider the interesting bug-inducing features, bug-related compilation flags, and test oracles"],"url":"http://arxiv.org/abs/2407.05981v1"}
{"created":"2024-07-08 14:22:46","title":"MMIS: Multimodal Dataset for Interior Scene Visual Generation and Recognition","abstract":"We introduce MMIS, a novel dataset designed to advance MultiModal Interior Scene generation and recognition. MMIS consists of nearly 160,000 images. Each image within the dataset is accompanied by its corresponding textual description and an audio recording of that description, providing rich and diverse sources of information for scene generation and recognition. MMIS encompasses a wide range of interior spaces, capturing various styles, layouts, and furnishings. To construct this dataset, we employed careful processes involving the collection of images, the generation of textual descriptions, and corresponding speech annotations. The presented dataset contributes to research in multi-modal representation learning tasks such as image generation, retrieval, captioning, and classification.","sentences":["We introduce MMIS, a novel dataset designed to advance MultiModal Interior Scene generation and recognition.","MMIS consists of nearly 160,000 images.","Each image within the dataset is accompanied by its corresponding textual description and an audio recording of that description, providing rich and diverse sources of information for scene generation and recognition.","MMIS encompasses a wide range of interior spaces, capturing various styles, layouts, and furnishings.","To construct this dataset, we employed careful processes involving the collection of images, the generation of textual descriptions, and corresponding speech annotations.","The presented dataset contributes to research in multi-modal representation learning tasks such as image generation, retrieval, captioning, and classification."],"url":"http://arxiv.org/abs/2407.05980v1"}
{"created":"2024-07-08 14:21:45","title":"Smoothing of Headland Path Edges and Headland-to-Mainfield Lane Transitions Based on a Spatial Domain Transformation and Linear Programming","abstract":"Within the context of in-field path planning and under the assumption of nonholonomic vehicle models this paper addresses two tasks: smoothing of headland path edges and smoothing of headland-to-mainfield lane transitions. Both tasks are solved by a two-step hierarchical algorithm. The first step differs for the two tasks generating either a piecewise-affine or a Dubins reference path. The second step leverages a transformation of vehicle dynamics from the time domain into the spatial domain and linear programming. Benefits such as a hyperparameter-free objective function and spatial constraints useful for area coverage gaps avoidance and precision path planning are discussed. The method, which is a deterministic optimisation-based method, is evaluated on a real-world field solving 3 instances of the first task and 16 instances of the second task.","sentences":["Within the context of in-field path planning and under the assumption of nonholonomic vehicle models this paper addresses two tasks: smoothing of headland path edges and smoothing of headland-to-mainfield lane transitions.","Both tasks are solved by a two-step hierarchical algorithm.","The first step differs for the two tasks generating either a piecewise-affine or a Dubins reference path.","The second step leverages a transformation of vehicle dynamics from the time domain into the spatial domain and linear programming.","Benefits such as a hyperparameter-free objective function and spatial constraints useful for area coverage gaps avoidance and precision path planning are discussed.","The method, which is a deterministic optimisation-based method, is evaluated on a real-world field solving 3 instances of the first task and 16 instances of the second task."],"url":"http://arxiv.org/abs/2407.05979v1"}
{"created":"2024-07-08 14:20:05","title":"Exploring Human-LLM Conversations: Mental Models and the Originator of Toxicity","abstract":"This study explores real-world human interactions with large language models (LLMs) in diverse, unconstrained settings in contrast to most prior research focusing on ethically trimmed models like ChatGPT for specific tasks. We aim to understand the originator of toxicity. Our findings show that although LLMs are rightfully accused of providing toxic content, it is mostly demanded or at least provoked by humans who actively seek such content. Our manual analysis of hundreds of conversations judged as toxic by APIs commercial vendors, also raises questions with respect to current practices of what user requests are refused to answer. Furthermore, we conjecture based on multiple empirical indicators that humans exhibit a change of their mental model, switching from the mindset of interacting with a machine more towards interacting with a human.","sentences":["This study explores real-world human interactions with large language models (LLMs) in diverse, unconstrained settings in contrast to most prior research focusing on ethically trimmed models like ChatGPT for specific tasks.","We aim to understand the originator of toxicity.","Our findings show that although LLMs are rightfully accused of providing toxic content, it is mostly demanded or at least provoked by humans who actively seek such content.","Our manual analysis of hundreds of conversations judged as toxic by APIs commercial vendors, also raises questions with respect to current practices of what user requests are refused to answer.","Furthermore, we conjecture based on multiple empirical indicators that humans exhibit a change of their mental model, switching from the mindset of interacting with a machine more towards interacting with a human."],"url":"http://arxiv.org/abs/2407.05977v1"}
{"created":"2024-07-08 14:18:33","title":"Change-Point Detection in Industrial Data Streams based on Online Dynamic Mode Decomposition with Control","abstract":"We propose a novel change-point detection method based on online Dynamic Mode Decomposition with control (ODMDwC). Leveraging ODMDwC's ability to find and track linear approximation of a non-linear system while incorporating control effects, the proposed method dynamically adapts to its changing behavior due to aging and seasonality. This approach enables the detection of changes in spatial, temporal, and spectral patterns, providing a robust solution that preserves correspondence between the score and the extent of change in the system dynamics. We formulate a truncated version of ODMDwC and utilize higher-order time-delay embeddings to mitigate noise and extract broad-band features. Our method addresses the challenges faced in industrial settings where safety-critical systems generate non-uniform data streams while requiring timely and accurate change-point detection to protect profit and life. Our results demonstrate that this method yields intuitive and improved detection results compared to the Singular-Value-Decomposition-based method. We validate our approach using synthetic and real-world data, showing its competitiveness to other approaches on complex systems' benchmark datasets. Provided guidelines for hyperparameters selection enhance our method's practical applicability.","sentences":["We propose a novel change-point detection method based on online Dynamic Mode Decomposition with control (ODMDwC).","Leveraging ODMDwC's ability to find and track linear approximation of a non-linear system while incorporating control effects, the proposed method dynamically adapts to its changing behavior due to aging and seasonality.","This approach enables the detection of changes in spatial, temporal, and spectral patterns, providing a robust solution that preserves correspondence between the score and the extent of change in the system dynamics.","We formulate a truncated version of ODMDwC and utilize higher-order time-delay embeddings to mitigate noise and extract broad-band features.","Our method addresses the challenges faced in industrial settings where safety-critical systems generate non-uniform data streams while requiring timely and accurate change-point detection to protect profit and life.","Our results demonstrate that this method yields intuitive and improved detection results compared to the Singular-Value-Decomposition-based method.","We validate our approach using synthetic and real-world data, showing its competitiveness to other approaches on complex systems' benchmark datasets.","Provided guidelines for hyperparameters selection enhance our method's practical applicability."],"url":"http://arxiv.org/abs/2407.05976v1"}
{"created":"2024-07-08 14:18:28","title":"LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages","abstract":"Large Language Models~(LLMs) demonstrate remarkable translation capabilities in high-resource language tasks, yet their performance in low-resource languages is hindered by insufficient multilingual data during pre-training. To address this, we dedicate 35,000 A100-SXM4-80GB GPU hours in conducting extensive multilingual continual pre-training on the LLaMA series models, enabling translation support across more than 100 languages. Through a comprehensive analysis of training strategies, such as vocabulary expansion and data augmentation, we develop LLaMAX. Remarkably, without sacrificing its generalization ability, LLaMAX achieves significantly higher translation performance compared to existing open-source LLMs~(by more than 10 spBLEU points) and performs on-par with specialized translation model~(M2M-100-12B) on the Flores-101 benchmark. Extensive experiments indicate that LLaMAX can serve as a robust multilingual foundation model. The code~\\footnote{\\url{https://github.com/CONE-MT/LLaMAX/.}} and models~\\footnote{\\url{https://huggingface.co/LLaMAX/.}} are publicly available.","sentences":["Large Language Models~(LLMs) demonstrate remarkable translation capabilities in high-resource language tasks, yet their performance in low-resource languages is hindered by insufficient multilingual data during pre-training.","To address this, we dedicate 35,000 A100-SXM4-80GB GPU hours in conducting extensive multilingual continual pre-training on the LLaMA series models, enabling translation support across more than 100 languages.","Through a comprehensive analysis of training strategies, such as vocabulary expansion and data augmentation, we develop LLaMAX.","Remarkably, without sacrificing its generalization ability, LLaMAX achieves significantly higher translation performance compared to existing open-source LLMs~(by more than 10 spBLEU points) and performs on-par with specialized translation model~(M2M-100-12B) on the Flores-101 benchmark.","Extensive experiments indicate that LLaMAX can serve as a robust multilingual foundation model.","The code~\\footnote{\\url{https://github.com/CONE-MT/LLaMAX/.}} and models~\\footnote{\\url{https://huggingface.co/LLaMAX/.}} are publicly available."],"url":"http://arxiv.org/abs/2407.05975v1"}
{"created":"2024-07-08 14:16:05","title":"Active Label Refinement for Robust Training of Imbalanced Medical Image Classification Tasks in the Presence of High Label Noise","abstract":"The robustness of supervised deep learning-based medical image classification is significantly undermined by label noise. Although several methods have been proposed to enhance classification performance in the presence of noisy labels, they face some challenges: 1) a struggle with class-imbalanced datasets, leading to the frequent overlooking of minority classes as noisy samples; 2) a singular focus on maximizing performance using noisy datasets, without incorporating experts-in-the-loop for actively cleaning the noisy labels. To mitigate these challenges, we propose a two-phase approach that combines Learning with Noisy Labels (LNL) and active learning. This approach not only improves the robustness of medical image classification in the presence of noisy labels, but also iteratively improves the quality of the dataset by relabeling the important incorrect labels, under a limited annotation budget. Furthermore, we introduce a novel Variance of Gradients approach in LNL phase, which complements the loss-based sample selection by also sampling under-represented samples. Using two imbalanced noisy medical classification datasets, we demonstrate that that our proposed technique is superior to its predecessors at handling class imbalance by not misidentifying clean samples from minority classes as mostly noisy samples.","sentences":["The robustness of supervised deep learning-based medical image classification is significantly undermined by label noise.","Although several methods have been proposed to enhance classification performance in the presence of noisy labels, they face some challenges: 1) a struggle with class-imbalanced datasets, leading to the frequent overlooking of minority classes as noisy samples; 2) a singular focus on maximizing performance using noisy datasets, without incorporating experts-in-the-loop for actively cleaning the noisy labels.","To mitigate these challenges, we propose a two-phase approach that combines Learning with Noisy Labels (LNL) and active learning.","This approach not only improves the robustness of medical image classification in the presence of noisy labels, but also iteratively improves the quality of the dataset by relabeling the important incorrect labels, under a limited annotation budget.","Furthermore, we introduce a novel Variance of Gradients approach in LNL phase, which complements the loss-based sample selection by also sampling under-represented samples.","Using two imbalanced noisy medical classification datasets, we demonstrate that that our proposed technique is superior to its predecessors at handling class imbalance by not misidentifying clean samples from minority classes as mostly noisy samples."],"url":"http://arxiv.org/abs/2407.05973v1"}
{"created":"2024-07-08 14:07:26","title":"Deform-Mamba Network for MRI Super-Resolution","abstract":"In this paper, we propose a new architecture, called Deform-Mamba, for MR image super-resolution. Unlike conventional CNN or Transformer-based super-resolution approaches which encounter challenges related to the local respective field or heavy computational cost, our approach aims to effectively explore the local and global information of images. Specifically, we develop a Deform-Mamba encoder which is composed of two branches, modulated deform block and vision Mamba block. We also design a multi-view context module in the bottleneck layer to explore the multi-view contextual content. Thanks to the extracted features of the encoder, which include content-adaptive local and efficient global information, the vision Mamba decoder finally generates high-quality MR images. Moreover, we introduce a contrastive edge loss to promote the reconstruction of edge and contrast related content. Quantitative and qualitative experimental results indicate that our approach on IXI and fastMRI datasets achieves competitive performance.","sentences":["In this paper, we propose a new architecture, called Deform-Mamba, for MR image super-resolution.","Unlike conventional CNN or Transformer-based super-resolution approaches which encounter challenges related to the local respective field or heavy computational cost, our approach aims to effectively explore the local and global information of images.","Specifically, we develop a Deform-Mamba encoder which is composed of two branches, modulated deform block and vision Mamba block.","We also design a multi-view context module in the bottleneck layer to explore the multi-view contextual content.","Thanks to the extracted features of the encoder, which include content-adaptive local and efficient global information, the vision Mamba decoder finally generates high-quality MR images.","Moreover, we introduce a contrastive edge loss to promote the reconstruction of edge and contrast related content.","Quantitative and qualitative experimental results indicate that our approach on IXI and fastMRI datasets achieves competitive performance."],"url":"http://arxiv.org/abs/2407.05969v1"}
{"created":"2024-07-08 14:05:27","title":"STMR: Spiral Transformer for Hand Mesh Reconstruction","abstract":"Recent advancements in both transformer-based methods and spiral neighbor sampling techniques have greatly enhanced hand mesh reconstruction. Transformers excel in capturing complex vertex relationships, and spiral neighbor sampling is vital for utilizing topological structures. This paper ingeniously integrates spiral sampling into the Transformer architecture, enhancing its ability to leverage mesh topology for superior performance in hand mesh reconstruction, resulting in substantial accuracy boosts. STMR employs a single image encoder for model efficiency. To augment its information extraction capability, we design the multi-scale pose feature extraction (MSPFE) module, which facilitates the extraction of rich pose features, ultimately enhancing the model's performance. Moreover, the proposed predefined pose-to-vertex lifting (PPVL) method improves vertex feature representation, further boosting reconstruction performance. Extensive experiments on the FreiHAND dataset demonstrate the state-of-the-art performance and unparalleled inference speed of STMR compared with similar backbone methods, showcasing its efficiency and effectiveness. The code is available at https://github.com/SmallXieGithub/STMR.","sentences":["Recent advancements in both transformer-based methods and spiral neighbor sampling techniques have greatly enhanced hand mesh reconstruction.","Transformers excel in capturing complex vertex relationships, and spiral neighbor sampling is vital for utilizing topological structures.","This paper ingeniously integrates spiral sampling into the Transformer architecture, enhancing its ability to leverage mesh topology for superior performance in hand mesh reconstruction, resulting in substantial accuracy boosts.","STMR employs a single image encoder for model efficiency.","To augment its information extraction capability, we design the multi-scale pose feature extraction (MSPFE) module, which facilitates the extraction of rich pose features, ultimately enhancing the model's performance.","Moreover, the proposed predefined pose-to-vertex lifting (PPVL) method improves vertex feature representation, further boosting reconstruction performance.","Extensive experiments on the FreiHAND dataset demonstrate the state-of-the-art performance and unparalleled inference speed of STMR compared with similar backbone methods, showcasing its efficiency and effectiveness.","The code is available at https://github.com/SmallXieGithub/STMR."],"url":"http://arxiv.org/abs/2407.05967v1"}
{"created":"2024-07-08 14:05:03","title":"On Bellman equations for continuous-time policy evaluation I: discretization and approximation","abstract":"We study the problem of computing the value function from a discretely-observed trajectory of a continuous-time diffusion process. We develop a new class of algorithms based on easily implementable numerical schemes that are compatible with discrete-time reinforcement learning (RL) with function approximation. We establish high-order numerical accuracy as well as the approximation error guarantees for the proposed approach. In contrast to discrete-time RL problems where the approximation factor depends on the effective horizon, we obtain a bounded approximation factor using the underlying elliptic structures, even if the effective horizon diverges to infinity.","sentences":["We study the problem of computing the value function from a discretely-observed trajectory of a continuous-time diffusion process.","We develop a new class of algorithms based on easily implementable numerical schemes that are compatible with discrete-time reinforcement learning (RL) with function approximation.","We establish high-order numerical accuracy as well as the approximation error guarantees for the proposed approach.","In contrast to discrete-time RL problems where the approximation factor depends on the effective horizon, we obtain a bounded approximation factor using the underlying elliptic structures, even if the effective horizon diverges to infinity."],"url":"http://arxiv.org/abs/2407.05966v1"}
{"created":"2024-07-08 14:04:58","title":"T2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models","abstract":"The recent development of Sora leads to a new era in text-to-video (T2V) generation. Along with this comes the rising concern about its security risks. The generated videos may contain illegal or unethical content, and there is a lack of comprehensive quantitative understanding of their safety, posing a challenge to their reliability and practical deployment. Previous evaluations primarily focus on the quality of video generation. While some evaluations of text-to-image models have considered safety, they cover fewer aspects and do not address the unique temporal risk inherent in video generation. To bridge this research gap, we introduce T2VSafetyBench, a new benchmark designed for conducting safety-critical assessments of text-to-video models. We define 12 critical aspects of video generation safety and construct a malicious prompt dataset using LLMs and jailbreaking prompt attacks. Based on our evaluation results, we draw several important findings, including: 1) no single model excels in all aspects, with different models showing various strengths; 2) the correlation between GPT-4 assessments and manual reviews is generally high; 3) there is a trade-off between the usability and safety of text-to-video generative models. This indicates that as the field of video generation rapidly advances, safety risks are set to surge, highlighting the urgency of prioritizing video safety. We hope that T2VSafetyBench can provide insights for better understanding the safety of video generation in the era of generative AI.","sentences":["The recent development of Sora leads to a new era in text-to-video (T2V) generation.","Along with this comes the rising concern about its security risks.","The generated videos may contain illegal or unethical content, and there is a lack of comprehensive quantitative understanding of their safety, posing a challenge to their reliability and practical deployment.","Previous evaluations primarily focus on the quality of video generation.","While some evaluations of text-to-image models have considered safety, they cover fewer aspects and do not address the unique temporal risk inherent in video generation.","To bridge this research gap, we introduce T2VSafetyBench, a new benchmark designed for conducting safety-critical assessments of text-to-video models.","We define 12 critical aspects of video generation safety and construct a malicious prompt dataset using LLMs and jailbreaking prompt attacks.","Based on our evaluation results, we draw several important findings, including: 1) no single model excels in all aspects, with different models showing various strengths; 2) the correlation between GPT-4 assessments and manual reviews is generally high; 3) there is a trade-off between the usability and safety of text-to-video generative models.","This indicates that as the field of video generation rapidly advances, safety risks are set to surge, highlighting the urgency of prioritizing video safety.","We hope that T2VSafetyBench can provide insights for better understanding the safety of video generation in the era of generative AI."],"url":"http://arxiv.org/abs/2407.05965v1"}
