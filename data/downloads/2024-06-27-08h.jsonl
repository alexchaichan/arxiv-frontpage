{"created":"2024-06-26 17:59:30","title":"Towards Compositionality in Concept Learning","abstract":"Concept-based interpretability methods offer a lens into the internals of foundation models by decomposing their embeddings into high-level concepts. These concept representations are most useful when they are compositional, meaning that the individual concepts compose to explain the full sample. We show that existing unsupervised concept extraction methods find concepts which are not compositional. To automatically discover compositional concept representations, we identify two salient properties of such representations, and propose Compositional Concept Extraction (CCE) for finding concepts which obey these properties. We evaluate CCE on five different datasets over image and text data. Our evaluation shows that CCE finds more compositional concept representations than baselines and yields better accuracy on four downstream classification tasks. Code and data are available at https://github.com/adaminsky/compositional_concepts .","sentences":["Concept-based interpretability methods offer a lens into the internals of foundation models by decomposing their embeddings into high-level concepts.","These concept representations are most useful when they are compositional, meaning that the individual concepts compose to explain the full sample.","We show that existing unsupervised concept extraction methods find concepts which are not compositional.","To automatically discover compositional concept representations, we identify two salient properties of such representations, and propose Compositional Concept Extraction (CCE) for finding concepts which obey these properties.","We evaluate CCE on five different datasets over image and text data.","Our evaluation shows that CCE finds more compositional concept representations than baselines and yields better accuracy on four downstream classification tasks.","Code and data are available at https://github.com/adaminsky/compositional_concepts ."],"url":"http://arxiv.org/abs/2406.18534v1"}
{"created":"2024-06-26 17:59:28","title":"On Scaling Up 3D Gaussian Splatting Training","abstract":"3D Gaussian Splatting (3DGS) is increasingly popular for 3D reconstruction due to its superior visual quality and rendering speed. However, 3DGS training currently occurs on a single GPU, limiting its ability to handle high-resolution and large-scale 3D reconstruction tasks due to memory constraints. We introduce Grendel, a distributed system designed to partition 3DGS parameters and parallelize computation across multiple GPUs. As each Gaussian affects a small, dynamic subset of rendered pixels, Grendel employs sparse all-to-all communication to transfer the necessary Gaussians to pixel partitions and performs dynamic load balancing. Unlike existing 3DGS systems that train using one camera view image at a time, Grendel supports batched training with multiple views. We explore various optimization hyperparameter scaling strategies and find that a simple sqrt(batch size) scaling rule is highly effective. Evaluations using large-scale, high-resolution scenes show that Grendel enhances rendering quality by scaling up 3DGS parameters across multiple GPUs. On the Rubble dataset, we achieve a test PSNR of 27.28 by distributing 40.4 million Gaussians across 16 GPUs, compared to a PSNR of 26.28 using 11.2 million Gaussians on a single GPU. Grendel is an open-source project available at: https://github.com/nyu-systems/Grendel-GS","sentences":["3D Gaussian Splatting (3DGS) is increasingly popular for 3D reconstruction due to its superior visual quality and rendering speed.","However, 3DGS training currently occurs on a single GPU, limiting its ability to handle high-resolution and large-scale 3D reconstruction tasks due to memory constraints.","We introduce Grendel, a distributed system designed to partition 3DGS parameters and parallelize computation across multiple GPUs.","As each Gaussian affects a small, dynamic subset of rendered pixels, Grendel employs sparse all-to-all communication to transfer the necessary Gaussians to pixel partitions and performs dynamic load balancing.","Unlike existing 3DGS systems that train using one camera view image at a time, Grendel supports batched training with multiple views.","We explore various optimization hyperparameter scaling strategies and find that a simple sqrt(batch size) scaling rule is highly effective.","Evaluations using large-scale, high-resolution scenes show that Grendel enhances rendering quality by scaling up 3DGS parameters across multiple GPUs.","On the Rubble dataset, we achieve a test PSNR of 27.28 by distributing 40.4 million Gaussians across 16 GPUs, compared to a PSNR of 26.28 using 11.2 million Gaussians on a single GPU.","Grendel is an open-source project available at: https://github.com/nyu-systems/Grendel-GS"],"url":"http://arxiv.org/abs/2406.18533v1"}
{"created":"2024-06-26 17:59:18","title":"Symbolic Learning Enables Self-Evolving Agents","abstract":"The AI community has been exploring a pathway to artificial general intelligence (AGI) by developing \"language agents\", which are complex large language models (LLMs) pipelines involving both prompting techniques and tool usage methods. While language agents have demonstrated impressive capabilities for many real-world tasks, a fundamental limitation of current language agents research is that they are model-centric, or engineering-centric. That's to say, the progress on prompts, tools, and pipelines of language agents requires substantial manual engineering efforts from human experts rather than automatically learning from data. We believe the transition from model-centric, or engineering-centric, to data-centric, i.e., the ability of language agents to autonomously learn and evolve in environments, is the key for them to possibly achieve AGI.   In this work, we introduce agent symbolic learning, a systematic framework that enables language agents to optimize themselves on their own in a data-centric way using symbolic optimizers. Specifically, we consider agents as symbolic networks where learnable weights are defined by prompts, tools, and the way they are stacked together. Agent symbolic learning is designed to optimize the symbolic network within language agents by mimicking two fundamental algorithms in connectionist learning: back-propagation and gradient descent. Instead of dealing with numeric weights, agent symbolic learning works with natural language simulacrums of weights, loss, and gradients. We conduct proof-of-concept experiments on both standard benchmarks and complex real-world tasks and show that agent symbolic learning enables language agents to update themselves after being created and deployed in the wild, resulting in \"self-evolving agents\".","sentences":["The AI community has been exploring a pathway to artificial general intelligence (AGI) by developing \"language agents\", which are complex large language models (LLMs) pipelines involving both prompting techniques and tool usage methods.","While language agents have demonstrated impressive capabilities for many real-world tasks, a fundamental limitation of current language agents research is that they are model-centric, or engineering-centric.","That's to say, the progress on prompts, tools, and pipelines of language agents requires substantial manual engineering efforts from human experts rather than automatically learning from data.","We believe the transition from model-centric, or engineering-centric, to data-centric, i.e., the ability of language agents to autonomously learn and evolve in environments, is the key for them to possibly achieve AGI.   ","In this work, we introduce agent symbolic learning, a systematic framework that enables language agents to optimize themselves on their own in a data-centric way using symbolic optimizers.","Specifically, we consider agents as symbolic networks where learnable weights are defined by prompts, tools, and the way they are stacked together.","Agent symbolic learning is designed to optimize the symbolic network within language agents by mimicking two fundamental algorithms in connectionist learning: back-propagation and gradient descent.","Instead of dealing with numeric weights, agent symbolic learning works with natural language simulacrums of weights, loss, and gradients.","We conduct proof-of-concept experiments on both standard benchmarks and complex real-world tasks and show that agent symbolic learning enables language agents to update themselves after being created and deployed in the wild, resulting in \"self-evolving agents\"."],"url":"http://arxiv.org/abs/2406.18532v1"}
{"created":"2024-06-26 17:57:25","title":"MatchTime: Towards Automatic Soccer Game Commentary Generation","abstract":"Soccer is a globally popular sport with a vast audience, in this paper, we consider constructing an automatic soccer game commentary model to improve the audiences' viewing experience. In general, we make the following contributions: First, observing the prevalent video-text misalignment in existing datasets, we manually annotate timestamps for 49 matches, establishing a more robust benchmark for soccer game commentary generation, termed as SN-Caption-test-align; Second, we propose a multi-modal temporal alignment pipeline to automatically correct and filter the existing dataset at scale, creating a higher-quality soccer game commentary dataset for training, denoted as MatchTime; Third, based on our curated dataset, we train an automatic commentary generation model, named MatchVoice. Extensive experiments and ablation studies have demonstrated the effectiveness of our alignment pipeline, and training model on the curated datasets achieves state-of-the-art performance for commentary generation, showcasing that better alignment can lead to significant performance improvements in downstream tasks.","sentences":["Soccer is a globally popular sport with a vast audience, in this paper, we consider constructing an automatic soccer game commentary model to improve the audiences' viewing experience.","In general, we make the following contributions: First, observing the prevalent video-text misalignment in existing datasets, we manually annotate timestamps for 49 matches, establishing a more robust benchmark for soccer game commentary generation, termed as SN-Caption-test-align; Second, we propose a multi-modal temporal alignment pipeline to automatically correct and filter the existing dataset at scale, creating a higher-quality soccer game commentary dataset for training, denoted as MatchTime; Third, based on our curated dataset, we train an automatic commentary generation model, named MatchVoice.","Extensive experiments and ablation studies have demonstrated the effectiveness of our alignment pipeline, and training model on the curated datasets achieves state-of-the-art performance for commentary generation, showcasing that better alignment can lead to significant performance improvements in downstream tasks."],"url":"http://arxiv.org/abs/2406.18530v1"}
{"created":"2024-06-26 17:57:13","title":"Confident Natural Policy Gradient for Local Planning in $q_\u03c0$-realizable Constrained MDPs","abstract":"The constrained Markov decision process (CMDP) framework emerges as an important reinforcement learning approach for imposing safety or other critical objectives while maximizing cumulative reward. However, the current understanding of how to learn efficiently in a CMDP environment with a potentially infinite number of states remains under investigation, particularly when function approximation is applied to the value functions. In this paper, we address the learning problem given linear function approximation with $q_{\\pi}$-realizability, where the value functions of all policies are linearly representable with a known feature map, a setting known to be more general and challenging than other linear settings. Utilizing a local-access model, we propose a novel primal-dual algorithm that, after $\\tilde{O}(\\text{poly}(d) \\epsilon^{-3})$ queries, outputs with high probability a policy that strictly satisfies the constraints while nearly optimizing the value with respect to a reward function. Here, $d$ is the feature dimension and $\\epsilon > 0$ is a given error. The algorithm relies on a carefully crafted off-policy evaluation procedure to evaluate the policy using historical data, which informs policy updates through policy gradients and conserves samples. To our knowledge, this is the first result achieving polynomial sample complexity for CMDP in the $q_{\\pi}$-realizable setting.","sentences":["The constrained Markov decision process (CMDP) framework emerges as an important reinforcement learning approach for imposing safety or other critical objectives while maximizing cumulative reward.","However, the current understanding of how to learn efficiently in a CMDP environment with a potentially infinite number of states remains under investigation, particularly when function approximation is applied to the value functions.","In this paper, we address the learning problem given linear function approximation with $q_{\\pi}$-realizability, where the value functions of all policies are linearly representable with a known feature map, a setting known to be more general and challenging than other linear settings.","Utilizing a local-access model, we propose a novel primal-dual algorithm that, after $\\tilde{O}(\\text{poly}(d) \\epsilon^{-3})$ queries, outputs with high probability a policy that strictly satisfies the constraints while nearly optimizing the value with respect to a reward function.","Here, $d$ is the feature dimension and $\\epsilon > 0$ is a given error.","The algorithm relies on a carefully crafted off-policy evaluation procedure to evaluate the policy using historical data, which informs policy updates through policy gradients and conserves samples.","To our knowledge, this is the first result achieving polynomial sample complexity for CMDP in the $q_{\\pi}$-realizable setting."],"url":"http://arxiv.org/abs/2406.18529v1"}
{"created":"2024-06-26 17:56:29","title":"PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation","abstract":"Large language models (LLMs) have revolutionized the field of NLP. Notably, their in-context learning capabilities also enable their use as evaluation metrics for natural language generation, making them particularly advantageous in low-resource scenarios and time-restricted applications. In this work, we introduce PrExMe, a large-scale prompt exploration for metrics, where we evaluate more than 720 prompt templates for open-source LLM-based metrics on machine translation (MT) and summarization datasets, totalling over 6.6M evaluations. This extensive comparison (1) serves as a benchmark of the performance of recent open-source LLMs as metrics and (2) explores the stability and variability of different prompting strategies. We discover that, on the one hand, there are scenarios for which prompts are stable. For instance, some LLMs show idiosyncratic preferences and favor to grade generated texts with textual labels while others prefer to return numeric scores. On the other hand, the stability of prompts and model rankings can be susceptible to seemingly innocuous changes. For example, changing the requested output format from \"0 to 100\" to \"-1 to +1\" can strongly affect the rankings in our evaluation. Our study contributes to understanding the impact of different prompting approaches on LLM-based metrics for MT and summarization evaluation, highlighting the most stable prompting patterns and potential limitations.","sentences":["Large language models (LLMs) have revolutionized the field of NLP.","Notably, their in-context learning capabilities also enable their use as evaluation metrics for natural language generation, making them particularly advantageous in low-resource scenarios and time-restricted applications.","In this work, we introduce PrExMe, a large-scale prompt exploration for metrics, where we evaluate more than 720 prompt templates for open-source LLM-based metrics on machine translation (MT) and summarization datasets, totalling over 6.6M evaluations.","This extensive comparison (1) serves as a benchmark of the performance of recent open-source LLMs as metrics and (2) explores the stability and variability of different prompting strategies.","We discover that, on the one hand, there are scenarios for which prompts are stable.","For instance, some LLMs show idiosyncratic preferences and favor to grade generated texts with textual labels while others prefer to return numeric scores.","On the other hand, the stability of prompts and model rankings can be susceptible to seemingly innocuous changes.","For example, changing the requested output format from \"0 to 100\" to \"-1 to +1\" can strongly affect the rankings in our evaluation.","Our study contributes to understanding the impact of different prompting approaches on LLM-based metrics for MT and summarization evaluation, highlighting the most stable prompting patterns and potential limitations."],"url":"http://arxiv.org/abs/2406.18528v1"}
{"created":"2024-06-26 17:53:51","title":"MultiDiff: Consistent Novel View Synthesis from a Single Image","abstract":"We introduce MultiDiff, a novel approach for consistent novel view synthesis of scenes from a single RGB image. The task of synthesizing novel views from a single reference image is highly ill-posed by nature, as there exist multiple, plausible explanations for unobserved areas. To address this issue, we incorporate strong priors in form of monocular depth predictors and video-diffusion models. Monocular depth enables us to condition our model on warped reference images for the target views, increasing geometric stability. The video-diffusion prior provides a strong proxy for 3D scenes, allowing the model to learn continuous and pixel-accurate correspondences across generated images. In contrast to approaches relying on autoregressive image generation that are prone to drifts and error accumulation, MultiDiff jointly synthesizes a sequence of frames yielding high-quality and multi-view consistent results -- even for long-term scene generation with large camera movements, while reducing inference time by an order of magnitude. For additional consistency and image quality improvements, we introduce a novel, structured noise distribution. Our experimental results demonstrate that MultiDiff outperforms state-of-the-art methods on the challenging, real-world datasets RealEstate10K and ScanNet. Finally, our model naturally supports multi-view consistent editing without the need for further tuning.","sentences":["We introduce MultiDiff, a novel approach for consistent novel view synthesis of scenes from a single RGB image.","The task of synthesizing novel views from a single reference image is highly ill-posed by nature, as there exist multiple, plausible explanations for unobserved areas.","To address this issue, we incorporate strong priors in form of monocular depth predictors and video-diffusion models.","Monocular depth enables us to condition our model on warped reference images for the target views, increasing geometric stability.","The video-diffusion prior provides a strong proxy for 3D scenes, allowing the model to learn continuous and pixel-accurate correspondences across generated images.","In contrast to approaches relying on autoregressive image generation that are prone to drifts and error accumulation, MultiDiff jointly synthesizes a sequence of frames yielding high-quality and multi-view consistent results -- even for long-term scene generation with large camera movements, while reducing inference time by an order of magnitude.","For additional consistency and image quality improvements, we introduce a novel, structured noise distribution.","Our experimental results demonstrate that MultiDiff outperforms state-of-the-art methods on the challenging, real-world datasets RealEstate10K and ScanNet.","Finally, our model naturally supports multi-view consistent editing without the need for further tuning."],"url":"http://arxiv.org/abs/2406.18524v1"}
{"created":"2024-06-26 17:50:47","title":"ChronoMagic-Bench: A Benchmark for Metamorphic Evaluation of Text-to-Time-lapse Video Generation","abstract":"We propose a novel text-to-video (T2V) generation benchmark, ChronoMagic-Bench, to evaluate the temporal and metamorphic capabilities of the T2V models (e.g. Sora and Lumiere) in time-lapse video generation. In contrast to existing benchmarks that focus on the visual quality and textual relevance of generated videos, ChronoMagic-Bench focuses on the model's ability to generate time-lapse videos with significant metamorphic amplitude and temporal coherence. The benchmark probes T2V models for their physics, biology, and chemistry capabilities, in a free-form text query. For these purposes, ChronoMagic-Bench introduces 1,649 prompts and real-world videos as references, categorized into four major types of time-lapse videos: biological, human-created, meteorological, and physical phenomena, which are further divided into 75 subcategories. This categorization comprehensively evaluates the model's capacity to handle diverse and complex transformations. To accurately align human preference with the benchmark, we introduce two new automatic metrics, MTScore and CHScore, to evaluate the videos' metamorphic attributes and temporal coherence. MTScore measures the metamorphic amplitude, reflecting the degree of change over time, while CHScore assesses the temporal coherence, ensuring the generated videos maintain logical progression and continuity. Based on the ChronoMagic-Bench, we conduct comprehensive manual evaluations of ten representative T2V models, revealing their strengths and weaknesses across different categories of prompts, and providing a thorough evaluation framework that addresses current gaps in video generation research. Moreover, we create a large-scale ChronoMagic-Pro dataset, containing 460k high-quality pairs of 720p time-lapse videos and detailed captions ensuring high physical pertinence and large metamorphic amplitude.","sentences":["We propose a novel text-to-video (T2V) generation benchmark, ChronoMagic-Bench, to evaluate the temporal and metamorphic capabilities of the T2V models (e.g. Sora and Lumiere) in time-lapse video generation.","In contrast to existing benchmarks that focus on the visual quality and textual relevance of generated videos, ChronoMagic-Bench focuses on the model's ability to generate time-lapse videos with significant metamorphic amplitude and temporal coherence.","The benchmark probes T2V models for their physics, biology, and chemistry capabilities, in a free-form text query.","For these purposes, ChronoMagic-Bench introduces 1,649 prompts and real-world videos as references, categorized into four major types of time-lapse videos: biological, human-created, meteorological, and physical phenomena, which are further divided into 75 subcategories.","This categorization comprehensively evaluates the model's capacity to handle diverse and complex transformations.","To accurately align human preference with the benchmark, we introduce two new automatic metrics, MTScore and CHScore, to evaluate the videos' metamorphic attributes and temporal coherence.","MTScore measures the metamorphic amplitude, reflecting the degree of change over time, while CHScore assesses the temporal coherence, ensuring the generated videos maintain logical progression and continuity.","Based on the ChronoMagic-Bench, we conduct comprehensive manual evaluations of ten representative T2V models, revealing their strengths and weaknesses across different categories of prompts, and providing a thorough evaluation framework that addresses current gaps in video generation research.","Moreover, we create a large-scale ChronoMagic-Pro dataset, containing 460k high-quality pairs of 720p time-lapse videos and detailed captions ensuring high physical pertinence and large metamorphic amplitude."],"url":"http://arxiv.org/abs/2406.18522v1"}
{"created":"2024-06-26 17:50:11","title":"CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal LLMs","abstract":"Chart understanding plays a pivotal role when applying Multimodal Large Language Models (MLLMs) to real-world tasks such as analyzing scientific papers or financial reports. However, existing datasets often focus on oversimplified and homogeneous charts with template-based questions, leading to an over-optimistic measure of progress. We demonstrate that although open-source models can appear to outperform strong proprietary models on these benchmarks, a simple stress test with slightly different charts or questions can deteriorate performance by up to 34.5%. In this work, we propose CharXiv, a comprehensive evaluation suite involving 2,323 natural, challenging, and diverse charts from arXiv papers. CharXiv includes two types of questions: 1) descriptive questions about examining basic chart elements and 2) reasoning questions that require synthesizing information across complex visual elements in the chart. To ensure quality, all charts and questions are handpicked, curated, and verified by human experts. Our results reveal a substantial, previously underestimated gap between the reasoning skills of the strongest proprietary model (i.e., GPT-4o), which achieves 47.1% accuracy, and the strongest open-source model (i.e., InternVL Chat V1.5), which achieves 29.2%. All models lag far behind human performance of 80.5%, underscoring weaknesses in the chart understanding capabilities of existing MLLMs. We hope CharXiv facilitates future research on MLLM chart understanding by providing a more realistic and faithful measure of progress. Project page and leaderboard: https://charxiv.github.io/","sentences":["Chart understanding plays a pivotal role when applying Multimodal Large Language Models (MLLMs) to real-world tasks such as analyzing scientific papers or financial reports.","However, existing datasets often focus on oversimplified and homogeneous charts with template-based questions, leading to an over-optimistic measure of progress.","We demonstrate that although open-source models can appear to outperform strong proprietary models on these benchmarks, a simple stress test with slightly different charts or questions can deteriorate performance by up to 34.5%.","In this work, we propose CharXiv, a comprehensive evaluation suite involving 2,323 natural, challenging, and diverse charts from arXiv papers.","CharXiv includes two types of questions: 1) descriptive questions about examining basic chart elements and 2) reasoning questions that require synthesizing information across complex visual elements in the chart.","To ensure quality, all charts and questions are handpicked, curated, and verified by human experts.","Our results reveal a substantial, previously underestimated gap between the reasoning skills of the strongest proprietary model (i.e., GPT-4o), which achieves 47.1% accuracy, and the strongest open-source model (i.e., InternVL Chat V1.5), which achieves 29.2%.","All models lag far behind human performance of 80.5%, underscoring weaknesses in the chart understanding capabilities of existing MLLMs.","We hope CharXiv facilitates future research on MLLM chart understanding by providing a more realistic and faithful measure of progress.","Project page and leaderboard: https://charxiv.github.io/"],"url":"http://arxiv.org/abs/2406.18521v1"}
{"created":"2024-06-26 17:49:24","title":"Distinguishing mechanisms of social contagion from local network view","abstract":"The adoption of individual behavioural patterns is largely determined by stimuli arriving from peers via social interactions or from external sources. Based on these influences, individuals are commonly assumed to follow simple or complex adoption rules, inducing social contagion processes. In reality, multiple adoption rules may coexist even within the same social contagion process, introducing additional complexity into the spreading phenomena. Our goal is to understand whether coexisting adoption mechanisms can be distinguished from a microscopic view, at the egocentric network level, without requiring global information about the underlying network, or the unfolding spreading process. We formulate this question as a classification problem, and study it through a Bayesian likelihood approach and with random forest classifiers in various synthetic and data-driven experiments. This study offers a novel perspective on the observations of propagation processes at the egocentric level and a better understanding of landmark contagion mechanisms from a local view.","sentences":["The adoption of individual behavioural patterns is largely determined by stimuli arriving from peers via social interactions or from external sources.","Based on these influences, individuals are commonly assumed to follow simple or complex adoption rules, inducing social contagion processes.","In reality, multiple adoption rules may coexist even within the same social contagion process, introducing additional complexity into the spreading phenomena.","Our goal is to understand whether coexisting adoption mechanisms can be distinguished from a microscopic view, at the egocentric network level, without requiring global information about the underlying network, or the unfolding spreading process.","We formulate this question as a classification problem, and study it through a Bayesian likelihood approach and with random forest classifiers in various synthetic and data-driven experiments.","This study offers a novel perspective on the observations of propagation processes at the egocentric level and a better understanding of landmark contagion mechanisms from a local view."],"url":"http://arxiv.org/abs/2406.18519v1"}
{"created":"2024-06-26 17:49:11","title":"APIGen: Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets","abstract":"The advancement of function-calling agent models requires diverse, reliable, and high-quality datasets. This paper presents APIGen, an automated data generation pipeline designed to synthesize verifiable high-quality datasets for function-calling applications. We leverage APIGen and collect 3,673 executable APIs across 21 different categories to generate diverse function-calling datasets in a scalable and structured manner. Each data in our dataset is verified through three hierarchical stages: format checking, actual function executions, and semantic verification, ensuring its reliability and correctness. We demonstrate that models trained with our curated datasets, even with only 7B parameters, can achieve state-of-the-art performance on the Berkeley Function-Calling Benchmark, outperforming multiple GPT-4 models. Moreover, our 1B model achieves exceptional performance, surpassing GPT-3.5-Turbo and Claude-3 Haiku. We release a dataset containing 60,000 high-quality entries, aiming to advance the field of function-calling agent domains. The dataset is available on Huggingface: https://huggingface.co/datasets/Salesforce/xlam-function-calling-60k and the project homepage: https://apigen-pipeline.github.io/","sentences":["The advancement of function-calling agent models requires diverse, reliable, and high-quality datasets.","This paper presents APIGen, an automated data generation pipeline designed to synthesize verifiable high-quality datasets for function-calling applications.","We leverage APIGen and collect 3,673 executable APIs across 21 different categories to generate diverse function-calling datasets in a scalable and structured manner.","Each data in our dataset is verified through three hierarchical stages: format checking, actual function executions, and semantic verification, ensuring its reliability and correctness.","We demonstrate that models trained with our curated datasets, even with only 7B parameters, can achieve state-of-the-art performance on the Berkeley Function-Calling Benchmark, outperforming multiple GPT-4 models.","Moreover, our 1B model achieves exceptional performance, surpassing GPT-3.5-Turbo and Claude-3 Haiku.","We release a dataset containing 60,000 high-quality entries, aiming to advance the field of function-calling agent domains.","The dataset is available on Huggingface: https://huggingface.co/datasets/Salesforce/xlam-function-calling-60k and the project homepage: https://apigen-pipeline.github.io/"],"url":"http://arxiv.org/abs/2406.18518v1"}
{"created":"2024-06-26 17:40:30","title":"Denoising as Adaptation: Noise-Space Domain Adaptation for Image Restoration","abstract":"Although deep learning-based image restoration methods have made significant progress, they still struggle with limited generalization to real-world scenarios due to the substantial domain gap caused by training on synthetic data. Existing methods address this issue by improving data synthesis pipelines, estimating degradation kernels, employing deep internal learning, and performing domain adaptation and regularization. Previous domain adaptation methods have sought to bridge the domain gap by learning domain-invariant knowledge in either feature or pixel space. However, these techniques often struggle to extend to low-level vision tasks within a stable and compact framework. In this paper, we show that it is possible to perform domain adaptation via the noise-space using diffusion models. In particular, by leveraging the unique property of how the multi-step denoising process is influenced by auxiliary conditional inputs, we obtain meaningful gradients from noise prediction to gradually align the restored results of both synthetic and real-world data to a common clean distribution. We refer to this method as denoising as adaptation. To prevent shortcuts during training, we present useful techniques such as channel shuffling and residual-swapping contrastive learning. Experimental results on three classical image restoration tasks, namely denoising, deblurring, and deraining, demonstrate the effectiveness of the proposed method. Code will be released at: https://github.com/KangLiao929/Noise-DA/.","sentences":["Although deep learning-based image restoration methods have made significant progress, they still struggle with limited generalization to real-world scenarios due to the substantial domain gap caused by training on synthetic data.","Existing methods address this issue by improving data synthesis pipelines, estimating degradation kernels, employing deep internal learning, and performing domain adaptation and regularization.","Previous domain adaptation methods have sought to bridge the domain gap by learning domain-invariant knowledge in either feature or pixel space.","However, these techniques often struggle to extend to low-level vision tasks within a stable and compact framework.","In this paper, we show that it is possible to perform domain adaptation via the noise-space using diffusion models.","In particular, by leveraging the unique property of how the multi-step denoising process is influenced by auxiliary conditional inputs, we obtain meaningful gradients from noise prediction to gradually align the restored results of both synthetic and real-world data to a common clean distribution.","We refer to this method as denoising as adaptation.","To prevent shortcuts during training, we present useful techniques such as channel shuffling and residual-swapping contrastive learning.","Experimental results on three classical image restoration tasks, namely denoising, deblurring, and deraining, demonstrate the effectiveness of the proposed method.","Code will be released at: https://github.com/KangLiao929/Noise-DA/."],"url":"http://arxiv.org/abs/2406.18516v1"}
{"created":"2024-06-26 17:33:51","title":"\"Is ChatGPT a Better Explainer than My Professor?\": Evaluating the Explanation Capabilities of LLMs in Conversation Compared to a Human Baseline","abstract":"Explanations form the foundation of knowledge sharing and build upon communication principles, social dynamics, and learning theories. We focus specifically on conversational approaches for explanations because the context is highly adaptive and interactive. Our research leverages previous work on explanatory acts, a framework for understanding the different strategies that explainers and explainees employ in a conversation to both explain, understand, and engage with the other party. We use the 5-Levels dataset was constructed from the WIRED YouTube series by Wachsmuth et al., and later annotated by Booshehri et al. with explanatory acts. These annotations provide a framework for understanding how explainers and explainees structure their response when crafting a response.   With the rise of generative AI in the past year, we hope to better understand the capabilities of Large Language Models (LLMs) and how they can augment expert explainer's capabilities in conversational settings. To achieve this goal, the 5-Levels dataset (We use Booshehri et al.'s 2023 annotated dataset with explanatory acts.) allows us to audit the ability of LLMs in engaging in explanation dialogues. To evaluate the effectiveness of LLMs in generating explainer responses, we compared 3 different strategies, we asked human annotators to evaluate 3 different strategies: human explainer response, GPT4 standard response, GPT4 response with Explanation Moves.","sentences":["Explanations form the foundation of knowledge sharing and build upon communication principles, social dynamics, and learning theories.","We focus specifically on conversational approaches for explanations because the context is highly adaptive and interactive.","Our research leverages previous work on explanatory acts, a framework for understanding the different strategies that explainers and explainees employ in a conversation to both explain, understand, and engage with the other party.","We use the 5-Levels dataset was constructed from the WIRED YouTube series by Wachsmuth et al., and later annotated by Booshehri et al. with explanatory acts.","These annotations provide a framework for understanding how explainers and explainees structure their response when crafting a response.   ","With the rise of generative AI in the past year, we hope to better understand the capabilities of Large Language Models (LLMs) and how they can augment expert explainer's capabilities in conversational settings.","To achieve this goal, the 5-Levels dataset (We use Booshehri et al.'s 2023 annotated dataset with explanatory acts.)","allows us to audit the ability of LLMs in engaging in explanation dialogues.","To evaluate the effectiveness of LLMs in generating explainer responses, we compared 3 different strategies, we asked human annotators to evaluate 3 different strategies: human explainer response, GPT4 standard response, GPT4 response with Explanation Moves."],"url":"http://arxiv.org/abs/2406.18512v1"}
{"created":"2024-06-26 17:31:22","title":"WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models","abstract":"We introduce WildTeaming, an automatic LLM safety red-teaming framework that mines in-the-wild user-chatbot interactions to discover 5.7K unique clusters of novel jailbreak tactics, and then composes multiple tactics for systematic exploration of novel jailbreaks. Compared to prior work that performed red-teaming via recruited human workers, gradient-based optimization, or iterative revision with LLMs, our work investigates jailbreaks from chatbot users who were not specifically instructed to break the system. WildTeaming reveals previously unidentified vulnerabilities of frontier LLMs, resulting in up to 4.6x more diverse and successful adversarial attacks compared to state-of-the-art jailbreak methods.   While many datasets exist for jailbreak evaluation, very few open-source datasets exist for jailbreak training, as safety training data has been closed even when model weights are open. With WildTeaming we create WildJailbreak, a large-scale open-source synthetic safety dataset with 262K vanilla (direct request) and adversarial (complex jailbreak) prompt-response pairs. To mitigate exaggerated safety behaviors, WildJailbreak provides two contrastive types of queries: 1) harmful queries (vanilla & adversarial) and 2) benign queries that resemble harmful queries in form but contain no harm. As WildJailbreak considerably upgrades the quality and scale of existing safety resources, it uniquely enables us to examine the scaling effects of data and the interplay of data properties and model capabilities during safety training. Through extensive experiments, we identify the training properties that enable an ideal balance of safety behaviors: appropriate safeguarding without over-refusal, effective handling of vanilla and adversarial queries, and minimal, if any, decrease in general capabilities. All components of WildJailbeak contribute to achieving balanced safety behaviors of models.","sentences":["We introduce WildTeaming, an automatic LLM safety red-teaming framework that mines in-the-wild user-chatbot interactions to discover 5.7K unique clusters of novel jailbreak tactics, and then composes multiple tactics for systematic exploration of novel jailbreaks.","Compared to prior work that performed red-teaming via recruited human workers, gradient-based optimization, or iterative revision with LLMs, our work investigates jailbreaks from chatbot users who were not specifically instructed to break the system.","WildTeaming reveals previously unidentified vulnerabilities of frontier LLMs, resulting in up to 4.6x more diverse and successful adversarial attacks compared to state-of-the-art jailbreak methods.   ","While many datasets exist for jailbreak evaluation, very few open-source datasets exist for jailbreak training, as safety training data has been closed even when model weights are open.","With WildTeaming we create WildJailbreak, a large-scale open-source synthetic safety dataset with 262K vanilla (direct request) and adversarial (complex jailbreak) prompt-response pairs.","To mitigate exaggerated safety behaviors, WildJailbreak provides two contrastive types of queries: 1) harmful queries (vanilla & adversarial) and 2) benign queries that resemble harmful queries in form but contain no harm.","As WildJailbreak considerably upgrades the quality and scale of existing safety resources, it uniquely enables us to examine the scaling effects of data and the interplay of data properties and model capabilities during safety training.","Through extensive experiments, we identify the training properties that enable an ideal balance of safety behaviors: appropriate safeguarding without over-refusal, effective handling of vanilla and adversarial queries, and minimal, if any, decrease in general capabilities.","All components of WildJailbeak contribute to achieving balanced safety behaviors of models."],"url":"http://arxiv.org/abs/2406.18510v1"}
{"created":"2024-06-26 17:14:45","title":"Mental Modeling of Reinforcement Learning Agents by Language Models","abstract":"Can emergent language models faithfully model the intelligence of decision-making agents? Though modern language models exhibit already some reasoning ability, and theoretically can potentially express any probable distribution over tokens, it remains underexplored how the world knowledge these pretrained models have memorized can be utilized to comprehend an agent's behaviour in the physical world. This study empirically examines, for the first time, how well large language models (LLMs) can build a mental model of agents, termed agent mental modelling, by reasoning about an agent's behaviour and its effect on states from agent interaction history. This research may unveil the potential of leveraging LLMs for elucidating RL agent behaviour, addressing a key challenge in eXplainable reinforcement learning (XRL). To this end, we propose specific evaluation metrics and test them on selected RL task datasets of varying complexity, reporting findings on agent mental model establishment. Our results disclose that LLMs are not yet capable of fully mental modelling agents through inference alone without further innovations. This work thus provides new insights into the capabilities and limitations of modern LLMs.","sentences":["Can emergent language models faithfully model the intelligence of decision-making agents?","Though modern language models exhibit already some reasoning ability, and theoretically can potentially express any probable distribution over tokens, it remains underexplored how the world knowledge these pretrained models have memorized can be utilized to comprehend an agent's behaviour in the physical world.","This study empirically examines, for the first time, how well large language models (LLMs) can build a mental model of agents, termed agent mental modelling, by reasoning about an agent's behaviour and its effect on states from agent interaction history.","This research may unveil the potential of leveraging LLMs for elucidating RL agent behaviour, addressing a key challenge in eXplainable reinforcement learning (XRL).","To this end, we propose specific evaluation metrics and test them on selected RL task datasets of varying complexity, reporting findings on agent mental model establishment.","Our results disclose that LLMs are not yet capable of fully mental modelling agents through inference alone without further innovations.","This work thus provides new insights into the capabilities and limitations of modern LLMs."],"url":"http://arxiv.org/abs/2406.18505v1"}
{"created":"2024-06-26 17:13:10","title":"From Tweet to Theft: Tracing the Flow of Stolen Cryptocurrency","abstract":"This paper presents a case study of a cryptocurrency scam that utilized coordinated and inauthentic behavior on Twitter. In 2020, 143 accounts sold by an underground merchant were used to orchestrate a fake giveaway. Tweets pointing to a fake blog post lured victims into sending Uniswap tokens (UNI) to designated addresses on the Ethereum blockchain, with the false promise of receiving more tokens in return. Using one of the scammer's addresses and leveraging the transparency and immutability of the Ethereum blockchain, we traced the flow of stolen funds through various addresses, revealing the tactics adopted to obfuscate traceability. The final destination of the funds involved two deposit addresses. The first, managed by a well-known cryptocurrency exchange, was likely associated with the scammer's own account on that platform and saw deposits exceeding $3.5 million. The second address was linked to a popular cryptocurrency swap service. These findings highlight the critical need for more stringent measures to verify the source of funds and prevent illicit activities.","sentences":["This paper presents a case study of a cryptocurrency scam that utilized coordinated and inauthentic behavior on Twitter.","In 2020, 143 accounts sold by an underground merchant were used to orchestrate a fake giveaway.","Tweets pointing to a fake blog post lured victims into sending Uniswap tokens (UNI) to designated addresses on the Ethereum blockchain, with the false promise of receiving more tokens in return.","Using one of the scammer's addresses and leveraging the transparency and immutability of the Ethereum blockchain, we traced the flow of stolen funds through various addresses, revealing the tactics adopted to obfuscate traceability.","The final destination of the funds involved two deposit addresses.","The first, managed by a well-known cryptocurrency exchange, was likely associated with the scammer's own account on that platform and saw deposits exceeding $3.5 million.","The second address was linked to a popular cryptocurrency swap service.","These findings highlight the critical need for more stringent measures to verify the source of funds and prevent illicit activities."],"url":"http://arxiv.org/abs/2406.18503v1"}
{"created":"2024-06-26 17:06:41","title":"Is In-Context Learning a Type of Gradient-Based Learning? Evidence from the Inverse Frequency Effect in Structural Priming","abstract":"Large language models (LLMs) have shown the emergent capability of in-context learning (ICL). One line of research has explained ICL as functionally performing gradient descent. In this paper, we introduce a new way of diagnosing whether ICL is functionally equivalent to gradient-based learning. Our approach is based on the inverse frequency effect (IFE) -- a phenomenon in which an error-driven learner is expected to show larger updates when trained on infrequent examples than frequent ones. The IFE has previously been studied in psycholinguistics because humans show this effect in the context of structural priming (the tendency for people to produce sentence structures they have encountered recently); the IFE has been used as evidence that human structural priming must involve error-driven learning mechanisms. In our experiments, we simulated structural priming within ICL and found that LLMs display the IFE, with the effect being stronger in larger models. We conclude that ICL is indeed a type of gradient-based learning, supporting the hypothesis that a gradient component is implicitly computed in the forward pass during ICL. Our results suggest that both humans and LLMs make use of gradient-based, error-driven processing mechanisms.","sentences":["Large language models (LLMs) have shown the emergent capability of in-context learning (ICL).","One line of research has explained ICL as functionally performing gradient descent.","In this paper, we introduce a new way of diagnosing whether ICL is functionally equivalent to gradient-based learning.","Our approach is based on the inverse frequency effect (IFE) -- a phenomenon in which an error-driven learner is expected to show larger updates when trained on infrequent examples than frequent ones.","The IFE has previously been studied in psycholinguistics because humans show this effect in the context of structural priming (the tendency for people to produce sentence structures they have encountered recently); the IFE has been used as evidence that human structural priming must involve error-driven learning mechanisms.","In our experiments, we simulated structural priming within ICL and found that LLMs display the IFE, with the effect being stronger in larger models.","We conclude that ICL is indeed a type of gradient-based learning, supporting the hypothesis that a gradient component is implicitly computed in the forward pass during ICL.","Our results suggest that both humans and LLMs make use of gradient-based, error-driven processing mechanisms."],"url":"http://arxiv.org/abs/2406.18501v1"}
{"created":"2024-06-26 16:58:20","title":"WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs","abstract":"We introduce WildGuard -- an open, light-weight moderation tool for LLM safety that achieves three goals: (1) identifying malicious intent in user prompts, (2) detecting safety risks of model responses, and (3) determining model refusal rate. Together, WildGuard serves the increasing needs for automatic safety moderation and evaluation of LLM interactions, providing a one-stop tool with enhanced accuracy and broad coverage across 13 risk categories. While existing open moderation tools such as Llama-Guard2 score reasonably well in classifying straightforward model interactions, they lag far behind a prompted GPT-4, especially in identifying adversarial jailbreaks and in evaluating models' refusals, a key measure for evaluating safety behaviors in model responses.   To address these challenges, we construct WildGuardMix, a large-scale and carefully balanced multi-task safety moderation dataset with 92K labeled examples that cover vanilla (direct) prompts and adversarial jailbreaks, paired with various refusal and compliance responses. WildGuardMix is a combination of WildGuardTrain, the training data of WildGuard, and WildGuardTest, a high-quality human-annotated moderation test set with 5K labeled items covering broad risk scenarios. Through extensive evaluations on WildGuardTest and ten existing public benchmarks, we show that WildGuard establishes state-of-the-art performance in open-source safety moderation across all the three tasks compared to ten strong existing open-source moderation models (e.g., up to 26.4% improvement on refusal detection). Importantly, WildGuard matches and sometimes exceeds GPT-4 performance (e.g., up to 3.9% improvement on prompt harmfulness identification). WildGuard serves as a highly effective safety moderator in an LLM interface, reducing the success rate of jailbreak attacks from 79.8% to 2.4%.","sentences":["We introduce WildGuard -- an open, light-weight moderation tool for LLM safety that achieves three goals: (1) identifying malicious intent in user prompts, (2) detecting safety risks of model responses, and (3) determining model refusal rate.","Together, WildGuard serves the increasing needs for automatic safety moderation and evaluation of LLM interactions, providing a one-stop tool with enhanced accuracy and broad coverage across 13 risk categories.","While existing open moderation tools such as Llama-Guard2 score reasonably well in classifying straightforward model interactions, they lag far behind a prompted GPT-4, especially in identifying adversarial jailbreaks and in evaluating models' refusals, a key measure for evaluating safety behaviors in model responses.   ","To address these challenges, we construct WildGuardMix, a large-scale and carefully balanced multi-task safety moderation dataset with 92K labeled examples that cover vanilla (direct) prompts and adversarial jailbreaks, paired with various refusal and compliance responses.","WildGuardMix is a combination of WildGuardTrain, the training data of WildGuard, and WildGuardTest, a high-quality human-annotated moderation test set with 5K labeled items covering broad risk scenarios.","Through extensive evaluations on WildGuardTest and ten existing public benchmarks, we show that WildGuard establishes state-of-the-art performance in open-source safety moderation across all the three tasks compared to ten strong existing open-source moderation models (e.g., up to 26.4% improvement on refusal detection).","Importantly, WildGuard matches and sometimes exceeds GPT-4 performance (e.g., up to 3.9% improvement on prompt harmfulness identification).","WildGuard serves as a highly effective safety moderator in an LLM interface, reducing the success rate of jailbreak attacks from 79.8% to 2.4%."],"url":"http://arxiv.org/abs/2406.18495v1"}
{"created":"2024-06-26 16:55:07","title":"Enhancing Federated Learning with Adaptive Differential Privacy and Priority-Based Aggregation","abstract":"Federated learning (FL), a novel branch of distributed machine learning (ML), develops global models through a private procedure without direct access to local datasets. However, it is still possible to access the model updates (gradient updates of deep neural networks) transferred between clients and servers, potentially revealing sensitive local information to adversaries using model inversion attacks. Differential privacy (DP) offers a promising approach to addressing this issue by adding noise to the parameters. On the other hand, heterogeneities in data structure, storage, communication, and computational capabilities of devices can cause convergence problems and delays in developing the global model. A personalized weighted averaging of local parameters based on the resources of each device can yield a better aggregated model in each round. In this paper, to efficiently preserve privacy, we propose a personalized DP framework that injects noise based on clients' relative impact factors and aggregates parameters while considering heterogeneities and adjusting properties. To fulfill the DP requirements, we first analyze the convergence boundary of the FL algorithm when impact factors are personalized and fixed throughout the learning process. We then further study the convergence property considering time-varying (adaptive) impact factors.","sentences":["Federated learning (FL), a novel branch of distributed machine learning (ML), develops global models through a private procedure without direct access to local datasets.","However, it is still possible to access the model updates (gradient updates of deep neural networks) transferred between clients and servers, potentially revealing sensitive local information to adversaries using model inversion attacks.","Differential privacy (DP) offers a promising approach to addressing this issue by adding noise to the parameters.","On the other hand, heterogeneities in data structure, storage, communication, and computational capabilities of devices can cause convergence problems and delays in developing the global model.","A personalized weighted averaging of local parameters based on the resources of each device can yield a better aggregated model in each round.","In this paper, to efficiently preserve privacy, we propose a personalized DP framework that injects noise based on clients' relative impact factors and aggregates parameters while considering heterogeneities and adjusting properties.","To fulfill the DP requirements, we first analyze the convergence boundary of the FL algorithm when impact factors are personalized and fixed throughout the learning process.","We then further study the convergence property considering time-varying (adaptive) impact factors."],"url":"http://arxiv.org/abs/2406.18491v1"}
{"created":"2024-06-26 16:51:28","title":"LoongTrain: Efficient Training of Long-Sequence LLMs with Head-Context Parallelism","abstract":"Efficiently training LLMs with long sequences is important yet challenged by the massive computation and memory requirements. Sequence parallelism has been proposed to tackle these problems, but existing methods suffer from scalability or efficiency issues. We propose LoongTrain, a novel system to efficiently train LLMs with long sequences at scale. The core of LoongTrain is the 2D-Attention mechanism, which combines both head-parallel and context-parallel techniques to break the scalability constraints while maintaining efficiency. We introduce Double-Ring-Attention and analyze the performance of device placement strategies to further speed up training. We implement LoongTrain with the hybrid ZeRO and Selective Checkpoint++ techniques. Experiment results show that LoongTrain outperforms state-of-the-art baselines, i.e., DeepSpeed-Ulysses and Megatron Context Parallelism, in both end-to-end training speed and scalability, and improves Model FLOPs Utilization (MFU) by up to 2.88x.","sentences":["Efficiently training LLMs with long sequences is important yet challenged by the massive computation and memory requirements.","Sequence parallelism has been proposed to tackle these problems, but existing methods suffer from scalability or efficiency issues.","We propose LoongTrain, a novel system to efficiently train LLMs with long sequences at scale.","The core of LoongTrain is the 2D-Attention mechanism, which combines both head-parallel and context-parallel techniques to break the scalability constraints while maintaining efficiency.","We introduce Double-Ring-Attention and analyze the performance of device placement strategies to further speed up training.","We implement LoongTrain with the hybrid ZeRO and Selective Checkpoint++ techniques.","Experiment results show that LoongTrain outperforms state-of-the-art baselines, i.e., DeepSpeed-Ulysses and Megatron Context Parallelism, in both end-to-end training speed and scalability, and improves Model FLOPs Utilization (MFU) by up to 2.88x."],"url":"http://arxiv.org/abs/2406.18485v1"}
{"created":"2024-06-26 16:47:31","title":"Robust Surgical Phase Recognition From Annotation Efficient Supervision","abstract":"Surgical phase recognition is a key task in computer-assisted surgery, aiming to automatically identify and categorize the different phases within a surgical procedure. Despite substantial advancements, most current approaches rely on fully supervised training, requiring expensive and time-consuming frame-level annotations. Timestamp supervision has recently emerged as a promising alternative, significantly reducing annotation costs while maintaining competitive performance. However, models trained on timestamp annotations can be negatively impacted by missing phase annotations, leading to a potential drawback in real-world scenarios. In this work, we address this issue by proposing a robust method for surgical phase recognition that can handle missing phase annotations effectively. Furthermore, we introduce the SkipTag@K annotation approach to the surgical domain, enabling a flexible balance between annotation effort and model performance. Our method achieves competitive results on two challenging datasets, demonstrating its efficacy in handling missing phase annotations and its potential for reducing annotation costs. Specifically, we achieve an accuracy of 85.1\\% on the MultiBypass140 dataset using only 3 annotated frames per video, showcasing the effectiveness of our method and the potential of the SkipTag@K setup. We perform extensive experiments to validate the robustness of our method and provide valuable insights to guide future research in surgical phase recognition. Our work contributes to the advancement of surgical workflow recognition and paves the way for more efficient and reliable surgical phase recognition systems.","sentences":["Surgical phase recognition is a key task in computer-assisted surgery, aiming to automatically identify and categorize the different phases within a surgical procedure.","Despite substantial advancements, most current approaches rely on fully supervised training, requiring expensive and time-consuming frame-level annotations.","Timestamp supervision has recently emerged as a promising alternative, significantly reducing annotation costs while maintaining competitive performance.","However, models trained on timestamp annotations can be negatively impacted by missing phase annotations, leading to a potential drawback in real-world scenarios.","In this work, we address this issue by proposing a robust method for surgical phase recognition that can handle missing phase annotations effectively.","Furthermore, we introduce the SkipTag@K annotation approach to the surgical domain, enabling a flexible balance between annotation effort and model performance.","Our method achieves competitive results on two challenging datasets, demonstrating its efficacy in handling missing phase annotations and its potential for reducing annotation costs.","Specifically, we achieve an accuracy of 85.1\\% on the MultiBypass140 dataset using only 3 annotated frames per video, showcasing the effectiveness of our method and the potential of the SkipTag@K setup.","We perform extensive experiments to validate the robustness of our method and provide valuable insights to guide future research in surgical phase recognition.","Our work contributes to the advancement of surgical workflow recognition and paves the way for more efficient and reliable surgical phase recognition systems."],"url":"http://arxiv.org/abs/2406.18481v1"}
{"created":"2024-06-26 16:33:36","title":"Unveiling the connection between the Lyndon factorization and the Canonical Inverse Lyndon factorization via a border property","abstract":"The notion of Lyndon word and Lyndon factorization has shown to have unexpected applications in theory as well in developing novel algorithms on words. A counterpart to these notions are those of inverse Lyndon word and inverse Lyndon factorization. Differently from the Lyndon words, the inverse Lyndon words may be bordered. The relationship between the two factorizations is related to the inverse lexicographic ordering, and has only been recently explored. More precisely, a main open question is how to get an inverse Lyndon factorization from a classical Lyndon factorization under the inverse lexicographic ordering, named CFLin. In this paper we reveal a strong connection between these two factorizations where the border plays a relevant role. More precisely, we show two main results. We say that a factorization has the border property if a nonempty border of a factor cannot be a prefix of the next factor. First we show that there exists a unique inverse Lyndon factorization having the border property. Then we show that this unique factorization with the border property is the so-called canonical inverse Lyndon factorization, named ICFL. By showing that ICFL is obtained by compacting factors of the Lyndon factorization over the inverse lexicographic ordering, we provide a linear time algorithm for computing ICFL from CFLin.","sentences":["The notion of Lyndon word and Lyndon factorization has shown to have unexpected applications in theory as well in developing novel algorithms on words.","A counterpart to these notions are those of inverse Lyndon word and inverse Lyndon factorization.","Differently from the Lyndon words, the inverse Lyndon words may be bordered.","The relationship between the two factorizations is related to the inverse lexicographic ordering, and has only been recently explored.","More precisely, a main open question is how to get an inverse Lyndon factorization from a classical Lyndon factorization under the inverse lexicographic ordering, named CFLin.","In this paper we reveal a strong connection between these two factorizations where the border plays a relevant role.","More precisely, we show two main results.","We say that a factorization has the border property if a nonempty border of a factor cannot be a prefix of the next factor.","First we show that there exists a unique inverse Lyndon factorization having the border property.","Then we show that this unique factorization with the border property is the so-called canonical inverse Lyndon factorization, named ICFL.","By showing that ICFL is obtained by compacting factors of the Lyndon factorization over the inverse lexicographic ordering, we provide a linear time algorithm for computing ICFL from CFLin."],"url":"http://arxiv.org/abs/2406.18473v1"}
{"created":"2024-06-26 16:28:24","title":"UniRec: A Dual Enhancement of Uniformity and Frequency in Sequential Recommendations","abstract":"Representation learning in sequential recommendation is critical for accurately modeling user interaction patterns and improving recommendation precision. However, existing approaches predominantly emphasize item-to-item transitions, often neglecting the time intervals between interactions, which are closely related to behavior pattern changes. Additionally, broader interaction attributes, such as item frequency, are frequently overlooked. We found that both sequences with more uniform time intervals and items with higher frequency yield better prediction performance. Conversely, non-uniform sequences exacerbate user interest drift and less-frequent items are difficult to model due to sparse sampling, presenting unique challenges inadequately addressed by current methods. In this paper, we propose UniRec, a novel bidirectional enhancement sequential recommendation method. UniRec leverages sequence uniformity and item frequency to enhance performance, particularly improving the representation of non-uniform sequences and less-frequent items. These two branches mutually reinforce each other, driving comprehensive performance optimization in complex sequential recommendation scenarios. Additionally, we present a multidimensional time module to further enhance adaptability. To the best of our knowledge, UniRec is the first method to utilize the characteristics of uniformity and frequency for feature augmentation. Comparing with eleven advanced models across four datasets, we demonstrate that UniRec outperforms SOTA models significantly. The code is available at https://github.com/Linxi000/UniRec.","sentences":["Representation learning in sequential recommendation is critical for accurately modeling user interaction patterns and improving recommendation precision.","However, existing approaches predominantly emphasize item-to-item transitions, often neglecting the time intervals between interactions, which are closely related to behavior pattern changes.","Additionally, broader interaction attributes, such as item frequency, are frequently overlooked.","We found that both sequences with more uniform time intervals and items with higher frequency yield better prediction performance.","Conversely, non-uniform sequences exacerbate user interest drift and less-frequent items are difficult to model due to sparse sampling, presenting unique challenges inadequately addressed by current methods.","In this paper, we propose UniRec, a novel bidirectional enhancement sequential recommendation method.","UniRec leverages sequence uniformity and item frequency to enhance performance, particularly improving the representation of non-uniform sequences and less-frequent items.","These two branches mutually reinforce each other, driving comprehensive performance optimization in complex sequential recommendation scenarios.","Additionally, we present a multidimensional time module to further enhance adaptability.","To the best of our knowledge, UniRec is the first method to utilize the characteristics of uniformity and frequency for feature augmentation.","Comparing with eleven advanced models across four datasets, we demonstrate that UniRec outperforms SOTA models significantly.","The code is available at https://github.com/Linxi000/UniRec."],"url":"http://arxiv.org/abs/2406.18470v1"}
{"created":"2024-06-26 16:20:14","title":"Parameterizing the quantification of CMSO: model checking on minor-closed graph classes","abstract":"Given a graph $G$ and a vertex set $X$, the annotated treewidth tw$(G,X)$ of $X$ in $G$ is the maximum treewidth of an $X$-rooted minor of $G$, i.e., a minor $H$ where the model of each vertex of $H$ contains some vertex of $X$. That way, tw$(G,X)$ can be seen as a measure of the contribution of $X$ to the tree-decomposability of $G$. We introduce the logic CMSO/tw as the fragment of monadic second-order logic on graphs obtained by restricting set quantification to sets of bounded annotated treewidth. We prove the following Algorithmic Meta-Theorem (AMT): for every non-trivial minor-closed graph class, model checking for CMSO/tw formulas can be done in quadratic time. Our proof works for the more general CMSO/tw+dp logic, that is CMSO/tw enhanced by disjoint-path predicates. Our AMT can be seen as an extension of Courcelle's theorem to minor-closed graph classes where the bounded-treewidth condition in the input graph is replaced by the bounded-treewidth quantification in the formulas. Our results yield, as special cases, all known AMTs whose combinatorial restriction is non-trivial minor-closedness.","sentences":["Given a graph $G$ and a vertex set $X$, the annotated treewidth tw$(G,X)$ of $X$ in $G$ is the maximum treewidth of an $X$-rooted minor of $G$, i.e., a minor $H$ where the model of each vertex of $H$ contains some vertex of $X$. That way, tw$(G,X)$ can be seen as a measure of the contribution of $X$ to the tree-decomposability of $G$. We introduce the logic CMSO/tw as the fragment of monadic second-order logic on graphs obtained by restricting set quantification to sets of bounded annotated treewidth.","We prove the following Algorithmic Meta-Theorem (AMT): for every non-trivial minor-closed graph class, model checking for CMSO/tw formulas can be done in quadratic time.","Our proof works for the more general CMSO/tw+dp logic, that is CMSO/tw enhanced by disjoint-path predicates.","Our AMT can be seen as an extension of Courcelle's theorem to minor-closed graph classes where the bounded-treewidth condition in the input graph is replaced by the bounded-treewidth quantification in the formulas.","Our results yield, as special cases, all known AMTs whose combinatorial restriction is non-trivial minor-closedness."],"url":"http://arxiv.org/abs/2406.18465v1"}
{"created":"2024-06-26 16:12:09","title":"GaussianDreamerPro: Text to Manipulable 3D Gaussians with Highly Enhanced Quality","abstract":"Recently, 3D Gaussian splatting (3D-GS) has achieved great success in reconstructing and rendering real-world scenes. To transfer the high rendering quality to generation tasks, a series of research works attempt to generate 3D-Gaussian assets from text. However, the generated assets have not achieved the same quality as those in reconstruction tasks. We observe that Gaussians tend to grow without control as the generation process may cause indeterminacy. Aiming at highly enhancing the generation quality, we propose a novel framework named GaussianDreamerPro. The main idea is to bind Gaussians to reasonable geometry, which evolves over the whole generation process. Along different stages of our framework, both the geometry and appearance can be enriched progressively. The final output asset is constructed with 3D Gaussians bound to mesh, which shows significantly enhanced details and quality compared with previous methods. Notably, the generated asset can also be seamlessly integrated into downstream manipulation pipelines, e.g. animation, composition, and simulation etc., greatly promoting its potential in wide applications. Demos are available at https://taoranyi.com/gaussiandreamerpro/.","sentences":["Recently, 3D Gaussian splatting (3D-GS) has achieved great success in reconstructing and rendering real-world scenes.","To transfer the high rendering quality to generation tasks, a series of research works attempt to generate 3D-Gaussian assets from text.","However, the generated assets have not achieved the same quality as those in reconstruction tasks.","We observe that Gaussians tend to grow without control as the generation process may cause indeterminacy.","Aiming at highly enhancing the generation quality, we propose a novel framework named GaussianDreamerPro.","The main idea is to bind Gaussians to reasonable geometry, which evolves over the whole generation process.","Along different stages of our framework, both the geometry and appearance can be enriched progressively.","The final output asset is constructed with 3D Gaussians bound to mesh, which shows significantly enhanced details and quality compared with previous methods.","Notably, the generated asset can also be seamlessly integrated into downstream manipulation pipelines, e.g. animation, composition, and simulation etc., greatly promoting its potential in wide applications.","Demos are available at https://taoranyi.com/gaussiandreamerpro/."],"url":"http://arxiv.org/abs/2406.18462v1"}
{"created":"2024-06-26 16:10:53","title":"Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation","abstract":"Recently, various methods have been proposed to create open-domain conversational agents with Large Language Models (LLMs). These models are able to answer user queries, but in a one-way Q&A format rather than a true conversation. Fine-tuning on particular datasets is the usual way to modify their style to increase conversational ability, but this is expensive and usually only available in a few languages. In this study, we explore role-play zero-shot prompting as an efficient and cost-effective solution for open-domain conversation, using capable multilingual LLMs (Beeching et al., 2023) trained to obey instructions. We design a prompting system that, when combined with an instruction-following model - here Vicuna (Chiang et al., 2023) - produces conversational agents that match and even surpass fine-tuned models in human evaluation in French in two different tasks.","sentences":["Recently, various methods have been proposed to create open-domain conversational agents with Large Language Models (LLMs).","These models are able to answer user queries, but in a one-way Q&A format rather than a true conversation.","Fine-tuning on particular datasets is the usual way to modify their style to increase conversational ability, but this is expensive and usually only available in a few languages.","In this study, we explore role-play zero-shot prompting as an efficient and cost-effective solution for open-domain conversation, using capable multilingual LLMs (Beeching et al., 2023) trained to obey instructions.","We design a prompting system that, when combined with an instruction-following model - here Vicuna (Chiang et al., 2023) - produces conversational agents that match and even surpass fine-tuned models in human evaluation in French in two different tasks."],"url":"http://arxiv.org/abs/2406.18460v1"}
{"created":"2024-06-26 16:10:31","title":"DiffuseHigh: Training-free Progressive High-Resolution Image Synthesis through Structure Guidance","abstract":"Recent surge in large-scale generative models has spurred the development of vast fields in computer vision. In particular, text-to-image diffusion models have garnered widespread adoption across diverse domain due to their potential for high-fidelity image generation. Nonetheless, existing large-scale diffusion models are confined to generate images of up to 1K resolution, which is far from meeting the demands of contemporary commercial applications. Directly sampling higher-resolution images often yields results marred by artifacts such as object repetition and distorted shapes. Addressing the aforementioned issues typically necessitates training or fine-tuning models on higher resolution datasets. However, this undertaking poses a formidable challenge due to the difficulty in collecting large-scale high-resolution contents and substantial computational resources. While several preceding works have proposed alternatives, they often fail to produce convincing results. In this work, we probe the generative ability of diffusion models at higher resolution beyond its original capability and propose a novel progressive approach that fully utilizes generated low-resolution image to guide the generation of higher resolution image. Our method obviates the need for additional training or fine-tuning which significantly lowers the burden of computational costs. Extensive experiments and results validate the efficiency and efficacy of our method.","sentences":["Recent surge in large-scale generative models has spurred the development of vast fields in computer vision.","In particular, text-to-image diffusion models have garnered widespread adoption across diverse domain due to their potential for high-fidelity image generation.","Nonetheless, existing large-scale diffusion models are confined to generate images of up to 1K resolution, which is far from meeting the demands of contemporary commercial applications.","Directly sampling higher-resolution images often yields results marred by artifacts such as object repetition and distorted shapes.","Addressing the aforementioned issues typically necessitates training or fine-tuning models on higher resolution datasets.","However, this undertaking poses a formidable challenge due to the difficulty in collecting large-scale high-resolution contents and substantial computational resources.","While several preceding works have proposed alternatives, they often fail to produce convincing results.","In this work, we probe the generative ability of diffusion models at higher resolution beyond its original capability and propose a novel progressive approach that fully utilizes generated low-resolution image to guide the generation of higher resolution image.","Our method obviates the need for additional training or fine-tuning which significantly lowers the burden of computational costs.","Extensive experiments and results validate the efficiency and efficacy of our method."],"url":"http://arxiv.org/abs/2406.18459v1"}
{"created":"2024-06-26 16:05:14","title":"System for Measurement of Electric Energy Using Beacons with Optical Sensors and LoRaWAN Transmission","abstract":"In this article, we present the results of experiments with finding an efficient radio transmission method for an electric energy measurement system called OneMeter 2.0. This system offers a way of collecting energy usage data from beacons attached to regular, non-smart meters. In our study, we compared several low power wide area network (LPWAN) protocols, out of which we chose the LoRaWAN protocol. We verified the energy consumption of a LoRa-based transmission unit, as well as the transmission range between network nodes in urban conditions. We discovered that LoRaWAN-based transmission was highly energy-efficient and offered decent coverage, even in a difficult, dense urban environment.","sentences":["In this article, we present the results of experiments with finding an efficient radio transmission method for an electric energy measurement system called OneMeter 2.0.","This system offers a way of collecting energy usage data from beacons attached to regular, non-smart meters.","In our study, we compared several low power wide area network (LPWAN) protocols, out of which we chose the LoRaWAN protocol.","We verified the energy consumption of a LoRa-based transmission unit, as well as the transmission range between network nodes in urban conditions.","We discovered that LoRaWAN-based transmission was highly energy-efficient and offered decent coverage, even in a difficult, dense urban environment."],"url":"http://arxiv.org/abs/2406.18455v1"}
{"created":"2024-06-26 16:01:53","title":"From Counting Stations to City-Wide Estimates: Data-Driven Bicycle Volume Extrapolation","abstract":"Shifting to cycling in urban areas reduces greenhouse gas emissions and improves public health. Street-level bicycle volume information would aid cities in planning targeted infrastructure improvements to encourage cycling and provide civil society with evidence to advocate for cyclists' needs. Yet, the data currently available to cities and citizens often only comes from sparsely located counting stations. This paper extrapolates bicycle volume beyond these few locations to estimate bicycle volume for the entire city of Berlin. We predict daily and average annual daily street-level bicycle volumes using machine-learning techniques and various public data sources. These include app-based crowdsourced data, infrastructure, bike-sharing, motorized traffic, socioeconomic indicators, weather, and holiday data. Our analysis reveals that the best-performing model is XGBoost, and crowdsourced cycling and infrastructure data are most important for the prediction. We further simulate how collecting short-term counts at predicted locations improves performance. By providing ten days of such sample counts for each predicted location to the model, we are able to halve the error and greatly reduce the variability in performance among predicted locations.","sentences":["Shifting to cycling in urban areas reduces greenhouse gas emissions and improves public health.","Street-level bicycle volume information would aid cities in planning targeted infrastructure improvements to encourage cycling and provide civil society with evidence to advocate for cyclists' needs.","Yet, the data currently available to cities and citizens often only comes from sparsely located counting stations.","This paper extrapolates bicycle volume beyond these few locations to estimate bicycle volume for the entire city of Berlin.","We predict daily and average annual daily street-level bicycle volumes using machine-learning techniques and various public data sources.","These include app-based crowdsourced data, infrastructure, bike-sharing, motorized traffic, socioeconomic indicators, weather, and holiday data.","Our analysis reveals that the best-performing model is XGBoost, and crowdsourced cycling and infrastructure data are most important for the prediction.","We further simulate how collecting short-term counts at predicted locations improves performance.","By providing ten days of such sample counts for each predicted location to the model, we are able to halve the error and greatly reduce the variability in performance among predicted locations."],"url":"http://arxiv.org/abs/2406.18454v1"}
{"created":"2024-06-26 16:01:10","title":"Towards Human-Level 3D Relative Pose Estimation: Generalizable, Training-Free, with Single Reference","abstract":"Humans can easily deduce the relative pose of an unseen object, without label/training, given only a single query-reference image pair. This is arguably achieved by incorporating (i) 3D/2.5D shape perception from a single image, (ii) render-and-compare simulation, and (iii) rich semantic cue awareness to furnish (coarse) reference-query correspondence. Existing methods implement (i) by a 3D CAD model or well-calibrated multiple images and (ii) by training a network on specific objects, which necessitate laborious ground-truth labeling and tedious training, potentially leading to challenges in generalization. Moreover, (iii) was less exploited in the paradigm of (ii), despite that the coarse correspondence from (iii) enhances the compare process by filtering out non-overlapped parts under substantial pose differences/occlusions. Motivated by this, we propose a novel 3D generalizable relative pose estimation method by elaborating (i) with a 2.5D shape from an RGB-D reference, (ii) with an off-the-shelf differentiable renderer, and (iii) with semantic cues from a pretrained model like DINOv2. Specifically, our differentiable renderer takes the 2.5D rotatable mesh textured by the RGB and the semantic maps (obtained by DINOv2 from the RGB input), then renders new RGB and semantic maps (with back-surface culling) under a novel rotated view. The refinement loss comes from comparing the rendered RGB and semantic maps with the query ones, back-propagating the gradients through the differentiable renderer to refine the 3D relative pose. As a result, our method can be readily applied to unseen objects, given only a single RGB-D reference, without label/training. Extensive experiments on LineMOD, LM-O, and YCB-V show that our training-free method significantly outperforms the SOTA supervised methods, especially under the rigorous Acc@5/10/15{\\deg} metrics and the challenging cross-dataset settings.","sentences":["Humans can easily deduce the relative pose of an unseen object, without label/training, given only a single query-reference image pair.","This is arguably achieved by incorporating (i) 3D/2.5D shape perception from a single image, (ii) render-and-compare simulation, and (iii) rich semantic cue awareness to furnish (coarse) reference-query correspondence.","Existing methods implement (i) by a 3D CAD model or well-calibrated multiple images and (ii) by training a network on specific objects, which necessitate laborious ground-truth labeling and tedious training, potentially leading to challenges in generalization.","Moreover, (iii) was less exploited in the paradigm of (ii), despite that the coarse correspondence from (iii) enhances the compare process by filtering out non-overlapped parts under substantial pose differences/occlusions.","Motivated by this, we propose a novel 3D generalizable relative pose estimation method by elaborating (i) with a 2.5D shape from an RGB-D reference, (ii) with an off-the-shelf differentiable renderer, and (iii) with semantic cues from a pretrained model like DINOv2.","Specifically, our differentiable renderer takes the 2.5D rotatable mesh textured by the RGB and the semantic maps (obtained by DINOv2 from the RGB input), then renders new RGB and semantic maps (with back-surface culling) under a novel rotated view.","The refinement loss comes from comparing the rendered RGB and semantic maps with the query ones, back-propagating the gradients through the differentiable renderer to refine the 3D relative pose.","As a result, our method can be readily applied to unseen objects, given only a single RGB-D reference, without label/training.","Extensive experiments on LineMOD, LM-O, and YCB-V show that our training-free method significantly outperforms the SOTA supervised methods, especially under the rigorous Acc@5/10/15{\\deg} metrics and the challenging cross-dataset settings."],"url":"http://arxiv.org/abs/2406.18453v1"}
{"created":"2024-06-26 16:01:00","title":"Optimal Multi-Robot Communication-Aware Trajectory Planning by Constraining the Fiedler Value","abstract":"The paper present a novel approach for the solution of the Multi-Robot Communication-Aware Trajectory Planning, which builds on a general optimisation framework where the changes in robots positions are used as decision variable, and linear constraints on the trajectories of the robots are introduced to ensure communication performance and collision avoidance. The Fiedler value is adopted as communication performance metric. The validity of the method in computing both feasible and optimal trajectories for the robots is demonstrated both in simulation and experimentally. Results show that the constraint on the Fiedler value ensures that the robot network fulfils its objective while maintaining communication connectivity at all times. Further, the paper shows that the introduction of approximations for the constraints enables a significant improvement in the computational time of the solution, which remain very close to the optimal solution.","sentences":["The paper present a novel approach for the solution of the Multi-Robot Communication-Aware Trajectory Planning, which builds on a general optimisation framework where the changes in robots positions are used as decision variable, and linear constraints on the trajectories of the robots are introduced to ensure communication performance and collision avoidance.","The Fiedler value is adopted as communication performance metric.","The validity of the method in computing both feasible and optimal trajectories for the robots is demonstrated both in simulation and experimentally.","Results show that the constraint on the Fiedler value ensures that the robot network fulfils its objective while maintaining communication connectivity at all times.","Further, the paper shows that the introduction of approximations for the constraints enables a significant improvement in the computational time of the solution, which remain very close to the optimal solution."],"url":"http://arxiv.org/abs/2406.18452v1"}
{"created":"2024-06-26 16:00:35","title":"Detecting Brittle Decisions for Free: Leveraging Margin Consistency in Deep Robust Classifiers","abstract":"Despite extensive research on adversarial training strategies to improve robustness, the decisions of even the most robust deep learning models can still be quite sensitive to imperceptible perturbations, creating serious risks when deploying them for high-stakes real-world applications. While detecting such cases may be critical, evaluating a model's vulnerability at a per-instance level using adversarial attacks is computationally too intensive and unsuitable for real-time deployment scenarios. The input space margin is the exact score to detect non-robust samples and is intractable for deep neural networks. This paper introduces the concept of margin consistency -- a property that links the input space margins and the logit margins in robust models -- for efficient detection of vulnerable samples. First, we establish that margin consistency is a necessary and sufficient condition to use a model's logit margin as a score for identifying non-robust samples. Next, through comprehensive empirical analysis of various robustly trained models on CIFAR10 and CIFAR100 datasets, we show that they indicate strong margin consistency with a strong correlation between their input space margins and the logit margins. Then, we show that we can effectively use the logit margin to confidently detect brittle decisions with such models and accurately estimate robust accuracy on an arbitrarily large test set by estimating the input margins only on a small subset. Finally, we address cases where the model is not sufficiently margin-consistent by learning a pseudo-margin from the feature representation. Our findings highlight the potential of leveraging deep representations to efficiently assess adversarial vulnerability in deployment scenarios.","sentences":["Despite extensive research on adversarial training strategies to improve robustness, the decisions of even the most robust deep learning models can still be quite sensitive to imperceptible perturbations, creating serious risks when deploying them for high-stakes real-world applications.","While detecting such cases may be critical, evaluating a model's vulnerability at a per-instance level using adversarial attacks is computationally too intensive and unsuitable for real-time deployment scenarios.","The input space margin is the exact score to detect non-robust samples and is intractable for deep neural networks.","This paper introduces the concept of margin consistency -- a property that links the input space margins and the logit margins in robust models -- for efficient detection of vulnerable samples.","First, we establish that margin consistency is a necessary and sufficient condition to use a model's logit margin as a score for identifying non-robust samples.","Next, through comprehensive empirical analysis of various robustly trained models on CIFAR10 and CIFAR100 datasets, we show that they indicate strong margin consistency with a strong correlation between their input space margins and the logit margins.","Then, we show that we can effectively use the logit margin to confidently detect brittle decisions with such models and accurately estimate robust accuracy on an arbitrarily large test set by estimating the input margins only on a small subset.","Finally, we address cases where the model is not sufficiently margin-consistent by learning a pseudo-margin from the feature representation.","Our findings highlight the potential of leveraging deep representations to efficiently assess adversarial vulnerability in deployment scenarios."],"url":"http://arxiv.org/abs/2406.18451v1"}
{"created":"2024-06-26 15:59:13","title":"Preference Elicitation for Offline Reinforcement Learning","abstract":"Applying reinforcement learning (RL) to real-world problems is often made challenging by the inability to interact with the environment and the difficulty of designing reward functions. Offline RL addresses the first challenge by considering access to an offline dataset of environment interactions labeled by the reward function. In contrast, Preference-based RL does not assume access to the reward function and learns it from preferences, but typically requires an online interaction with the environment. We bridge the gap between these frameworks by exploring efficient methods for acquiring preference feedback in a fully offline setup. We propose Sim-OPRL, an offline preference-based reinforcement learning algorithm, which leverages a learned environment model to elicit preference feedback on simulated rollouts. Drawing on insights from both the offline RL and the preference-based RL literature, our algorithm employs a pessimistic approach for out-of-distribution data, and an optimistic approach for acquiring informative preferences about the optimal policy. We provide theoretical guarantees regarding the sample complexity of our approach, dependent on how well the offline data covers the optimal policy. Finally, we demonstrate the empirical performance of Sim-OPRL in different environments.","sentences":["Applying reinforcement learning (RL) to real-world problems is often made challenging by the inability to interact with the environment and the difficulty of designing reward functions.","Offline RL addresses the first challenge by considering access to an offline dataset of environment interactions labeled by the reward function.","In contrast, Preference-based RL does not assume access to the reward function and learns it from preferences, but typically requires an online interaction with the environment.","We bridge the gap between these frameworks by exploring efficient methods for acquiring preference feedback in a fully offline setup.","We propose Sim-OPRL, an offline preference-based reinforcement learning algorithm, which leverages a learned environment model to elicit preference feedback on simulated rollouts.","Drawing on insights from both the offline RL and the preference-based RL literature, our algorithm employs a pessimistic approach for out-of-distribution data, and an optimistic approach for acquiring informative preferences about the optimal policy.","We provide theoretical guarantees regarding the sample complexity of our approach, dependent on how well the offline data covers the optimal policy.","Finally, we demonstrate the empirical performance of Sim-OPRL in different environments."],"url":"http://arxiv.org/abs/2406.18450v1"}
{"created":"2024-06-26 15:53:54","title":"Cascading Large Language Models for Salient Event Graph Generation","abstract":"Generating event graphs from long documents is challenging due to the inherent complexity of multiple tasks involved such as detecting events, identifying their relationships, and reconciling unstructured input with structured graphs. Recent studies typically consider all events with equal importance, failing to distinguish salient events crucial for understanding narratives. This paper presents CALLMSAE, a CAscading Large Language Model framework for SAlient Event graph generation, which leverages the capabilities of LLMs and eliminates the need for costly human annotations. We first identify salient events by prompting LLMs to generate summaries, from which salient events are identified. Next, we develop an iterative code refinement prompting strategy to generate event relation graphs, removing hallucinated relations and recovering missing edges. Fine-tuning contextualised graph generation models on the LLM-generated graphs outperforms the models trained on CAEVO-generated data. Experimental results on a human-annotated test set show that the proposed method generates salient and more accurate graphs, outperforming competitive baselines.","sentences":["Generating event graphs from long documents is challenging due to the inherent complexity of multiple tasks involved such as detecting events, identifying their relationships, and reconciling unstructured input with structured graphs.","Recent studies typically consider all events with equal importance, failing to distinguish salient events crucial for understanding narratives.","This paper presents CALLMSAE, a CAscading Large Language Model framework for SAlient Event graph generation, which leverages the capabilities of LLMs and eliminates the need for costly human annotations.","We first identify salient events by prompting LLMs to generate summaries, from which salient events are identified.","Next, we develop an iterative code refinement prompting strategy to generate event relation graphs, removing hallucinated relations and recovering missing edges.","Fine-tuning contextualised graph generation models on the LLM-generated graphs outperforms the models trained on CAEVO-generated data.","Experimental results on a human-annotated test set show that the proposed method generates salient and more accurate graphs, outperforming competitive baselines."],"url":"http://arxiv.org/abs/2406.18449v1"}
{"created":"2024-06-26 15:50:13","title":"An Autotuning-based Optimization Framework for Mixed-kernel SVM Classifications in Smart Pixel Datasets and Heterojunction Transistors","abstract":"Support Vector Machine (SVM) is a state-of-the-art classification method widely used in science and engineering due to its high accuracy, its ability to deal with high dimensional data, and its flexibility in modeling diverse sources of data. In this paper, we propose an autotuning-based optimization framework to quantify the ranges of hyperparameters in SVMs to identify their optimal choices, and apply the framework to two SVMs with the mixed-kernel between Sigmoid and Gaussian kernels for smart pixel datasets in high energy physics (HEP) and mixed-kernel heterojunction transistors (MKH). Our experimental results show that the optimal selection of hyperparameters in the SVMs and the kernels greatly varies for different applications and datasets, and choosing their optimal choices is critical for a high classification accuracy of the mixed kernel SVMs. Uninformed choices of hyperparameters C and coef0 in the mixed-kernel SVMs result in severely low accuracy, and the proposed framework effectively quantifies the proper ranges for the hyperparameters in the SVMs to identify their optimal choices to achieve the highest accuracy 94.6\\% for the HEP application and the highest average accuracy 97.2\\% with far less tuning time for the MKH application.","sentences":["Support Vector Machine (SVM) is a state-of-the-art classification method widely used in science and engineering due to its high accuracy, its ability to deal with high dimensional data, and its flexibility in modeling diverse sources of data.","In this paper, we propose an autotuning-based optimization framework to quantify the ranges of hyperparameters in SVMs to identify their optimal choices, and apply the framework to two SVMs with the mixed-kernel between Sigmoid and Gaussian kernels for smart pixel datasets in high energy physics (HEP) and mixed-kernel heterojunction transistors (MKH).","Our experimental results show that the optimal selection of hyperparameters in the SVMs and the kernels greatly varies for different applications and datasets, and choosing their optimal choices is critical for a high classification accuracy of the mixed kernel SVMs.","Uninformed choices of hyperparameters C and coef0 in the mixed-kernel SVMs result in severely low accuracy, and the proposed framework effectively quantifies the proper ranges for the hyperparameters in the SVMs to identify their optimal choices to achieve the highest accuracy 94.6\\% for the HEP application and the highest average accuracy 97.2\\% with far less tuning time for the MKH application."],"url":"http://arxiv.org/abs/2406.18445v1"}
{"created":"2024-06-26 15:48:24","title":"Unveiling the Unknown: Conditional Evidence Decoupling for Unknown Rejection","abstract":"In this paper, we focus on training an open-set object detector under the condition of scarce training samples, which should distinguish the known and unknown categories. Under this challenging scenario, the decision boundaries of unknowns are difficult to learn and often ambiguous. To mitigate this issue, we develop a novel open-set object detection framework, which delves into conditional evidence decoupling for the unknown rejection. Specifically, we select pseudo-unknown samples by leveraging the discrepancy in attribution gradients between known and unknown classes, alleviating the inadequate unknown distribution coverage of training data. Subsequently, we propose a Conditional Evidence Decoupling Loss (CEDL) based on Evidential Deep Learning (EDL) theory, which decouples known and unknown properties in pseudo-unknown samples to learn distinct knowledge, enhancing separability between knowns and unknowns. Additionally, we propose an Abnormality Calibration Loss (ACL), which serves as a regularization term to adjust the output probability distribution, establishing robust decision boundaries for the unknown rejection. Our method has achieved the superiority performance over previous state-of-the-art approaches, improving the mean recall of unknown class by 7.24% across all shots in VOC10-5-5 dataset settings and 1.38% in VOC-COCO dataset settings. The code is available via https://github.com/zjzwzw/CED-FOOD.","sentences":["In this paper, we focus on training an open-set object detector under the condition of scarce training samples, which should distinguish the known and unknown categories.","Under this challenging scenario, the decision boundaries of unknowns are difficult to learn and often ambiguous.","To mitigate this issue, we develop a novel open-set object detection framework, which delves into conditional evidence decoupling for the unknown rejection.","Specifically, we select pseudo-unknown samples by leveraging the discrepancy in attribution gradients between known and unknown classes, alleviating the inadequate unknown distribution coverage of training data.","Subsequently, we propose a Conditional Evidence Decoupling Loss (CEDL) based on Evidential Deep Learning (EDL) theory, which decouples known and unknown properties in pseudo-unknown samples to learn distinct knowledge, enhancing separability between knowns and unknowns.","Additionally, we propose an Abnormality Calibration Loss (ACL), which serves as a regularization term to adjust the output probability distribution, establishing robust decision boundaries for the unknown rejection.","Our method has achieved the superiority performance over previous state-of-the-art approaches, improving the mean recall of unknown class by 7.24% across all shots in VOC10-5-5 dataset settings and 1.38% in VOC-COCO dataset settings.","The code is available via https://github.com/zjzwzw/CED-FOOD."],"url":"http://arxiv.org/abs/2406.18443v1"}
{"created":"2024-06-26 15:48:03","title":"On Approximate 8-bit Floating-Point Operations Using Integer Operations","abstract":"In this work, approximate eight-bit floating-point operations performed using simple integer operations is discussed. For two-bit mantissa formats, faithful rounding can always be obtained for the considered operations. For all operations, correctly rounded results can be obtained for different rounding modes, either directly or by adding a conditional carry in. For three-bit mantissa formats, faithful rounding can be sometimes be obtained directly, while for other operations a conditional carry in must be added. Correctly rounded results can be obtained for most operations and rounding modes using slightly more complicated expressions for the carry in. Hardware implementation results for multiplication using both standard cell and FPGA technology are presented illustrating the potential benefit of integer computation. Especially for FPGA, significant resource savings are obtained.","sentences":["In this work, approximate eight-bit floating-point operations performed using simple integer operations is discussed.","For two-bit mantissa formats, faithful rounding can always be obtained for the considered operations.","For all operations, correctly rounded results can be obtained for different rounding modes, either directly or by adding a conditional carry in.","For three-bit mantissa formats, faithful rounding can be sometimes be obtained directly, while for other operations a conditional carry in must be added.","Correctly rounded results can be obtained for most operations and rounding modes using slightly more complicated expressions for the carry in.","Hardware implementation results for multiplication using both standard cell and FPGA technology are presented illustrating the potential benefit of integer computation.","Especially for FPGA, significant resource savings are obtained."],"url":"http://arxiv.org/abs/2406.18441v1"}
{"created":"2024-06-26 15:27:26","title":"Facial Image Feature Analysis and its Specialization for Fr\u00e9chet Distance and Neighborhoods","abstract":"Assessing distances between images and image datasets is a fundamental task in vision-based research. It is a challenging open problem in the literature and despite the criticism it receives, the most ubiquitous method remains the Fr\\'echet Inception Distance. The Inception network is trained on a specific labeled dataset, ImageNet, which has caused the core of its criticism in the most recent research. Improvements were shown by moving to self-supervision learning over ImageNet, leaving the training data domain as an open question. We make that last leap and provide the first analysis on domain-specific feature training and its effects on feature distance, on the widely-researched facial image domain. We provide our findings and insights on this domain specialization for Fr\\'echet distance and image neighborhoods, supported by extensive experiments and in-depth user studies.","sentences":["Assessing distances between images and image datasets is a fundamental task in vision-based research.","It is a challenging open problem in the literature and despite the criticism it receives, the most ubiquitous method remains the Fr\\'echet Inception Distance.","The Inception network is trained on a specific labeled dataset, ImageNet, which has caused the core of its criticism in the most recent research.","Improvements were shown by moving to self-supervision learning over ImageNet, leaving the training data domain as an open question.","We make that last leap and provide the first analysis on domain-specific feature training and its effects on feature distance, on the widely-researched facial image domain.","We provide our findings and insights on this domain specialization for Fr\\'echet distance and image neighborhoods, supported by extensive experiments and in-depth user studies."],"url":"http://arxiv.org/abs/2406.18430v1"}
{"created":"2024-06-26 15:26:34","title":"Sum-of-Squares Lower Bounds for Independent Set in Ultra-Sparse Random Graphs","abstract":"We prove that for every $D \\in \\N$, and large enough constant $d \\in \\N$, with high probability over the choice of $G \\sim G(n,d/n)$, the \\Erdos-\\Renyi random graph distribution, the canonical degree $2D$ Sum-of-Squares relaxation fails to certify that the largest independent set in $G$ is of size $o(\\frac{n}{\\sqrt{d} D^4})$. In particular, degree $D$ sum-of-squares strengthening can reduce the integrality gap of the classical \\Lovasz theta SDP relaxation by at most a $O(D^4)$ factor.   This is the first lower bound for $>4$-degree Sum-of-Squares (SoS) relaxation for any problems on \\emph{ultra sparse} random graphs (i.e. average degree of an absolute constant). Such ultra-sparse graphs were a known barrier for previous methods and explicitly identified as a major open direction (e.g.,~\\cite{deshpande2019threshold, kothari2021stressfree}). Indeed, the only other example of an SoS lower bound on ultra-sparse random graphs was a degree-4 lower bound for Max-Cut.   Our main technical result is a new method to obtain spectral norm estimates on graph matrices (a class of low-degree matrix-valued polynomials in $G(n,d/n)$) that are accurate to within an absolute constant factor. All prior works lose $\\poly log n$ factors that trivialize any lower bound on $o(\\log n)$-degree random graphs. We combine these new bounds with several upgrades on the machinery for analyzing lower-bound witnesses constructed by pseudo-calibration so that our analysis does not lose any $\\omega(1)$-factors that would trivialize our results. In addition to other SoS lower bounds, we believe that our methods for establishing spectral norm estimates on graph matrices will be useful in the analyses of numerical algorithms on average-case inputs.","sentences":["We prove that for every $D \\in \\N$, and large enough constant $d \\in \\N$, with high probability over the choice of $G \\sim G(n,d/n)$, the \\Erdos-\\Renyi random graph distribution, the canonical degree $2D$ Sum-of-Squares relaxation fails to certify that the largest independent set in $G$ is of size $o(\\frac{n}{\\sqrt{d} D^4})$.","In particular, degree $D$ sum-of-squares strengthening can reduce the integrality gap of the classical \\Lovasz theta SDP relaxation by at most a $O(D^4)$ factor.   ","This is the first lower bound for $>4$-degree Sum-of-Squares (SoS) relaxation for any problems on \\emph{ultra sparse} random graphs (i.e. average degree of an absolute constant).","Such ultra-sparse graphs were a known barrier for previous methods and explicitly identified as a major open direction (e.g.,~\\cite{deshpande2019threshold, kothari2021stressfree}).","Indeed, the only other example of an SoS lower bound on ultra-sparse random graphs was a degree-4 lower bound for Max-Cut.   ","Our main technical result is a new method to obtain spectral norm estimates on graph matrices (a class of low-degree matrix-valued polynomials in $G(n,d/n)$) that are accurate to within an absolute constant factor.","All prior works lose $\\poly log n$ factors that trivialize any lower bound on $o(\\log n)$-degree random graphs.","We combine these new bounds with several upgrades on the machinery for analyzing lower-bound witnesses constructed by pseudo-calibration so that our analysis does not lose any $\\omega(1)$-factors that would trivialize our results.","In addition to other SoS lower bounds, we believe that our methods for establishing spectral norm estimates on graph matrices will be useful in the analyses of numerical algorithms on average-case inputs."],"url":"http://arxiv.org/abs/2406.18429v1"}
{"created":"2024-06-26 15:18:49","title":"Graph Neural Networks for Emulation of Finite-Element Ice Dynamics in Greenland and Antarctic Ice Sheets","abstract":"Although numerical models provide accurate solutions for ice sheet dynamics based on physics laws, they accompany intensified computational demands to solve partial differential equations. In recent years, convolutional neural networks (CNNs) have been widely used as statistical emulators for those numerical models. However, since CNNs operate on regular grids, they cannot represent the refined meshes and computational efficiency of finite-element numerical models. Therefore, instead of CNNs, this study adopts an equivariant graph convolutional network (EGCN) as an emulator for the ice sheet dynamics modeling. EGCN reproduces ice thickness and velocity changes in the Helheim Glacier, Greenland, and Pine Island Glacier, Antarctica, with 260 times and 44 times faster computation time, respectively. Compared to the traditional CNN and graph convolutional network, EGCN shows outstanding accuracy in thickness prediction near fast ice streams by preserving the equivariance to the translation and rotation of graphs.","sentences":["Although numerical models provide accurate solutions for ice sheet dynamics based on physics laws, they accompany intensified computational demands to solve partial differential equations.","In recent years, convolutional neural networks (CNNs) have been widely used as statistical emulators for those numerical models.","However, since CNNs operate on regular grids, they cannot represent the refined meshes and computational efficiency of finite-element numerical models.","Therefore, instead of CNNs, this study adopts an equivariant graph convolutional network (EGCN) as an emulator for the ice sheet dynamics modeling.","EGCN reproduces ice thickness and velocity changes in the Helheim Glacier, Greenland, and Pine Island Glacier, Antarctica, with 260 times and 44 times faster computation time, respectively.","Compared to the traditional CNN and graph convolutional network, EGCN shows outstanding accuracy in thickness prediction near fast ice streams by preserving the equivariance to the translation and rotation of graphs."],"url":"http://arxiv.org/abs/2406.18423v1"}
{"created":"2024-06-26 15:18:20","title":"Repeat and Concatenate: 2D to 3D Image Translation with 3D to 3D Generative Modeling","abstract":"This paper investigates a 2D to 3D image translation method with a straightforward technique, enabling correlated 2D X-ray to 3D CT-like reconstruction. We observe that existing approaches, which integrate information across multiple 2D views in the latent space, lose valuable signal information during latent encoding. Instead, we simply repeat and concatenate the 2D views into higher-channel 3D volumes and approach the 3D reconstruction challenge as a straightforward 3D to 3D generative modeling problem, sidestepping several complex modeling issues. This method enables the reconstructed 3D volume to retain valuable information from the 2D inputs, which are passed between channel states in a Swin UNETR backbone. Our approach applies neural optimal transport, which is fast and stable to train, effectively integrating signal information across multiple views without the requirement for precise alignment; it produces non-collapsed reconstructions that are highly faithful to the 2D views, even after limited training. We demonstrate correlated results, both qualitatively and quantitatively, having trained our model on a single dataset and evaluated its generalization ability across six datasets, including out-of-distribution samples.","sentences":["This paper investigates a 2D to 3D image translation method with a straightforward technique, enabling correlated 2D X-ray to 3D CT-like reconstruction.","We observe that existing approaches, which integrate information across multiple 2D views in the latent space, lose valuable signal information during latent encoding.","Instead, we simply repeat and concatenate the 2D views into higher-channel 3D volumes and approach the 3D reconstruction challenge as a straightforward 3D to 3D generative modeling problem, sidestepping several complex modeling issues.","This method enables the reconstructed 3D volume to retain valuable information from the 2D inputs, which are passed between channel states in a Swin UNETR backbone.","Our approach applies neural optimal transport, which is fast and stable to train, effectively integrating signal information across multiple views without the requirement for precise alignment; it produces non-collapsed reconstructions that are highly faithful to the 2D views, even after limited training.","We demonstrate correlated results, both qualitatively and quantitatively, having trained our model on a single dataset and evaluated its generalization ability across six datasets, including out-of-distribution samples."],"url":"http://arxiv.org/abs/2406.18422v1"}
{"created":"2024-06-26 15:15:15","title":"Mixture of Experts in a Mixture of RL settings","abstract":"Mixtures of Experts (MoEs) have gained prominence in (self-)supervised learning due to their enhanced inference efficiency, adaptability to distributed training, and modularity. Previous research has illustrated that MoEs can significantly boost Deep Reinforcement Learning (DRL) performance by expanding the network's parameter count while reducing dormant neurons, thereby enhancing the model's learning capacity and ability to deal with non-stationarity. In this work, we shed more light on MoEs' ability to deal with non-stationarity and investigate MoEs in DRL settings with \"amplified\" non-stationarity via multi-task training, providing further evidence that MoEs improve learning capacity. In contrast to previous work, our multi-task results allow us to better understand the underlying causes for the beneficial effect of MoE in DRL training, the impact of the various MoE components, and insights into how best to incorporate them in actor-critic-based DRL networks. Finally, we also confirm results from previous work.","sentences":["Mixtures of Experts (MoEs) have gained prominence in (self-)supervised learning due to their enhanced inference efficiency, adaptability to distributed training, and modularity.","Previous research has illustrated that MoEs can significantly boost Deep Reinforcement Learning (DRL) performance by expanding the network's parameter count while reducing dormant neurons, thereby enhancing the model's learning capacity and ability to deal with non-stationarity.","In this work, we shed more light on MoEs' ability to deal with non-stationarity and investigate MoEs in DRL settings with \"amplified\" non-stationarity via multi-task training, providing further evidence that MoEs improve learning capacity.","In contrast to previous work, our multi-task results allow us to better understand the underlying causes for the beneficial effect of MoE in DRL training, the impact of the various MoE components, and insights into how best to incorporate them in actor-critic-based DRL networks.","Finally, we also confirm results from previous work."],"url":"http://arxiv.org/abs/2406.18420v1"}
{"created":"2024-06-26 15:11:26","title":"Differential error feedback for communication-efficient decentralized learning","abstract":"Communication-constrained algorithms for decentralized learning and optimization rely on local updates coupled with the exchange of compressed signals. In this context, differential quantization is an effective technique to mitigate the negative impact of compression by leveraging correlations between successive iterates. In addition, the use of error feedback, which consists of incorporating the compression error into subsequent steps, is a powerful mechanism to compensate for the bias caused by the compression. Under error feedback, performance guarantees in the literature have so far focused on algorithms employing a fusion center or a special class of contractive compressors that cannot be implemented with a finite number of bits. In this work, we propose a new decentralized communication-efficient learning approach that blends differential quantization with error feedback. The approach is specifically tailored for decentralized learning problems where agents have individual risk functions to minimize subject to subspace constraints that require the minimizers across the network to lie in low-dimensional subspaces. This constrained formulation includes consensus or single-task optimization as special cases, and allows for more general task relatedness models such as multitask smoothness and coupled optimization. We show that, under some general conditions on the compression noise, and for sufficiently small step-sizes $\\mu$, the resulting communication-efficient strategy is stable both in terms of mean-square error and average bit rate: by reducing $\\mu$, it is possible to keep the estimation errors small (on the order of $\\mu$) without increasing indefinitely the bit rate as $\\mu\\rightarrow 0$. The results establish that, in the small step-size regime and with a finite number of bits, it is possible to attain the performance achievable in the absence of compression.","sentences":["Communication-constrained algorithms for decentralized learning and optimization rely on local updates coupled with the exchange of compressed signals.","In this context, differential quantization is an effective technique to mitigate the negative impact of compression by leveraging correlations between successive iterates.","In addition, the use of error feedback, which consists of incorporating the compression error into subsequent steps, is a powerful mechanism to compensate for the bias caused by the compression.","Under error feedback, performance guarantees in the literature have so far focused on algorithms employing a fusion center or a special class of contractive compressors that cannot be implemented with a finite number of bits.","In this work, we propose a new decentralized communication-efficient learning approach that blends differential quantization with error feedback.","The approach is specifically tailored for decentralized learning problems where agents have individual risk functions to minimize subject to subspace constraints that require the minimizers across the network to lie in low-dimensional subspaces.","This constrained formulation includes consensus or single-task optimization as special cases, and allows for more general task relatedness models such as multitask smoothness and coupled optimization.","We show that, under some general conditions on the compression noise, and for sufficiently small step-sizes $\\mu$, the resulting communication-efficient strategy is stable both in terms of mean-square error and average bit rate: by reducing $\\mu$, it is possible to keep the estimation errors small (on the order of $\\mu$) without increasing indefinitely the bit rate as $\\mu\\rightarrow 0$.","The results establish that, in the small step-size regime and with a finite number of bits, it is possible to attain the performance achievable in the absence of compression."],"url":"http://arxiv.org/abs/2406.18418v1"}
{"created":"2024-06-26 15:11:15","title":"Towards diffusion models for large-scale sea-ice modelling","abstract":"We make the first steps towards diffusion models for unconditional generation of multivariate and Arctic-wide sea-ice states. While targeting to reduce the computational costs by diffusion in latent space, latent diffusion models also offer the possibility to integrate physical knowledge into the generation process. We tailor latent diffusion models to sea-ice physics with a censored Gaussian distribution in data space to generate data that follows the physical bounds of the modelled variables. Our latent diffusion models reach similar scores as the diffusion model trained in data space, but they smooth the generated fields as caused by the latent mapping. While enforcing physical bounds cannot reduce the smoothing, it improves the representation of the marginal ice zone. Therefore, for large-scale Earth system modelling, latent diffusion models can have many advantages compared to diffusion in data space if the significant barrier of smoothing can be resolved.","sentences":["We make the first steps towards diffusion models for unconditional generation of multivariate and Arctic-wide sea-ice states.","While targeting to reduce the computational costs by diffusion in latent space, latent diffusion models also offer the possibility to integrate physical knowledge into the generation process.","We tailor latent diffusion models to sea-ice physics with a censored Gaussian distribution in data space to generate data that follows the physical bounds of the modelled variables.","Our latent diffusion models reach similar scores as the diffusion model trained in data space, but they smooth the generated fields as caused by the latent mapping.","While enforcing physical bounds cannot reduce the smoothing, it improves the representation of the marginal ice zone.","Therefore, for large-scale Earth system modelling, latent diffusion models can have many advantages compared to diffusion in data space if the significant barrier of smoothing can be resolved."],"url":"http://arxiv.org/abs/2406.18417v1"}
{"created":"2024-06-26 15:09:54","title":"BiTrack: Bidirectional Offline 3D Multi-Object Tracking Using Camera-LiDAR Data","abstract":"Compared with real-time multi-object tracking (MOT), offline multi-object tracking (OMOT) has the advantages to perform 2D-3D detection fusion, erroneous link correction, and full track optimization but has to deal with the challenges from bounding box misalignment and track evaluation, editing, and refinement. This paper proposes \"BiTrack\", a 3D OMOT framework that includes modules of 2D-3D detection fusion, initial trajectory generation, and bidirectional trajectory re-optimization to achieve optimal tracking results from camera-LiDAR data. The novelty of this paper includes threefold: (1) development of a point-level object registration technique that employs a density-based similarity metric to achieve accurate fusion of 2D-3D detection results; (2) development of a set of data association and track management skills that utilizes a vertex-based similarity metric as well as false alarm rejection and track recovery mechanisms to generate reliable bidirectional object trajectories; (3) development of a trajectory re-optimization scheme that re-organizes track fragments of different fidelities in a greedy fashion, as well as refines each trajectory with completion and smoothing techniques. The experiment results on the KITTI dataset demonstrate that BiTrack achieves the state-of-the-art performance for 3D OMOT tasks in terms of accuracy and efficiency.","sentences":["Compared with real-time multi-object tracking (MOT), offline multi-object tracking (OMOT) has the advantages to perform 2D-3D detection fusion, erroneous link correction, and full track optimization but has to deal with the challenges from bounding box misalignment and track evaluation, editing, and refinement.","This paper proposes \"BiTrack\", a 3D OMOT framework that includes modules of 2D-3D detection fusion, initial trajectory generation, and bidirectional trajectory re-optimization to achieve optimal tracking results from camera-LiDAR data.","The novelty of this paper includes threefold: (1) development of a point-level object registration technique that employs a density-based similarity metric to achieve accurate fusion of 2D-3D detection results; (2) development of a set of data association and track management skills that utilizes a vertex-based similarity metric as well as false alarm rejection and track recovery mechanisms to generate reliable bidirectional object trajectories; (3) development of a trajectory re-optimization scheme that re-organizes track fragments of different fidelities in a greedy fashion, as well as refines each trajectory with completion and smoothing techniques.","The experiment results on the KITTI dataset demonstrate that BiTrack achieves the state-of-the-art performance for 3D OMOT tasks in terms of accuracy and efficiency."],"url":"http://arxiv.org/abs/2406.18414v1"}
{"created":"2024-06-26 15:08:26","title":"Sensorless model-based tension control for a cable-driven exosuit","abstract":"Cable-driven exosuits have the potential to support individuals with motor disabilities across the continuum of care. When supporting a limb with a cable, force sensors are often used to measure tension. However, force sensors add cost, complexity, and distal components. This paper presents a design and control approach to remove the force sensor from an upper limb cable-driven exosuit. A mechanical design for the exosuit was developed to maximize passive transparency. Then, a data-driven friction identification was conducted on a mannequin test bench to design a model-based tension controller. Seventeen healthy participants raised and lowered their right arms to evaluate tension tracking, movement quality, and muscular effort. Questionnaires on discomfort, physical exertion, and fatigue were collected. The proposed strategy allowed tracking the desired assistive torque with an RMSE of 0.71 Nm (18%) at 50% gravity support. During the raising phase, the EMG signals of the anterior deltoid, trapezius, and pectoralis major were reduced on average compared to the no-suit condition by 30%, 38%, and 38%, respectively. The posterior deltoid activity was increased by 32% during lowering. Position tracking was not significantly altered, whereas movement smoothness significantly decreased. This work demonstrates the feasibility and effectiveness of removing the force sensor from a cable-driven exosuit. A significant increase in discomfort in the lower neck and right shoulder indicated that the ergonomics of the suit could be improved. Overall this work paves the way towards simpler and more affordable exosuits.","sentences":["Cable-driven exosuits have the potential to support individuals with motor disabilities across the continuum of care.","When supporting a limb with a cable, force sensors are often used to measure tension.","However, force sensors add cost, complexity, and distal components.","This paper presents a design and control approach to remove the force sensor from an upper limb cable-driven exosuit.","A mechanical design for the exosuit was developed to maximize passive transparency.","Then, a data-driven friction identification was conducted on a mannequin test bench to design a model-based tension controller.","Seventeen healthy participants raised and lowered their right arms to evaluate tension tracking, movement quality, and muscular effort.","Questionnaires on discomfort, physical exertion, and fatigue were collected.","The proposed strategy allowed tracking the desired assistive torque with an RMSE of 0.71 Nm (18%) at 50% gravity support.","During the raising phase, the EMG signals of the anterior deltoid, trapezius, and pectoralis major were reduced on average compared to the no-suit condition by 30%, 38%, and 38%, respectively.","The posterior deltoid activity was increased by 32% during lowering.","Position tracking was not significantly altered, whereas movement smoothness significantly decreased.","This work demonstrates the feasibility and effectiveness of removing the force sensor from a cable-driven exosuit.","A significant increase in discomfort in the lower neck and right shoulder indicated that the ergonomics of the suit could be improved.","Overall this work paves the way towards simpler and more affordable exosuits."],"url":"http://arxiv.org/abs/2406.18412v1"}
{"created":"2024-06-26 14:57:38","title":"IRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying and Reweighting Context-Aware Neurons","abstract":"It is widely acknowledged that large language models (LLMs) encode a vast reservoir of knowledge after being trained on mass data. Recent studies disclose knowledge conflicts in LLM generation, wherein outdated or incorrect parametric knowledge (i.e., encoded knowledge) contradicts new knowledge provided in the context. To mitigate such knowledge conflicts, we propose a novel framework, IRCAN (Identifying and Reweighting Context-Aware Neurons) to capitalize on neurons that are crucial in processing contextual cues. Specifically, IRCAN first identifies neurons that significantly contribute to context processing, utilizing a context-aware attribution score derived from integrated gradients. Subsequently, the identified context-aware neurons are strengthened via reweighting. In doing so, we steer LLMs to generate context-sensitive outputs with respect to the new knowledge provided in the context. Extensive experiments conducted across a variety of models and tasks demonstrate that IRCAN not only achieves remarkable improvements in handling knowledge conflicts but also offers a scalable, plug-andplay solution that can be integrated seamlessly with existing models.","sentences":["It is widely acknowledged that large language models (LLMs) encode a vast reservoir of knowledge after being trained on mass data.","Recent studies disclose knowledge conflicts in LLM generation, wherein outdated or incorrect parametric knowledge (i.e., encoded knowledge) contradicts new knowledge provided in the context.","To mitigate such knowledge conflicts, we propose a novel framework, IRCAN (Identifying and Reweighting Context-Aware Neurons) to capitalize on neurons that are crucial in processing contextual cues.","Specifically, IRCAN first identifies neurons that significantly contribute to context processing, utilizing a context-aware attribution score derived from integrated gradients.","Subsequently, the identified context-aware neurons are strengthened via reweighting.","In doing so, we steer LLMs to generate context-sensitive outputs with respect to the new knowledge provided in the context.","Extensive experiments conducted across a variety of models and tasks demonstrate that IRCAN not only achieves remarkable improvements in handling knowledge conflicts but also offers a scalable, plug-andplay solution that can be integrated seamlessly with existing models."],"url":"http://arxiv.org/abs/2406.18406v1"}
{"created":"2024-06-26 14:56:13","title":"LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks","abstract":"There is an increasing trend towards evaluating NLP models with LLM-generated judgments instead of human judgments. In the absence of a comparison against human data, this raises concerns about the validity of these evaluations; in case they are conducted with proprietary models, this also raises concerns over reproducibility. We provide JUDGE-BENCH, a collection of 20 NLP datasets with human annotations, and comprehensively evaluate 11 current LLMs, covering both open-weight and proprietary models, for their ability to replicate the annotations. Our evaluations show that each LLM exhibits a large variance across datasets in its correlation to human judgments. We conclude that LLMs are not yet ready to systematically replace human judges in NLP.","sentences":["There is an increasing trend towards evaluating NLP models with LLM-generated judgments instead of human judgments.","In the absence of a comparison against human data, this raises concerns about the validity of these evaluations; in case they are conducted with proprietary models, this also raises concerns over reproducibility.","We provide JUDGE-BENCH, a collection of 20 NLP datasets with human annotations, and comprehensively evaluate 11 current LLMs, covering both open-weight and proprietary models, for their ability to replicate the annotations.","Our evaluations show that each LLM exhibits a large variance across datasets in its correlation to human judgments.","We conclude that LLMs are not yet ready to systematically replace human judges in NLP."],"url":"http://arxiv.org/abs/2406.18403v1"}
{"created":"2024-06-26 14:49:54","title":"Do LLMs dream of elephants (when told not to)? Latent concept association and associative memory in transformers","abstract":"Large Language Models (LLMs) have the capacity to store and recall facts. Through experimentation with open-source models, we observe that this ability to retrieve facts can be easily manipulated by changing contexts, even without altering their factual meanings. These findings highlight that LLMs might behave like an associative memory model where certain tokens in the contexts serve as clues to retrieving facts. We mathematically explore this property by studying how transformers, the building blocks of LLMs, can complete such memory tasks. We study a simple latent concept association problem with a one-layer transformer and we show theoretically and empirically that the transformer gathers information using self-attention and uses the value matrix for associative memory.","sentences":["Large Language Models (LLMs) have the capacity to store and recall facts.","Through experimentation with open-source models, we observe that this ability to retrieve facts can be easily manipulated by changing contexts, even without altering their factual meanings.","These findings highlight that LLMs might behave like an associative memory model where certain tokens in the contexts serve as clues to retrieving facts.","We mathematically explore this property by studying how transformers, the building blocks of LLMs, can complete such memory tasks.","We study a simple latent concept association problem with a one-layer transformer and we show theoretically and empirically that the transformer gathers information using self-attention and uses the value matrix for associative memory."],"url":"http://arxiv.org/abs/2406.18400v1"}
{"created":"2024-06-26 14:30:56","title":"Blockchain Based Zero-Knowledge Proof of Location in IoT","abstract":"With the development of precise positioning technology, a growing number of location-based services (LBSs) facilitate people's life. Most LBSs require proof of location (PoL) to prove that the user satisfies the service requirement, which exposes the user's privacy. In this paper, we propose a zero-knowledge proof of location (zk-PoL) protocol to better protect the user's privacy. With the zk-PoL protocol, the user can choose necessary information to expose to the server, so that hierarchical privacy protection can be achieved. The evaluation shows that the zk-PoL has excellent security to resist main attacks, moreover the computational efficiency is independent of input parameters and the zk-PoL is appropriate to delay-tolerant LBSs.","sentences":["With the development of precise positioning technology, a growing number of location-based services (LBSs) facilitate people's life.","Most LBSs require proof of location (PoL) to prove that the user satisfies the service requirement, which exposes the user's privacy.","In this paper, we propose a zero-knowledge proof of location (zk-PoL) protocol to better protect the user's privacy.","With the zk-PoL protocol, the user can choose necessary information to expose to the server, so that hierarchical privacy protection can be achieved.","The evaluation shows that the zk-PoL has excellent security to resist main attacks, moreover the computational efficiency is independent of input parameters and the zk-PoL is appropriate to delay-tolerant LBSs."],"url":"http://arxiv.org/abs/2406.18389v1"}
{"created":"2024-06-26 14:30:51","title":"SAM: Semi-Active Mechanism for Extensible Continuum Manipulator and Real-time Hysteresis Compensation Control Algorithm","abstract":"Cable-Driven Continuum Manipulators (CDCMs) enable scar-free procedures via natural orifices and improve target lesion accessibility through curved paths. However, CDCMs face limitations in workspace and control accuracy due to non-linear cable effects causing hysteresis. This paper introduces an extensible CDCM with a Semi-active Mechanism (SAM) to expand the workspace via translational motion without additional mechanical elements or actuation. We collect a hysteresis dataset using 8 fiducial markers and RGBD sensing. Based on this dataset, we develop a real-time hysteresis compensation control algorithm using the trained Temporal Convolutional Network (TCN) with a 1ms time latency, effectively estimating the manipulator's hysteresis behavior. Performance validation through random trajectory tracking tests and box pointing tasks shows the proposed controller significantly reduces hysteresis by up to 69.5% in joint space and approximately 26% in the box pointing task.","sentences":["Cable-Driven Continuum Manipulators (CDCMs) enable scar-free procedures via natural orifices and improve target lesion accessibility through curved paths.","However, CDCMs face limitations in workspace and control accuracy due to non-linear cable effects causing hysteresis.","This paper introduces an extensible CDCM with a Semi-active Mechanism (SAM) to expand the workspace via translational motion without additional mechanical elements or actuation.","We collect a hysteresis dataset using 8 fiducial markers and RGBD sensing.","Based on this dataset, we develop a real-time hysteresis compensation control algorithm using the trained Temporal Convolutional Network (TCN) with a 1ms time latency, effectively estimating the manipulator's hysteresis behavior.","Performance validation through random trajectory tracking tests and box pointing tasks shows the proposed controller significantly reduces hysteresis by up to 69.5% in joint space and approximately 26% in the box pointing task."],"url":"http://arxiv.org/abs/2406.18388v1"}
{"created":"2024-06-26 14:29:05","title":"DoubleTake: Geometry Guided Depth Estimation","abstract":"Estimating depth from a sequence of posed RGB images is a fundamental computer vision task, with applications in augmented reality, path planning etc. Prior work typically makes use of previous frames in a multi view stereo framework, relying on matching textures in a local neighborhood. In contrast, our model leverages historical predictions by giving the latest 3D geometry data as an extra input to our network. This self-generated geometric hint can encode information from areas of the scene not covered by the keyframes and it is more regularized when compared to individual predicted depth maps for previous frames. We introduce a Hint MLP which combines cost volume features with a hint of the prior geometry, rendered as a depth map from the current camera location, together with a measure of the confidence in the prior geometry. We demonstrate that our method, which can run at interactive speeds, achieves state-of-the-art estimates of depth and 3D scene reconstruction in both offline and incremental evaluation scenarios.","sentences":["Estimating depth from a sequence of posed RGB images is a fundamental computer vision task, with applications in augmented reality, path planning etc.","Prior work typically makes use of previous frames in a multi view stereo framework, relying on matching textures in a local neighborhood.","In contrast, our model leverages historical predictions by giving the latest 3D geometry data as an extra input to our network.","This self-generated geometric hint can encode information from areas of the scene not covered by the keyframes and it is more regularized when compared to individual predicted depth maps for previous frames.","We introduce a Hint MLP which combines cost volume features with a hint of the prior geometry, rendered as a depth map from the current camera location, together with a measure of the confidence in the prior geometry.","We demonstrate that our method, which can run at interactive speeds, achieves state-of-the-art estimates of depth and 3D scene reconstruction in both offline and incremental evaluation scenarios."],"url":"http://arxiv.org/abs/2406.18387v1"}
{"created":"2024-06-26 14:24:58","title":"Rauzy dimension and finite-state dimension","abstract":"In a paper of 1976, Rauzy studied two complexity notions, $\\underline{\\beta}$ and $\\overline{\\beta}$, for infinite sequences over a finite alphabet. The function $\\underline{\\beta}$ is maximum exactly in the Borel normal sequences and $\\overline{\\beta}$ is minimum exactly in the sequences that, when added to any Borel normal sequence, the result is also Borel normal. Although the definition of $\\underline{\\beta}$ and $\\overline{\\beta}$ do not involve finite-state automata, we establish some connections between them and the lower $\\underline{\\rm dim}$ and upper $\\overline{\\rm dim}$ finite-state dimension (or other equivalent notions like finite-state compression ratio, aligned-entropy or cumulative log-loss of finite-state predictors). We show tight lower and upper bounds on $\\underline{\\rm dim}$ and $\\overline{\\rm dim}$ as functions of $\\underline{\\beta}$ and $\\overline{\\beta}$, respectively. In particular this implies that sequences with $\\overline{\\rm dim}$ zero are exactly the ones that that, when added to any Borel normal sequence, the result is also Borel normal. We also show that the finite-state dimensions $\\underline{\\rm dim}$ and $\\overline{\\rm dim}$ are essentially subadditive. We need two technical tools that are of independent interest. One is the family of local finite-state automata, which are automata whose memory consists of the last $k$ read symbols for some fixed integer $k$. We show that compressors based on local finite-state automata are as good as standard finite-state compressors. The other one is a notion of finite-state relational (non-deterministic) compressor, which can compress an input in several ways provided the input can always be recovered from any of its outputs. We show that such compressors cannot compress more than standard (deterministic) finite-state compressors.","sentences":["In a paper of 1976, Rauzy studied two complexity notions, $\\underline{\\beta}$ and $\\overline{\\beta}$, for infinite sequences over a finite alphabet.","The function $\\underline{\\beta}$ is maximum exactly in the Borel normal sequences and $\\overline{\\beta}$ is minimum exactly in the sequences that, when added to any Borel normal sequence, the result is also Borel normal.","Although the definition of $\\underline{\\beta}$ and $\\overline{\\beta}$ do not involve finite-state automata, we establish some connections between them and the lower $\\underline{\\rm dim}$ and upper $\\overline{\\rm dim}$ finite-state dimension (or other equivalent notions like finite-state compression ratio, aligned-entropy or cumulative log-loss of finite-state predictors).","We show tight lower and upper bounds on $\\underline{\\rm dim}$ and $\\overline{\\rm dim}$ as functions of $\\underline{\\beta}$ and $\\overline{\\beta}$, respectively.","In particular this implies that sequences with $\\overline{\\rm dim}$ zero are exactly the ones that that, when added to any Borel normal sequence, the result is also Borel normal.","We also show that the finite-state dimensions $\\underline{\\rm dim}$ and $\\overline{\\rm dim}$ are essentially subadditive.","We need two technical tools that are of independent interest.","One is the family of local finite-state automata, which are automata whose memory consists of the last $k$ read symbols for some fixed integer $k$.","We show that compressors based on local finite-state automata are as good as standard finite-state compressors.","The other one is a notion of finite-state relational (non-deterministic) compressor, which can compress an input in several ways provided the input can always be recovered from any of its outputs.","We show that such compressors cannot compress more than standard (deterministic) finite-state compressors."],"url":"http://arxiv.org/abs/2406.18383v1"}
{"created":"2024-06-26 14:24:51","title":"Adversarial Search Engine Optimization for Large Language Models","abstract":"Large Language Models (LLMs) are increasingly used in applications where the model selects from competing third-party content, such as in LLM-powered search engines or chatbot plugins. In this paper, we introduce Preference Manipulation Attacks, a new class of attacks that manipulate an LLM's selections to favor the attacker. We demonstrate that carefully crafted website content or plugin documentations can trick an LLM to promote the attacker products and discredit competitors, thereby increasing user traffic and monetization. We show this leads to a prisoner's dilemma, where all parties are incentivized to launch attacks, but the collective effect degrades the LLM's outputs for everyone. We demonstrate our attacks on production LLM search engines (Bing and Perplexity) and plugin APIs (for GPT-4 and Claude). As LLMs are increasingly used to rank third-party content, we expect Preference Manipulation Attacks to emerge as a significant threat.","sentences":["Large Language Models (LLMs) are increasingly used in applications where the model selects from competing third-party content, such as in LLM-powered search engines or chatbot plugins.","In this paper, we introduce Preference Manipulation Attacks, a new class of attacks that manipulate an LLM's selections to favor the attacker.","We demonstrate that carefully crafted website content or plugin documentations can trick an LLM to promote the attacker products and discredit competitors, thereby increasing user traffic and monetization.","We show this leads to a prisoner's dilemma, where all parties are incentivized to launch attacks, but the collective effect degrades the LLM's outputs for everyone.","We demonstrate our attacks on production LLM search engines (Bing and Perplexity) and plugin APIs (for GPT-4 and Claude).","As LLMs are increasingly used to rank third-party content, we expect Preference Manipulation Attacks to emerge as a significant threat."],"url":"http://arxiv.org/abs/2406.18382v1"}
{"created":"2024-06-26 14:24:07","title":"Robotic Exploration through Semantic Topometric Mapping","abstract":"In this article, we introduce a novel strategy for robotic exploration in unknown environments using a semantic topometric map. As it will be presented, the semantic topometric map is generated by segmenting the grid map of the currently explored parts of the environment into regions, such as intersections, pathways, dead-ends, and unexplored frontiers, which constitute the structural semantics of an environment. The proposed exploration strategy leverages metric information of the frontier, such as distance and angle to the frontier, similar to existing frameworks, with the key difference being the additional utilization of structural semantic information, such as properties of the intersections leading to frontiers. The algorithm for generating semantic topometric mapping utilized by the proposed method is lightweight, resulting in the method's online execution being both rapid and computationally efficient. Moreover, the proposed framework can be applied to both structured and unstructured indoor and outdoor environments, which enhances the versatility of the proposed exploration algorithm. We validate our exploration strategy and demonstrate the utility of structural semantics in exploration in two complex indoor environments by utilizing a Turtlebot3 as the robotic agent. Compared to traditional frontier-based methods, our findings indicate that the proposed approach leads to faster exploration and requires less computation time.","sentences":["In this article, we introduce a novel strategy for robotic exploration in unknown environments using a semantic topometric map.","As it will be presented, the semantic topometric map is generated by segmenting the grid map of the currently explored parts of the environment into regions, such as intersections, pathways, dead-ends, and unexplored frontiers, which constitute the structural semantics of an environment.","The proposed exploration strategy leverages metric information of the frontier, such as distance and angle to the frontier, similar to existing frameworks, with the key difference being the additional utilization of structural semantic information, such as properties of the intersections leading to frontiers.","The algorithm for generating semantic topometric mapping utilized by the proposed method is lightweight, resulting in the method's online execution being both rapid and computationally efficient.","Moreover, the proposed framework can be applied to both structured and unstructured indoor and outdoor environments, which enhances the versatility of the proposed exploration algorithm.","We validate our exploration strategy and demonstrate the utility of structural semantics in exploration in two complex indoor environments by utilizing a Turtlebot3 as the robotic agent.","Compared to traditional frontier-based methods, our findings indicate that the proposed approach leads to faster exploration and requires less computation time."],"url":"http://arxiv.org/abs/2406.18381v1"}
{"created":"2024-06-26 14:21:21","title":"KAGNNs: Kolmogorov-Arnold Networks meet Graph Learning","abstract":"In recent years, Graph Neural Networks (GNNs) have become the de facto tool for learning node and graph representations. Most GNNs typically consist of a sequence of neighborhood aggregation (a.k.a., message passing) layers. Within each of these layers, the representation of each node is updated from an aggregation and transformation of its neighbours representations at the previous layer. The upper bound for the expressive power of message passing GNNs was reached through the use of MLPs as a transformation, due to their universal approximation capabilities. However, MLPs suffer from well-known limitations, which recently motivated the introduction of Kolmogorov-Arnold Networks (KANs). KANs rely on the Kolmogorov-Arnold representation theorem, rendering them a promising alternative to MLPs. In this work, we compare the performance of KANs against that of MLPs in graph learning tasks. We perform extensive experiments on node classification, graph classification and graph regression datasets. Our preliminary results indicate that while KANs are on-par with MLPs in classification tasks, they seem to have a clear advantage in the graph regression tasks.","sentences":["In recent years, Graph Neural Networks (GNNs) have become the de facto tool for learning node and graph representations.","Most GNNs typically consist of a sequence of neighborhood aggregation (a.k.a., message passing) layers.","Within each of these layers, the representation of each node is updated from an aggregation and transformation of its neighbours representations at the previous layer.","The upper bound for the expressive power of message passing GNNs was reached through the use of MLPs as a transformation, due to their universal approximation capabilities.","However, MLPs suffer from well-known limitations, which recently motivated the introduction of Kolmogorov-Arnold Networks (KANs).","KANs rely on the Kolmogorov-Arnold representation theorem, rendering them a promising alternative to MLPs.","In this work, we compare the performance of KANs against that of MLPs in graph learning tasks.","We perform extensive experiments on node classification, graph classification and graph regression datasets.","Our preliminary results indicate that while KANs are on-par with MLPs in classification tasks, they seem to have a clear advantage in the graph regression tasks."],"url":"http://arxiv.org/abs/2406.18380v1"}
{"created":"2024-06-26 14:21:09","title":"MALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization","abstract":"Binary malware summarization aims to automatically generate human-readable descriptions of malware behaviors from executable files, facilitating tasks like malware cracking and detection. Previous methods based on Large Language Models (LLMs) have shown great promise. However, they still face significant issues, including poor usability, inaccurate explanations, and incomplete summaries, primarily due to the obscure pseudocode structure and the lack of malware training summaries. Further, calling relationships between functions, which involve the rich interactions within a binary malware, remain largely underexplored. To this end, we propose MALSIGHT, a novel code summarization framework that can iteratively generate descriptions of binary malware by exploring malicious source code and benign pseudocode. Specifically, we construct the first malware summaries, MalS and MalP, using an LLM and manually refine this dataset with human effort. At the training stage, we tune our proposed MalT5, a novel LLM-based code model, on the MalS dataset and a benign pseudocode dataset. Then, at the test stage, we iteratively feed the pseudocode functions into MalT5 to obtain the summary. Such a procedure facilitates the understanding of pseudocode structure and captures the intricate interactions between functions, thereby benefiting the usability, accuracy, and completeness of summaries. Additionally, we propose a novel evaluation benchmark, BLEURT-sum, to measure the quality of summaries. Experiments on three datasets show the effectiveness of the proposed MALSIGHT. Notably, our proposed MalT5, with only 0.77B parameters, delivers comparable performance to much larger ChatGPT3.5.","sentences":["Binary malware summarization aims to automatically generate human-readable descriptions of malware behaviors from executable files, facilitating tasks like malware cracking and detection.","Previous methods based on Large Language Models (LLMs) have shown great promise.","However, they still face significant issues, including poor usability, inaccurate explanations, and incomplete summaries, primarily due to the obscure pseudocode structure and the lack of malware training summaries.","Further, calling relationships between functions, which involve the rich interactions within a binary malware, remain largely underexplored.","To this end, we propose MALSIGHT, a novel code summarization framework that can iteratively generate descriptions of binary malware by exploring malicious source code and benign pseudocode.","Specifically, we construct the first malware summaries, MalS and MalP, using an LLM and manually refine this dataset with human effort.","At the training stage, we tune our proposed MalT5, a novel LLM-based code model, on the MalS dataset and a benign pseudocode dataset.","Then, at the test stage, we iteratively feed the pseudocode functions into MalT5 to obtain the summary.","Such a procedure facilitates the understanding of pseudocode structure and captures the intricate interactions between functions, thereby benefiting the usability, accuracy, and completeness of summaries.","Additionally, we propose a novel evaluation benchmark, BLEURT-sum, to measure the quality of summaries.","Experiments on three datasets show the effectiveness of the proposed MALSIGHT.","Notably, our proposed MalT5, with only 0.77B parameters, delivers comparable performance to much larger ChatGPT3.5."],"url":"http://arxiv.org/abs/2406.18379v1"}
{"created":"2024-06-26 14:19:31","title":"From Majority to Minority: A Diffusion-based Augmentation for Underrepresented Groups in Skin Lesion Analysis","abstract":"AI-based diagnoses have demonstrated dermatologist-level performance in classifying skin cancer. However, such systems are prone to under-performing when tested on data from minority groups that lack sufficient representation in the training sets. Although data collection and annotation offer the best means for promoting minority groups, these processes are costly and time-consuming. Prior works have suggested that data from majority groups may serve as a valuable information source to supplement the training of diagnosis tools for minority groups. In this work, we propose an effective diffusion-based augmentation framework that maximizes the use of rich information from majority groups to benefit minority groups. Using groups with different skin types as a case study, our results show that the proposed framework can generate synthetic images that improve diagnostic results for the minority groups, even when there is little or no reference data from these target groups. The practical value of our work is evident in medical imaging analysis, where under-diagnosis persists as a problem for certain groups due to insufficient representation.","sentences":["AI-based diagnoses have demonstrated dermatologist-level performance in classifying skin cancer.","However, such systems are prone to under-performing when tested on data from minority groups that lack sufficient representation in the training sets.","Although data collection and annotation offer the best means for promoting minority groups, these processes are costly and time-consuming.","Prior works have suggested that data from majority groups may serve as a valuable information source to supplement the training of diagnosis tools for minority groups.","In this work, we propose an effective diffusion-based augmentation framework that maximizes the use of rich information from majority groups to benefit minority groups.","Using groups with different skin types as a case study, our results show that the proposed framework can generate synthetic images that improve diagnostic results for the minority groups, even when there is little or no reference data from these target groups.","The practical value of our work is evident in medical imaging analysis, where under-diagnosis persists as a problem for certain groups due to insufficient representation."],"url":"http://arxiv.org/abs/2406.18375v1"}
{"created":"2024-06-26 14:17:36","title":"Dynamic Data Pruning for Automatic Speech Recognition","abstract":"The recent success of Automatic Speech Recognition (ASR) is largely attributed to the ever-growing amount of training data. However, this trend has made model training prohibitively costly and imposed computational demands. While data pruning has been proposed to mitigate this issue by identifying a small subset of relevant data, its application in ASR has been barely explored, and existing works often entail significant overhead to achieve meaningful results. To fill this gap, this paper presents the first investigation of dynamic data pruning for ASR, finding that we can reach the full-data performance by dynamically selecting 70% of data. Furthermore, we introduce Dynamic Data Pruning for ASR (DDP-ASR), which offers several fine-grained pruning granularities specifically tailored for speech-related datasets, going beyond the conventional pruning of entire time sequences. Our intensive experiments show that DDP-ASR can save up to 1.6x training time with negligible performance loss.","sentences":["The recent success of Automatic Speech Recognition (ASR) is largely attributed to the ever-growing amount of training data.","However, this trend has made model training prohibitively costly and imposed computational demands.","While data pruning has been proposed to mitigate this issue by identifying a small subset of relevant data, its application in ASR has been barely explored, and existing works often entail significant overhead to achieve meaningful results.","To fill this gap, this paper presents the first investigation of dynamic data pruning for ASR, finding that we can reach the full-data performance by dynamically selecting 70% of data.","Furthermore, we introduce Dynamic Data Pruning for ASR (DDP-ASR), which offers several fine-grained pruning granularities specifically tailored for speech-related datasets, going beyond the conventional pruning of entire time sequences.","Our intensive experiments show that DDP-ASR can save up to 1.6x training time with negligible performance loss."],"url":"http://arxiv.org/abs/2406.18373v1"}
{"created":"2024-06-26 14:16:22","title":"A Lightweight Algorithm for Classifying Ex Vivo Tissues Samples","abstract":"In this paper, we present a novel algorithm for classifying ex vivo tissue that comprises multi-channel bioimpedance analysis and a hardware neural network. When implemented in a mixed-signal 180 nm CMOS process, the classifier has an estimated power budget of 39 mW and an area of 30 mm2. This means that the classifier can be integrated into the tip of a surgical margin assessment probe, for in vivo use during radical prostatectomy. We tested our classifier on digital phantoms of prostate tissue and also on an animal model of ex vivo bovine tissue. The classifier achieved an accuracy of 90% on the prostate tissue phantoms, and an accuracy of 84% on the animal model.","sentences":["In this paper, we present a novel algorithm for classifying ex vivo tissue that comprises multi-channel bioimpedance analysis and a hardware neural network.","When implemented in a mixed-signal 180 nm CMOS process, the classifier has an estimated power budget of 39 mW and an area of 30 mm2.","This means that the classifier can be integrated into the tip of a surgical margin assessment probe, for in vivo use during radical prostatectomy.","We tested our classifier on digital phantoms of prostate tissue and also on an animal model of ex vivo bovine tissue.","The classifier achieved an accuracy of 90% on the prostate tissue phantoms, and an accuracy of 84% on the animal model."],"url":"http://arxiv.org/abs/2406.18372v1"}
{"created":"2024-06-26 14:04:29","title":"Themis: Towards Flexible and Interpretable NLG Evaluation","abstract":"The evaluation of natural language generation (NLG) tasks is a significant and longstanding research issue. With the recent emergence of powerful large language models (LLMs), some studies have turned to LLM-based automatic evaluation methods, which demonstrate great potential to become a new evaluation paradigm following traditional string-based and model-based metrics. However, despite the improved performance of existing methods, they still possess some deficiencies, such as dependency on references and limited evaluation flexibility. Therefore, in this paper, we meticulously construct a large-scale NLG evaluation corpus NLG-Eval with human and GPT-4 annotations to alleviate the lack of relevant data in this field. Furthermore, we propose Themis, an LLM dedicated to NLG evaluation, which has been trained with our designed multi-perspective consistency and rating-oriented preference alignment methods. Themis can conduct flexible and interpretable evaluations without references, and it exhibits superior evaluation performance on various NLG tasks, simultaneously generalizing well to unseen tasks and surpassing other evaluation models, including GPT-4.","sentences":["The evaluation of natural language generation (NLG) tasks is a significant and longstanding research issue.","With the recent emergence of powerful large language models (LLMs), some studies have turned to LLM-based automatic evaluation methods, which demonstrate great potential to become a new evaluation paradigm following traditional string-based and model-based metrics.","However, despite the improved performance of existing methods, they still possess some deficiencies, such as dependency on references and limited evaluation flexibility.","Therefore, in this paper, we meticulously construct a large-scale NLG evaluation corpus NLG-Eval with human and GPT-4 annotations to alleviate the lack of relevant data in this field.","Furthermore, we propose Themis, an LLM dedicated to NLG evaluation, which has been trained with our designed multi-perspective consistency and rating-oriented preference alignment methods.","Themis can conduct flexible and interpretable evaluations without references, and it exhibits superior evaluation performance on various NLG tasks, simultaneously generalizing well to unseen tasks and surpassing other evaluation models, including GPT-4."],"url":"http://arxiv.org/abs/2406.18365v1"}
{"created":"2024-06-26 14:04:15","title":"Research on Information Extraction of LCSTS Dataset Based on an Improved BERTSum-LSTM Model","abstract":"With the continuous advancement of artificial intelligence, natural language processing technology has become widely utilized in various fields. At the same time, there are many challenges in creating Chinese news summaries. First of all, the semantics of Chinese news is complex, and the amount of information is enormous. Extracting critical information from Chinese news presents a significant challenge. Second, the news summary should be concise and clear, focusing on the main content and avoiding redundancy. In addition, the particularity of the Chinese language, such as polysemy, word segmentation, etc., makes it challenging to generate Chinese news summaries. Based on the above, this paper studies the information extraction method of the LCSTS dataset based on an improved BERTSum-LSTM model. We improve the BERTSum-LSTM model to make it perform better in generating Chinese news summaries. The experimental results show that the proposed method has a good effect on creating news summaries, which is of great importance to the construction of news summaries.","sentences":["With the continuous advancement of artificial intelligence, natural language processing technology has become widely utilized in various fields.","At the same time, there are many challenges in creating Chinese news summaries.","First of all, the semantics of Chinese news is complex, and the amount of information is enormous.","Extracting critical information from Chinese news presents a significant challenge.","Second, the news summary should be concise and clear, focusing on the main content and avoiding redundancy.","In addition, the particularity of the Chinese language, such as polysemy, word segmentation, etc., makes it challenging to generate Chinese news summaries.","Based on the above, this paper studies the information extraction method of the LCSTS dataset based on an improved BERTSum-LSTM model.","We improve the BERTSum-LSTM model to make it perform better in generating Chinese news summaries.","The experimental results show that the proposed method has a good effect on creating news summaries, which is of great importance to the construction of news summaries."],"url":"http://arxiv.org/abs/2406.18364v1"}
{"created":"2024-06-26 14:01:07","title":"Stable Diffusion Segmentation for Biomedical Images with Single-step Reverse Process","abstract":"Diffusion models have demonstrated their effectiveness across various generative tasks. However, when applied to medical image segmentation, these models encounter several challenges, including significant resource and time requirements. They also necessitate a multi-step reverse process and multiple samples to produce reliable predictions. To address these challenges, we introduce the first latent diffusion segmentation model, named SDSeg, built upon stable diffusion (SD). SDSeg incorporates a straightforward latent estimation strategy to facilitate a single-step reverse process and utilizes latent fusion concatenation to remove the necessity for multiple samples. Extensive experiments indicate that SDSeg surpasses existing state-of-the-art methods on five benchmark datasets featuring diverse imaging modalities. Remarkably, SDSeg is capable of generating stable predictions with a solitary reverse step and sample, epitomizing the model's stability as implied by its name. The code is available at https://github.com/lin-tianyu/Stable-Diffusion-Seg","sentences":["Diffusion models have demonstrated their effectiveness across various generative tasks.","However, when applied to medical image segmentation, these models encounter several challenges, including significant resource and time requirements.","They also necessitate a multi-step reverse process and multiple samples to produce reliable predictions.","To address these challenges, we introduce the first latent diffusion segmentation model, named SDSeg, built upon stable diffusion (SD).","SDSeg incorporates a straightforward latent estimation strategy to facilitate a single-step reverse process and utilizes latent fusion concatenation to remove the necessity for multiple samples.","Extensive experiments indicate that SDSeg surpasses existing state-of-the-art methods on five benchmark datasets featuring diverse imaging modalities.","Remarkably, SDSeg is capable of generating stable predictions with a solitary reverse step and sample, epitomizing the model's stability as implied by its name.","The code is available at https://github.com/lin-tianyu/Stable-Diffusion-Seg"],"url":"http://arxiv.org/abs/2406.18361v1"}
{"created":"2024-06-26 14:00:21","title":"XLD: A Cross-Lane Dataset for Benchmarking Novel Driving View Synthesis","abstract":"Thoroughly testing autonomy systems is crucial in the pursuit of safe autonomous driving vehicles. It necessitates creating safety-critical scenarios that go beyond what can be safely collected from real-world data, as many of these scenarios occur infrequently on public roads. However, the evaluation of most existing NVS methods relies on sporadic sampling of image frames from the training data, comparing the rendered images with ground truth images using metrics. Unfortunately, this evaluation protocol falls short of meeting the actual requirements in closed-loop simulations. Specifically, the true application demands the capability to render novel views that extend beyond the original trajectory (such as cross-lane views), which are challenging to capture in the real world. To address this, this paper presents a novel driving view synthesis dataset and benchmark specifically designed for autonomous driving simulations. This dataset is unique as it includes testing images captured by deviating from the training trajectory by 1-4 meters. It comprises six sequences encompassing various time and weather conditions. Each sequence contains 450 training images, 150 testing images, and their corresponding camera poses and intrinsic parameters. Leveraging this novel dataset, we establish the first realistic benchmark for evaluating existing NVS approaches under front-only and multi-camera settings. The experimental findings underscore the significant gap that exists in current approaches, revealing their inadequate ability to fulfill the demanding prerequisites of cross-lane or closed-loop simulation. Our dataset is released publicly at the project page: https://3d-aigc.github.io/XLD/.","sentences":["Thoroughly testing autonomy systems is crucial in the pursuit of safe autonomous driving vehicles.","It necessitates creating safety-critical scenarios that go beyond what can be safely collected from real-world data, as many of these scenarios occur infrequently on public roads.","However, the evaluation of most existing NVS methods relies on sporadic sampling of image frames from the training data, comparing the rendered images with ground truth images using metrics.","Unfortunately, this evaluation protocol falls short of meeting the actual requirements in closed-loop simulations.","Specifically, the true application demands the capability to render novel views that extend beyond the original trajectory (such as cross-lane views), which are challenging to capture in the real world.","To address this, this paper presents a novel driving view synthesis dataset and benchmark specifically designed for autonomous driving simulations.","This dataset is unique as it includes testing images captured by deviating from the training trajectory by 1-4 meters.","It comprises six sequences encompassing various time and weather conditions.","Each sequence contains 450 training images, 150 testing images, and their corresponding camera poses and intrinsic parameters.","Leveraging this novel dataset, we establish the first realistic benchmark for evaluating existing NVS approaches under front-only and multi-camera settings.","The experimental findings underscore the significant gap that exists in current approaches, revealing their inadequate ability to fulfill the demanding prerequisites of cross-lane or closed-loop simulation.","Our dataset is released publicly at the project page: https://3d-aigc.github.io/XLD/."],"url":"http://arxiv.org/abs/2406.18360v1"}
{"created":"2024-06-26 13:54:59","title":"Kolmogorov-Arnold Graph Neural Networks","abstract":"Graph neural networks (GNNs) excel in learning from network-like data but often lack interpretability, making their application challenging in domains requiring transparent decision-making. We propose the Graph Kolmogorov-Arnold Network (GKAN), a novel GNN model leveraging spline-based activation functions on edges to enhance both accuracy and interpretability. Our experiments on five benchmark datasets demonstrate that GKAN outperforms state-of-the-art GNN models in node classification, link prediction, and graph classification tasks. In addition to the improved accuracy, GKAN's design inherently provides clear insights into the model's decision-making process, eliminating the need for post-hoc explainability techniques. This paper discusses the methodology, performance, and interpretability of GKAN, highlighting its potential for applications in domains where interpretability is crucial.","sentences":["Graph neural networks (GNNs) excel in learning from network-like data but often lack interpretability, making their application challenging in domains requiring transparent decision-making.","We propose the Graph Kolmogorov-Arnold Network (GKAN), a novel GNN model leveraging spline-based activation functions on edges to enhance both accuracy and interpretability.","Our experiments on five benchmark datasets demonstrate that GKAN outperforms state-of-the-art GNN models in node classification, link prediction, and graph classification tasks.","In addition to the improved accuracy, GKAN's design inherently provides clear insights into the model's decision-making process, eliminating the need for post-hoc explainability techniques.","This paper discusses the methodology, performance, and interpretability of GKAN, highlighting its potential for applications in domains where interpretability is crucial."],"url":"http://arxiv.org/abs/2406.18354v1"}
{"created":"2024-06-26 13:52:47","title":"Reinforcement Learning with Intrinsically Motivated Feedback Graph for Lost-sales Inventory Control","abstract":"Reinforcement learning (RL) has proven to be well-performed and general-purpose in the inventory control (IC). However, further improvement of RL algorithms in the IC domain is impeded due to two limitations of online experience. First, online experience is expensive to acquire in real-world applications. With the low sample efficiency nature of RL algorithms, it would take extensive time to train the RL policy to convergence. Second, online experience may not reflect the true demand due to the lost sales phenomenon typical in IC, which makes the learning process more challenging. To address the above challenges, we propose a decision framework that combines reinforcement learning with feedback graph (RLFG) and intrinsically motivated exploration (IME) to boost sample efficiency. In particular, we first take advantage of the inherent properties of lost-sales IC problems and design the feedback graph (FG) specially for lost-sales IC problems to generate abundant side experiences aid RL updates. Then we conduct a rigorous theoretical analysis of how the designed FG reduces the sample complexity of RL methods. Based on the theoretical insights, we design an intrinsic reward to direct the RL agent to explore to the state-action space with more side experiences, further exploiting FG's power. Experimental results demonstrate that our method greatly improves the sample efficiency of applying RL in IC. Our code is available at https://anonymous.4open.science/r/RLIMFG4IC-811D/","sentences":["Reinforcement learning (RL) has proven to be well-performed and general-purpose in the inventory control (IC).","However, further improvement of RL algorithms in the IC domain is impeded due to two limitations of online experience.","First, online experience is expensive to acquire in real-world applications.","With the low sample efficiency nature of RL algorithms, it would take extensive time to train the RL policy to convergence.","Second, online experience may not reflect the true demand due to the lost sales phenomenon typical in IC, which makes the learning process more challenging.","To address the above challenges, we propose a decision framework that combines reinforcement learning with feedback graph (RLFG) and intrinsically motivated exploration (IME) to boost sample efficiency.","In particular, we first take advantage of the inherent properties of lost-sales IC problems and design the feedback graph (FG) specially for lost-sales IC problems to generate abundant side experiences aid RL updates.","Then we conduct a rigorous theoretical analysis of how the designed FG reduces the sample complexity of RL methods.","Based on the theoretical insights, we design an intrinsic reward to direct the RL agent to explore to the state-action space with more side experiences, further exploiting FG's power.","Experimental results demonstrate that our method greatly improves the sample efficiency of applying RL in IC.","Our code is available at https://anonymous.4open.science/r/RLIMFG4IC-811D/"],"url":"http://arxiv.org/abs/2406.18351v1"}
{"created":"2024-06-26 13:51:57","title":"On Reducing Activity with Distillation and Regularization for Energy Efficient Spiking Neural Networks","abstract":"Interest in spiking neural networks (SNNs) has been growing steadily, promising an energy-efficient alternative to formal neural networks (FNNs), commonly known as artificial neural networks (ANNs). Despite increasing interest, especially for Edge applications, these event-driven neural networks suffered from their difficulty to be trained compared to FNNs. To alleviate this problem, a number of innovative methods have been developed to provide performance more or less equivalent to that of FNNs. However, the spiking activity of a network during inference is usually not considered. While SNNs may usually have performance comparable to that of FNNs, it is often at the cost of an increase of the network's activity, thus limiting the benefit of using them as a more energy-efficient solution.   In this paper, we propose to leverage Knowledge Distillation (KD) for SNNs training with surrogate gradient descent in order to optimize the trade-off between performance and spiking activity. Then, after understanding why KD led to an increase in sparsity, we also explored Activations regularization and proposed a novel method with Logits Regularization. These approaches, validated on several datasets, clearly show a reduction in network spiking activity (-26.73% on GSC and -14.32% on CIFAR-10) while preserving accuracy.","sentences":["Interest in spiking neural networks (SNNs) has been growing steadily, promising an energy-efficient alternative to formal neural networks (FNNs), commonly known as artificial neural networks (ANNs).","Despite increasing interest, especially for Edge applications, these event-driven neural networks suffered from their difficulty to be trained compared to FNNs.","To alleviate this problem, a number of innovative methods have been developed to provide performance more or less equivalent to that of FNNs.","However, the spiking activity of a network during inference is usually not considered.","While SNNs may usually have performance comparable to that of FNNs, it is often at the cost of an increase of the network's activity, thus limiting the benefit of using them as a more energy-efficient solution.   ","In this paper, we propose to leverage Knowledge Distillation (KD) for SNNs training with surrogate gradient descent in order to optimize the trade-off between performance and spiking activity.","Then, after understanding why KD led to an increase in sparsity, we also explored Activations regularization and proposed a novel method with Logits Regularization.","These approaches, validated on several datasets, clearly show a reduction in network spiking activity (-26.73% on GSC and -14.32% on CIFAR-10) while preserving accuracy."],"url":"http://arxiv.org/abs/2406.18350v1"}
{"created":"2024-06-26 13:42:13","title":"AI Alignment through Reinforcement Learning from Human Feedback? Contradictions and Limitations","abstract":"This paper critically evaluates the attempts to align Artificial Intelligence (AI) systems, especially Large Language Models (LLMs), with human values and intentions through Reinforcement Learning from Feedback (RLxF) methods, involving either human feedback (RLHF) or AI feedback (RLAIF). Specifically, we show the shortcomings of the broadly pursued alignment goals of honesty, harmlessness, and helpfulness. Through a multidisciplinary sociotechnical critique, we examine both the theoretical underpinnings and practical implementations of RLxF techniques, revealing significant limitations in their approach to capturing the complexities of human ethics and contributing to AI safety. We highlight tensions and contradictions inherent in the goals of RLxF. In addition, we discuss ethically-relevant issues that tend to be neglected in discussions about alignment and RLxF, among which the trade-offs between user-friendliness and deception, flexibility and interpretability, and system safety. We conclude by urging researchers and practitioners alike to critically assess the sociotechnical ramifications of RLxF, advocating for a more nuanced and reflective approach to its application in AI development.","sentences":["This paper critically evaluates the attempts to align Artificial Intelligence (AI) systems, especially Large Language Models (LLMs), with human values and intentions through Reinforcement Learning from Feedback (RLxF) methods, involving either human feedback (RLHF) or AI feedback (RLAIF).","Specifically, we show the shortcomings of the broadly pursued alignment goals of honesty, harmlessness, and helpfulness.","Through a multidisciplinary sociotechnical critique, we examine both the theoretical underpinnings and practical implementations of RLxF techniques, revealing significant limitations in their approach to capturing the complexities of human ethics and contributing to AI safety.","We highlight tensions and contradictions inherent in the goals of RLxF.","In addition, we discuss ethically-relevant issues that tend to be neglected in discussions about alignment and RLxF, among which the trade-offs between user-friendliness and deception, flexibility and interpretability, and system safety.","We conclude by urging researchers and practitioners alike to critically assess the sociotechnical ramifications of RLxF, advocating for a more nuanced and reflective approach to its application in AI development."],"url":"http://arxiv.org/abs/2406.18346v1"}
{"created":"2024-06-26 13:42:11","title":"EmT: A Novel Transformer for Generalized Cross-subject EEG Emotion Recognition","abstract":"Integrating prior knowledge of neurophysiology into neural network architecture enhances the performance of emotion decoding. While numerous techniques emphasize learning spatial and short-term temporal patterns, there has been limited emphasis on capturing the vital long-term contextual information associated with emotional cognitive processes. In order to address this discrepancy, we introduce a novel transformer model called emotion transformer (EmT). EmT is designed to excel in both generalized cross-subject EEG emotion classification and regression tasks. In EmT, EEG signals are transformed into a temporal graph format, creating a sequence of EEG feature graphs using a temporal graph construction module (TGC). A novel residual multi-view pyramid GCN module (RMPG) is then proposed to learn dynamic graph representations for each EEG feature graph within the series, and the learned representations of each graph are fused into one token. Furthermore, we design a temporal contextual transformer module (TCT) with two types of token mixers to learn the temporal contextual information. Finally, the task-specific output module (TSO) generates the desired outputs. Experiments on four publicly available datasets show that EmT achieves higher results than the baseline methods for both EEG emotion classification and regression tasks. The code is available at https://github.com/yi-ding-cs/EmT.","sentences":["Integrating prior knowledge of neurophysiology into neural network architecture enhances the performance of emotion decoding.","While numerous techniques emphasize learning spatial and short-term temporal patterns, there has been limited emphasis on capturing the vital long-term contextual information associated with emotional cognitive processes.","In order to address this discrepancy, we introduce a novel transformer model called emotion transformer (EmT).","EmT is designed to excel in both generalized cross-subject EEG emotion classification and regression tasks.","In EmT, EEG signals are transformed into a temporal graph format, creating a sequence of EEG feature graphs using a temporal graph construction module (TGC).","A novel residual multi-view pyramid GCN module (RMPG) is then proposed to learn dynamic graph representations for each EEG feature graph within the series, and the learned representations of each graph are fused into one token.","Furthermore, we design a temporal contextual transformer module (TCT) with two types of token mixers to learn the temporal contextual information.","Finally, the task-specific output module (TSO) generates the desired outputs.","Experiments on four publicly available datasets show that EmT achieves higher results than the baseline methods for both EEG emotion classification and regression tasks.","The code is available at https://github.com/yi-ding-cs/EmT."],"url":"http://arxiv.org/abs/2406.18345v1"}
{"created":"2024-06-26 13:38:16","title":"AlignedCut: Visual Concepts Discovery on Brain-Guided Universal Feature Space","abstract":"We study the intriguing connection between visual data, deep networks, and the brain. Our method creates a universal channel alignment by using brain voxel fMRI response prediction as the training objective. We discover that deep networks, trained with different objectives, share common feature channels across various models. These channels can be clustered into recurring sets, corresponding to distinct brain regions, indicating the formation of visual concepts. Tracing the clusters of channel responses onto the images, we see semantically meaningful object segments emerge, even without any supervised decoder. Furthermore, the universal feature alignment and the clustering of channels produce a picture and quantification of how visual information is processed through the different network layers, which produces precise comparisons between the networks.","sentences":["We study the intriguing connection between visual data, deep networks, and the brain.","Our method creates a universal channel alignment by using brain voxel fMRI response prediction as the training objective.","We discover that deep networks, trained with different objectives, share common feature channels across various models.","These channels can be clustered into recurring sets, corresponding to distinct brain regions, indicating the formation of visual concepts.","Tracing the clusters of channel responses onto the images, we see semantically meaningful object segments emerge, even without any supervised decoder.","Furthermore, the universal feature alignment and the clustering of channels produce a picture and quantification of how visual information is processed through the different network layers, which produces precise comparisons between the networks."],"url":"http://arxiv.org/abs/2406.18344v1"}
{"created":"2024-06-26 13:37:34","title":"Enhanced Runge-Kutta Discontinuous Galerkin Method for Ultrasound Propagation in Transit-Time Flow Meters","abstract":"We illustrate a time and memory efficient application of Runge-Kutta discontinuous Galerkin (RKDG) methods for the simulation of the ultrasounds advection in moving fluids. In particular, this study addresses to the analysis of transit-time ultrasonic meters which rely on the propagation of acoustic waves to measure fluids flow rate. Accurate and efficient simulations of the physics related to the transport of ultrasounds are therefore crucial for studying and enhancing these devices. Starting from the description of the linearized Euler equations (LEE) model and presenting the general theory of explicit-time DG methods for hyperbolic systems, we then motivate the use of a spectral basis and introduce a novel high-accuracy method for the imposition of absorbing and resistive walls which analyses the incident wave direction across the boundary surface. The proposed implementation is both accurate and efficient, making it suitable for industrial applications of acoustic wave propagation.","sentences":["We illustrate a time and memory efficient application of Runge-Kutta discontinuous Galerkin (RKDG) methods for the simulation of the ultrasounds advection in moving fluids.","In particular, this study addresses to the analysis of transit-time ultrasonic meters which rely on the propagation of acoustic waves to measure fluids flow rate.","Accurate and efficient simulations of the physics related to the transport of ultrasounds are therefore crucial for studying and enhancing these devices.","Starting from the description of the linearized Euler equations (LEE) model and presenting the general theory of explicit-time DG methods for hyperbolic systems, we then motivate the use of a spectral basis and introduce a novel high-accuracy method for the imposition of absorbing and resistive walls which analyses the incident wave direction across the boundary surface.","The proposed implementation is both accurate and efficient, making it suitable for industrial applications of acoustic wave propagation."],"url":"http://arxiv.org/abs/2406.18342v1"}
{"created":"2024-06-26 13:35:10","title":"Grammar Assistance Using Syntactic Structures (GAUSS)","abstract":"Automatic grammar coaching serves an important purpose of advising on standard grammar varieties while not imposing social pressures or reinforcing established social roles. Such systems already exist but most of them are for English and few of them offer meaningful feedback. Furthermore, they typically rely completely on neural methods and require huge computational resources which most of the world cannot afford. We propose a grammar coaching system for Spanish that relies on (i) a rich linguistic formalism capable of giving informative feedback; and (ii) a faster parsing algorithm which makes using this formalism practical in a real-world application. The approach is feasible for any language for which there is a computerized grammar and is less reliant on expensive and environmentally costly neural methods. We seek to contribute to Greener AI and to address global education challenges by raising the standards of inclusivity and engagement in grammar coaching.","sentences":["Automatic grammar coaching serves an important purpose of advising on standard grammar varieties while not imposing social pressures or reinforcing established social roles.","Such systems already exist but most of them are for English and few of them offer meaningful feedback.","Furthermore, they typically rely completely on neural methods and require huge computational resources which most of the world cannot afford.","We propose a grammar coaching system for Spanish that relies on (i) a rich linguistic formalism capable of giving informative feedback; and (ii) a faster parsing algorithm which makes using this formalism practical in a real-world application.","The approach is feasible for any language for which there is a computerized grammar and is less reliant on expensive and environmentally costly neural methods.","We seek to contribute to Greener AI and to address global education challenges by raising the standards of inclusivity and engagement in grammar coaching."],"url":"http://arxiv.org/abs/2406.18340v1"}
{"created":"2024-06-26 13:24:08","title":"An interactive framework for the evaluation and detection of stereoacuity threshold under ambient lighting","abstract":"Objective: Our study aims to provide a novel framework for the continuous evaluation of stereoacuity under ambient lighting conditions using Bayesian inference.   Methods: We applied a combination of psychophysical and expected entropy minimization procedures for the computation of a continuous stereoacuity threshold. Subsequently, we evaluated the effect of ambient lighting during stereoacuity testing (ST) by adopting a bisection-matching based adaptive gamma calibration (AGC). Participants ($N=187$) including visually healthy controls ($N=51$), patients with Intermittent Divergent Squint (IDS; $N=45$), and controls with induced anisometropia (IA; $N=91$) performed ST with and without AGC under two lighting conditions: completely dark (20 cd/m$^2$) and normally lit (130 cd/m$^2$) rooms.   Results: Our framework demonstrated \"excellent\" reliability ($> 0.9$) and a positive correlation with TNO (a clinical stereo test), regardless of whether AGC was conducted. However, when AGC is not performed, significant differences (Friedman $X_{r}^{2} = 28.015$; $p<0.00001$; Bland-Altman bias: 30 arc-sec) were found in stereoacuity thresholds between dark and light conditions for participants with IDS and IA. Controls are unaffected by AGC and yield a similar stereoacuity threshold under both lighting conditions.   Conclusion: Our study proves that stereoacuity threshold is significantly deviated particularly in participants with IDS or IA stereo-deficits if ambient lighting is not taken into consideration. Moreover, our framework provides a quick (approximately 5-10 minutes) assessment of stereoacuity threshold and can be performed within 30 ST and 15 AGC trials.   Significance: Our test is useful in planning treatments and monitoring prognosis for patients with stereo-deficits by accurately assessing stereovision.","sentences":["Objective: Our study aims to provide a novel framework for the continuous evaluation of stereoacuity under ambient lighting conditions using Bayesian inference.   ","Methods: We applied a combination of psychophysical and expected entropy minimization procedures for the computation of a continuous stereoacuity threshold.","Subsequently, we evaluated the effect of ambient lighting during stereoacuity testing (ST) by adopting a bisection-matching based adaptive gamma calibration (AGC).","Participants ($N=187$) including visually healthy controls ($N=51$), patients with Intermittent Divergent Squint (IDS; $N=45$), and controls with induced anisometropia (IA; $N=91$) performed ST with and without AGC under two lighting conditions: completely dark (20 cd/m$^2$) and normally lit (130 cd/m$^2$) rooms.   ","Results: Our framework demonstrated \"excellent\" reliability ($> 0.9$) and a positive correlation with TNO (a clinical stereo test), regardless of whether AGC was conducted.","However, when AGC is not performed, significant differences (Friedman $X_{r}^{2} = 28.015$; $p<0.00001$; Bland-Altman bias: 30 arc-sec) were found in stereoacuity thresholds between dark and light conditions for participants with IDS and IA.","Controls are unaffected by AGC and yield a similar stereoacuity threshold under both lighting conditions.   ","Conclusion: Our study proves that stereoacuity threshold is significantly deviated particularly in participants with IDS or IA stereo-deficits if ambient lighting is not taken into consideration.","Moreover, our framework provides a quick (approximately 5-10 minutes) assessment of stereoacuity threshold and can be performed within 30 ST and 15 AGC trials.   ","Significance: Our test is useful in planning treatments and monitoring prognosis for patients with stereo-deficits by accurately assessing stereovision."],"url":"http://arxiv.org/abs/2406.18336v1"}
{"created":"2024-06-26 13:21:24","title":"Efficient and Accurate Explanation Estimation with Distribution Compression","abstract":"Exact computation of various machine learning explanations requires numerous model evaluations and in extreme cases becomes impractical. The computational cost of approximation increases with an ever-increasing size of data and model parameters. Many heuristics have been proposed to approximate post-hoc explanations efficiently. This paper shows that the standard i.i.d. sampling used in a broad spectrum of algorithms for explanation estimation leads to an approximation error worthy of improvement. To this end, we introduce Compress Then Explain (CTE), a new paradigm for more efficient and accurate explanation estimation. CTE uses distribution compression through kernel thinning to obtain a data sample that best approximates the marginal distribution. We show that CTE improves the estimation of removal-based local and global explanations with negligible computational overhead. It often achieves an on-par explanation approximation error using 2-3x less samples, i.e. requiring 2-3x less model evaluations. CTE is a simple, yet powerful, plug-in for any explanation method that now relies on i.i.d. sampling.","sentences":["Exact computation of various machine learning explanations requires numerous model evaluations and in extreme cases becomes impractical.","The computational cost of approximation increases with an ever-increasing size of data and model parameters.","Many heuristics have been proposed to approximate post-hoc explanations efficiently.","This paper shows that the standard i.i.d. sampling used in a broad spectrum of algorithms for explanation estimation leads to an approximation error worthy of improvement.","To this end, we introduce Compress Then Explain (CTE), a new paradigm for more efficient and accurate explanation estimation.","CTE uses distribution compression through kernel thinning to obtain a data sample that best approximates the marginal distribution.","We show that CTE improves the estimation of removal-based local and global explanations with negligible computational overhead.","It often achieves an on-par explanation approximation error using 2-3x less samples, i.e. requiring 2-3x less model evaluations.","CTE is a simple, yet powerful, plug-in for any explanation method that now relies on i.i.d. sampling."],"url":"http://arxiv.org/abs/2406.18334v1"}
{"created":"2024-06-26 13:21:08","title":"Continuous Sign Language Recognition Using Intra-inter Gloss Attention","abstract":"Many continuous sign language recognition (CSLR) studies adopt transformer-based architectures for sequence modeling due to their powerful capacity for capturing global contexts. Nevertheless, vanilla self-attention, which serves as the core module of the transformer, calculates a weighted average over all time steps; therefore, the local temporal semantics of sign videos may not be fully exploited. In this study, we introduce a novel module in sign language recognition studies, called intra-inter gloss attention module, to leverage the relationships among frames within glosses and the semantic and grammatical dependencies between glosses in the video. In the intra-gloss attention module, the video is divided into equally sized chunks and a self-attention mechanism is applied within each chunk. This localized self-attention significantly reduces complexity and eliminates noise introduced by considering non-relative frames. In the inter-gloss attention module, we first aggregate the chunk-level features within each gloss chunk by average pooling along the temporal dimension. Subsequently, multi-head self-attention is applied to all chunk-level features. Given the non-significance of the signer-environment interaction, we utilize segmentation to remove the background of the videos. This enables the proposed model to direct its focus toward the signer. Experimental results on the PHOENIX-2014 benchmark dataset demonstrate that our method can effectively extract sign language features in an end-to-end manner without any prior knowledge, improve the accuracy of CSLR, and achieve the word error rate (WER) of 20.4 on the test set which is a competitive result compare to the state-of-the-art which uses additional supervisions.","sentences":["Many continuous sign language recognition (CSLR) studies adopt transformer-based architectures for sequence modeling due to their powerful capacity for capturing global contexts.","Nevertheless, vanilla self-attention, which serves as the core module of the transformer, calculates a weighted average over all time steps; therefore, the local temporal semantics of sign videos may not be fully exploited.","In this study, we introduce a novel module in sign language recognition studies, called intra-inter gloss attention module, to leverage the relationships among frames within glosses and the semantic and grammatical dependencies between glosses in the video.","In the intra-gloss attention module, the video is divided into equally sized chunks and a self-attention mechanism is applied within each chunk.","This localized self-attention significantly reduces complexity and eliminates noise introduced by considering non-relative frames.","In the inter-gloss attention module, we first aggregate the chunk-level features within each gloss chunk by average pooling along the temporal dimension.","Subsequently, multi-head self-attention is applied to all chunk-level features.","Given the non-significance of the signer-environment interaction, we utilize segmentation to remove the background of the videos.","This enables the proposed model to direct its focus toward the signer.","Experimental results on the PHOENIX-2014 benchmark dataset demonstrate that our method can effectively extract sign language features in an end-to-end manner without any prior knowledge, improve the accuracy of CSLR, and achieve the word error rate (WER) of 20.4 on the test set which is a competitive result compare to the state-of-the-art which uses additional supervisions."],"url":"http://arxiv.org/abs/2406.18333v1"}
{"created":"2024-06-26 13:21:00","title":"Early Classification of Time Series: Taxonomy and Benchmark","abstract":"In many situations, the measurements of a studied phenomenon are provided sequentially, and the prediction of its class needs to be made as early as possible so as not to incur too high a time penalty, but not too early and risk paying the cost of misclassification. This problem has been particularly studied in the case of time series, and is known as Early Classification of Time Series (ECTS). Although it has been the subject of a growing body of literature, there is still a lack of a systematic, shared evaluation protocol to compare the relative merits of the various existing methods. This document begins by situating these methods within a principle-based taxonomy. It defines dimensions for organizing their evaluation, and then reports the results of a very extensive set of experiments along these dimensions involving nine state-of-the art ECTS algorithms. In addition, these and other experiments can be carried out using an open-source library in which most of the existing ECTS algorithms have been implemented (see \\url{https://github.com/ML-EDM/ml_edm}).","sentences":["In many situations, the measurements of a studied phenomenon are provided sequentially, and the prediction of its class needs to be made as early as possible so as not to incur too high a time penalty, but not too early and risk paying the cost of misclassification.","This problem has been particularly studied in the case of time series, and is known as Early Classification of Time Series (ECTS).","Although it has been the subject of a growing body of literature, there is still a lack of a systematic, shared evaluation protocol to compare the relative merits of the various existing methods.","This document begins by situating these methods within a principle-based taxonomy.","It defines dimensions for organizing their evaluation, and then reports the results of a very extensive set of experiments along these dimensions involving nine state-of-the art ECTS algorithms.","In addition, these and other experiments can be carried out using an open-source library in which most of the existing ECTS algorithms have been implemented (see \\url{https://github.com/ML-EDM/ml_edm})."],"url":"http://arxiv.org/abs/2406.18332v1"}
