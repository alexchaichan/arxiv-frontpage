{"created":"2024-04-04 17:59:59","title":"Know Your Neighbors: Improving Single-View Reconstruction via Spatial Vision-Language Reasoning","abstract":"Recovering the 3D scene geometry from a single view is a fundamental yet ill-posed problem in computer vision. While classical depth estimation methods infer only a 2.5D scene representation limited to the image plane, recent approaches based on radiance fields reconstruct a full 3D representation. However, these methods still struggle with occluded regions since inferring geometry without visual observation requires (i) semantic knowledge of the surroundings, and (ii) reasoning about spatial context. We propose KYN, a novel method for single-view scene reconstruction that reasons about semantic and spatial context to predict each point's density. We introduce a vision-language modulation module to enrich point features with fine-grained semantic information. We aggregate point representations across the scene through a language-guided spatial attention mechanism to yield per-point density predictions aware of the 3D semantic context. We show that KYN improves 3D shape recovery compared to predicting density for each 3D point in isolation. We achieve state-of-the-art results in scene and object reconstruction on KITTI-360, and show improved zero-shot generalization compared to prior work. Project page: https://ruili3.github.io/kyn.","sentences":["Recovering the 3D scene geometry from a single view is a fundamental yet ill-posed problem in computer vision.","While classical depth estimation methods infer only a 2.5D scene representation limited to the image plane, recent approaches based on radiance fields reconstruct a full 3D representation.","However, these methods still struggle with occluded regions since inferring geometry without visual observation requires (i) semantic knowledge of the surroundings, and (ii) reasoning about spatial context.","We propose KYN, a novel method for single-view scene reconstruction that reasons about semantic and spatial context to predict each point's density.","We introduce a vision-language modulation module to enrich point features with fine-grained semantic information.","We aggregate point representations across the scene through a language-guided spatial attention mechanism to yield per-point density predictions aware of the 3D semantic context.","We show that KYN improves 3D shape recovery compared to predicting density for each 3D point in isolation.","We achieve state-of-the-art results in scene and object reconstruction on KITTI-360, and show improved zero-shot generalization compared to prior work.","Project page: https://ruili3.github.io/kyn."],"url":"http://arxiv.org/abs/2404.03658v1"}
{"created":"2024-04-04 17:59:58","title":"OW-VISCap: Open-World Video Instance Segmentation and Captioning","abstract":"Open-world video instance segmentation is an important video understanding task. Yet most methods either operate in a closed-world setting, require an additional user-input, or use classic region-based proposals to identify never before seen objects. Further, these methods only assign a one-word label to detected objects, and don't generate rich object-centric descriptions. They also often suffer from highly overlapping predictions. To address these issues, we propose Open-World Video Instance Segmentation and Captioning (OW-VISCap), an approach to jointly segment, track, and caption previously seen or unseen objects in a video. For this, we introduce open-world object queries to discover never before seen objects without additional user-input. We generate rich and descriptive object-centric captions for each detected object via a masked attention augmented LLM input. We introduce an inter-query contrastive loss to ensure that the object queries differ from one another. Our generalized approach matches or surpasses state-of-the-art on three tasks: open-world video instance segmentation on the BURST dataset, dense video object captioning on the VidSTG dataset, and closed-world video instance segmentation on the OVIS dataset.","sentences":["Open-world video instance segmentation is an important video understanding task.","Yet most methods either operate in a closed-world setting, require an additional user-input, or use classic region-based proposals to identify never before seen objects.","Further, these methods only assign a one-word label to detected objects, and don't generate rich object-centric descriptions.","They also often suffer from highly overlapping predictions.","To address these issues, we propose Open-World Video Instance Segmentation and Captioning (OW-VISCap), an approach to jointly segment, track, and caption previously seen or unseen objects in a video.","For this, we introduce open-world object queries to discover never before seen objects without additional user-input.","We generate rich and descriptive object-centric captions for each detected object via a masked attention augmented LLM input.","We introduce an inter-query contrastive loss to ensure that the object queries differ from one another.","Our generalized approach matches or surpasses state-of-the-art on three tasks: open-world video instance segmentation on the BURST dataset, dense video object captioning on the VidSTG dataset, and closed-world video instance segmentation on the OVIS dataset."],"url":"http://arxiv.org/abs/2404.03657v1"}
{"created":"2024-04-04 17:59:57","title":"MVD-Fusion: Single-view 3D via Depth-consistent Multi-view Generation","abstract":"We present MVD-Fusion: a method for single-view 3D inference via generative modeling of multi-view-consistent RGB-D images. While recent methods pursuing 3D inference advocate learning novel-view generative models, these generations are not 3D-consistent and require a distillation process to generate a 3D output. We instead cast the task of 3D inference as directly generating mutually-consistent multiple views and build on the insight that additionally inferring depth can provide a mechanism for enforcing this consistency. Specifically, we train a denoising diffusion model to generate multi-view RGB-D images given a single RGB input image and leverage the (intermediate noisy) depth estimates to obtain reprojection-based conditioning to maintain multi-view consistency. We train our model using large-scale synthetic dataset Obajverse as well as the real-world CO3D dataset comprising of generic camera viewpoints. We demonstrate that our approach can yield more accurate synthesis compared to recent state-of-the-art, including distillation-based 3D inference and prior multi-view generation methods. We also evaluate the geometry induced by our multi-view depth prediction and find that it yields a more accurate representation than other direct 3D inference approaches.","sentences":["We present MVD-Fusion: a method for single-view 3D inference via generative modeling of multi-view-consistent RGB-D images.","While recent methods pursuing 3D inference advocate learning novel-view generative models, these generations are not 3D-consistent and require a distillation process to generate a 3D output.","We instead cast the task of 3D inference as directly generating mutually-consistent multiple views and build on the insight that additionally inferring depth can provide a mechanism for enforcing this consistency.","Specifically, we train a denoising diffusion model to generate multi-view RGB-D images given a single RGB input image and leverage the (intermediate noisy) depth estimates to obtain reprojection-based conditioning to maintain multi-view consistency.","We train our model using large-scale synthetic dataset Obajverse as well as the real-world CO3D dataset comprising of generic camera viewpoints.","We demonstrate that our approach can yield more accurate synthesis compared to recent state-of-the-art, including distillation-based 3D inference and prior multi-view generation methods.","We also evaluate the geometry induced by our multi-view depth prediction and find that it yields a more accurate representation than other direct 3D inference approaches."],"url":"http://arxiv.org/abs/2404.03656v1"}
{"created":"2024-04-04 17:59:50","title":"RaFE: Generative Radiance Fields Restoration","abstract":"NeRF (Neural Radiance Fields) has demonstrated tremendous potential in novel view synthesis and 3D reconstruction, but its performance is sensitive to input image quality, which struggles to achieve high-fidelity rendering when provided with low-quality sparse input viewpoints. Previous methods for NeRF restoration are tailored for specific degradation type, ignoring the generality of restoration. To overcome this limitation, we propose a generic radiance fields restoration pipeline, named RaFE, which applies to various types of degradations, such as low resolution, blurriness, noise, compression artifacts, or their combinations. Our approach leverages the success of off-the-shelf 2D restoration methods to recover the multi-view images individually. Instead of reconstructing a blurred NeRF by averaging inconsistencies, we introduce a novel approach using Generative Adversarial Networks (GANs) for NeRF generation to better accommodate the geometric and appearance inconsistencies present in the multi-view images. Specifically, we adopt a two-level tri-plane architecture, where the coarse level remains fixed to represent the low-quality NeRF, and a fine-level residual tri-plane to be added to the coarse level is modeled as a distribution with GAN to capture potential variations in restoration. We validate RaFE on both synthetic and real cases for various restoration tasks, demonstrating superior performance in both quantitative and qualitative evaluations, surpassing other 3D restoration methods specific to single task. Please see our project website https://zkaiwu.github.io/RaFE-Project/.","sentences":["NeRF (Neural Radiance Fields) has demonstrated tremendous potential in novel view synthesis and 3D reconstruction, but its performance is sensitive to input image quality, which struggles to achieve high-fidelity rendering when provided with low-quality sparse input viewpoints.","Previous methods for NeRF restoration are tailored for specific degradation type, ignoring the generality of restoration.","To overcome this limitation, we propose a generic radiance fields restoration pipeline, named RaFE, which applies to various types of degradations, such as low resolution, blurriness, noise, compression artifacts, or their combinations.","Our approach leverages the success of off-the-shelf 2D restoration methods to recover the multi-view images individually.","Instead of reconstructing a blurred NeRF by averaging inconsistencies, we introduce a novel approach using Generative Adversarial Networks (GANs) for NeRF generation to better accommodate the geometric and appearance inconsistencies present in the multi-view images.","Specifically, we adopt a two-level tri-plane architecture, where the coarse level remains fixed to represent the low-quality NeRF, and a fine-level residual tri-plane to be added to the coarse level is modeled as a distribution with GAN to capture potential variations in restoration.","We validate RaFE on both synthetic and real cases for various restoration tasks, demonstrating superior performance in both quantitative and qualitative evaluations, surpassing other 3D restoration methods specific to single task.","Please see our project website https://zkaiwu.github.io/RaFE-Project/."],"url":"http://arxiv.org/abs/2404.03654v1"}
{"created":"2024-04-04 17:59:46","title":"CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching","abstract":"Diffusion models have demonstrated great success in the field of text-to-image generation. However, alleviating the misalignment between the text prompts and images is still challenging. The root reason behind the misalignment has not been extensively investigated. We observe that the misalignment is caused by inadequate token attention activation. We further attribute this phenomenon to the diffusion model's insufficient condition utilization, which is caused by its training paradigm. To address the issue, we propose CoMat, an end-to-end diffusion model fine-tuning strategy with an image-to-text concept matching mechanism. We leverage an image captioning model to measure image-to-text alignment and guide the diffusion model to revisit ignored tokens. A novel attribute concentration module is also proposed to address the attribute binding problem. Without any image or human preference data, we use only 20K text prompts to fine-tune SDXL to obtain CoMat-SDXL. Extensive experiments show that CoMat-SDXL significantly outperforms the baseline model SDXL in two text-to-image alignment benchmarks and achieves start-of-the-art performance.","sentences":["Diffusion models have demonstrated great success in the field of text-to-image generation.","However, alleviating the misalignment between the text prompts and images is still challenging.","The root reason behind the misalignment has not been extensively investigated.","We observe that the misalignment is caused by inadequate token attention activation.","We further attribute this phenomenon to the diffusion model's insufficient condition utilization, which is caused by its training paradigm.","To address the issue, we propose CoMat, an end-to-end diffusion model fine-tuning strategy with an image-to-text concept matching mechanism.","We leverage an image captioning model to measure image-to-text alignment and guide the diffusion model to revisit ignored tokens.","A novel attribute concentration module is also proposed to address the attribute binding problem.","Without any image or human preference data, we use only 20K text prompts to fine-tune SDXL to obtain CoMat-SDXL.","Extensive experiments show that CoMat-SDXL significantly outperforms the baseline model SDXL in two text-to-image alignment benchmarks and achieves start-of-the-art performance."],"url":"http://arxiv.org/abs/2404.03653v1"}
{"created":"2024-04-04 17:59:40","title":"The More You See in 2D, the More You Perceive in 3D","abstract":"Humans can infer 3D structure from 2D images of an object based on past experience and improve their 3D understanding as they see more images. Inspired by this behavior, we introduce SAP3D, a system for 3D reconstruction and novel view synthesis from an arbitrary number of unposed images. Given a few unposed images of an object, we adapt a pre-trained view-conditioned diffusion model together with the camera poses of the images via test-time fine-tuning. The adapted diffusion model and the obtained camera poses are then utilized as instance-specific priors for 3D reconstruction and novel view synthesis. We show that as the number of input images increases, the performance of our approach improves, bridging the gap between optimization-based prior-less 3D reconstruction methods and single-image-to-3D diffusion-based methods. We demonstrate our system on real images as well as standard synthetic benchmarks. Our ablation studies confirm that this adaption behavior is key for more accurate 3D understanding.","sentences":["Humans can infer 3D structure from 2D images of an object based on past experience and improve their 3D understanding as they see more images.","Inspired by this behavior, we introduce SAP3D, a system for 3D reconstruction and novel view synthesis from an arbitrary number of unposed images.","Given a few unposed images of an object, we adapt a pre-trained view-conditioned diffusion model together with the camera poses of the images via test-time fine-tuning.","The adapted diffusion model and the obtained camera poses are then utilized as instance-specific priors for 3D reconstruction and novel view synthesis.","We show that as the number of input images increases, the performance of our approach improves, bridging the gap between optimization-based prior-less 3D reconstruction methods and single-image-to-3D diffusion-based methods.","We demonstrate our system on real images as well as standard synthetic benchmarks.","Our ablation studies confirm that this adaption behavior is key for more accurate 3D understanding."],"url":"http://arxiv.org/abs/2404.03652v1"}
{"created":"2024-04-04 17:59:08","title":"OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views","abstract":"Large visual-language models (VLMs), like CLIP, enable open-set image segmentation to segment arbitrary concepts from an image in a zero-shot manner. This goes beyond the traditional closed-set assumption, i.e., where models can only segment classes from a pre-defined training set. More recently, first works on open-set segmentation in 3D scenes have appeared in the literature. These methods are heavily influenced by closed-set 3D convolutional approaches that process point clouds or polygon meshes. However, these 3D scene representations do not align well with the image-based nature of the visual-language models. Indeed, point cloud and 3D meshes typically have a lower resolution than images and the reconstructed 3D scene geometry might not project well to the underlying 2D image sequences used to compute pixel-aligned CLIP features. To address these challenges, we propose OpenNeRF which naturally operates on posed images and directly encodes the VLM features within the NeRF. This is similar in spirit to LERF, however our work shows that using pixel-wise VLM features (instead of global CLIP features) results in an overall less complex architecture without the need for additional DINO regularization. Our OpenNeRF further leverages NeRF's ability to render novel views and extract open-set VLM features from areas that are not well observed in the initial posed images. For 3D point cloud segmentation on the Replica dataset, OpenNeRF outperforms recent open-vocabulary methods such as LERF and OpenScene by at least +4.9 mIoU.","sentences":["Large visual-language models (VLMs), like CLIP, enable open-set image segmentation to segment arbitrary concepts from an image in a zero-shot manner.","This goes beyond the traditional closed-set assumption, i.e., where models can only segment classes from a pre-defined training set.","More recently, first works on open-set segmentation in 3D scenes have appeared in the literature.","These methods are heavily influenced by closed-set 3D convolutional approaches that process point clouds or polygon meshes.","However, these 3D scene representations do not align well with the image-based nature of the visual-language models.","Indeed, point cloud and 3D meshes typically have a lower resolution than images and the reconstructed 3D scene geometry might not project well to the underlying 2D image sequences used to compute pixel-aligned CLIP features.","To address these challenges, we propose OpenNeRF which naturally operates on posed images and directly encodes the VLM features within the NeRF.","This is similar in spirit to LERF, however our work shows that using pixel-wise VLM features (instead of global CLIP features) results in an overall less complex architecture without the need for additional DINO regularization.","Our OpenNeRF further leverages NeRF's ability to render novel views and extract open-set VLM features from areas that are not well observed in the initial posed images.","For 3D point cloud segmentation on the Replica dataset, OpenNeRF outperforms recent open-vocabulary methods such as LERF and OpenScene by at least +4.9 mIoU."],"url":"http://arxiv.org/abs/2404.03650v1"}
{"created":"2024-04-04 17:58:40","title":"AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent","abstract":"Large language models (LLMs) have fueled many intelligent agent tasks, such as web navigation -- but most existing agents perform far from satisfying in real-world webpages due to three factors: (1) the versatility of actions on webpages, (2) HTML text exceeding model processing capacity, and (3) the complexity of decision-making due to the open-domain nature of web. In light of the challenge, we develop AutoWebGLM, a GPT-4-outperforming automated web navigation agent built upon ChatGLM3-6B. Inspired by human browsing patterns, we design an HTML simplification algorithm to represent webpages, preserving vital information succinctly. We employ a hybrid human-AI method to build web browsing data for curriculum training. Then, we bootstrap the model by reinforcement learning and rejection sampling to further facilitate webpage comprehension, browser operations, and efficient task decomposition by itself. For testing, we establish a bilingual benchmark -- AutoWebBench -- for real-world web browsing tasks. We evaluate AutoWebGLM across diverse web navigation benchmarks, revealing its improvements but also underlying challenges to tackle real environments. Related code, model, and data will be released at \\url{https://github.com/THUDM/AutoWebGLM}.","sentences":["Large language models (LLMs) have fueled many intelligent agent tasks, such as web navigation -- but most existing agents perform far from satisfying in real-world webpages due to three factors: (1) the versatility of actions on webpages, (2) HTML text exceeding model processing capacity, and (3) the complexity of decision-making due to the open-domain nature of web.","In light of the challenge, we develop AutoWebGLM, a GPT-4-outperforming automated web navigation agent built upon ChatGLM3-6B. Inspired by human browsing patterns, we design an HTML simplification algorithm to represent webpages, preserving vital information succinctly.","We employ a hybrid human-AI method to build web browsing data for curriculum training.","Then, we bootstrap the model by reinforcement learning and rejection sampling to further facilitate webpage comprehension, browser operations, and efficient task decomposition by itself.","For testing, we establish a bilingual benchmark -- AutoWebBench -- for real-world web browsing tasks.","We evaluate AutoWebGLM across diverse web navigation benchmarks, revealing its improvements but also underlying challenges to tackle real environments.","Related code, model, and data will be released at \\url{https://github.com/THUDM/AutoWebGLM}."],"url":"http://arxiv.org/abs/2404.03648v1"}
{"created":"2024-04-04 17:58:31","title":"Locating and Editing Factual Associations in Mamba","abstract":"We investigate the mechanisms of factual recall in the Mamba state space model. Our work is inspired by previous findings in autoregressive transformer language models suggesting that their knowledge recall is localized to particular modules at specific token locations; we therefore ask whether factual recall in Mamba can be similarly localized. To investigate this, we conduct four lines of experiments on Mamba. First, we apply causal tracing or interchange interventions to localize key components inside Mamba that are responsible for recalling facts, revealing that specific components within middle layers show strong causal effects at the last token of the subject, while the causal effect of intervening on later layers is most pronounced at the last token of the prompt, matching previous findings on autoregressive transformers. Second, we show that rank-one model editing methods can successfully insert facts at specific locations, again resembling findings on transformer models. Third, we examine the linearity of Mamba's representations of factual relations. Finally we adapt attention-knockout techniques to Mamba to dissect information flow during factual recall. We compare Mamba directly to a similar-sized transformer and conclude that despite significant differences in architectural approach, when it comes to factual recall, the two architectures share many similarities.","sentences":["We investigate the mechanisms of factual recall in the Mamba state space model.","Our work is inspired by previous findings in autoregressive transformer language models suggesting that their knowledge recall is localized to particular modules at specific token locations; we therefore ask whether factual recall in Mamba can be similarly localized.","To investigate this, we conduct four lines of experiments on Mamba.","First, we apply causal tracing or interchange interventions to localize key components inside Mamba that are responsible for recalling facts, revealing that specific components within middle layers show strong causal effects at the last token of the subject, while the causal effect of intervening on later layers is most pronounced at the last token of the prompt, matching previous findings on autoregressive transformers.","Second, we show that rank-one model editing methods can successfully insert facts at specific locations, again resembling findings on transformer models.","Third, we examine the linearity of Mamba's representations of factual relations.","Finally we adapt attention-knockout techniques to Mamba to dissect information flow during factual recall.","We compare Mamba directly to a similar-sized transformer and conclude that despite significant differences in architectural approach, when it comes to factual recall, the two architectures share many similarities."],"url":"http://arxiv.org/abs/2404.03646v1"}
{"created":"2024-04-04 17:58:21","title":"Decoupling Static and Hierarchical Motion Perception for Referring Video Segmentation","abstract":"Referring video segmentation relies on natural language expressions to identify and segment objects, often emphasizing motion clues. Previous works treat a sentence as a whole and directly perform identification at the video-level, mixing up static image-level cues with temporal motion cues. However, image-level features cannot well comprehend motion cues in sentences, and static cues are not crucial for temporal perception. In fact, static cues can sometimes interfere with temporal perception by overshadowing motion cues. In this work, we propose to decouple video-level referring expression understanding into static and motion perception, with a specific emphasis on enhancing temporal comprehension. Firstly, we introduce an expression-decoupling module to make static cues and motion cues perform their distinct role, alleviating the issue of sentence embeddings overlooking motion cues. Secondly, we propose a hierarchical motion perception module to capture temporal information effectively across varying timescales. Furthermore, we employ contrastive learning to distinguish the motions of visually similar objects. These contributions yield state-of-the-art performance across five datasets, including a remarkable $\\textbf{9.2%}$ $\\mathcal{J\\&F}$ improvement on the challenging $\\textbf{MeViS}$ dataset. Code is available at https://github.com/heshuting555/DsHmp.","sentences":["Referring video segmentation relies on natural language expressions to identify and segment objects, often emphasizing motion clues.","Previous works treat a sentence as a whole and directly perform identification at the video-level, mixing up static image-level cues with temporal motion cues.","However, image-level features cannot well comprehend motion cues in sentences, and static cues are not crucial for temporal perception.","In fact, static cues can sometimes interfere with temporal perception by overshadowing motion cues.","In this work, we propose to decouple video-level referring expression understanding into static and motion perception, with a specific emphasis on enhancing temporal comprehension.","Firstly, we introduce an expression-decoupling module to make static cues and motion cues perform their distinct role, alleviating the issue of sentence embeddings overlooking motion cues.","Secondly, we propose a hierarchical motion perception module to capture temporal information effectively across varying timescales.","Furthermore, we employ contrastive learning to distinguish the motions of visually similar objects.","These contributions yield state-of-the-art performance across five datasets, including a remarkable $\\textbf{9.2%}$ $\\mathcal{J\\&F}$ improvement on the challenging $\\textbf{MeViS}$ dataset.","Code is available at https://github.com/heshuting555/DsHmp."],"url":"http://arxiv.org/abs/2404.03645v1"}
{"created":"2024-04-04 17:57:25","title":"DiffBody: Human Body Restoration by Imagining with Generative Diffusion Prior","abstract":"Human body restoration plays a vital role in various applications related to the human body. Despite recent advances in general image restoration using generative models, their performance in human body restoration remains mediocre, often resulting in foreground and background blending, over-smoothing surface textures, missing accessories, and distorted limbs. Addressing these challenges, we propose a novel approach by constructing a human body-aware diffusion model that leverages domain-specific knowledge to enhance performance. Specifically, we employ a pretrained body attention module to guide the diffusion model's focus on the foreground, addressing issues caused by blending between the subject and background. We also demonstrate the value of revisiting the language modality of the diffusion model in restoration tasks by seamlessly incorporating text prompt to improve the quality of surface texture and additional clothing and accessories details. Additionally, we introduce a diffusion sampler tailored for fine-grained human body parts, utilizing local semantic information to rectify limb distortions. Lastly, we collect a comprehensive dataset for benchmarking and advancing the field of human body restoration. Extensive experimental validation showcases the superiority of our approach, both quantitatively and qualitatively, over existing methods.","sentences":["Human body restoration plays a vital role in various applications related to the human body.","Despite recent advances in general image restoration using generative models, their performance in human body restoration remains mediocre, often resulting in foreground and background blending, over-smoothing surface textures, missing accessories, and distorted limbs.","Addressing these challenges, we propose a novel approach by constructing a human body-aware diffusion model that leverages domain-specific knowledge to enhance performance.","Specifically, we employ a pretrained body attention module to guide the diffusion model's focus on the foreground, addressing issues caused by blending between the subject and background.","We also demonstrate the value of revisiting the language modality of the diffusion model in restoration tasks by seamlessly incorporating text prompt to improve the quality of surface texture and additional clothing and accessories details.","Additionally, we introduce a diffusion sampler tailored for fine-grained human body parts, utilizing local semantic information to rectify limb distortions.","Lastly, we collect a comprehensive dataset for benchmarking and advancing the field of human body restoration.","Extensive experimental validation showcases the superiority of our approach, both quantitatively and qualitatively, over existing methods."],"url":"http://arxiv.org/abs/2404.03642v1"}
{"created":"2024-04-04 17:57:22","title":"Amortized Analysis via Coalgebra","abstract":"Amortized analysis is a cost analysis technique for data structures in which cost is studied in aggregate, rather than considering the maximum cost of a single operation. Traditionally, amortized analysis has been phrased inductively, in terms of finite sequences of operations. Connecting to prior work on coalgebraic semantics for data structures, we develop the perspective that amortized analysis is naturally viewed coalgebraically in the category of algebras for a cost monad, where a morphism of coalgebras serves as a first-class generalization of potential function suitable for integrating cost and behavior. Using this simple definition, we consider amortization of other effects, such as randomization, and we compose amortization arguments in the indexed category of coalgebras. We generalize this to parallel data structure usage patterns by using coalgebras for an endoprofunctor instead of an endofunctor, combining potential using a monoidal structure on the underlying category. Finally, we adapt our discussion to the bicategorical setting, supporting imprecise amortized upper bounds.","sentences":["Amortized analysis is a cost analysis technique for data structures in which cost is studied in aggregate, rather than considering the maximum cost of a single operation.","Traditionally, amortized analysis has been phrased inductively, in terms of finite sequences of operations.","Connecting to prior work on coalgebraic semantics for data structures, we develop the perspective that amortized analysis is naturally viewed coalgebraically in the category of algebras for a cost monad, where a morphism of coalgebras serves as a first-class generalization of potential function suitable for integrating cost and behavior.","Using this simple definition, we consider amortization of other effects, such as randomization, and we compose amortization arguments in the indexed category of coalgebras.","We generalize this to parallel data structure usage patterns by using coalgebras for an endoprofunctor instead of an endofunctor, combining potential using a monoidal structure on the underlying category.","Finally, we adapt our discussion to the bicategorical setting, supporting imprecise amortized upper bounds."],"url":"http://arxiv.org/abs/2404.03641v1"}
{"created":"2024-04-04 17:55:38","title":"Sequential Recommendation for Optimizing Both Immediate Feedback and Long-term Retention","abstract":"In the landscape of Recommender System (RS) applications, reinforcement learning (RL) has recently emerged as a powerful tool, primarily due to its proficiency in optimizing long-term rewards. Nevertheless, it suffers from instability in the learning process, stemming from the intricate interactions among bootstrapping, off-policy training, and function approximation. Moreover, in multi-reward recommendation scenarios, designing a proper reward setting that reconciles the inner dynamics of various tasks is quite intricate. In response to these challenges, we introduce DT4IER, an advanced decision transformer-based recommendation model that is engineered to not only elevate the effectiveness of recommendations but also to achieve a harmonious balance between immediate user engagement and long-term retention. The DT4IER applies an innovative multi-reward design that adeptly balances short and long-term rewards with user-specific attributes, which serve to enhance the contextual richness of the reward sequence ensuring a more informed and personalized recommendation process. To enhance its predictive capabilities, DT4IER incorporates a high-dimensional encoder, skillfully designed to identify and leverage the intricate interrelations across diverse tasks. Furthermore, we integrate a contrastive learning approach within the action embedding predictions, a strategy that significantly boosts the model's overall performance. Experiments on three real-world datasets demonstrate the effectiveness of DT4IER against state-of-the-art Sequential Recommender Systems (SRSs) and Multi-Task Learning (MTL) models in terms of both prediction accuracy and effectiveness in specific tasks. The source code is accessible online to facilitate replication","sentences":["In the landscape of Recommender System (RS) applications, reinforcement learning (RL) has recently emerged as a powerful tool, primarily due to its proficiency in optimizing long-term rewards.","Nevertheless, it suffers from instability in the learning process, stemming from the intricate interactions among bootstrapping, off-policy training, and function approximation.","Moreover, in multi-reward recommendation scenarios, designing a proper reward setting that reconciles the inner dynamics of various tasks is quite intricate.","In response to these challenges, we introduce DT4IER, an advanced decision transformer-based recommendation model that is engineered to not only elevate the effectiveness of recommendations but also to achieve a harmonious balance between immediate user engagement and long-term retention.","The DT4IER applies an innovative multi-reward design that adeptly balances short and long-term rewards with user-specific attributes, which serve to enhance the contextual richness of the reward sequence ensuring a more informed and personalized recommendation process.","To enhance its predictive capabilities, DT4IER incorporates a high-dimensional encoder, skillfully designed to identify and leverage the intricate interrelations across diverse tasks.","Furthermore, we integrate a contrastive learning approach within the action embedding predictions, a strategy that significantly boosts the model's overall performance.","Experiments on three real-world datasets demonstrate the effectiveness of DT4IER against state-of-the-art Sequential Recommender Systems (SRSs) and Multi-Task Learning (MTL) models in terms of both prediction accuracy and effectiveness in specific tasks.","The source code is accessible online to facilitate replication"],"url":"http://arxiv.org/abs/2404.03637v1"}
{"created":"2024-04-04 17:54:33","title":"WorDepth: Variational Language Prior for Monocular Depth Estimation","abstract":"Three-dimensional (3D) reconstruction from a single image is an ill-posed problem with inherent ambiguities, i.e. scale. Predicting a 3D scene from text description(s) is similarly ill-posed, i.e. spatial arrangements of objects described. We investigate the question of whether two inherently ambiguous modalities can be used in conjunction to produce metric-scaled reconstructions. To test this, we focus on monocular depth estimation, the problem of predicting a dense depth map from a single image, but with an additional text caption describing the scene. To this end, we begin by encoding the text caption as a mean and standard deviation; using a variational framework, we learn the distribution of the plausible metric reconstructions of 3D scenes corresponding to the text captions as a prior. To \"select\" a specific reconstruction or depth map, we encode the given image through a conditional sampler that samples from the latent space of the variational text encoder, which is then decoded to the output depth map. Our approach is trained alternatingly between the text and image branches: in one optimization step, we predict the mean and standard deviation from the text description and sample from a standard Gaussian, and in the other, we sample using a (image) conditional sampler. Once trained, we directly predict depth from the encoded text using the conditional sampler. We demonstrate our approach on indoor (NYUv2) and outdoor (KITTI) scenarios, where we show that language can consistently improve performance in both.","sentences":["Three-dimensional (3D) reconstruction from a single image is an ill-posed problem with inherent ambiguities, i.e. scale.","Predicting a 3D scene from text description(s) is similarly ill-posed, i.e. spatial arrangements of objects described.","We investigate the question of whether two inherently ambiguous modalities can be used in conjunction to produce metric-scaled reconstructions.","To test this, we focus on monocular depth estimation, the problem of predicting a dense depth map from a single image, but with an additional text caption describing the scene.","To this end, we begin by encoding the text caption as a mean and standard deviation; using a variational framework, we learn the distribution of the plausible metric reconstructions of 3D scenes corresponding to the text captions as a prior.","To \"select\" a specific reconstruction or depth map, we encode the given image through a conditional sampler that samples from the latent space of the variational text encoder, which is then decoded to the output depth map.","Our approach is trained alternatingly between the text and image branches: in one optimization step, we predict the mean and standard deviation from the text description and sample from a standard Gaussian, and in the other, we sample using a (image) conditional sampler.","Once trained, we directly predict depth from the encoded text using the conditional sampler.","We demonstrate our approach on indoor (NYUv2) and outdoor (KITTI) scenarios, where we show that language can consistently improve performance in both."],"url":"http://arxiv.org/abs/2404.03635v1"}
{"created":"2024-04-04 17:54:12","title":"PreAfford: Universal Affordance-Based Pre-Grasping for Diverse Objects and Environments","abstract":"Robotic manipulation of ungraspable objects with two-finger grippers presents significant challenges due to the paucity of graspable features, while traditional pre-grasping techniques, which rely on repositioning objects and leveraging external aids like table edges, lack the adaptability across object categories and scenes. Addressing this, we introduce PreAfford, a novel pre-grasping planning framework that utilizes a point-level affordance representation and a relay training approach to enhance adaptability across a broad range of environments and object types, including those previously unseen. Demonstrated on the ShapeNet-v2 dataset, PreAfford significantly improves grasping success rates by 69% and validates its practicality through real-world experiments. This work offers a robust and adaptable solution for manipulating ungraspable objects.","sentences":["Robotic manipulation of ungraspable objects with two-finger grippers presents significant challenges due to the paucity of graspable features, while traditional pre-grasping techniques, which rely on repositioning objects and leveraging external aids like table edges, lack the adaptability across object categories and scenes.","Addressing this, we introduce PreAfford, a novel pre-grasping planning framework that utilizes a point-level affordance representation and a relay training approach to enhance adaptability across a broad range of environments and object types, including those previously unseen.","Demonstrated on the ShapeNet-v2 dataset, PreAfford significantly improves grasping success rates by 69% and validates its practicality through real-world experiments.","This work offers a robust and adaptable solution for manipulating ungraspable objects."],"url":"http://arxiv.org/abs/2404.03634v1"}
{"created":"2024-04-04 17:53:33","title":"Reference-Based 3D-Aware Image Editing with Triplane","abstract":"Generative Adversarial Networks (GANs) have emerged as powerful tools not only for high-quality image generation but also for real image editing through manipulation of their interpretable latent spaces. Recent advancements in GANs include the development of 3D-aware models such as EG3D, characterized by efficient triplane-based architectures enabling the reconstruction of 3D geometry from single images. However, scant attention has been devoted to providing an integrated framework for high-quality reference-based 3D-aware image editing within this domain. This study addresses this gap by exploring and demonstrating the effectiveness of EG3D's triplane space for achieving advanced reference-based edits, presenting a unique perspective on 3D-aware image editing through our novel pipeline. Our approach integrates the encoding of triplane features, spatial disentanglement and automatic localization of features in the triplane domain, and fusion learning for desired image editing. Moreover, our framework demonstrates versatility across domains, extending its effectiveness to animal face edits and partial stylization of cartoon portraits. The method shows significant improvements over relevant 3D-aware latent editing and 2D reference-based editing methods, both qualitatively and quantitatively. Project page: https://three-bee.github.io/triplane_edit","sentences":["Generative Adversarial Networks (GANs) have emerged as powerful tools not only for high-quality image generation but also for real image editing through manipulation of their interpretable latent spaces.","Recent advancements in GANs include the development of 3D-aware models such as EG3D, characterized by efficient triplane-based architectures enabling the reconstruction of 3D geometry from single images.","However, scant attention has been devoted to providing an integrated framework for high-quality reference-based 3D-aware image editing within this domain.","This study addresses this gap by exploring and demonstrating the effectiveness of EG3D's triplane space for achieving advanced reference-based edits, presenting a unique perspective on 3D-aware image editing through our novel pipeline.","Our approach integrates the encoding of triplane features, spatial disentanglement and automatic localization of features in the triplane domain, and fusion learning for desired image editing.","Moreover, our framework demonstrates versatility across domains, extending its effectiveness to animal face edits and partial stylization of cartoon portraits.","The method shows significant improvements over relevant 3D-aware latent editing and 2D reference-based editing methods, both qualitatively and quantitatively.","Project page: https://three-bee.github.io/triplane_edit"],"url":"http://arxiv.org/abs/2404.03632v1"}
{"created":"2024-04-04 17:52:13","title":"Robust Concept Erasure Using Task Vectors","abstract":"With the rapid growth of text-to-image models, a variety of techniques have been suggested to prevent undesirable image generations. Yet, these methods often only protect against specific user prompts and have been shown to allow unsafe generations with other inputs. Here we focus on unconditionally erasing a concept from a text-to-image model rather than conditioning the erasure on the user's prompt. We first show that compared to input-dependent erasure methods, concept erasure that uses Task Vectors (TV) is more robust to unexpected user inputs, not seen during training. However, TV-based erasure can also affect the core performance of the edited model, particularly when the required edit strength is unknown. To this end, we propose a method called Diverse Inversion, which we use to estimate the required strength of the TV edit. Diverse Inversion finds within the model input space a large set of word embeddings, each of which induces the generation of the target concept. We find that encouraging diversity in the set makes our estimation more robust to unexpected prompts. Finally, we show that Diverse Inversion enables us to apply a TV edit only to a subset of the model weights, enhancing the erasure capabilities while better maintaining the core functionality of the model.","sentences":["With the rapid growth of text-to-image models, a variety of techniques have been suggested to prevent undesirable image generations.","Yet, these methods often only protect against specific user prompts and have been shown to allow unsafe generations with other inputs.","Here we focus on unconditionally erasing a concept from a text-to-image model rather than conditioning the erasure on the user's prompt.","We first show that compared to input-dependent erasure methods, concept erasure that uses Task Vectors (TV) is more robust to unexpected user inputs, not seen during training.","However, TV-based erasure can also affect the core performance of the edited model, particularly when the required edit strength is unknown.","To this end, we propose a method called Diverse Inversion, which we use to estimate the required strength of the TV edit.","Diverse Inversion finds within the model input space a large set of word embeddings, each of which induces the generation of the target concept.","We find that encouraging diversity in the set makes our estimation more robust to unexpected prompts.","Finally, we show that Diverse Inversion enables us to apply a TV edit only to a subset of the model weights, enhancing the erasure capabilities while better maintaining the core functionality of the model."],"url":"http://arxiv.org/abs/2404.03631v1"}
{"created":"2024-04-04 17:49:38","title":"ROBUST: 221 Bugs in the Robot Operating System","abstract":"As robotic systems such as autonomous cars and delivery drones assume greater roles and responsibilities within society, the likelihood and impact of catastrophic software failure within those systems is increased.To aid researchers in the development of new methods to measure and assure the safety and quality of robotics software, we systematically curated a dataset of 221 bugs across 7 popular and diverse software systems implemented via the Robot Operating System (ROS). We produce historically accurate recreations of each of the 221 defective software versions in the form of Docker images, and use a grounded theory approach to examine and categorize their corresponding faults, failures, and fixes. Finally, we reflect on the implications of our findings and outline future research directions for the community.","sentences":["As robotic systems such as autonomous cars and delivery drones assume greater roles and responsibilities within society, the likelihood and impact of catastrophic software failure within those systems is increased.","To aid researchers in the development of new methods to measure and assure the safety and quality of robotics software, we systematically curated a dataset of 221 bugs across 7 popular and diverse software systems implemented via the Robot Operating System (ROS).","We produce historically accurate recreations of each of the 221 defective software versions in the form of Docker images, and use a grounded theory approach to examine and categorize their corresponding faults, failures, and fixes.","Finally, we reflect on the implications of our findings and outline future research directions for the community."],"url":"http://arxiv.org/abs/2404.03629v1"}
{"created":"2024-04-04 17:48:28","title":"Training LLMs over Neurally Compressed Text","abstract":"In this paper, we explore the idea of training large language models (LLMs) over highly compressed text. While standard subword tokenizers compress text by a small factor, neural text compressors can achieve much higher rates of compression. If it were possible to train LLMs directly over neurally compressed text, this would confer advantages in training and serving efficiency, as well as easier handling of long text spans. The main obstacle to this goal is that strong compression tends to produce opaque outputs that are not well-suited for learning. In particular, we find that text na\\\"ively compressed via Arithmetic Coding is not readily learnable by LLMs. To overcome this, we propose Equal-Info Windows, a novel compression technique whereby text is segmented into blocks that each compress to the same bit length. Using this method, we demonstrate effective learning over neurally compressed text that improves with scale, and outperforms byte-level baselines by a wide margin on perplexity and inference speed benchmarks. While our method delivers worse perplexity than subword tokenizers for models trained with the same parameter count, it has the benefit of shorter sequence lengths. Shorter sequence lengths require fewer autoregressive generation steps, and reduce latency. Finally, we provide extensive analysis of the properties that contribute to learnability, and offer concrete suggestions for how to further improve the performance of high-compression tokenizers.","sentences":["In this paper, we explore the idea of training large language models (LLMs) over highly compressed text.","While standard subword tokenizers compress text by a small factor, neural text compressors can achieve much higher rates of compression.","If it were possible to train LLMs directly over neurally compressed text, this would confer advantages in training and serving efficiency, as well as easier handling of long text spans.","The main obstacle to this goal is that strong compression tends to produce opaque outputs that are not well-suited for learning.","In particular, we find that text na\\\"ively compressed via Arithmetic Coding is not readily learnable by LLMs.","To overcome this, we propose Equal-Info Windows, a novel compression technique whereby text is segmented into blocks that each compress to the same bit length.","Using this method, we demonstrate effective learning over neurally compressed text that improves with scale, and outperforms byte-level baselines by a wide margin on perplexity and inference speed benchmarks.","While our method delivers worse perplexity than subword tokenizers for models trained with the same parameter count, it has the benefit of shorter sequence lengths.","Shorter sequence lengths require fewer autoregressive generation steps, and reduce latency.","Finally, we provide extensive analysis of the properties that contribute to learnability, and offer concrete suggestions for how to further improve the performance of high-compression tokenizers."],"url":"http://arxiv.org/abs/2404.03626v1"}
{"created":"2024-04-04 17:46:32","title":"Standardizing Knowledge Engineering Practices with a Reference Architecture","abstract":"Knowledge engineering is the process of creating and maintaining knowledge-producing systems. Throughout the history of computer science and AI, knowledge engineering workflows have been widely used given the importance of high-quality knowledge for reliable intelligent agents. Meanwhile, the scope of knowledge engineering, as apparent from its target tasks and use cases, has been shifting, together with its paradigms such as expert systems, semantic web, and language modeling. The intended use cases and supported user requirements between these paradigms have not been analyzed globally, as new paradigms often satisfy prior pain points while possibly introducing new ones. The recent abstraction of systemic patterns into a boxology provides an opening for aligning the requirements and use cases of knowledge engineering with the systems, components, and software that can satisfy them best. This paper proposes a vision of harmonizing the best practices in the field of knowledge engineering by leveraging the software engineering methodology of creating reference architectures. We describe how a reference architecture can be iteratively designed and implemented to associate user needs with recurring systemic patterns, building on top of existing knowledge engineering workflows and boxologies. We provide a six-step roadmap that can enable the development of such an architecture, providing an initial design and outcome of the definition of architectural scope, selection of information sources, and analysis. We expect that following through on this vision will lead to well-grounded reference architectures for knowledge engineering, will advance the ongoing initiatives of organizing the neurosymbolic knowledge engineering space, and will build new links to the software architectures and data science communities.","sentences":["Knowledge engineering is the process of creating and maintaining knowledge-producing systems.","Throughout the history of computer science and AI, knowledge engineering workflows have been widely used given the importance of high-quality knowledge for reliable intelligent agents.","Meanwhile, the scope of knowledge engineering, as apparent from its target tasks and use cases, has been shifting, together with its paradigms such as expert systems, semantic web, and language modeling.","The intended use cases and supported user requirements between these paradigms have not been analyzed globally, as new paradigms often satisfy prior pain points while possibly introducing new ones.","The recent abstraction of systemic patterns into a boxology provides an opening for aligning the requirements and use cases of knowledge engineering with the systems, components, and software that can satisfy them best.","This paper proposes a vision of harmonizing the best practices in the field of knowledge engineering by leveraging the software engineering methodology of creating reference architectures.","We describe how a reference architecture can be iteratively designed and implemented to associate user needs with recurring systemic patterns, building on top of existing knowledge engineering workflows and boxologies.","We provide a six-step roadmap that can enable the development of such an architecture, providing an initial design and outcome of the definition of architectural scope, selection of information sources, and analysis.","We expect that following through on this vision will lead to well-grounded reference architectures for knowledge engineering, will advance the ongoing initiatives of organizing the neurosymbolic knowledge engineering space, and will build new links to the software architectures and data science communities."],"url":"http://arxiv.org/abs/2404.03624v1"}
{"created":"2024-04-04 17:45:59","title":"Unveiling LLMs: The Evolution of Latent Representations in a Temporal Knowledge Graph","abstract":"Large Language Models (LLMs) demonstrate an impressive capacity to recall a vast range of common factual knowledge information. However, unravelling the underlying reasoning of LLMs and explaining their internal mechanisms of exploiting this factual knowledge remain active areas of investigation. Our work analyzes the factual knowledge encoded in the latent representation of LLMs when prompted to assess the truthfulness of factual claims. We propose an end-to-end framework that jointly decodes the factual knowledge embedded in the latent space of LLMs from a vector space to a set of ground predicates and represents its evolution across the layers using a temporal knowledge graph. Our framework relies on the technique of activation patching which intervenes in the inference computation of a model by dynamically altering its latent representations. Consequently, we neither rely on external models nor training processes. We showcase our framework with local and global interpretability analyses using two claim verification datasets: FEVER and CLIMATE-FEVER. The local interpretability analysis exposes different latent errors from representation to multi-hop reasoning errors. On the other hand, the global analysis uncovered patterns in the underlying evolution of the model's factual knowledge (e.g., store-and-seek factual information). By enabling graph-based analyses of the latent representations, this work represents a step towards the mechanistic interpretability of LLMs.","sentences":["Large Language Models (LLMs) demonstrate an impressive capacity to recall a vast range of common factual knowledge information.","However, unravelling the underlying reasoning of LLMs and explaining their internal mechanisms of exploiting this factual knowledge remain active areas of investigation.","Our work analyzes the factual knowledge encoded in the latent representation of LLMs when prompted to assess the truthfulness of factual claims.","We propose an end-to-end framework that jointly decodes the factual knowledge embedded in the latent space of LLMs from a vector space to a set of ground predicates and represents its evolution across the layers using a temporal knowledge graph.","Our framework relies on the technique of activation patching which intervenes in the inference computation of a model by dynamically altering its latent representations.","Consequently, we neither rely on external models nor training processes.","We showcase our framework with local and global interpretability analyses using two claim verification datasets: FEVER and CLIMATE-FEVER.","The local interpretability analysis exposes different latent errors from representation to multi-hop reasoning errors.","On the other hand, the global analysis uncovered patterns in the underlying evolution of the model's factual knowledge (e.g., store-and-seek factual information).","By enabling graph-based analyses of the latent representations, this work represents a step towards the mechanistic interpretability of LLMs."],"url":"http://arxiv.org/abs/2404.03623v1"}
{"created":"2024-04-04 17:45:08","title":"Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models","abstract":"Large language models (LLMs) have exhibited impressive performance in language comprehension and various reasoning tasks. However, their abilities in spatial reasoning, a crucial aspect of human cognition, remain relatively unexplored. Human possess a remarkable ability to create mental images of unseen objects and actions through a process known as \\textbf{the Mind's Eye}, enabling the imagination of the unseen world. Inspired by this cognitive capacity, we propose Visualization-of-Thought (\\textbf{VoT}) prompting. VoT aims to elicit spatial reasoning of LLMs by visualizing their reasoning traces, thereby guiding subsequent reasoning steps. We employed VoT for multi-hop spatial reasoning tasks, including natural language navigation, visual navigation, and visual tiling in 2D grid worlds. Experimental results demonstrated that VoT significantly enhances the spatial reasoning abilities of LLMs. Notably, VoT outperformed existing multimodal large language models (MLLMs) in these tasks. While VoT works surprisingly well on LLMs, the ability to generate \\textit{mental images} to facilitate spatial reasoning resembles the mind's eye process, suggesting its potential viability in MLLMs.","sentences":["Large language models (LLMs) have exhibited impressive performance in language comprehension and various reasoning tasks.","However, their abilities in spatial reasoning, a crucial aspect of human cognition, remain relatively unexplored.","Human possess a remarkable ability to create mental images of unseen objects and actions through a process known as \\textbf{the Mind's Eye}, enabling the imagination of the unseen world.","Inspired by this cognitive capacity, we propose Visualization-of-Thought (\\textbf{VoT}) prompting.","VoT aims to elicit spatial reasoning of LLMs by visualizing their reasoning traces, thereby guiding subsequent reasoning steps.","We employed VoT for multi-hop spatial reasoning tasks, including natural language navigation, visual navigation, and visual tiling in 2D grid worlds.","Experimental results demonstrated that VoT significantly enhances the spatial reasoning abilities of LLMs.","Notably, VoT outperformed existing multimodal large language models (MLLMs) in these tasks.","While VoT works surprisingly well on LLMs, the ability to generate \\textit{mental images} to facilitate spatial reasoning resembles the mind's eye process, suggesting its potential viability in MLLMs."],"url":"http://arxiv.org/abs/2404.03622v1"}
{"created":"2024-04-04 17:43:06","title":"LCM-Lookahead for Encoder-based Text-to-Image Personalization","abstract":"Recent advancements in diffusion models have introduced fast sampling methods that can effectively produce high-quality images in just one or a few denoising steps. Interestingly, when these are distilled from existing diffusion models, they often maintain alignment with the original model, retaining similar outputs for similar prompts and seeds. These properties present opportunities to leverage fast sampling methods as a shortcut-mechanism, using them to create a preview of denoised outputs through which we can backpropagate image-space losses. In this work, we explore the potential of using such shortcut-mechanisms to guide the personalization of text-to-image models to specific facial identities. We focus on encoder-based personalization approaches, and demonstrate that by tuning them with a lookahead identity loss, we can achieve higher identity fidelity, without sacrificing layout diversity or prompt alignment. We further explore the use of attention sharing mechanisms and consistent data generation for the task of personalization, and find that encoder training can benefit from both.","sentences":["Recent advancements in diffusion models have introduced fast sampling methods that can effectively produce high-quality images in just one or a few denoising steps.","Interestingly, when these are distilled from existing diffusion models, they often maintain alignment with the original model, retaining similar outputs for similar prompts and seeds.","These properties present opportunities to leverage fast sampling methods as a shortcut-mechanism, using them to create a preview of denoised outputs through which we can backpropagate image-space losses.","In this work, we explore the potential of using such shortcut-mechanisms to guide the personalization of text-to-image models to specific facial identities.","We focus on encoder-based personalization approaches, and demonstrate that by tuning them with a lookahead identity loss, we can achieve higher identity fidelity, without sacrificing layout diversity or prompt alignment.","We further explore the use of attention sharing mechanisms and consistent data generation for the task of personalization, and find that encoder training can benefit from both."],"url":"http://arxiv.org/abs/2404.03620v1"}
{"created":"2024-04-04 17:40:06","title":"DeViDe: Faceted medical knowledge for improved medical vision-language pre-training","abstract":"Vision-language pre-training for chest X-rays has made significant strides, primarily by utilizing paired radiographs and radiology reports. However, existing approaches often face challenges in encoding medical knowledge effectively. While radiology reports provide insights into the current disease manifestation, medical definitions (as used by contemporary methods) tend to be overly abstract, creating a gap in knowledge. To address this, we propose DeViDe, a novel transformer-based method that leverages radiographic descriptions from the open web. These descriptions outline general visual characteristics of diseases in radiographs, and when combined with abstract definitions and radiology reports, provide a holistic snapshot of knowledge. DeViDe incorporates three key features for knowledge-augmented vision language alignment: First, a large-language model-based augmentation is employed to homogenise medical knowledge from diverse sources. Second, this knowledge is aligned with image information at various levels of granularity. Third, a novel projection layer is proposed to handle the complexity of aligning each image with multiple descriptions arising in a multi-label setting. In zero-shot settings, DeViDe performs comparably to fully supervised models on external datasets and achieves state-of-the-art results on three large-scale datasets. Additionally, fine-tuning DeViDe on four downstream tasks and six segmentation tasks showcases its superior performance across data from diverse distributions.","sentences":["Vision-language pre-training for chest X-rays has made significant strides, primarily by utilizing paired radiographs and radiology reports.","However, existing approaches often face challenges in encoding medical knowledge effectively.","While radiology reports provide insights into the current disease manifestation, medical definitions (as used by contemporary methods) tend to be overly abstract, creating a gap in knowledge.","To address this, we propose DeViDe, a novel transformer-based method that leverages radiographic descriptions from the open web.","These descriptions outline general visual characteristics of diseases in radiographs, and when combined with abstract definitions and radiology reports, provide a holistic snapshot of knowledge.","DeViDe incorporates three key features for knowledge-augmented vision language alignment: First, a large-language model-based augmentation is employed to homogenise medical knowledge from diverse sources.","Second, this knowledge is aligned with image information at various levels of granularity.","Third, a novel projection layer is proposed to handle the complexity of aligning each image with multiple descriptions arising in a multi-label setting.","In zero-shot settings, DeViDe performs comparably to fully supervised models on external datasets and achieves state-of-the-art results on three large-scale datasets.","Additionally, fine-tuning DeViDe on four downstream tasks and six segmentation tasks showcases its superior performance across data from diverse distributions."],"url":"http://arxiv.org/abs/2404.03618v1"}
{"created":"2024-04-04 17:39:41","title":"On the Efficiency of Convolutional Neural Networks","abstract":"Since the breakthrough performance of AlexNet in 2012, convolutional neural networks (convnets) have grown into extremely powerful vision models. Deep learning researchers have used convnets to produce accurate results that were unachievable a decade ago. Yet computer scientists make computational efficiency their primary objective. Accuracy with exorbitant cost is not acceptable; an algorithm must also minimize its computational requirements. Confronted with the daunting computation that convnets use, deep learning researchers also became interested in efficiency. Researchers applied tremendous effort to find the convnet architectures that have the greatest efficiency. However, skepticism grew among researchers and engineers alike about the relevance of arithmetic complexity. Contrary to the prevailing view that latency and arithmetic complexity are irreconcilable, a simple formula relates both through computational efficiency. This insight enabled us to co-optimize the separate factors that determine latency. We observed that the degenerate conv2d layers that produce the best accuracy-complexity trade-off also have low operational intensity. Therefore, kernels that implement these layers use significant memory resources. We solved this optimization problem with block-fusion kernels that implement all layers of a residual block, thereby creating temporal locality, avoiding communication, and reducing workspace size. Our ConvFirst model with block-fusion kernels ran approximately four times as fast as the ConvNeXt baseline with PyTorch Inductor, at equal accuracy on the ImageNet-1K classification task. Our unified approach to convnet efficiency envisions a new era of models and kernels that achieve greater accuracy at lower cost.","sentences":["Since the breakthrough performance of AlexNet in 2012, convolutional neural networks (convnets) have grown into extremely powerful vision models.","Deep learning researchers have used convnets to produce accurate results that were unachievable a decade ago.","Yet computer scientists make computational efficiency their primary objective.","Accuracy with exorbitant cost is not acceptable; an algorithm must also minimize its computational requirements.","Confronted with the daunting computation that convnets use, deep learning researchers also became interested in efficiency.","Researchers applied tremendous effort to find the convnet architectures that have the greatest efficiency.","However, skepticism grew among researchers and engineers alike about the relevance of arithmetic complexity.","Contrary to the prevailing view that latency and arithmetic complexity are irreconcilable, a simple formula relates both through computational efficiency.","This insight enabled us to co-optimize the separate factors that determine latency.","We observed that the degenerate conv2d layers that produce the best accuracy-complexity trade-off also have low operational intensity.","Therefore, kernels that implement these layers use significant memory resources.","We solved this optimization problem with block-fusion kernels that implement all layers of a residual block, thereby creating temporal locality, avoiding communication, and reducing workspace size.","Our ConvFirst model with block-fusion kernels ran approximately four times as fast as the ConvNeXt baseline with PyTorch Inductor, at equal accuracy on the ImageNet-1K classification task.","Our unified approach to convnet efficiency envisions a new era of models and kernels that achieve greater accuracy at lower cost."],"url":"http://arxiv.org/abs/2404.03617v1"}
{"created":"2024-04-04 17:36:20","title":"Towards Trustworthy Automated Program Verifiers: Formally Validating Translations into an Intermediate Verification Language (extended version)","abstract":"Automated program verifiers are typically implemented using an intermediate verification language (IVL), such as Boogie or Why3. A verifier front-end translates the input program and specification into an IVL program, while the back-end generates proof obligations for the IVL program and employs an SMT solver to discharge them. Soundness of such verifiers therefore requires that the front-end translation faithfully captures the semantics of the input program and specification in the IVL program, and that the back-end reports success only if the IVL program is actually correct. For a verification tool to be trustworthy, these soundness conditions must be satisfied by its actual implementation, not just the program logic it uses.   In this paper, we present a novel validation methodology that, given a formal semantics for the input language and IVL, provides formal soundness guarantees for front-end implementations. For each run of the verifier, we automatically generate a proof in Isabelle showing that the correctness of the produced IVL program implies the correctness of the input program. This proof can be checked independently from the verifier in Isabelle and can be combined with existing work on validating back-ends to obtain an end-to-end soundness result. Our methodology based on forward simulation employs several modularisation strategies to handle the large semantic gap between the input language and the IVL, as well as the intricacies of practical, optimised translations. We present our methodology for the widely-used Viper and Boogie languages. Our evaluation shows that it is effective in validating the translations performed by the existing Viper implementation.","sentences":["Automated program verifiers are typically implemented using an intermediate verification language (IVL), such as Boogie or Why3.","A verifier front-end translates the input program and specification into an IVL program, while the back-end generates proof obligations for the IVL program and employs an SMT solver to discharge them.","Soundness of such verifiers therefore requires that the front-end translation faithfully captures the semantics of the input program and specification in the IVL program, and that the back-end reports success only if the IVL program is actually correct.","For a verification tool to be trustworthy, these soundness conditions must be satisfied by its actual implementation, not just the program logic it uses.   ","In this paper, we present a novel validation methodology that, given a formal semantics for the input language and IVL, provides formal soundness guarantees for front-end implementations.","For each run of the verifier, we automatically generate a proof in Isabelle showing that the correctness of the produced IVL program implies the correctness of the input program.","This proof can be checked independently from the verifier in Isabelle and can be combined with existing work on validating back-ends to obtain an end-to-end soundness result.","Our methodology based on forward simulation employs several modularisation strategies to handle the large semantic gap between the input language and the IVL, as well as the intricacies of practical, optimised translations.","We present our methodology for the widely-used Viper and Boogie languages.","Our evaluation shows that it is effective in validating the translations performed by the existing Viper implementation."],"url":"http://arxiv.org/abs/2404.03614v1"}
{"created":"2024-04-04 17:34:41","title":"Per-Gaussian Embedding-Based Deformation for Deformable 3D Gaussian Splatting","abstract":"As 3D Gaussian Splatting (3DGS) provides fast and high-quality novel view synthesis, it is a natural extension to deform a canonical 3DGS to multiple frames. However, previous works fail to accurately reconstruct dynamic scenes, especially 1) static parts moving along nearby dynamic parts, and 2) some dynamic areas are blurry. We attribute the failure to the wrong design of the deformation field, which is built as a coordinate-based function. This approach is problematic because 3DGS is a mixture of multiple fields centered at the Gaussians, not just a single coordinate-based framework. To resolve this problem, we define the deformation as a function of per-Gaussian embeddings and temporal embeddings. Moreover, we decompose deformations as coarse and fine deformations to model slow and fast movements, respectively. Also, we introduce an efficient training strategy for faster convergence and higher quality. Project page: https://jeongminb.github.io/e-d3dgs/","sentences":["As 3D Gaussian Splatting (3DGS) provides fast and high-quality novel view synthesis, it is a natural extension to deform a canonical 3DGS to multiple frames.","However, previous works fail to accurately reconstruct dynamic scenes, especially 1) static parts moving along nearby dynamic parts, and 2) some dynamic areas are blurry.","We attribute the failure to the wrong design of the deformation field, which is built as a coordinate-based function.","This approach is problematic because 3DGS is a mixture of multiple fields centered at the Gaussians, not just a single coordinate-based framework.","To resolve this problem, we define the deformation as a function of per-Gaussian embeddings and temporal embeddings.","Moreover, we decompose deformations as coarse and fine deformations to model slow and fast movements, respectively.","Also, we introduce an efficient training strategy for faster convergence and higher quality.","Project page: https://jeongminb.github.io/e-d3dgs/"],"url":"http://arxiv.org/abs/2404.03613v1"}
{"created":"2024-04-04 17:34:35","title":"Creator Hearts: Investigating the Impact Positive Signals from YouTube Creators in Shaping Comment Section Behavior","abstract":"Much of the research in online moderation focuses on punitive actions. However, emerging research has shown that positive reinforcement is effective at encouraging desirable behavior on online platforms. We extend this research by studying the \"creator heart\" feature on YouTube, quantifying their primary effects on comments that receive hearts and on videos where hearts have been given. We find that creator hearts increased the visibility of comments, and increased the amount of positive engagement they received from other users. We also find that the presence of a creator hearted comment soon after a video is published can incentivize viewers to comment, increasing the total engagement with the video over time. We discuss the potential for creators to use hearts to shape behavior in their communities by highlighting, rewarding, and incentivizing desirable behaviors from users. We discuss avenues for extending our study to understanding positive signals from moderators on other platforms.","sentences":["Much of the research in online moderation focuses on punitive actions.","However, emerging research has shown that positive reinforcement is effective at encouraging desirable behavior on online platforms.","We extend this research by studying the \"creator heart\" feature on YouTube, quantifying their primary effects on comments that receive hearts and on videos where hearts have been given.","We find that creator hearts increased the visibility of comments, and increased the amount of positive engagement they received from other users.","We also find that the presence of a creator hearted comment soon after a video is published can incentivize viewers to comment, increasing the total engagement with the video over time.","We discuss the potential for creators to use hearts to shape behavior in their communities by highlighting, rewarding, and incentivizing desirable behaviors from users.","We discuss avenues for extending our study to understanding positive signals from moderators on other platforms."],"url":"http://arxiv.org/abs/2404.03612v1"}
{"created":"2024-04-04 17:34:21","title":"InsectMamba: Insect Pest Classification with State Space Model","abstract":"The classification of insect pests is a critical task in agricultural technology, vital for ensuring food security and environmental sustainability. However, the complexity of pest identification, due to factors like high camouflage and species diversity, poses significant obstacles. Existing methods struggle with the fine-grained feature extraction needed to distinguish between closely related pest species. Although recent advancements have utilized modified network structures and combined deep learning approaches to improve accuracy, challenges persist due to the similarity between pests and their surroundings. To address this problem, we introduce InsectMamba, a novel approach that integrates State Space Models (SSMs), Convolutional Neural Networks (CNNs), Multi-Head Self-Attention mechanism (MSA), and Multilayer Perceptrons (MLPs) within Mix-SSM blocks. This integration facilitates the extraction of comprehensive visual features by leveraging the strengths of each encoding strategy. A selective module is also proposed to adaptively aggregate these features, enhancing the model's ability to discern pest characteristics. InsectMamba was evaluated against strong competitors across five insect pest classification datasets. The results demonstrate its superior performance and verify the significance of each model component by an ablation study.","sentences":["The classification of insect pests is a critical task in agricultural technology, vital for ensuring food security and environmental sustainability.","However, the complexity of pest identification, due to factors like high camouflage and species diversity, poses significant obstacles.","Existing methods struggle with the fine-grained feature extraction needed to distinguish between closely related pest species.","Although recent advancements have utilized modified network structures and combined deep learning approaches to improve accuracy, challenges persist due to the similarity between pests and their surroundings.","To address this problem, we introduce InsectMamba, a novel approach that integrates State Space Models (SSMs), Convolutional Neural Networks (CNNs), Multi-Head Self-Attention mechanism (MSA), and Multilayer Perceptrons (MLPs) within Mix-SSM blocks.","This integration facilitates the extraction of comprehensive visual features by leveraging the strengths of each encoding strategy.","A selective module is also proposed to adaptively aggregate these features, enhancing the model's ability to discern pest characteristics.","InsectMamba was evaluated against strong competitors across five insect pest classification datasets.","The results demonstrate its superior performance and verify the significance of each model component by an ablation study."],"url":"http://arxiv.org/abs/2404.03611v1"}
{"created":"2024-04-04 17:31:32","title":"Sailor: Open Language Models for South-East Asia","abstract":"We present Sailor, a family of open language models ranging from 0.5B to 7B parameters, tailored for South-East Asian (SEA) languages. These models are continually pre-trained from Qwen1.5, a great language model for multilingual use cases. From Qwen1.5, Sailor models accept 200B to 400B tokens, primarily covering the languages of English, Chinese, Vietnamese, Thai, Indonesian, Malay, and Lao. The training leverages several techniques, including BPE dropout for improving the model robustness, aggressive data cleaning and deduplication, and small proxy models to optimize data mixture. Experimental results on four typical tasks indicate that Sailor models demonstrate strong performance across different benchmarks, including commonsense reasoning, question answering, reading comprehension and examination. Embracing the open-source spirit, we share our insights through this report to spark a wider interest in developing large language models for multilingual use cases.","sentences":["We present Sailor, a family of open language models ranging from 0.5B to 7B parameters, tailored for South-East Asian (SEA) languages.","These models are continually pre-trained from Qwen1.5, a great language model for multilingual use cases.","From Qwen1.5, Sailor models accept 200B to 400B tokens, primarily covering the languages of English, Chinese, Vietnamese, Thai, Indonesian, Malay, and Lao.","The training leverages several techniques, including BPE dropout for improving the model robustness, aggressive data cleaning and deduplication, and small proxy models to optimize data mixture.","Experimental results on four typical tasks indicate that Sailor models demonstrate strong performance across different benchmarks, including commonsense reasoning, question answering, reading comprehension and examination.","Embracing the open-source spirit, we share our insights through this report to spark a wider interest in developing large language models for multilingual use cases."],"url":"http://arxiv.org/abs/2404.03608v1"}
{"created":"2024-04-04 17:25:31","title":"Analyzing Musical Characteristics of National Anthems in Relation to Global Indices","abstract":"Music plays a huge part in shaping peoples' psychology and behavioral patterns. This paper investigates the connection between national anthems and different global indices with computational music analysis and statistical correlation analysis. We analyze national anthem musical data to determine whether certain musical characteristics are associated with peace, happiness, suicide rate, crime rate, etc. To achieve this, we collect national anthems from 169 countries and use computational music analysis techniques to extract pitch, tempo, beat, and other pertinent audio features. We then compare these musical characteristics with data on different global indices to ascertain whether a significant correlation exists. Our findings indicate that there may be a correlation between the musical characteristics of national anthems and the indices we investigated. The implications of our findings for music psychology and policymakers interested in promoting social well-being are discussed. This paper emphasizes the potential of musical data analysis in social research and offers a novel perspective on the relationship between music and social indices. The source code and data are made open-access for reproducibility and future research endeavors. It can be accessed at http://bit.ly/na_code.","sentences":["Music plays a huge part in shaping peoples' psychology and behavioral patterns.","This paper investigates the connection between national anthems and different global indices with computational music analysis and statistical correlation analysis.","We analyze national anthem musical data to determine whether certain musical characteristics are associated with peace, happiness, suicide rate, crime rate, etc.","To achieve this, we collect national anthems from 169 countries and use computational music analysis techniques to extract pitch, tempo, beat, and other pertinent audio features.","We then compare these musical characteristics with data on different global indices to ascertain whether a significant correlation exists.","Our findings indicate that there may be a correlation between the musical characteristics of national anthems and the indices we investigated.","The implications of our findings for music psychology and policymakers interested in promoting social well-being are discussed.","This paper emphasizes the potential of musical data analysis in social research and offers a novel perspective on the relationship between music and social indices.","The source code and data are made open-access for reproducibility and future research endeavors.","It can be accessed at http://bit.ly/na_code."],"url":"http://arxiv.org/abs/2404.03606v1"}
{"created":"2024-04-04 17:25:30","title":"Mitigating the Impact of Outlier Channels for Language Model Quantization with Activation Regularization","abstract":"We consider the problem of accurate quantization for language models, where both the weights and activations are uniformly quantized to 4 bits per parameter, the lowest bitwidth format natively supported by GPU hardware. In this context, the key challenge is activation quantization: it is known that language models contain outlier channels whose values on average are orders of magnitude higher than than other channels, which prevents accurate low-bitwidth quantization with known techniques. We systematically study this phenomena and find that these outlier channels emerge early in training, and that they occur more frequently in layers with residual streams. We then propose a simple strategy which regularizes a layer's inputs via quantization-aware training (QAT) and its outputs via activation kurtosis regularization. We show that regularizing both the inputs and outputs is crucial for preventing a model's \"migrating\" the difficulty in input quantization to the weights, which makes post-training quantization (PTQ) of weights more difficult. When combined with weight PTQ, we show that our approach can obtain a W4A4 model that performs competitively to the standard-precision W16A16 baseline.","sentences":["We consider the problem of accurate quantization for language models, where both the weights and activations are uniformly quantized to 4 bits per parameter, the lowest bitwidth format natively supported by GPU hardware.","In this context, the key challenge is activation quantization: it is known that language models contain outlier channels whose values on average are orders of magnitude higher than than other channels, which prevents accurate low-bitwidth quantization with known techniques.","We systematically study this phenomena and find that these outlier channels emerge early in training, and that they occur more frequently in layers with residual streams.","We then propose a simple strategy which regularizes a layer's inputs via quantization-aware training (QAT) and its outputs via activation kurtosis regularization.","We show that regularizing both the inputs and outputs is crucial for preventing a model's \"migrating\" the difficulty in input quantization to the weights, which makes post-training quantization (PTQ) of weights more difficult.","When combined with weight PTQ, we show that our approach can obtain a W4A4 model that performs competitively to the standard-precision W16A16 baseline."],"url":"http://arxiv.org/abs/2404.03605v1"}
{"created":"2024-04-04 17:19:47","title":"Evaluating LLMs at Detecting Errors in LLM Responses","abstract":"With Large Language Models (LLMs) being widely used across various tasks, detecting errors in their responses is increasingly crucial. However, little research has been conducted on error detection of LLM responses. Collecting error annotations on LLM responses is challenging due to the subjective nature of many NLP tasks, and thus previous research focuses on tasks of little practical value (e.g., word sorting) or limited error types (e.g., faithfulness in summarization). This work introduces ReaLMistake, the first error detection benchmark consisting of objective, realistic, and diverse errors made by LLMs. ReaLMistake contains three challenging and meaningful tasks that introduce objectively assessable errors in four categories (reasoning correctness, instruction-following, context-faithfulness, and parameterized knowledge), eliciting naturally observed and diverse errors in responses of GPT-4 and Llama 2 70B annotated by experts. We use ReaLMistake to evaluate error detectors based on 12 LLMs. Our findings show: 1) Top LLMs like GPT-4 and Claude 3 detect errors made by LLMs at very low recall, and all LLM-based error detectors perform much worse than humans. 2) Explanations by LLM-based error detectors lack reliability. 3) LLMs-based error detection is sensitive to small changes in prompts but remains challenging to improve. 4) Popular approaches to improving LLMs, including self-consistency and majority vote, do not improve the error detection performance. Our benchmark and code are provided at https://github.com/psunlpgroup/ReaLMistake.","sentences":["With Large Language Models (LLMs) being widely used across various tasks, detecting errors in their responses is increasingly crucial.","However, little research has been conducted on error detection of LLM responses.","Collecting error annotations on LLM responses is challenging due to the subjective nature of many NLP tasks, and thus previous research focuses on tasks of little practical value (e.g., word sorting) or limited error types (e.g., faithfulness in summarization).","This work introduces ReaLMistake, the first error detection benchmark consisting of objective, realistic, and diverse errors made by LLMs.","ReaLMistake contains three challenging and meaningful tasks that introduce objectively assessable errors in four categories (reasoning correctness, instruction-following, context-faithfulness, and parameterized knowledge), eliciting naturally observed and diverse errors in responses of GPT-4 and Llama 2 70B annotated by experts.","We use ReaLMistake to evaluate error detectors based on 12 LLMs.","Our findings show: 1) Top LLMs like GPT-4 and Claude 3 detect errors made by LLMs at very low recall, and all LLM-based error detectors perform much worse than humans.","2) Explanations by LLM-based error detectors lack reliability.","3) LLMs-based error detection is sensitive to small changes in prompts but remains challenging to improve.","4) Popular approaches to improving LLMs, including self-consistency and majority vote, do not improve the error detection performance.","Our benchmark and code are provided at https://github.com/psunlpgroup/ReaLMistake."],"url":"http://arxiv.org/abs/2404.03602v1"}
{"created":"2024-04-04 17:09:52","title":"Intent Detection and Entity Extraction from BioMedical Literature","abstract":"Biomedical queries have become increasingly prevalent in web searches, reflecting the growing interest in accessing biomedical literature. Despite recent research on large-language models (LLMs) motivated by endeavours to attain generalized intelligence, their efficacy in replacing task and domain-specific natural language understanding approaches remains questionable. In this paper, we address this question by conducting a comprehensive empirical evaluation of intent detection and named entity recognition (NER) tasks from biomedical text. We show that Supervised Fine Tuned approaches are still relevant and more effective than general-purpose LLMs. Biomedical transformer models such as PubMedBERT can surpass ChatGPT on NER task with only 5 supervised examples.","sentences":["Biomedical queries have become increasingly prevalent in web searches, reflecting the growing interest in accessing biomedical literature.","Despite recent research on large-language models (LLMs) motivated by endeavours to attain generalized intelligence, their efficacy in replacing task and domain-specific natural language understanding approaches remains questionable.","In this paper, we address this question by conducting a comprehensive empirical evaluation of intent detection and named entity recognition (NER) tasks from biomedical text.","We show that Supervised Fine Tuned approaches are still relevant and more effective than general-purpose LLMs.","Biomedical transformer models such as PubMedBERT can surpass ChatGPT on NER task with only 5 supervised examples."],"url":"http://arxiv.org/abs/2404.03598v1"}
{"created":"2024-04-04 17:05:42","title":"Laser Learning Environment: A new environment for coordination-critical multi-agent tasks","abstract":"We introduce the Laser Learning Environment (LLE), a collaborative multi-agent reinforcement learning environment in which coordination is central. In LLE, agents depend on each other to make progress (interdependence), must jointly take specific sequences of actions to succeed (perfect coordination), and accomplishing those joint actions does not yield any intermediate reward (zero-incentive dynamics). The challenge of such problems lies in the difficulty of escaping state space bottlenecks caused by interdependence steps since escaping those bottlenecks is not rewarded. We test multiple state-of-the-art value-based MARL algorithms against LLE and show that they consistently fail at the collaborative task because of their inability to escape state space bottlenecks, even though they successfully achieve perfect coordination. We show that Q-learning extensions such as prioritized experience replay and n-steps return hinder exploration in environments with zero-incentive dynamics, and find that intrinsic curiosity with random network distillation is not sufficient to escape those bottlenecks. We demonstrate the need for novel methods to solve this problem and the relevance of LLE as cooperative MARL benchmark.","sentences":["We introduce the Laser Learning Environment (LLE), a collaborative multi-agent reinforcement learning environment in which coordination is central.","In LLE, agents depend on each other to make progress (interdependence), must jointly take specific sequences of actions to succeed (perfect coordination), and accomplishing those joint actions does not yield any intermediate reward (zero-incentive dynamics).","The challenge of such problems lies in the difficulty of escaping state space bottlenecks caused by interdependence steps since escaping those bottlenecks is not rewarded.","We test multiple state-of-the-art value-based MARL algorithms against LLE and show that they consistently fail at the collaborative task because of their inability to escape state space bottlenecks, even though they successfully achieve perfect coordination.","We show that Q-learning extensions such as prioritized experience replay and n-steps return hinder exploration in environments with zero-incentive dynamics, and find that intrinsic curiosity with random network distillation is not sufficient to escape those bottlenecks.","We demonstrate the need for novel methods to solve this problem and the relevance of LLE as cooperative MARL benchmark."],"url":"http://arxiv.org/abs/2404.03596v1"}
{"created":"2024-04-04 17:00:37","title":"ReFT: Representation Finetuning for Language Models","abstract":"Parameter-efficient fine-tuning (PEFT) methods seek to adapt large models via updates to a small number of weights. However, much prior interpretability work has shown that representations encode rich semantic information, suggesting that editing representations might be a more powerful alternative. Here, we pursue this hypothesis by developing a family of $\\textbf{Representation Finetuning (ReFT)}$ methods. ReFT methods operate on a frozen base model and learn task-specific interventions on hidden representations. We define a strong instance of the ReFT family, Low-rank Linear Subspace ReFT (LoReFT). LoReFT is a drop-in replacement for existing PEFTs and learns interventions that are 10x-50x more parameter-efficient than prior state-of-the-art PEFTs. We showcase LoReFT on eight commonsense reasoning tasks, four arithmetic reasoning tasks, Alpaca-Eval v1.0, and GLUE. In all these evaluations, LoReFT delivers the best balance of efficiency and performance, and almost always outperforms state-of-the-art PEFTs. We release a generic ReFT training library publicly at https://github.com/stanfordnlp/pyreft.","sentences":["Parameter-efficient fine-tuning (PEFT) methods seek to adapt large models via updates to a small number of weights.","However, much prior interpretability work has shown that representations encode rich semantic information, suggesting that editing representations might be a more powerful alternative.","Here, we pursue this hypothesis by developing a family of $\\textbf{Representation Finetuning (ReFT)}$ methods.","ReFT methods operate on a frozen base model and learn task-specific interventions on hidden representations.","We define a strong instance of the ReFT family, Low-rank Linear Subspace ReFT (LoReFT).","LoReFT is a drop-in replacement for existing PEFTs and learns interventions that are 10x-50x more parameter-efficient than prior state-of-the-art PEFTs.","We showcase LoReFT on eight commonsense reasoning tasks, four arithmetic reasoning tasks, Alpaca-Eval v1.0, and GLUE.","In all these evaluations, LoReFT delivers the best balance of efficiency and performance, and almost always outperforms state-of-the-art PEFTs.","We release a generic ReFT training library publicly at https://github.com/stanfordnlp/pyreft."],"url":"http://arxiv.org/abs/2404.03592v1"}
{"created":"2024-04-04 16:59:13","title":"Wilkins: HPC In Situ Workflows Made Easy","abstract":"In situ approaches can accelerate the pace of scientific discoveries by allowing scientists to perform data analysis at simulation time. Current in situ workflow systems, however, face challenges in handling the growing complexity and diverse computational requirements of scientific tasks. In this work, we present Wilkins, an in situ workflow system that is designed for ease-of-use while providing scalable and efficient execution of workflow tasks. Wilkins provides a flexible workflow description interface, employs a high-performance data transport layer based on HDF5, and supports tasks with disparate data rates by providing a flow control mechanism. Wilkins seamlessly couples scientific tasks that already use HDF5, without requiring task code modifications. We demonstrate the above features using both synthetic benchmarks and two science use cases in materials science and cosmology.","sentences":["In situ approaches can accelerate the pace of scientific discoveries by allowing scientists to perform data analysis at simulation time.","Current in situ workflow systems, however, face challenges in handling the growing complexity and diverse computational requirements of scientific tasks.","In this work, we present Wilkins, an in situ workflow system that is designed for ease-of-use while providing scalable and efficient execution of workflow tasks.","Wilkins provides a flexible workflow description interface, employs a high-performance data transport layer based on HDF5, and supports tasks with disparate data rates by providing a flow control mechanism.","Wilkins seamlessly couples scientific tasks that already use HDF5, without requiring task code modifications.","We demonstrate the above features using both synthetic benchmarks and two science use cases in materials science and cosmology."],"url":"http://arxiv.org/abs/2404.03591v1"}
{"created":"2024-04-04 16:58:26","title":"SemGrasp: Semantic Grasp Generation via Language Aligned Discretization","abstract":"Generating natural human grasps necessitates consideration of not just object geometry but also semantic information. Solely depending on object shape for grasp generation confines the applications of prior methods in downstream tasks. This paper presents a novel semantic-based grasp generation method, termed SemGrasp, which generates a static human grasp pose by incorporating semantic information into the grasp representation. We introduce a discrete representation that aligns the grasp space with semantic space, enabling the generation of grasp postures in accordance with language instructions. A Multimodal Large Language Model (MLLM) is subsequently fine-tuned, integrating object, grasp, and language within a unified semantic space. To facilitate the training of SemGrasp, we have compiled a large-scale, grasp-text-aligned dataset named CapGrasp, featuring about 260k detailed captions and 50k diverse grasps. Experimental findings demonstrate that SemGrasp efficiently generates natural human grasps in alignment with linguistic intentions. Our code, models, and dataset are available publicly at: https://kailinli.github.io/SemGrasp.","sentences":["Generating natural human grasps necessitates consideration of not just object geometry but also semantic information.","Solely depending on object shape for grasp generation confines the applications of prior methods in downstream tasks.","This paper presents a novel semantic-based grasp generation method, termed SemGrasp, which generates a static human grasp pose by incorporating semantic information into the grasp representation.","We introduce a discrete representation that aligns the grasp space with semantic space, enabling the generation of grasp postures in accordance with language instructions.","A Multimodal Large Language Model (MLLM) is subsequently fine-tuned, integrating object, grasp, and language within a unified semantic space.","To facilitate the training of SemGrasp, we have compiled a large-scale, grasp-text-aligned dataset named CapGrasp, featuring about 260k detailed captions and 50k diverse grasps.","Experimental findings demonstrate that SemGrasp efficiently generates natural human grasps in alignment with linguistic intentions.","Our code, models, and dataset are available publicly at: https://kailinli.github.io/SemGrasp."],"url":"http://arxiv.org/abs/2404.03590v1"}
{"created":"2024-04-04 16:52:48","title":"Anticipate & Collab: Data-driven Task Anticipation and Knowledge-driven Planning for Human-robot Collaboration","abstract":"An agent assisting humans in daily living activities can collaborate more effectively by anticipating upcoming tasks. Data-driven methods represent the state of the art in task anticipation, planning, and related problems, but these methods are resource-hungry and opaque. Our prior work introduced a proof of concept framework that used an LLM to anticipate 3 high-level tasks that served as goals for a classical planning system that computed a sequence of low-level actions for the agent to achieve these goals. This paper describes DaTAPlan, our framework that significantly extends our prior work toward human-robot collaboration. Specifically, DaTAPlan planner computes actions for an agent and a human to collaboratively and jointly achieve the tasks anticipated by the LLM, and the agent automatically adapts to unexpected changes in human action outcomes and preferences. We evaluate DaTAPlan capabilities in a realistic simulation environment, demonstrating accurate task anticipation, effective human-robot collaboration, and the ability to adapt to unexpected changes. Project website: https://dataplan-hrc.github.io","sentences":["An agent assisting humans in daily living activities can collaborate more effectively by anticipating upcoming tasks.","Data-driven methods represent the state of the art in task anticipation, planning, and related problems, but these methods are resource-hungry and opaque.","Our prior work introduced a proof of concept framework that used an LLM to anticipate 3 high-level tasks that served as goals for a classical planning system that computed a sequence of low-level actions for the agent to achieve these goals.","This paper describes DaTAPlan, our framework that significantly extends our prior work toward human-robot collaboration.","Specifically, DaTAPlan planner computes actions for an agent and a human to collaboratively and jointly achieve the tasks anticipated by the LLM, and the agent automatically adapts to unexpected changes in human action outcomes and preferences.","We evaluate DaTAPlan capabilities in a realistic simulation environment, demonstrating accurate task anticipation, effective human-robot collaboration, and the ability to adapt to unexpected changes.","Project website: https://dataplan-hrc.github.io"],"url":"http://arxiv.org/abs/2404.03587v1"}
{"created":"2024-04-04 16:52:17","title":"Leveraging Interpolation Models and Error Bounds for Verifiable Scientific Machine Learning","abstract":"Effective verification and validation techniques for modern scientific machine learning workflows are challenging to devise. Statistical methods are abundant and easily deployed, but often rely on speculative assumptions about the data and methods involved. Error bounds for classical interpolation techniques can provide mathematically rigorous estimates of accuracy, but often are difficult or impractical to determine computationally. In this work, we present a best-of-both-worlds approach to verifiable scientific machine learning by demonstrating that (1) multiple standard interpolation techniques have informative error bounds that can be computed or estimated efficiently; (2) comparative performance among distinct interpolants can aid in validation goals; (3) deploying interpolation methods on latent spaces generated by deep learning techniques enables some interpretability for black-box models. We present a detailed case study of our approach for predicting lift-drag ratios from airfoil images. Code developed for this work is available in a public Github repository.","sentences":["Effective verification and validation techniques for modern scientific machine learning workflows are challenging to devise.","Statistical methods are abundant and easily deployed, but often rely on speculative assumptions about the data and methods involved.","Error bounds for classical interpolation techniques can provide mathematically rigorous estimates of accuracy, but often are difficult or impractical to determine computationally.","In this work, we present a best-of-both-worlds approach to verifiable scientific machine learning by demonstrating that (1) multiple standard interpolation techniques have informative error bounds that can be computed or estimated efficiently; (2) comparative performance among distinct interpolants can aid in validation goals; (3) deploying interpolation methods on latent spaces generated by deep learning techniques enables some interpretability for black-box models.","We present a detailed case study of our approach for predicting lift-drag ratios from airfoil images.","Code developed for this work is available in a public Github repository."],"url":"http://arxiv.org/abs/2404.03586v1"}
{"created":"2024-04-04 16:48:40","title":"Towards more realistic human motion prediction with attention to motion coordination","abstract":"Joint relation modeling is a curial component in human motion prediction. Most existing methods rely on skeletal-based graphs to build the joint relations, where local interactive relations between joint pairs are well learned. However, the motion coordination, a global joint relation reflecting the simultaneous cooperation of all joints, is usually weakened because it is learned from part to whole progressively and asynchronously. Thus, the final predicted motions usually appear unrealistic. To tackle this issue, we learn a medium, called coordination attractor (CA), from the spatiotemporal features of motion to characterize the global motion features, which is subsequently used to build new relative joint relations. Through the CA, all joints are related simultaneously, and thus the motion coordination of all joints can be better learned. Based on this, we further propose a novel joint relation modeling module, Comprehensive Joint Relation Extractor (CJRE), to combine this motion coordination with the local interactions between joint pairs in a unified manner. Additionally, we also present a Multi-timescale Dynamics Extractor (MTDE) to extract enriched dynamics from the raw position information for effective prediction. Extensive experiments show that the proposed framework outperforms state-of-the-art methods in both short- and long-term predictions on H3.6M, CMU-Mocap, and 3DPW.","sentences":["Joint relation modeling is a curial component in human motion prediction.","Most existing methods rely on skeletal-based graphs to build the joint relations, where local interactive relations between joint pairs are well learned.","However, the motion coordination, a global joint relation reflecting the simultaneous cooperation of all joints, is usually weakened because it is learned from part to whole progressively and asynchronously.","Thus, the final predicted motions usually appear unrealistic.","To tackle this issue, we learn a medium, called coordination attractor (CA), from the spatiotemporal features of motion to characterize the global motion features, which is subsequently used to build new relative joint relations.","Through the CA, all joints are related simultaneously, and thus the motion coordination of all joints can be better learned.","Based on this, we further propose a novel joint relation modeling module, Comprehensive Joint Relation Extractor (CJRE), to combine this motion coordination with the local interactions between joint pairs in a unified manner.","Additionally, we also present a Multi-timescale Dynamics Extractor (MTDE) to extract enriched dynamics from the raw position information for effective prediction.","Extensive experiments show that the proposed framework outperforms state-of-the-art methods in both short- and long-term predictions on H3.6M, CMU-Mocap, and 3DPW."],"url":"http://arxiv.org/abs/2404.03584v1"}
{"created":"2024-04-04 16:40:22","title":"Distributionally Robust Reinforcement Learning with Interactive Data Collection: Fundamental Hardness and Near-Optimal Algorithm","abstract":"The sim-to-real gap, which represents the disparity between training and testing environments, poses a significant challenge in reinforcement learning (RL). A promising approach to addressing this challenge is distributionally robust RL, often framed as a robust Markov decision process (RMDP). In this framework, the objective is to find a robust policy that achieves good performance under the worst-case scenario among all environments within a pre-specified uncertainty set centered around the training environment. Unlike previous work, which relies on a generative model or a pre-collected offline dataset enjoying good coverage of the deployment environment, we tackle robust RL via interactive data collection, where the learner interacts with the training environment only and refines the policy through trial and error. In this robust RL paradigm, two main challenges emerge: managing distributional robustness while striking a balance between exploration and exploitation during data collection. Initially, we establish that sample-efficient learning without additional assumptions is unattainable owing to the curse of support shift; i.e., the potential disjointedness of the distributional supports between the training and testing environments. To circumvent such a hardness result, we introduce the vanishing minimal value assumption to RMDPs with a total-variation (TV) distance robust set, postulating that the minimal value of the optimal robust value function is zero. We prove that such an assumption effectively eliminates the support shift issue for RMDPs with a TV distance robust set, and present an algorithm with a provable sample complexity guarantee. Our work makes the initial step to uncovering the inherent difficulty of robust RL via interactive data collection and sufficient conditions for designing a sample-efficient algorithm accompanied by sharp sample complexity analysis.","sentences":["The sim-to-real gap, which represents the disparity between training and testing environments, poses a significant challenge in reinforcement learning (RL).","A promising approach to addressing this challenge is distributionally robust RL, often framed as a robust Markov decision process (RMDP).","In this framework, the objective is to find a robust policy that achieves good performance under the worst-case scenario among all environments within a pre-specified uncertainty set centered around the training environment.","Unlike previous work, which relies on a generative model or a pre-collected offline dataset enjoying good coverage of the deployment environment, we tackle robust RL via interactive data collection, where the learner interacts with the training environment only and refines the policy through trial and error.","In this robust RL paradigm, two main challenges emerge: managing distributional robustness while striking a balance between exploration and exploitation during data collection.","Initially, we establish that sample-efficient learning without additional assumptions is unattainable owing to the curse of support shift; i.e., the potential disjointedness of the distributional supports between the training and testing environments.","To circumvent such a hardness result, we introduce the vanishing minimal value assumption to RMDPs with a total-variation (TV) distance robust set, postulating that the minimal value of the optimal robust value function is zero.","We prove that such an assumption effectively eliminates the support shift issue for RMDPs with a TV distance robust set, and present an algorithm with a provable sample complexity guarantee.","Our work makes the initial step to uncovering the inherent difficulty of robust RL via interactive data collection and sufficient conditions for designing a sample-efficient algorithm accompanied by sharp sample complexity analysis."],"url":"http://arxiv.org/abs/2404.03578v1"}
{"created":"2024-04-04 16:40:11","title":"Untangle the KNOT: Interweaving Conflicting Knowledge and Reasoning Skills in Large Language Models","abstract":"Providing knowledge documents for large language models (LLMs) has emerged as a promising solution to update the static knowledge inherent in their parameters. However, knowledge in the document may conflict with the memory of LLMs due to outdated or incorrect knowledge in the LLMs' parameters. This leads to the necessity of examining the capability of LLMs to assimilate supplemental external knowledge that conflicts with their memory. While previous studies have explained to what extent LLMs extract conflicting knowledge from the provided text, they neglect the necessity to reason with conflicting knowledge. Furthermore, there lack a detailed analysis on strategies to enable LLMs to resolve conflicting knowledge via prompting, decoding strategy, and supervised fine-tuning. To address these limitations, we construct a new dataset, dubbed KNOT, for knowledge conflict resolution examination in the form of question answering. KNOT facilitates in-depth analysis by dividing reasoning with conflicting knowledge into three levels: (1) Direct Extraction, which directly extracts conflicting knowledge to answer questions. (2) Explicit Reasoning, which reasons with conflicting knowledge when the reasoning path is explicitly provided in the question. (3) Implicit Reasoning, where reasoning with conflicting knowledge requires LLMs to infer the reasoning path independently to answer questions. We also conduct extensive experiments on KNOT to establish empirical guidelines for LLMs to utilize conflicting knowledge in complex circumstances. Dataset and associated codes can be accessed at https://github.com/THU-KEG/KNOT .","sentences":["Providing knowledge documents for large language models (LLMs) has emerged as a promising solution to update the static knowledge inherent in their parameters.","However, knowledge in the document may conflict with the memory of LLMs due to outdated or incorrect knowledge in the LLMs' parameters.","This leads to the necessity of examining the capability of LLMs to assimilate supplemental external knowledge that conflicts with their memory.","While previous studies have explained to what extent LLMs extract conflicting knowledge from the provided text, they neglect the necessity to reason with conflicting knowledge.","Furthermore, there lack a detailed analysis on strategies to enable LLMs to resolve conflicting knowledge via prompting, decoding strategy, and supervised fine-tuning.","To address these limitations, we construct a new dataset, dubbed KNOT, for knowledge conflict resolution examination in the form of question answering.","KNOT facilitates in-depth analysis by dividing reasoning with conflicting knowledge into three levels: (1) Direct Extraction, which directly extracts conflicting knowledge to answer questions.","(2) Explicit Reasoning, which reasons with conflicting knowledge when the reasoning path is explicitly provided in the question.","(3) Implicit Reasoning, where reasoning with conflicting knowledge requires LLMs to infer the reasoning path independently to answer questions.","We also conduct extensive experiments on KNOT to establish empirical guidelines for LLMs to utilize conflicting knowledge in complex circumstances.","Dataset and associated codes can be accessed at https://github.com/THU-KEG/KNOT ."],"url":"http://arxiv.org/abs/2404.03577v1"}
{"created":"2024-04-04 16:38:57","title":"DreamScene: 3D Gaussian-based Text-to-3D Scene Generation via Formation Pattern Sampling","abstract":"Text-to-3D scene generation holds immense potential for the gaming, film, and architecture sectors. Despite significant progress, existing methods struggle with maintaining high quality, consistency, and editing flexibility. In this paper, we propose DreamScene, a 3D Gaussian-based novel text-to-3D scene generation framework, to tackle the aforementioned three challenges mainly via two strategies. First, DreamScene employs Formation Pattern Sampling (FPS), a multi-timestep sampling strategy guided by the formation patterns of 3D objects, to form fast, semantically rich, and high-quality representations. FPS uses 3D Gaussian filtering for optimization stability, and leverages reconstruction techniques to generate plausible textures. Second, DreamScene employs a progressive three-stage camera sampling strategy, specifically designed for both indoor and outdoor settings, to effectively ensure object-environment integration and scene-wide 3D consistency. Last, DreamScene enhances scene editing flexibility by integrating objects and environments, enabling targeted adjustments. Extensive experiments validate DreamScene's superiority over current state-of-the-art techniques, heralding its wide-ranging potential for diverse applications. Code and demos will be released at https://dreamscene-project.github.io .","sentences":["Text-to-3D scene generation holds immense potential for the gaming, film, and architecture sectors.","Despite significant progress, existing methods struggle with maintaining high quality, consistency, and editing flexibility.","In this paper, we propose DreamScene, a 3D Gaussian-based novel text-to-3D scene generation framework, to tackle the aforementioned three challenges mainly via two strategies.","First, DreamScene employs Formation Pattern Sampling (FPS), a multi-timestep sampling strategy guided by the formation patterns of 3D objects, to form fast, semantically rich, and high-quality representations.","FPS uses 3D Gaussian filtering for optimization stability, and leverages reconstruction techniques to generate plausible textures.","Second, DreamScene employs a progressive three-stage camera sampling strategy, specifically designed for both indoor and outdoor settings, to effectively ensure object-environment integration and scene-wide 3D consistency.","Last, DreamScene enhances scene editing flexibility by integrating objects and environments, enabling targeted adjustments.","Extensive experiments validate DreamScene's superiority over current state-of-the-art techniques, heralding its wide-ranging potential for diverse applications.","Code and demos will be released at https://dreamscene-project.github.io ."],"url":"http://arxiv.org/abs/2404.03575v1"}
{"created":"2024-04-04 16:38:49","title":"TinyVQA: Compact Multimodal Deep Neural Network for Visual Question Answering on Resource-Constrained Devices","abstract":"Traditional machine learning models often require powerful hardware, making them unsuitable for deployment on resource-limited devices. Tiny Machine Learning (tinyML) has emerged as a promising approach for running machine learning models on these devices, but integrating multiple data modalities into tinyML models still remains a challenge due to increased complexity, latency, and power consumption. This paper proposes TinyVQA, a novel multimodal deep neural network for visual question answering tasks that can be deployed on resource-constrained tinyML hardware. TinyVQA leverages a supervised attention-based model to learn how to answer questions about images using both vision and language modalities. Distilled knowledge from the supervised attention-based VQA model trains the memory aware compact TinyVQA model and low bit-width quantization technique is employed to further compress the model for deployment on tinyML devices. The TinyVQA model was evaluated on the FloodNet dataset, which is used for post-disaster damage assessment. The compact model achieved an accuracy of 79.5%, demonstrating the effectiveness of TinyVQA for real-world applications. Additionally, the model was deployed on a Crazyflie 2.0 drone, equipped with an AI deck and GAP8 microprocessor. The TinyVQA model achieved low latencies of 56 ms and consumes 693 mW power while deployed on the tiny drone, showcasing its suitability for resource-constrained embedded systems.","sentences":["Traditional machine learning models often require powerful hardware, making them unsuitable for deployment on resource-limited devices.","Tiny Machine Learning (tinyML) has emerged as a promising approach for running machine learning models on these devices, but integrating multiple data modalities into tinyML models still remains a challenge due to increased complexity, latency, and power consumption.","This paper proposes TinyVQA, a novel multimodal deep neural network for visual question answering tasks that can be deployed on resource-constrained tinyML hardware.","TinyVQA leverages a supervised attention-based model to learn how to answer questions about images using both vision and language modalities.","Distilled knowledge from the supervised attention-based VQA model trains the memory aware compact TinyVQA model and low bit-width quantization technique is employed to further compress the model for deployment on tinyML devices.","The TinyVQA model was evaluated on the FloodNet dataset, which is used for post-disaster damage assessment.","The compact model achieved an accuracy of 79.5%, demonstrating the effectiveness of TinyVQA for real-world applications.","Additionally, the model was deployed on a Crazyflie 2.0 drone, equipped with an AI deck and GAP8 microprocessor.","The TinyVQA model achieved low latencies of 56 ms and consumes 693 mW power while deployed on the tiny drone, showcasing its suitability for resource-constrained embedded systems."],"url":"http://arxiv.org/abs/2404.03574v1"}
{"created":"2024-04-04 16:37:42","title":"Terrain Point Cloud Inpainting via Signal Decomposition","abstract":"The rapid development of 3D acquisition technology has made it possible to obtain point clouds of real-world terrains. However, due to limitations in sensor acquisition technology or specific requirements, point clouds often contain defects such as holes with missing data. Inpainting algorithms are widely used to patch these holes. However, existing traditional inpainting algorithms rely on precise hole boundaries, which limits their ability to handle cases where the boundaries are not well-defined. On the other hand, learning-based completion methods often prioritize reconstructing the entire point cloud instead of solely focusing on hole filling. Based on the fact that real-world terrain exhibits both global smoothness and rich local detail, we propose a novel representation for terrain point clouds. This representation can help to repair the holes without clear boundaries. Specifically, it decomposes terrains into low-frequency and high-frequency components, which are represented by B-spline surfaces and relative height maps respectively. In this way, the terrain point cloud inpainting problem is transformed into a B-spline surface fitting and 2D image inpainting problem. By solving the two problems, the highly complex and irregular holes on the terrain point clouds can be well-filled, which not only satisfies the global terrain undulation but also exhibits rich geometric details. The experimental results also demonstrate the effectiveness of our method.","sentences":["The rapid development of 3D acquisition technology has made it possible to obtain point clouds of real-world terrains.","However, due to limitations in sensor acquisition technology or specific requirements, point clouds often contain defects such as holes with missing data.","Inpainting algorithms are widely used to patch these holes.","However, existing traditional inpainting algorithms rely on precise hole boundaries, which limits their ability to handle cases where the boundaries are not well-defined.","On the other hand, learning-based completion methods often prioritize reconstructing the entire point cloud instead of solely focusing on hole filling.","Based on the fact that real-world terrain exhibits both global smoothness and rich local detail, we propose a novel representation for terrain point clouds.","This representation can help to repair the holes without clear boundaries.","Specifically, it decomposes terrains into low-frequency and high-frequency components, which are represented by B-spline surfaces and relative height maps respectively.","In this way, the terrain point cloud inpainting problem is transformed into a B-spline surface fitting and 2D image inpainting problem.","By solving the two problems, the highly complex and irregular holes on the terrain point clouds can be well-filled, which not only satisfies the global terrain undulation but also exhibits rich geometric details.","The experimental results also demonstrate the effectiveness of our method."],"url":"http://arxiv.org/abs/2404.03572v1"}
{"created":"2024-04-04 16:30:20","title":"Embodied AI with Two Arms: Zero-shot Learning, Safety and Modularity","abstract":"We present an embodied AI system which receives open-ended natural language instructions from a human, and controls two arms to collaboratively accomplish potentially long-horizon tasks over a large workspace. Our system is modular: it deploys state of the art Large Language Models for task planning,Vision-Language models for semantic perception, and Point Cloud transformers for grasping. With semantic and physical safety in mind, these modules are interfaced with a real-time trajectory optimizer and a compliant tracking controller to enable human-robot proximity. We demonstrate performance for the following tasks: bi-arm sorting, bottle opening, and trash disposal tasks. These are done zero-shot where the models used have not been trained with any real world data from this bi-arm robot, scenes or workspace.Composing both learning- and non-learning-based components in a modular fashion with interpretable inputs and outputs allows the user to easily debug points of failures and fragilities. One may also in-place swap modules to improve the robustness of the overall platform, for instance with imitation-learned policies.","sentences":["We present an embodied AI system which receives open-ended natural language instructions from a human, and controls two arms to collaboratively accomplish potentially long-horizon tasks over a large workspace.","Our system is modular: it deploys state of the art Large Language Models for task planning,Vision-Language models for semantic perception, and Point Cloud transformers for grasping.","With semantic and physical safety in mind, these modules are interfaced with a real-time trajectory optimizer and a compliant tracking controller to enable human-robot proximity.","We demonstrate performance for the following tasks: bi-arm sorting, bottle opening, and trash disposal tasks.","These are done zero-shot where the models used have not been trained with any real world data from this bi-arm robot, scenes or workspace.","Composing both learning- and non-learning-based components in a modular fashion with interpretable inputs and outputs allows the user to easily debug points of failures and fragilities.","One may also in-place swap modules to improve the robustness of the overall platform, for instance with imitation-learned policies."],"url":"http://arxiv.org/abs/2404.03570v1"}
{"created":"2024-04-04 16:25:23","title":"Factored Task and Motion Planning with Combined Optimization, Sampling and Learning","abstract":"In this thesis, we aim to improve the performance of TAMP algorithms from three complementary perspectives. First, we investigate the integration of discrete task planning with continuous trajectory optimization. Our main contribution is a conflict-based solver that automatically discovers why a task plan might fail when considering the constraints of the physical world. This information is then fed back into the task planner, resulting in an efficient, bidirectional, and intuitive interface between task and motion, capable of solving TAMP problems with multiple objects, robots, and tight physical constraints. In the second part, we first illustrate that, given the wide range of tasks and environments within TAMP, neither sampling nor optimization is superior in all settings. To combine the strengths of both approaches, we have designed meta-solvers for TAMP, adaptive solvers that automatically select which algorithms and computations to use and how to best decompose each problem to find a solution faster. In the third part, we combine deep learning architectures with model-based reasoning to accelerate computations within our TAMP solver. Specifically, we target infeasibility detection and nonlinear optimization, focusing on generalization, accuracy, compute time, and data efficiency. At the core of our contributions is a refined, factored representation of the trajectory optimization problems inside TAMP. This structure not only facilitates more efficient planning, encoding of geometric infeasibility, and meta-reasoning but also provides better generalization in neural architectures.","sentences":["In this thesis, we aim to improve the performance of TAMP algorithms from three complementary perspectives.","First, we investigate the integration of discrete task planning with continuous trajectory optimization.","Our main contribution is a conflict-based solver that automatically discovers why a task plan might fail when considering the constraints of the physical world.","This information is then fed back into the task planner, resulting in an efficient, bidirectional, and intuitive interface between task and motion, capable of solving TAMP problems with multiple objects, robots, and tight physical constraints.","In the second part, we first illustrate that, given the wide range of tasks and environments within TAMP, neither sampling nor optimization is superior in all settings.","To combine the strengths of both approaches, we have designed meta-solvers for TAMP, adaptive solvers that automatically select which algorithms and computations to use and how to best decompose each problem to find a solution faster.","In the third part, we combine deep learning architectures with model-based reasoning to accelerate computations within our TAMP solver.","Specifically, we target infeasibility detection and nonlinear optimization, focusing on generalization, accuracy, compute time, and data efficiency.","At the core of our contributions is a refined, factored representation of the trajectory optimization problems inside TAMP.","This structure not only facilitates more efficient planning, encoding of geometric infeasibility, and meta-reasoning but also provides better generalization in neural architectures."],"url":"http://arxiv.org/abs/2404.03567v1"}
{"created":"2024-04-04 16:24:32","title":"PointInfinity: Resolution-Invariant Point Diffusion Models","abstract":"We present PointInfinity, an efficient family of point cloud diffusion models. Our core idea is to use a transformer-based architecture with a fixed-size, resolution-invariant latent representation. This enables efficient training with low-resolution point clouds, while allowing high-resolution point clouds to be generated during inference. More importantly, we show that scaling the test-time resolution beyond the training resolution improves the fidelity of generated point clouds and surfaces. We analyze this phenomenon and draw a link to classifier-free guidance commonly used in diffusion models, demonstrating that both allow trading off fidelity and variability during inference. Experiments on CO3D show that PointInfinity can efficiently generate high-resolution point clouds (up to 131k points, 31 times more than Point-E) with state-of-the-art quality.","sentences":["We present PointInfinity, an efficient family of point cloud diffusion models.","Our core idea is to use a transformer-based architecture with a fixed-size, resolution-invariant latent representation.","This enables efficient training with low-resolution point clouds, while allowing high-resolution point clouds to be generated during inference.","More importantly, we show that scaling the test-time resolution beyond the training resolution improves the fidelity of generated point clouds and surfaces.","We analyze this phenomenon and draw a link to classifier-free guidance commonly used in diffusion models, demonstrating that both allow trading off fidelity and variability during inference.","Experiments on CO3D show that PointInfinity can efficiently generate high-resolution point clouds (up to 131k points, 31 times more than Point-E) with state-of-the-art quality."],"url":"http://arxiv.org/abs/2404.03566v1"}
{"created":"2024-04-04 16:20:34","title":"Personalized LLM Response Generation with Parameterized Memory Injection","abstract":"Large Language Models (LLMs) have exhibited remarkable proficiency in comprehending and generating natural language. On the other hand, personalized LLM response generation holds the potential to offer substantial benefits for individuals in critical areas such as medical. Existing research has explored memory-augmented methods to prompt the LLM with pre-stored user-specific knowledge for personalized response generation in terms of new queries. We contend that such paradigm is unable to perceive fine-granularity information. In this study, we propose a novel \\textbf{M}emory-\\textbf{i}njected approach using parameter-efficient fine-tuning (PEFT) and along with a Bayesian Optimisation searching strategy to achieve \\textbf{L}LM \\textbf{P}ersonalization(\\textbf{MiLP}).","sentences":["Large Language Models (LLMs) have exhibited remarkable proficiency in comprehending and generating natural language.","On the other hand, personalized LLM response generation holds the potential to offer substantial benefits for individuals in critical areas such as medical.","Existing research has explored memory-augmented methods to prompt the LLM with pre-stored user-specific knowledge for personalized response generation in terms of new queries.","We contend that such paradigm is unable to perceive fine-granularity information.","In this study, we propose a novel \\textbf{M}emory-\\textbf{i}njected approach using parameter-efficient fine-tuning (PEFT) and along with a Bayesian Optimisation searching strategy to achieve \\textbf{L}LM \\textbf{P}ersonalization(\\textbf{MiLP})."],"url":"http://arxiv.org/abs/2404.03565v1"}
{"created":"2024-04-04 16:18:37","title":"EASSE-DE: Easier Automatic Sentence Simplification Evaluation for German","abstract":"In this work, we propose EASSE-multi, a framework for easier automatic sentence evaluation for languages other than English. Compared to the original EASSE framework, EASSE-multi does not focus only on English. It contains tokenizers and versions of text simplification evaluation metrics which are suitable for multiple languages. In this paper, we exemplify the usage of EASSE-multi for German TS, resulting in EASSE-DE. Further, we compare text simplification results when evaluating with different language or tokenization settings of the metrics. Based on this, we formulate recommendations on how to make the evaluation of (German) TS models more transparent and better comparable. The code of EASSE-multi and its German specialisation (EASSE-DE) can be found at https://github.com/rstodden/easse-de.","sentences":["In this work, we propose EASSE-multi, a framework for easier automatic sentence evaluation for languages other than English.","Compared to the original EASSE framework, EASSE-multi does not focus only on English.","It contains tokenizers and versions of text simplification evaluation metrics which are suitable for multiple languages.","In this paper, we exemplify the usage of EASSE-multi for German TS, resulting in EASSE-DE.","Further, we compare text simplification results when evaluating with different language or tokenization settings of the metrics.","Based on this, we formulate recommendations on how to make the evaluation of (German) TS models more transparent and better comparable.","The code of EASSE-multi and its German specialisation (EASSE-DE) can be found at https://github.com/rstodden/easse-de."],"url":"http://arxiv.org/abs/2404.03563v1"}
{"created":"2024-04-04 16:16:53","title":"Select and Summarize: Scene Saliency for Movie Script Summarization","abstract":"Abstractive summarization for long-form narrative texts such as movie scripts is challenging due to the computational and memory constraints of current language models. A movie script typically comprises a large number of scenes; however, only a fraction of these scenes are salient, i.e., important for understanding the overall narrative. The salience of a scene can be operationalized by considering it as salient if it is mentioned in the summary. Automatically identifying salient scenes is difficult due to the lack of suitable datasets. In this work, we introduce a scene saliency dataset that consists of human-annotated salient scenes for 100 movies. We propose a two-stage abstractive summarization approach which first identifies the salient scenes in script and then generates a summary using only those scenes. Using QA-based evaluation, we show that our model outperforms previous state-of-the-art summarization methods and reflects the information content of a movie more accurately than a model that takes the whole movie script as input.","sentences":["Abstractive summarization for long-form narrative texts such as movie scripts is challenging due to the computational and memory constraints of current language models.","A movie script typically comprises a large number of scenes; however, only a fraction of these scenes are salient, i.e., important for understanding the overall narrative.","The salience of a scene can be operationalized by considering it as salient if it is mentioned in the summary.","Automatically identifying salient scenes is difficult due to the lack of suitable datasets.","In this work, we introduce a scene saliency dataset that consists of human-annotated salient scenes for 100 movies.","We propose a two-stage abstractive summarization approach which first identifies the salient scenes in script and then generates a summary using only those scenes.","Using QA-based evaluation, we show that our model outperforms previous state-of-the-art summarization methods and reflects the information content of a movie more accurately than a model that takes the whole movie script as input."],"url":"http://arxiv.org/abs/2404.03561v1"}
{"created":"2024-04-04 16:15:23","title":"How does Multi-Task Training Affect Transformer In-Context Capabilities? Investigations with Function Classes","abstract":"Large language models (LLM) have recently shown the extraordinary ability to perform unseen tasks based on few-shot examples provided as text, also known as in-context learning (ICL). While recent works have attempted to understand the mechanisms driving ICL, few have explored training strategies that incentivize these models to generalize to multiple tasks. Multi-task learning (MTL) for generalist models is a promising direction that offers transfer learning potential, enabling large parameterized models to be trained from simpler, related tasks. In this work, we investigate the combination of MTL with ICL to build models that efficiently learn tasks while being robust to out-of-distribution examples. We propose several effective curriculum learning strategies that allow ICL models to achieve higher data efficiency and more stable convergence. Our experiments reveal that ICL models can effectively learn difficult tasks by training on progressively harder tasks while mixing in prior tasks, denoted as mixed curriculum in this work. Our code and models are available at https://github.com/harmonbhasin/curriculum_learning_icl .","sentences":["Large language models (LLM) have recently shown the extraordinary ability to perform unseen tasks based on few-shot examples provided as text, also known as in-context learning (ICL).","While recent works have attempted to understand the mechanisms driving ICL, few have explored training strategies that incentivize these models to generalize to multiple tasks.","Multi-task learning (MTL) for generalist models is a promising direction that offers transfer learning potential, enabling large parameterized models to be trained from simpler, related tasks.","In this work, we investigate the combination of MTL with ICL to build models that efficiently learn tasks while being robust to out-of-distribution examples.","We propose several effective curriculum learning strategies that allow ICL models to achieve higher data efficiency and more stable convergence.","Our experiments reveal that ICL models can effectively learn difficult tasks by training on progressively harder tasks while mixing in prior tasks, denoted as mixed curriculum in this work.","Our code and models are available at https://github.com/harmonbhasin/curriculum_learning_icl ."],"url":"http://arxiv.org/abs/2404.03558v1"}
{"created":"2024-04-04 16:07:21","title":"Robot Safety Monitoring using Programmable Light Curtains","abstract":"As factories continue to evolve into collaborative spaces with multiple robots working together with human supervisors in the loop, ensuring safety for all actors involved becomes critical. Currently, laser-based light curtain sensors are widely used in factories for safety monitoring. While these conventional safety sensors meet high accuracy standards, they are difficult to reconfigure and can only monitor a fixed user-defined region of space. Furthermore, they are typically expensive. Instead, we leverage a controllable depth sensor, programmable light curtains (PLC), to develop an inexpensive and flexible real-time safety monitoring system for collaborative robot workspaces. Our system projects virtual dynamic safety envelopes that tightly envelop the moving robot at all times and detect any objects that intrude the envelope. Furthermore, we develop an instrumentation algorithm that optimally places (multiple) PLCs in a workspace to maximize the visibility coverage of robots. Our work enables fence-less human-robot collaboration, while scaling to monitor multiple robots with few sensors. We analyze our system in a real manufacturing testbed with four robot arms and demonstrate its capabilities as a fast, accurate, and inexpensive safety monitoring solution.","sentences":["As factories continue to evolve into collaborative spaces with multiple robots working together with human supervisors in the loop, ensuring safety for all actors involved becomes critical.","Currently, laser-based light curtain sensors are widely used in factories for safety monitoring.","While these conventional safety sensors meet high accuracy standards, they are difficult to reconfigure and can only monitor a fixed user-defined region of space.","Furthermore, they are typically expensive.","Instead, we leverage a controllable depth sensor, programmable light curtains (PLC), to develop an inexpensive and flexible real-time safety monitoring system for collaborative robot workspaces.","Our system projects virtual dynamic safety envelopes that tightly envelop the moving robot at all times and detect any objects that intrude the envelope.","Furthermore, we develop an instrumentation algorithm that optimally places (multiple) PLCs in a workspace to maximize the visibility coverage of robots.","Our work enables fence-less human-robot collaboration, while scaling to monitor multiple robots with few sensors.","We analyze our system in a real manufacturing testbed with four robot arms and demonstrate its capabilities as a fast, accurate, and inexpensive safety monitoring solution."],"url":"http://arxiv.org/abs/2404.03556v1"}
{"created":"2024-04-04 16:07:06","title":"From News to Summaries: Building a Hungarian Corpus for Extractive and Abstractive Summarization","abstract":"Training summarization models requires substantial amounts of training data. However for less resourceful languages like Hungarian, openly available models and datasets are notably scarce. To address this gap our paper introduces HunSum-2 an open-source Hungarian corpus suitable for training abstractive and extractive summarization models. The dataset is assembled from segments of the Common Crawl corpus undergoing thorough cleaning, preprocessing and deduplication. In addition to abstractive summarization we generate sentence-level labels for extractive summarization using sentence similarity. We train baseline models for both extractive and abstractive summarization using the collected dataset. To demonstrate the effectiveness of the trained models, we perform both quantitative and qualitative evaluation. Our dataset, models and code are publicly available, encouraging replication, further research, and real-world applications across various domains.","sentences":["Training summarization models requires substantial amounts of training data.","However for less resourceful languages like Hungarian, openly available models and datasets are notably scarce.","To address this gap our paper introduces HunSum-2 an open-source Hungarian corpus suitable for training abstractive and extractive summarization models.","The dataset is assembled from segments of the Common Crawl corpus undergoing thorough cleaning, preprocessing and deduplication.","In addition to abstractive summarization we generate sentence-level labels for extractive summarization using sentence similarity.","We train baseline models for both extractive and abstractive summarization using the collected dataset.","To demonstrate the effectiveness of the trained models, we perform both quantitative and qualitative evaluation.","Our dataset, models and code are publicly available, encouraging replication, further research, and real-world applications across various domains."],"url":"http://arxiv.org/abs/2404.03555v1"}
{"created":"2024-04-04 16:06:39","title":"No Panacea in Planning: Algorithm Selection for Suboptimal Multi-Agent Path Finding","abstract":"Since more and more algorithms are proposed for multi-agent path finding (MAPF) and each of them has its strengths, choosing the correct one for a specific scenario that fulfills some specified requirements is an important task. Previous research in algorithm selection for MAPF built a standard workflow and showed that machine learning can help. In this paper, we study general solvers for MAPF, which further include suboptimal algorithms. We propose different groups of optimization objectives and learning tasks to handle the new tradeoff between runtime and solution quality. We conduct extensive experiments to show that the same loss can not be used for different groups of optimization objectives, and that standard computer vision models are no worse than customized architecture. We also provide insightful discussions on how feature-sensitive pre-processing is needed for learning for MAPF, and how different learning metrics are correlated to different learning tasks.","sentences":["Since more and more algorithms are proposed for multi-agent path finding (MAPF) and each of them has its strengths, choosing the correct one for a specific scenario that fulfills some specified requirements is an important task.","Previous research in algorithm selection for MAPF built a standard workflow and showed that machine learning can help.","In this paper, we study general solvers for MAPF, which further include suboptimal algorithms.","We propose different groups of optimization objectives and learning tasks to handle the new tradeoff between runtime and solution quality.","We conduct extensive experiments to show that the same loss can not be used for different groups of optimization objectives, and that standard computer vision models are no worse than customized architecture.","We also provide insightful discussions on how feature-sensitive pre-processing is needed for learning for MAPF, and how different learning metrics are correlated to different learning tasks."],"url":"http://arxiv.org/abs/2404.03554v1"}
{"created":"2024-04-04 16:05:01","title":"Bringing memory to Boolean networks: a unifying framework","abstract":"Boolean networks are extensively applied as models of complex dynamical systems, aiming at capturing essential features related to causality and synchronicity of the state changes of components along time. Dynamics of Boolean networks result from the application of their Boolean map according to a so-called update mode, specifying the possible transitions between network configurations. In this paper, we explore update modes that possess a memory on past configurations, and provide a generic framework to define them. We show that recently introduced modes such as the most permissive and interval modes can be naturally expressed in this framework. We propose novel update modes, the history-based and trapping modes, and provide a comprehensive comparison between them. Furthermore, we show that trapping dynamics, which further generalize the most permissive mode, correspond to a rich class of networks related to transitive dynamics and encompassing commutative networks. Finally, we provide a thorough characterization of the structure of minimal and principal trapspaces, bringing a combinatorial and algebraic understanding of these objects.","sentences":["Boolean networks are extensively applied as models of complex dynamical systems, aiming at capturing essential features related to causality and synchronicity of the state changes of components along time.","Dynamics of Boolean networks result from the application of their Boolean map according to a so-called update mode, specifying the possible transitions between network configurations.","In this paper, we explore update modes that possess a memory on past configurations, and provide a generic framework to define them.","We show that recently introduced modes such as the most permissive and interval modes can be naturally expressed in this framework.","We propose novel update modes, the history-based and trapping modes, and provide a comprehensive comparison between them.","Furthermore, we show that trapping dynamics, which further generalize the most permissive mode, correspond to a rich class of networks related to transitive dynamics and encompassing commutative networks.","Finally, we provide a thorough characterization of the structure of minimal and principal trapspaces, bringing a combinatorial and algebraic understanding of these objects."],"url":"http://arxiv.org/abs/2404.03553v1"}
{"created":"2024-04-04 16:03:02","title":"Streamlining CXL Adoption for Hyperscale Efficiency","abstract":"In our exploration of Composable Memory systems utilizing CXL, we focus on overcoming adoption barriers at Hyperscale, underscored by economic models demonstrating Total Cost of Ownership (TCO). While CXL addresses the pressing memory capacity needs of emerging Hyperscale applications, the escalating demands from evolving use cases such as AI outpace the capabilities of current CXL solutions. Hyperscalers resort to software-based memory (de)compression technology, alleviating memory capacity, storage, and network constraints but incurring a notable \"Tax\" on Compute CPU cycles. As a pivotal guide to the CXL community, Hyperscalers have formulated the groundbreaking Open Compute Project (OCP) Hyperscale CXL Tiered Memory Expander specification. If implemented, this specification lowers TCO adoption barriers, enabling diverse CXL deployments at both Hyperscaler and Enterprise levels. We present a CXL integrated solution, aligning with the aforementioned specification, introducing an energy-efficient, scalable, hardware-accelerated, Lossless Compressed Memory CXL Tier. This solution, slated for mid-2024 production and open for integration with Memory Expander controller manufacturers, offers 2-3X CXL memory compression in nanoseconds, delivering a 20-25% reduction in TCO for end customers without requiring additional physical slots. In our discussion, we pinpoint areas for collaborative innovation within the CXL Community to expedite software/hardware advancements for CXL Tiered Memory Expansion. Furthermore, we delve into unresolved challenges in Pooled deployment and explore potential solutions, collectively aiming to make CXL adoption a \"No Brainer\" at Hyperscale.","sentences":["In our exploration of Composable Memory systems utilizing CXL, we focus on overcoming adoption barriers at Hyperscale, underscored by economic models demonstrating Total Cost of Ownership (TCO).","While CXL addresses the pressing memory capacity needs of emerging Hyperscale applications, the escalating demands from evolving use cases such as AI outpace the capabilities of current CXL solutions.","Hyperscalers resort to software-based memory (de)compression technology, alleviating memory capacity, storage, and network constraints but incurring a notable \"Tax\" on Compute CPU cycles.","As a pivotal guide to the CXL community, Hyperscalers have formulated the groundbreaking Open Compute Project (OCP)","Hyperscale CXL Tiered Memory Expander specification.","If implemented, this specification lowers TCO adoption barriers, enabling diverse CXL deployments at both Hyperscaler and Enterprise levels.","We present a CXL integrated solution, aligning with the aforementioned specification, introducing an energy-efficient, scalable, hardware-accelerated, Lossless Compressed Memory CXL Tier.","This solution, slated for mid-2024 production and open for integration with Memory Expander controller manufacturers, offers 2-3X CXL memory compression in nanoseconds, delivering a 20-25% reduction in TCO for end customers without requiring additional physical slots.","In our discussion, we pinpoint areas for collaborative innovation within the CXL Community to expedite software/hardware advancements for CXL Tiered Memory Expansion.","Furthermore, we delve into unresolved challenges in Pooled deployment and explore potential solutions, collectively aiming to make CXL adoption a \"No Brainer\" at Hyperscale."],"url":"http://arxiv.org/abs/2404.03551v1"}
{"created":"2024-04-04 15:49:49","title":"CodeEditorBench: Evaluating Code Editing Capability of Large Language Models","abstract":"Large Language Models (LLMs) for code are rapidly evolving, with code editing emerging as a critical capability. We introduce CodeEditorBench, an evaluation framework designed to rigorously assess the performance of LLMs in code editing tasks, including debugging, translating, polishing, and requirement switching. Unlike existing benchmarks focusing solely on code generation, CodeEditorBench emphasizes real-world scenarios and practical aspects of software development. We curate diverse coding challenges and scenarios from five sources, covering various programming languages, complexity levels, and editing tasks. Evaluation of 19 LLMs reveals that closed-source models (particularly Gemini-Ultra and GPT-4), outperform open-source models in CodeEditorBench, highlighting differences in model performance based on problem types and prompt sensitivities. CodeEditorBench aims to catalyze advancements in LLMs by providing a robust platform for assessing code editing capabilities. We will release all prompts and datasets to enable the community to expand the dataset and benchmark emerging LLMs. By introducing CodeEditorBench, we contribute to the advancement of LLMs in code editing and provide a valuable resource for researchers and practitioners.","sentences":["Large Language Models (LLMs) for code are rapidly evolving, with code editing emerging as a critical capability.","We introduce CodeEditorBench, an evaluation framework designed to rigorously assess the performance of LLMs in code editing tasks, including debugging, translating, polishing, and requirement switching.","Unlike existing benchmarks focusing solely on code generation, CodeEditorBench emphasizes real-world scenarios and practical aspects of software development.","We curate diverse coding challenges and scenarios from five sources, covering various programming languages, complexity levels, and editing tasks.","Evaluation of 19 LLMs reveals that closed-source models (particularly Gemini-Ultra and GPT-4), outperform open-source models in CodeEditorBench, highlighting differences in model performance based on problem types and prompt sensitivities.","CodeEditorBench aims to catalyze advancements in LLMs by providing a robust platform for assessing code editing capabilities.","We will release all prompts and datasets to enable the community to expand the dataset and benchmark emerging LLMs.","By introducing CodeEditorBench, we contribute to the advancement of LLMs in code editing and provide a valuable resource for researchers and practitioners."],"url":"http://arxiv.org/abs/2404.03543v1"}
{"created":"2024-04-04 15:47:30","title":"Is CLIP the main roadblock for fine-grained open-world perception?","abstract":"Modern applications increasingly demand flexible computer vision models that adapt to novel concepts not encountered during training. This necessity is pivotal in emerging domains like extended reality, robotics, and autonomous driving, which require the ability to respond to open-world stimuli. A key ingredient is the ability to identify objects based on free-form textual queries defined at inference time - a task known as open-vocabulary object detection. Multimodal backbones like CLIP are the main enabling technology for current open-world perception solutions. Despite performing well on generic queries, recent studies highlighted limitations on the fine-grained recognition capabilities in open-vocabulary settings - i.e., for distinguishing subtle object features like color, shape, and material. In this paper, we perform a detailed examination of these open-vocabulary object recognition limitations to find the root cause. We evaluate the performance of CLIP, the most commonly used vision-language backbone, against a fine-grained object-matching benchmark, revealing interesting analogies between the limitations of open-vocabulary object detectors and their backbones. Experiments suggest that the lack of fine-grained understanding is caused by the poor separability of object characteristics in the CLIP latent space. Therefore, we try to understand whether fine-grained knowledge is present in CLIP embeddings but not exploited at inference time due, for example, to the unsuitability of the cosine similarity matching function, which may discard important object characteristics. Our preliminary experiments show that simple CLIP latent-space re-projections help separate fine-grained concepts, paving the way towards the development of backbones inherently able to process fine-grained details. The code for reproducing these experiments is available at https://github.com/lorebianchi98/FG-CLIP.","sentences":["Modern applications increasingly demand flexible computer vision models that adapt to novel concepts not encountered during training.","This necessity is pivotal in emerging domains like extended reality, robotics, and autonomous driving, which require the ability to respond to open-world stimuli.","A key ingredient is the ability to identify objects based on free-form textual queries defined at inference time - a task known as open-vocabulary object detection.","Multimodal backbones like CLIP are the main enabling technology for current open-world perception solutions.","Despite performing well on generic queries, recent studies highlighted limitations on the fine-grained recognition capabilities in open-vocabulary settings - i.e., for distinguishing subtle object features like color, shape, and material.","In this paper, we perform a detailed examination of these open-vocabulary object recognition limitations to find the root cause.","We evaluate the performance of CLIP, the most commonly used vision-language backbone, against a fine-grained object-matching benchmark, revealing interesting analogies between the limitations of open-vocabulary object detectors and their backbones.","Experiments suggest that the lack of fine-grained understanding is caused by the poor separability of object characteristics in the CLIP latent space.","Therefore, we try to understand whether fine-grained knowledge is present in CLIP embeddings but not exploited at inference time due, for example, to the unsuitability of the cosine similarity matching function, which may discard important object characteristics.","Our preliminary experiments show that simple CLIP latent-space re-projections help separate fine-grained concepts, paving the way towards the development of backbones inherently able to process fine-grained details.","The code for reproducing these experiments is available at https://github.com/lorebianchi98/FG-CLIP."],"url":"http://arxiv.org/abs/2404.03539v1"}
{"created":"2024-04-04 15:45:25","title":"If It's Not Enough, Make It So: Reducing Authentic Data Demand in Face Recognition through Synthetic Faces","abstract":"Recent advances in deep face recognition have spurred a growing demand for large, diverse, and manually annotated face datasets. Acquiring authentic, high-quality data for face recognition has proven to be a challenge, primarily due to privacy concerns. Large face datasets are primarily sourced from web-based images, lacking explicit user consent. In this paper, we examine whether and how synthetic face data can be used to train effective face recognition models with reduced reliance on authentic images, thereby mitigating data collection concerns. First, we explored the performance gap among recent state-of-the-art face recognition models, trained with synthetic data only and authentic (scarce) data only. Then, we deepened our analysis by training a state-of-the-art backbone with various combinations of synthetic and authentic data, gaining insights into optimizing the limited use of the latter for verification accuracy. Finally, we assessed the effectiveness of data augmentation approaches on synthetic and authentic data, with the same goal in mind. Our results highlighted the effectiveness of FR trained on combined datasets, particularly when combined with appropriate augmentation techniques.","sentences":["Recent advances in deep face recognition have spurred a growing demand for large, diverse, and manually annotated face datasets.","Acquiring authentic, high-quality data for face recognition has proven to be a challenge, primarily due to privacy concerns.","Large face datasets are primarily sourced from web-based images, lacking explicit user consent.","In this paper, we examine whether and how synthetic face data can be used to train effective face recognition models with reduced reliance on authentic images, thereby mitigating data collection concerns.","First, we explored the performance gap among recent state-of-the-art face recognition models, trained with synthetic data only and authentic (scarce) data only.","Then, we deepened our analysis by training a state-of-the-art backbone with various combinations of synthetic and authentic data, gaining insights into optimizing the limited use of the latter for verification accuracy.","Finally, we assessed the effectiveness of data augmentation approaches on synthetic and authentic data, with the same goal in mind.","Our results highlighted the effectiveness of FR trained on combined datasets, particularly when combined with appropriate augmentation techniques."],"url":"http://arxiv.org/abs/2404.03537v1"}
{"created":"2024-04-04 15:36:53","title":"Evaluating Generative Language Models in Information Extraction as Subjective Question Correction","abstract":"Modern Large Language Models (LLMs) have showcased remarkable prowess in various tasks necessitating sophisticated cognitive behaviors. Nevertheless, a paradoxical performance discrepancy is observed, where these models underperform in seemingly elementary tasks like relation extraction and event extraction due to two issues in conventional evaluation. (1) The imprecision of existing evaluation metrics that struggle to effectively gauge semantic consistency between model outputs and ground truth, and (2) The inherent incompleteness of evaluation benchmarks, primarily due to restrictive human annotation schemas, resulting in underestimated LLM performances. Inspired by the principles in subjective question correction, we propose a new evaluation method, SQC-Score. This method innovatively utilizes LLMs, fine-tuned through subjective question correction data, to refine matching between model outputs and golden labels. Additionally, by incorporating a Natural Language Inference (NLI) model, SQC-Score enriches golden labels, addressing benchmark incompleteness by acknowledging correct yet previously omitted answers. Results on three information extraction tasks show that SQC-Score is more preferred by human annotators than the baseline metrics. Utilizing SQC-Score, we conduct a comprehensive evaluation of the state-of-the-art LLMs and provide insights for future research for information extraction. Dataset and associated codes can be accessed at https://github.com/THU-KEG/SQC-Score.","sentences":["Modern Large Language Models (LLMs) have showcased remarkable prowess in various tasks necessitating sophisticated cognitive behaviors.","Nevertheless, a paradoxical performance discrepancy is observed, where these models underperform in seemingly elementary tasks like relation extraction and event extraction due to two issues in conventional evaluation.","(1) The imprecision of existing evaluation metrics that struggle to effectively gauge semantic consistency between model outputs and ground truth, and (2) The inherent incompleteness of evaluation benchmarks, primarily due to restrictive human annotation schemas, resulting in underestimated LLM performances.","Inspired by the principles in subjective question correction, we propose a new evaluation method, SQC-Score.","This method innovatively utilizes LLMs, fine-tuned through subjective question correction data, to refine matching between model outputs and golden labels.","Additionally, by incorporating a Natural Language Inference (NLI) model, SQC-Score enriches golden labels, addressing benchmark incompleteness by acknowledging correct yet previously omitted answers.","Results on three information extraction tasks show that SQC-Score is more preferred by human annotators than the baseline metrics.","Utilizing SQC-Score, we conduct a comprehensive evaluation of the state-of-the-art LLMs and provide insights for future research for information extraction.","Dataset and associated codes can be accessed at https://github.com/THU-KEG/SQC-Score."],"url":"http://arxiv.org/abs/2404.03532v1"}
{"created":"2024-04-04 15:35:43","title":"COMO: Compact Mapping and Odometry","abstract":"We present COMO, a real-time monocular mapping and odometry system that encodes dense geometry via a compact set of 3D anchor points. Decoding anchor point projections into dense geometry via per-keyframe depth covariance functions guarantees that depth maps are joined together at visible anchor points. The representation enables joint optimization of camera poses and dense geometry, intrinsic 3D consistency, and efficient second-order inference. To maintain a compact yet expressive map, we introduce a frontend that leverages the covariance function for tracking and initializing potentially visually indistinct 3D points across frames. Altogether, we introduce a real-time system capable of estimating accurate poses and consistent geometry.","sentences":["We present COMO, a real-time monocular mapping and odometry system that encodes dense geometry via a compact set of 3D anchor points.","Decoding anchor point projections into dense geometry via per-keyframe depth covariance functions guarantees that depth maps are joined together at visible anchor points.","The representation enables joint optimization of camera poses and dense geometry, intrinsic 3D consistency, and efficient second-order inference.","To maintain a compact yet expressive map, we introduce a frontend that leverages the covariance function for tracking and initializing potentially visually indistinct 3D points across frames.","Altogether, we introduce a real-time system capable of estimating accurate poses and consistent geometry."],"url":"http://arxiv.org/abs/2404.03531v1"}
{"created":"2024-04-04 15:31:21","title":"BanglaAutoKG: Automatic Bangla Knowledge Graph Construction with Semantic Neural Graph Filtering","abstract":"Knowledge Graphs (KGs) have proven essential in information processing and reasoning applications because they link related entities and give context-rich information, supporting efficient information retrieval and knowledge discovery; presenting information flow in a very effective manner. Despite being widely used globally, Bangla is relatively underrepresented in KGs due to a lack of comprehensive datasets, encoders, NER (named entity recognition) models, POS (part-of-speech) taggers, and lemmatizers, hindering efficient information processing and reasoning applications in the language. Addressing the KG scarcity in Bengali, we propose BanglaAutoKG, a pioneering framework that is able to automatically construct Bengali KGs from any Bangla text. We utilize multilingual LLMs to understand various languages and correlate entities and relations universally. By employing a translation dictionary to identify English equivalents and extracting word features from pre-trained BERT models, we construct the foundational KG. To reduce noise and align word embeddings with our goal, we employ graph-based polynomial filters. Lastly, we implement a GNN-based semantic filter, which elevates contextual understanding and trims unnecessary edges, culminating in the formation of the definitive KG. Empirical findings and case studies demonstrate the universal effectiveness of our model, capable of autonomously constructing semantically enriched KGs from any text.","sentences":["Knowledge Graphs (KGs) have proven essential in information processing and reasoning applications because they link related entities and give context-rich information, supporting efficient information retrieval and knowledge discovery; presenting information flow in a very effective manner.","Despite being widely used globally, Bangla is relatively underrepresented in KGs due to a lack of comprehensive datasets, encoders, NER (named entity recognition) models, POS (part-of-speech) taggers, and lemmatizers, hindering efficient information processing and reasoning applications in the language.","Addressing the KG scarcity in Bengali, we propose BanglaAutoKG, a pioneering framework that is able to automatically construct Bengali KGs from any Bangla text.","We utilize multilingual LLMs to understand various languages and correlate entities and relations universally.","By employing a translation dictionary to identify English equivalents and extracting word features from pre-trained BERT models, we construct the foundational KG.","To reduce noise and align word embeddings with our goal, we employ graph-based polynomial filters.","Lastly, we implement a GNN-based semantic filter, which elevates contextual understanding and trims unnecessary edges, culminating in the formation of the definitive KG.","Empirical findings and case studies demonstrate the universal effectiveness of our model, capable of autonomously constructing semantically enriched KGs from any text."],"url":"http://arxiv.org/abs/2404.03528v1"}
{"created":"2024-04-04 15:31:11","title":"HAPNet: Toward Superior RGB-Thermal Scene Parsing via Hybrid, Asymmetric, and Progressive Heterogeneous Feature Fusion","abstract":"Data-fusion networks have shown significant promise for RGB-thermal scene parsing. However, the majority of existing studies have relied on symmetric duplex encoders for heterogeneous feature extraction and fusion, paying inadequate attention to the inherent differences between RGB and thermal modalities. Recent progress in vision foundation models (VFMs) trained through self-supervision on vast amounts of unlabeled data has proven their ability to extract informative, general-purpose features. However, this potential has yet to be fully leveraged in the domain. In this study, we take one step toward this new research area by exploring a feasible strategy to fully exploit VFM features for RGB-thermal scene parsing. Specifically, we delve deeper into the unique characteristics of RGB and thermal modalities, thereby designing a hybrid, asymmetric encoder that incorporates both a VFM and a convolutional neural network. This design allows for more effective extraction of complementary heterogeneous features, which are subsequently fused in a dual-path, progressive manner. Moreover, we introduce an auxiliary task to further enrich the local semantics of the fused features, thereby improving the overall performance of RGB-thermal scene parsing. Our proposed HAPNet, equipped with all these components, demonstrates superior performance compared to all other state-of-the-art RGB-thermal scene parsing networks, achieving top ranks across three widely used public RGB-thermal scene parsing datasets. We believe this new paradigm has opened up new opportunities for future developments in data-fusion scene parsing approaches.","sentences":["Data-fusion networks have shown significant promise for RGB-thermal scene parsing.","However, the majority of existing studies have relied on symmetric duplex encoders for heterogeneous feature extraction and fusion, paying inadequate attention to the inherent differences between RGB and thermal modalities.","Recent progress in vision foundation models (VFMs) trained through self-supervision on vast amounts of unlabeled data has proven their ability to extract informative, general-purpose features.","However, this potential has yet to be fully leveraged in the domain.","In this study, we take one step toward this new research area by exploring a feasible strategy to fully exploit VFM features for RGB-thermal scene parsing.","Specifically, we delve deeper into the unique characteristics of RGB and thermal modalities, thereby designing a hybrid, asymmetric encoder that incorporates both a VFM and a convolutional neural network.","This design allows for more effective extraction of complementary heterogeneous features, which are subsequently fused in a dual-path, progressive manner.","Moreover, we introduce an auxiliary task to further enrich the local semantics of the fused features, thereby improving the overall performance of RGB-thermal scene parsing.","Our proposed HAPNet, equipped with all these components, demonstrates superior performance compared to all other state-of-the-art RGB-thermal scene parsing networks, achieving top ranks across three widely used public RGB-thermal scene parsing datasets.","We believe this new paradigm has opened up new opportunities for future developments in data-fusion scene parsing approaches."],"url":"http://arxiv.org/abs/2404.03527v1"}
{"created":"2024-04-04 15:30:13","title":"WeSee: Using Malicious #VC Interrupts to Break AMD SEV-SNP","abstract":"AMD SEV-SNP offers VM-level trusted execution environments (TEEs) to protect the confidentiality and integrity for sensitive cloud workloads from untrusted hypervisor controlled by the cloud provider. AMD introduced a new exception, #VC, to facilitate the communication between the VM and the untrusted hypervisor. We present WeSee attack, where the hypervisor injects malicious #VC into a victim VM's CPU to compromise the security guarantees of AMD SEV-SNP. Specifically, WeSee injects interrupt number 29, which delivers a #VC exception to the VM who then executes the corresponding handler that performs data and register copies between the VM and the hypervisor. WeSee shows that using well-crafted #VC injections, the attacker can induce arbitrary behavior in the VM. Our case-studies demonstrate that WeSee can leak sensitive VM information (kTLS keys for NGINX), corrupt kernel data (firewall rules), and inject arbitrary code (launch a root shell from the kernel space).","sentences":["AMD SEV-SNP offers VM-level trusted execution environments (TEEs) to protect the confidentiality and integrity for sensitive cloud workloads from untrusted hypervisor controlled by the cloud provider.","AMD introduced a new exception, #VC, to facilitate the communication between the VM and the untrusted hypervisor.","We present WeSee attack, where the hypervisor injects malicious #VC into a victim VM's CPU to compromise the security guarantees of AMD SEV-SNP.","Specifically, WeSee injects interrupt number 29, which delivers a #VC exception to the VM who then executes the corresponding handler that performs data and register copies between the VM and the hypervisor.","WeSee shows that using well-crafted #VC injections, the attacker can induce arbitrary behavior in the VM.","Our case-studies demonstrate that WeSee can leak sensitive VM information (kTLS keys for NGINX), corrupt kernel data (firewall rules), and inject arbitrary code (launch a root shell from the kernel space)."],"url":"http://arxiv.org/abs/2404.03526v1"}
{"created":"2024-04-04 15:29:50","title":"Approximate Gradient Coding for Privacy-Flexible Federated Learning with Non-IID Data","abstract":"This work focuses on the challenges of non-IID data and stragglers/dropouts in federated learning. We introduce and explore a privacy-flexible paradigm that models parts of the clients' local data as non-private, offering a more versatile and business-oriented perspective on privacy. Within this framework, we propose a data-driven strategy for mitigating the effects of label heterogeneity and client straggling on federated learning. Our solution combines both offline data sharing and approximate gradient coding techniques. Through numerical simulations using the MNIST dataset, we demonstrate that our approach enables achieving a deliberate trade-off between privacy and utility, leading to improved model convergence and accuracy while using an adaptable portion of non-private data.","sentences":["This work focuses on the challenges of non-IID data and stragglers/dropouts in federated learning.","We introduce and explore a privacy-flexible paradigm that models parts of the clients' local data as non-private, offering a more versatile and business-oriented perspective on privacy.","Within this framework, we propose a data-driven strategy for mitigating the effects of label heterogeneity and client straggling on federated learning.","Our solution combines both offline data sharing and approximate gradient coding techniques.","Through numerical simulations using the MNIST dataset, we demonstrate that our approach enables achieving a deliberate trade-off between privacy and utility, leading to improved model convergence and accuracy while using an adaptable portion of non-private data."],"url":"http://arxiv.org/abs/2404.03524v1"}
{"created":"2024-04-04 15:26:26","title":"Integrating Generative AI into Financial Market Prediction for Improved Decision Making","abstract":"This study provides an in-depth analysis of the model architecture and key technologies of generative artificial intelligence, combined with specific application cases, and uses conditional generative adversarial networks ( cGAN ) and time series analysis methods to simulate and predict dynamic changes in financial markets. The research results show that the cGAN model can effectively capture the complexity of financial market data, and the deviation between the prediction results and the actual market performance is minimal, showing a high degree of accuracy.","sentences":["This study provides an in-depth analysis of the model architecture and key technologies of generative artificial intelligence, combined with specific application cases, and uses conditional generative adversarial networks ( cGAN ) and time series analysis methods to simulate and predict dynamic changes in financial markets.","The research results show that the cGAN model can effectively capture the complexity of financial market data, and the deviation between the prediction results and the actual market performance is minimal, showing a high degree of accuracy."],"url":"http://arxiv.org/abs/2404.03523v1"}
{"created":"2024-04-04 15:23:14","title":"SDPose: Tokenized Pose Estimation via Circulation-Guide Self-Distillation","abstract":"Recently, transformer-based methods have achieved state-of-the-art prediction quality on human pose estimation(HPE). Nonetheless, most of these top-performing transformer-based models are too computation-consuming and storage-demanding to deploy on edge computing platforms. Those transformer-based models that require fewer resources are prone to under-fitting due to their smaller scale and thus perform notably worse than their larger counterparts. Given this conundrum, we introduce SDPose, a new self-distillation method for improving the performance of small transformer-based models. To mitigate the problem of under-fitting, we design a transformer module named Multi-Cycled Transformer(MCT) based on multiple-cycled forwards to more fully exploit the potential of small model parameters. Further, in order to prevent the additional inference compute-consuming brought by MCT, we introduce a self-distillation scheme, extracting the knowledge from the MCT module to a naive forward model. Specifically, on the MSCOCO validation dataset, SDPose-T obtains 69.7% mAP with 4.4M parameters and 1.8 GFLOPs. Furthermore, SDPose-S-V2 obtains 73.5% mAP on the MSCOCO validation dataset with 6.2M parameters and 4.7 GFLOPs, achieving a new state-of-the-art among predominant tiny neural network methods. Our code is available at https://github.com/MartyrPenink/SDPose.","sentences":["Recently, transformer-based methods have achieved state-of-the-art prediction quality on human pose estimation(HPE).","Nonetheless, most of these top-performing transformer-based models are too computation-consuming and storage-demanding to deploy on edge computing platforms.","Those transformer-based models that require fewer resources are prone to under-fitting due to their smaller scale and thus perform notably worse than their larger counterparts.","Given this conundrum, we introduce SDPose, a new self-distillation method for improving the performance of small transformer-based models.","To mitigate the problem of under-fitting, we design a transformer module named Multi-Cycled Transformer(MCT) based on multiple-cycled forwards to more fully exploit the potential of small model parameters.","Further, in order to prevent the additional inference compute-consuming brought by MCT, we introduce a self-distillation scheme, extracting the knowledge from the MCT module to a naive forward model.","Specifically, on the MSCOCO validation dataset, SDPose-T obtains 69.7% mAP with 4.4M parameters and 1.8 GFLOPs.","Furthermore, SDPose-S-V2 obtains 73.5% mAP on the MSCOCO validation dataset with 6.2M parameters and 4.7 GFLOPs, achieving a new state-of-the-art among predominant tiny neural network methods.","Our code is available at https://github.com/MartyrPenink/SDPose."],"url":"http://arxiv.org/abs/2404.03518v1"}
{"created":"2024-04-04 15:21:40","title":"Model Checking Recursive Probabilistic Programs with Conditioning","abstract":"We address the problem of model checking temporal logic specifications for probabilistic programs with recursive procedures, nested queries, and conditioning expressed with observe statements. We introduce probabilistic Operator Precedence Automata (pOPA), a new class of probabilistic pushdown automata suitable to model constructs and behaviors of probabilistic programs. We develop a model checking algorithm that can verify requirements expressed in a fragment of Precedence Oriented Temporal Logic (POTL$^f_\\mathcal{X}$) on a pOPA in single EXPTIME. POTL$^f_\\mathcal{X}$ is a temporal logic based on Operator Precedence Languages, which features modalities that interact with the context-free structure of program traces, matching procedure calls with returns or observe statements. We provide the first probabilistic model checking implementation of context-free language properties for probabilistic pushdown systems.","sentences":["We address the problem of model checking temporal logic specifications for probabilistic programs with recursive procedures, nested queries, and conditioning expressed with observe statements.","We introduce probabilistic Operator Precedence Automata (pOPA), a new class of probabilistic pushdown automata suitable to model constructs and behaviors of probabilistic programs.","We develop a model checking algorithm that can verify requirements expressed in a fragment of Precedence Oriented Temporal Logic (POTL$^f_\\mathcal{X}$) on a pOPA in single EXPTIME.","POTL$^f_\\mathcal{X}$ is a temporal logic based on Operator Precedence Languages, which features modalities that interact with the context-free structure of program traces, matching procedure calls with returns or observe statements.","We provide the first probabilistic model checking implementation of context-free language properties for probabilistic pushdown systems."],"url":"http://arxiv.org/abs/2404.03515v1"}
{"created":"2024-04-04 15:21:22","title":"Learn When (not) to Trust Language Models: A Privacy-Centric Adaptive Model-Aware Approach","abstract":"Retrieval-augmented large language models (LLMs) have been remarkably competent in various NLP tasks. Despite their great success, the knowledge provided by the retrieval process is not always useful for improving the model prediction, since in some samples LLMs may already be quite knowledgeable and thus be able to answer the question correctly without retrieval. Aiming to save the cost of retrieval, previous work has proposed to determine when to do/skip the retrieval in a data-aware manner by analyzing the LLMs' pretraining data. However, these data-aware methods pose privacy risks and memory limitations, especially when requiring access to sensitive or extensive pretraining data. Moreover, these methods offer limited adaptability under fine-tuning or continual learning settings. We hypothesize that token embeddings are able to capture the model's intrinsic knowledge, which offers a safer and more straightforward way to judge the need for retrieval without the privacy risks associated with accessing pre-training data. Moreover, it alleviates the need to retain all the data utilized during model pre-training, necessitating only the upkeep of the token embeddings. Extensive experiments and in-depth analyses demonstrate the superiority of our model-aware approach.","sentences":["Retrieval-augmented large language models (LLMs) have been remarkably competent in various NLP tasks.","Despite their great success, the knowledge provided by the retrieval process is not always useful for improving the model prediction, since in some samples LLMs may already be quite knowledgeable and thus be able to answer the question correctly without retrieval.","Aiming to save the cost of retrieval, previous work has proposed to determine when to do/skip the retrieval in a data-aware manner by analyzing the LLMs' pretraining data.","However, these data-aware methods pose privacy risks and memory limitations, especially when requiring access to sensitive or extensive pretraining data.","Moreover, these methods offer limited adaptability under fine-tuning or continual learning settings.","We hypothesize that token embeddings are able to capture the model's intrinsic knowledge, which offers a safer and more straightforward way to judge the need for retrieval without the privacy risks associated with accessing pre-training data.","Moreover, it alleviates the need to retain all the data utilized during model pre-training, necessitating only the upkeep of the token embeddings.","Extensive experiments and in-depth analyses demonstrate the superiority of our model-aware approach."],"url":"http://arxiv.org/abs/2404.03514v1"}
{"created":"2024-04-04 15:15:38","title":"Improved Total Domination and Total Roman Domination in Unit Disk Graphs","abstract":"Let $G=(V, E)$ be a simple undirected graph with no isolated vertex. A set $D_t\\subseteq V$ is a total dominating set of $G$ if $(i)$ $D_t$ is a dominating set, and $(ii)$ the set $D_t$ induces a subgraph with no isolated vertex. The total dominating set of minimum cardinality is called the minimum total dominating set, and the size of the minimum total dominating set is called the total domination number ($\\gamma_t(G)$). Given a graph $G$, the total dominating set (TDS) problem is to find a total dominating set of minimum cardinality. A Roman dominating function (RDF) on a graph $G$ is a function $f:V\\rightarrow \\{0,1,2\\}$ such that each vertex $v\\in V$ with $f(v)=0$ is adjacent to at least one vertex $u\\in V$ with $f(u)=2$. A RDF $f$ of a graph $G$ is said to be a total Roman dominating function (TRDF) if the induced subgraph of $V_1\\cup V_2$ does not contain any isolated vertex, where $V_i=\\{u\\in V|f(u)=i\\}$. Given a graph $G$, the total Roman dominating set (TRDS) problem is to minimize the weight, $W(f)=\\sum_{u\\in V} f(u)$, called the total Roman domination number ($\\gamma_{tR}(G)$). In this paper, we are the first to show that the TRDS problem is NP-complete in unit disk graphs (UDGs). Furthermore, we propose a $7.17\\operatorname{-}$ factor approximation algorithm for the TDS problem and a $6.03\\operatorname{-}$ factor approximation algorithm for the TRDS problem in geometric unit disk graphs. The running time for both algorithms is notably bounded by $O(n\\log{k})$, where $n$ represents the number of vertices in the given UDG and $k$ represents the size of the independent set in (i.e., $D$ and $V_2$ in TDS and TRDS problems, respectively) the given UDG.","sentences":["Let $G=(V, E)$ be a simple undirected graph with no isolated vertex.","A set $D_t\\subseteq V$ is a total dominating set of $G$ if $(i)$ $D_t$ is a dominating set, and $(ii)$ the set $D_t$ induces a subgraph with no isolated vertex.","The total dominating set of minimum cardinality is called the minimum total dominating set, and the size of the minimum total dominating set is called the total domination number ($\\gamma_t(G)$).","Given a graph $G$, the total dominating set (TDS) problem is to find a total dominating set of minimum cardinality.","A Roman dominating function (RDF) on a graph $G$ is a function $f:V\\rightarrow \\{0,1,2\\}$ such that each vertex $v\\in V$ with $f(v)=0$ is adjacent to at least one vertex $u\\in V$ with $f(u)=2$. A RDF $f$ of a graph $G$ is said to be a total Roman dominating function (TRDF) if the induced subgraph of $V_1\\cup V_2$ does not contain any isolated vertex, where $V_i=\\{u\\in V|f(u)=i\\}$. Given a graph $G$, the total Roman dominating set (TRDS) problem is to minimize the weight, $W(f)=\\sum_{u\\in V} f(u)$, called the total Roman domination number ($\\gamma_{tR}(G)$).","In this paper, we are the first to show that the TRDS problem is NP-complete in unit disk graphs (UDGs).","Furthermore, we propose a $7.17\\operatorname{-}$ factor approximation algorithm for the TDS problem and a $6.03\\operatorname{-}$ factor approximation algorithm for the TRDS problem in geometric unit disk graphs.","The running time for both algorithms is notably bounded by $O(n\\log{k})$, where $n$ represents the number of vertices in the given UDG and $k$ represents the size of the independent set in (i.e., $D$ and $V_2$ in TDS and TRDS problems, respectively) the given UDG."],"url":"http://arxiv.org/abs/2404.03511v1"}
{"created":"2024-04-04 15:14:40","title":"Privacy-Enhancing Technologies for Artificial Intelligence-Enabled Systems","abstract":"Artificial intelligence (AI) models introduce privacy vulnerabilities to systems. These vulnerabilities may impact model owners or system users; they exist during model development, deployment, and inference phases, and threats can be internal or external to the system. In this paper, we investigate potential threats and propose the use of several privacy-enhancing technologies (PETs) to defend AI-enabled systems. We then provide a framework for PETs evaluation for a AI-enabled systems and discuss the impact PETs may have on system-level variables.","sentences":["Artificial intelligence (AI) models introduce privacy vulnerabilities to systems.","These vulnerabilities may impact model owners or system users; they exist during model development, deployment, and inference phases, and threats can be internal or external to the system.","In this paper, we investigate potential threats and propose the use of several privacy-enhancing technologies (PETs) to defend AI-enabled systems.","We then provide a framework for PETs evaluation for a AI-enabled systems and discuss the impact PETs may have on system-level variables."],"url":"http://arxiv.org/abs/2404.03509v1"}
{"created":"2024-04-04 15:10:24","title":"DQ-DETR: DETR with Dynamic Query for Tiny Object Detection","abstract":"Despite previous DETR-like methods having performed successfully in generic object detection, tiny object detection is still a challenging task for them since the positional information of object queries is not customized for detecting tiny objects, whose scale is extraordinarily smaller than general objects. Also, DETR-like methods using a fixed number of queries make them unsuitable for aerial datasets, which only contain tiny objects, and the numbers of instances are imbalanced between different images. Thus, we present a simple yet effective model, named DQ-DETR, which consists of three different components: categorical counting module, counting-guided feature enhancement, and dynamic query selection to solve the above-mentioned problems. DQ-DETR uses the prediction and density maps from the categorical counting module to dynamically adjust the number of object queries and improve the positional information of queries. Our model DQ-DETR outperforms previous CNN-based and DETR-like methods, achieving state-of-the-art mAP 30.2% on the AI-TOD-V2 dataset, which mostly consists of tiny objects.","sentences":["Despite previous DETR-like methods having performed successfully in generic object detection, tiny object detection is still a challenging task for them since the positional information of object queries is not customized for detecting tiny objects, whose scale is extraordinarily smaller than general objects.","Also, DETR-like methods using a fixed number of queries make them unsuitable for aerial datasets, which only contain tiny objects, and the numbers of instances are imbalanced between different images.","Thus, we present a simple yet effective model, named DQ-DETR, which consists of three different components: categorical counting module, counting-guided feature enhancement, and dynamic query selection to solve the above-mentioned problems.","DQ-DETR uses the prediction and density maps from the categorical counting module to dynamically adjust the number of object queries and improve the positional information of queries.","Our model DQ-DETR outperforms previous CNN-based and DETR-like methods, achieving state-of-the-art mAP 30.2% on the AI-TOD-V2 dataset, which mostly consists of tiny objects."],"url":"http://arxiv.org/abs/2404.03507v1"}
{"created":"2024-04-04 15:06:23","title":"AI and the Problem of Knowledge Collapse","abstract":"While artificial intelligence has the potential to process vast amounts of data, generate new insights, and unlock greater productivity, its widespread adoption may entail unforeseen consequences. We identify conditions under which AI, by reducing the cost of access to certain modes of knowledge, can paradoxically harm public understanding. While large language models are trained on vast amounts of diverse data, they naturally generate output towards the 'center' of the distribution. This is generally useful, but widespread reliance on recursive AI systems could lead to a process we define as \"knowledge collapse\", and argue this could harm innovation and the richness of human understanding and culture. However, unlike AI models that cannot choose what data they are trained on, humans may strategically seek out diverse forms of knowledge if they perceive them to be worthwhile. To investigate this, we provide a simple model in which a community of learners or innovators choose to use traditional methods or to rely on a discounted AI-assisted process and identify conditions under which knowledge collapse occurs. In our default model, a 20% discount on AI-generated content generates public beliefs 2.3 times further from the truth than when there is no discount. Finally, based on the results, we consider further research directions to counteract such outcomes.","sentences":["While artificial intelligence has the potential to process vast amounts of data, generate new insights, and unlock greater productivity, its widespread adoption may entail unforeseen consequences.","We identify conditions under which AI, by reducing the cost of access to certain modes of knowledge, can paradoxically harm public understanding.","While large language models are trained on vast amounts of diverse data, they naturally generate output towards the 'center' of the distribution.","This is generally useful, but widespread reliance on recursive AI systems could lead to a process we define as \"knowledge collapse\", and argue this could harm innovation and the richness of human understanding and culture.","However, unlike AI models that cannot choose what data they are trained on, humans may strategically seek out diverse forms of knowledge if they perceive them to be worthwhile.","To investigate this, we provide a simple model in which a community of learners or innovators choose to use traditional methods or to rely on a discounted AI-assisted process and identify conditions under which knowledge collapse occurs.","In our default model, a 20% discount on AI-generated content generates public beliefs 2.3 times further from the truth than when there is no discount.","Finally, based on the results, we consider further research directions to counteract such outcomes."],"url":"http://arxiv.org/abs/2404.03502v1"}
{"created":"2024-04-04 14:57:32","title":"Comprehensible Artificial Intelligence on Knowledge Graphs: A survey","abstract":"Artificial Intelligence applications gradually move outside the safe walls of research labs and invade our daily lives. This is also true for Machine Learning methods on Knowledge Graphs, which has led to a steady increase in their application since the beginning of the 21st century. However, in many applications, users require an explanation of the Artificial Intelligences decision. This led to increased demand for Comprehensible Artificial Intelligence. Knowledge Graphs epitomize fertile soil for Comprehensible Artificial Intelligence, due to their ability to display connected data, i.e. knowledge, in a human- as well as machine-readable way. This survey gives a short history to Comprehensible Artificial Intelligence on Knowledge Graphs. Furthermore, we contribute by arguing that the concept Explainable Artificial Intelligence is overloaded and overlapping with Interpretable Machine Learning. By introducing the parent concept Comprehensible Artificial Intelligence, we provide a clear-cut distinction of both concepts while accounting for their similarities. Thus, we provide in this survey a case for Comprehensible Artificial Intelligence on Knowledge Graphs consisting of Interpretable Machine Learning on Knowledge Graphs and Explainable Artificial Intelligence on Knowledge Graphs. This leads to the introduction of a novel taxonomy for Comprehensible Artificial Intelligence on Knowledge Graphs. In addition, a comprehensive overview of the research on Comprehensible Artificial Intelligence on Knowledge Graphs is presented and put into the context of the taxonomy. Finally, research gaps in the field of Comprehensible Artificial Intelligence on Knowledge Graphs are identified for future research.","sentences":["Artificial Intelligence applications gradually move outside the safe walls of research labs and invade our daily lives.","This is also true for Machine Learning methods on Knowledge Graphs, which has led to a steady increase in their application since the beginning of the 21st century.","However, in many applications, users require an explanation of the Artificial Intelligences decision.","This led to increased demand for Comprehensible Artificial Intelligence.","Knowledge Graphs epitomize fertile soil for Comprehensible Artificial Intelligence, due to their ability to display connected data, i.e. knowledge, in a human- as well as machine-readable way.","This survey gives a short history to Comprehensible Artificial Intelligence on Knowledge Graphs.","Furthermore, we contribute by arguing that the concept Explainable Artificial Intelligence is overloaded and overlapping with Interpretable Machine Learning.","By introducing the parent concept Comprehensible Artificial Intelligence, we provide a clear-cut distinction of both concepts while accounting for their similarities.","Thus, we provide in this survey a case for Comprehensible Artificial Intelligence on Knowledge Graphs consisting of Interpretable Machine Learning on Knowledge Graphs and Explainable Artificial Intelligence on Knowledge Graphs.","This leads to the introduction of a novel taxonomy for Comprehensible Artificial Intelligence on Knowledge Graphs.","In addition, a comprehensive overview of the research on Comprehensible Artificial Intelligence on Knowledge Graphs is presented and put into the context of the taxonomy.","Finally, research gaps in the field of Comprehensible Artificial Intelligence on Knowledge Graphs are identified for future research."],"url":"http://arxiv.org/abs/2404.03499v1"}
{"created":"2024-04-04 14:56:41","title":"Integrating Large Language Models with Multimodal Virtual Reality Interfaces to Support Collaborative Human-Robot Construction Work","abstract":"In the construction industry, where work environments are complex, unstructured and often dangerous, the implementation of Human-Robot Collaboration (HRC) is emerging as a promising advancement. This underlines the critical need for intuitive communication interfaces that enable construction workers to collaborate seamlessly with robotic assistants. This study introduces a conversational Virtual Reality (VR) interface integrating multimodal interaction to enhance intuitive communication between construction workers and robots. By integrating voice and controller inputs with the Robot Operating System (ROS), Building Information Modeling (BIM), and a game engine featuring a chat interface powered by a Large Language Model (LLM), the proposed system enables intuitive and precise interaction within a VR setting. Evaluated by twelve construction workers through a drywall installation case study, the proposed system demonstrated its low workload and high usability with succinct command inputs. The proposed multimodal interaction system suggests that such technological integration can substantially advance the integration of robotic assistants in the construction industry.","sentences":["In the construction industry, where work environments are complex, unstructured and often dangerous, the implementation of Human-Robot Collaboration (HRC) is emerging as a promising advancement.","This underlines the critical need for intuitive communication interfaces that enable construction workers to collaborate seamlessly with robotic assistants.","This study introduces a conversational Virtual Reality (VR) interface integrating multimodal interaction to enhance intuitive communication between construction workers and robots.","By integrating voice and controller inputs with the Robot Operating System (ROS), Building Information Modeling (BIM), and a game engine featuring a chat interface powered by a Large Language Model (LLM), the proposed system enables intuitive and precise interaction within a VR setting.","Evaluated by twelve construction workers through a drywall installation case study, the proposed system demonstrated its low workload and high usability with succinct command inputs.","The proposed multimodal interaction system suggests that such technological integration can substantially advance the integration of robotic assistants in the construction industry."],"url":"http://arxiv.org/abs/2404.03498v1"}
{"created":"2024-04-04 14:50:50","title":"About Test-time training for outlier detection","abstract":"In this paper, we introduce DOUST, our method applying test-time training for outlier detection, significantly improving the detection performance. After thoroughly evaluating our algorithm on common benchmark datasets, we discuss a common problem and show that it disappears with a large enough test set. Thus, we conclude that under reasonable conditions, our algorithm can reach almost supervised performance even when no labeled outliers are given.","sentences":["In this paper, we introduce DOUST, our method applying test-time training for outlier detection, significantly improving the detection performance.","After thoroughly evaluating our algorithm on common benchmark datasets, we discuss a common problem and show that it disappears with a large enough test set.","Thus, we conclude that under reasonable conditions, our algorithm can reach almost supervised performance even when no labeled outliers are given."],"url":"http://arxiv.org/abs/2404.03495v1"}
{"created":"2024-04-04 14:48:26","title":"A Methodology to Study the Impact of Spiking Neural Network Parameters considering Event-Based Automotive Data","abstract":"Autonomous Driving (AD) systems are considered as the future of human mobility and transportation. Solving computer vision tasks such as image classification and object detection/segmentation, with high accuracy and low power/energy consumption, is highly needed to realize AD systems in real life. These requirements can potentially be satisfied by Spiking Neural Networks (SNNs). However, the state-of-the-art works in SNN-based AD systems still focus on proposing network models that can achieve high accuracy, and they have not systematically studied the roles of SNN parameters when used for learning event-based automotive data. Therefore, we still lack understanding of how to effectively develop SNN models for AD systems. Toward this, we propose a novel methodology to systematically study and analyze the impact of SNN parameters considering event-based automotive data, then leverage this analysis for enhancing SNN developments. To do this, we first explore different settings of SNN parameters that directly affect the learning mechanism (i.e., batch size, learning rate, neuron threshold potential, and weight decay), then analyze the accuracy results. Afterward, we propose techniques that jointly improve SNN accuracy and reduce training time. Experimental results show that our methodology can improve the SNN models for AD systems than the state-of-the-art, as it achieves higher accuracy (i.e., 86%) for the NCARS dataset, and it can also achieve iso-accuracy (i.e., ~85% with standard deviation less than 0.5%) while speeding up the training time by 1.9x. In this manner, our research work provides a set of guidelines for SNN parameter enhancements, thereby enabling the practical developments of SNN-based AD systems.","sentences":["Autonomous Driving (AD) systems are considered as the future of human mobility and transportation.","Solving computer vision tasks such as image classification and object detection/segmentation, with high accuracy and low power/energy consumption, is highly needed to realize AD systems in real life.","These requirements can potentially be satisfied by Spiking Neural Networks (SNNs).","However, the state-of-the-art works in SNN-based AD systems still focus on proposing network models that can achieve high accuracy, and they have not systematically studied the roles of SNN parameters when used for learning event-based automotive data.","Therefore, we still lack understanding of how to effectively develop SNN models for AD systems.","Toward this, we propose a novel methodology to systematically study and analyze the impact of SNN parameters considering event-based automotive data, then leverage this analysis for enhancing SNN developments.","To do this, we first explore different settings of SNN parameters that directly affect the learning mechanism (i.e., batch size, learning rate, neuron threshold potential, and weight decay), then analyze the accuracy results.","Afterward, we propose techniques that jointly improve SNN accuracy and reduce training time.","Experimental results show that our methodology can improve the SNN models for AD systems than the state-of-the-art, as it achieves higher accuracy (i.e., 86%) for the NCARS dataset, and it can also achieve iso-accuracy (i.e., ~85% with standard deviation less than 0.5%) while speeding up the training time by 1.9x.","In this manner, our research work provides a set of guidelines for SNN parameter enhancements, thereby enabling the practical developments of SNN-based AD systems."],"url":"http://arxiv.org/abs/2404.03493v1"}
{"created":"2024-04-04 14:45:26","title":"A Cause-Effect Look at Alleviating Hallucination of Knowledge-grounded Dialogue Generation","abstract":"Empowered by the large-scale pretrained language models, existing dialogue systems have demonstrated impressive performance conducting fluent and natural-sounding conversations. However, they are still plagued by the hallucination problem, causing unpredictable factual errors in the generated responses. Recently, knowledge-grounded dialogue generation models, that intentionally invoke external knowledge resources to more informative responses, are also proven to be effective in reducing hallucination. Following the idea of getting high-quality knowledge, a few efforts have achieved pretty good performance on this issue. As some inevitable knowledge noises may also lead to hallucinations, it is emergent to investigate the reason and future directions for building noise-tolerant methods in KGD tasks. In this paper, we analyze the causal story behind this problem with counterfactual reasoning methods. Based on the causal effect analysis, we propose a possible solution for alleviating the hallucination in KGD by exploiting the dialogue-knowledge interaction. Experimental results of our example implementation show that this method can reduce hallucination without disrupting other dialogue performance, while keeping adaptive to different generation models. We hope our efforts can support and call for more attention to developing lightweight techniques towards robust and trusty dialogue systems.","sentences":["Empowered by the large-scale pretrained language models, existing dialogue systems have demonstrated impressive performance conducting fluent and natural-sounding conversations.","However, they are still plagued by the hallucination problem, causing unpredictable factual errors in the generated responses.","Recently, knowledge-grounded dialogue generation models, that intentionally invoke external knowledge resources to more informative responses, are also proven to be effective in reducing hallucination.","Following the idea of getting high-quality knowledge, a few efforts have achieved pretty good performance on this issue.","As some inevitable knowledge noises may also lead to hallucinations, it is emergent to investigate the reason and future directions for building noise-tolerant methods in KGD tasks.","In this paper, we analyze the causal story behind this problem with counterfactual reasoning methods.","Based on the causal effect analysis, we propose a possible solution for alleviating the hallucination in KGD by exploiting the dialogue-knowledge interaction.","Experimental results of our example implementation show that this method can reduce hallucination without disrupting other dialogue performance, while keeping adaptive to different generation models.","We hope our efforts can support and call for more attention to developing lightweight techniques towards robust and trusty dialogue systems."],"url":"http://arxiv.org/abs/2404.03491v1"}
{"created":"2024-04-04 14:43:43","title":"Design of Stickbug: a Six-Armed Precision Pollination Robot","abstract":"This work presents the design of Stickbug, a six-armed, multi-agent, precision pollination robot that combines the accuracy of single-agent systems with swarm parallelization in greenhouses. Precision pollination robots have often been proposed to offset the effects of a decreasing population of natural pollinators, but they frequently lack the required parallelization and scalability. Stickbug achieves this by allowing each arm and drive base to act as an individual agent, significantly reducing planning complexity. Stickbug uses a compact holonomic Kiwi drive to navigate narrow greenhouse rows, a tall mast to support multiple manipulators and reach plant heights, a detection model and classifier to identify Bramble flowers, and a felt-tipped end-effector for contact-based pollination. Initial experimental validation demonstrates that Stickbug can attempt over 1.5 pollinations per minute with a 50% success rate. Additionally, a Bramble flower perception dataset was created and is publicly available alongside Stickbug's software and design files.","sentences":["This work presents the design of Stickbug, a six-armed, multi-agent, precision pollination robot that combines the accuracy of single-agent systems with swarm parallelization in greenhouses.","Precision pollination robots have often been proposed to offset the effects of a decreasing population of natural pollinators, but they frequently lack the required parallelization and scalability.","Stickbug achieves this by allowing each arm and drive base to act as an individual agent, significantly reducing planning complexity.","Stickbug uses a compact holonomic Kiwi drive to navigate narrow greenhouse rows, a tall mast to support multiple manipulators and reach plant heights, a detection model and classifier to identify Bramble flowers, and a felt-tipped end-effector for contact-based pollination.","Initial experimental validation demonstrates that Stickbug can attempt over 1.5 pollinations per minute with a 50% success rate.","Additionally, a Bramble flower perception dataset was created and is publicly available alongside Stickbug's software and design files."],"url":"http://arxiv.org/abs/2404.03489v1"}
{"created":"2024-04-04 14:40:07","title":"Generative AI and Teachers -- For Us or Against Us? A Case Study","abstract":"We present insightful results of a survey on the adoption of generative artificial intelligence (GenAI) by university teachers in their teaching activities. The transformation of education by GenAI, particularly large language models (LLMs), has been presenting both opportunities and challenges, including cheating by students. We prepared the online survey according to best practices and the questions were created by the authors, who have pedagogy experience. The survey contained 12 questions and a pilot study was first conducted. The survey was then sent to all teachers in multiple departments across different campuses of the university of interest in Sweden: Lule{\\aa} University of Technology. The survey was available in both Swedish and English. The results show that 35 teachers (more than half) use GenAI out of 67 respondents. Preparation is the teaching activity with the most frequency that GenAI is used for and ChatGPT is the most commonly used GenAI. 59% say it has impacted their teaching, however, 55% say there should be legislation around the use of GenAI, especially as inaccuracies and cheating are the biggest concerns.","sentences":["We present insightful results of a survey on the adoption of generative artificial intelligence (GenAI) by university teachers in their teaching activities.","The transformation of education by GenAI, particularly large language models (LLMs), has been presenting both opportunities and challenges, including cheating by students.","We prepared the online survey according to best practices and the questions were created by the authors, who have pedagogy experience.","The survey contained 12 questions and a pilot study was first conducted.","The survey was then sent to all teachers in multiple departments across different campuses of the university of interest in Sweden: Lule{\\aa} University of Technology.","The survey was available in both Swedish and English.","The results show that 35 teachers (more than half) use GenAI out of 67 respondents.","Preparation is the teaching activity with the most frequency that GenAI is used for and ChatGPT is the most commonly used GenAI.","59% say it has impacted their teaching, however, 55% say there should be legislation around the use of GenAI, especially as inaccuracies and cheating are the biggest concerns."],"url":"http://arxiv.org/abs/2404.03486v1"}
{"created":"2024-04-04 14:35:49","title":"AdaGlimpse: Active Visual Exploration with Arbitrary Glimpse Position and Scale","abstract":"Active Visual Exploration (AVE) is a task that involves dynamically selecting observations (glimpses), which is critical to facilitate comprehension and navigation within an environment. While modern AVE methods have demonstrated impressive performance, they are constrained to fixed-scale glimpses from rigid grids. In contrast, existing mobile platforms equipped with optical zoom capabilities can capture glimpses of arbitrary positions and scales. To address this gap between software and hardware capabilities, we introduce AdaGlimpse. It uses Soft Actor-Critic, a reinforcement learning algorithm tailored for exploration tasks, to select glimpses of arbitrary position and scale. This approach enables our model to rapidly establish a general awareness of the environment before zooming in for detailed analysis. Experimental results demonstrate that AdaGlimpse surpasses previous methods across various visual tasks while maintaining greater applicability in realistic AVE scenarios.","sentences":["Active Visual Exploration (AVE) is a task that involves dynamically selecting observations (glimpses), which is critical to facilitate comprehension and navigation within an environment.","While modern AVE methods have demonstrated impressive performance, they are constrained to fixed-scale glimpses from rigid grids.","In contrast, existing mobile platforms equipped with optical zoom capabilities can capture glimpses of arbitrary positions and scales.","To address this gap between software and hardware capabilities, we introduce AdaGlimpse.","It uses Soft Actor-Critic, a reinforcement learning algorithm tailored for exploration tasks, to select glimpses of arbitrary position and scale.","This approach enables our model to rapidly establish a general awareness of the environment before zooming in for detailed analysis.","Experimental results demonstrate that AdaGlimpse surpasses previous methods across various visual tasks while maintaining greater applicability in realistic AVE scenarios."],"url":"http://arxiv.org/abs/2404.03482v1"}
{"created":"2024-04-04 14:28:34","title":"Towards Automated Movie Trailer Generation","abstract":"Movie trailers are an essential tool for promoting films and attracting audiences. However, the process of creating trailers can be time-consuming and expensive. To streamline this process, we propose an automatic trailer generation framework that generates plausible trailers from a full movie by automating shot selection and composition. Our approach draws inspiration from machine translation techniques and models the movies and trailers as sequences of shots, thus formulating the trailer generation problem as a sequence-to-sequence task. We introduce Trailer Generation Transformer (TGT), a deep-learning framework utilizing an encoder-decoder architecture. TGT movie encoder is tasked with contextualizing each movie shot representation via self-attention, while the autoregressive trailer decoder predicts the feature representation of the next trailer shot, accounting for the relevance of shots' temporal order in trailers. Our TGT significantly outperforms previous methods on a comprehensive suite of metrics.","sentences":["Movie trailers are an essential tool for promoting films and attracting audiences.","However, the process of creating trailers can be time-consuming and expensive.","To streamline this process, we propose an automatic trailer generation framework that generates plausible trailers from a full movie by automating shot selection and composition.","Our approach draws inspiration from machine translation techniques and models the movies and trailers as sequences of shots, thus formulating the trailer generation problem as a sequence-to-sequence task.","We introduce Trailer Generation Transformer (TGT), a deep-learning framework utilizing an encoder-decoder architecture.","TGT movie encoder is tasked with contextualizing each movie shot representation via self-attention, while the autoregressive trailer decoder predicts the feature representation of the next trailer shot, accounting for the relevance of shots' temporal order in trailers.","Our TGT significantly outperforms previous methods on a comprehensive suite of metrics."],"url":"http://arxiv.org/abs/2404.03477v1"}
{"created":"2024-04-04 14:28:05","title":"A Reduction from Multi-Parameter to Single-Parameter Bayesian Contract Design","abstract":"The main result of this paper is an almost approximation-preserving polynomial-time reduction from the most general multi-parameter Bayesian contract design (BCD) to single-parameter BCD. That is, for any multi-parameter BCD instance $I^M$, we construct a single-parameter instance $I^S$ such that any $\\beta$-approximate contract (resp. menu of contracts) of $I^S$ can in turn be converted to a $(\\beta -\\epsilon)$-approximate contract (resp. menu of contracts) of $I^M$. The reduction is in time polynomial in the input size and $\\log(\\frac{1}{\\epsilon})$; moreover, when $\\beta = 1$ (i.e., the given single-parameter solution is exactly optimal), the dependence on $\\frac{1}{\\epsilon}$ can be removed, leading to a polynomial-time exact reduction. This efficient reduction is somewhat surprising because in the closely related problem of Bayesian mechanism design, a polynomial-time reduction from multi-parameter to single-parameter setting is believed to not exist. Our result demonstrates the intrinsic difficulty of addressing moral hazard in Bayesian contract design, regardless of being single-parameter or multi-parameter.   As byproducts, our reduction answers two open questions in recent literature of algorithmic contract design: (a) it implies that optimal contract design in single-parameter BCD is not in APX unless P=NP even when the agent's type distribution is regular, answering the open question of [Alon et al. 2021] in the negative; (b) it implies that the principal's (order-wise) tight utility gap between using a menu of contracts and a single contract is $\\Theta(n)$ where $n$ is the number of actions, answering the major open question of [Guruganesh et al. 2021] for the single-parameter case.","sentences":["The main result of this paper is an almost approximation-preserving polynomial-time reduction from the most general multi-parameter Bayesian contract design (BCD) to single-parameter BCD.","That is, for any multi-parameter BCD instance $I^M$, we construct a single-parameter instance $I^S$ such that any $\\beta$-approximate contract (resp.","menu of contracts) of $I^S$ can in turn be converted to a $(\\beta -\\epsilon)$-approximate contract (resp.","menu of contracts) of $I^M$. The reduction is in time polynomial in the input size and $\\log(\\frac{1}{\\epsilon})$; moreover, when $\\beta = 1$ (i.e., the given single-parameter solution is exactly optimal), the dependence on $\\frac{1}{\\epsilon}$ can be removed, leading to a polynomial-time exact reduction.","This efficient reduction is somewhat surprising because in the closely related problem of Bayesian mechanism design, a polynomial-time reduction from multi-parameter to single-parameter setting is believed to not exist.","Our result demonstrates the intrinsic difficulty of addressing moral hazard in Bayesian contract design, regardless of being single-parameter or multi-parameter.   ","As byproducts, our reduction answers two open questions in recent literature of algorithmic contract design: (a) it implies that optimal contract design in single-parameter BCD is not in APX unless P=NP even when the agent's type distribution is regular, answering the open question of [Alon et al. 2021] in the negative; (b) it implies that the principal's (order-wise) tight utility gap between using a menu of contracts and a single contract is $\\Theta(n)$ where $n$ is the number of actions, answering the major open question of [Guruganesh et al. 2021] for the single-parameter case."],"url":"http://arxiv.org/abs/2404.03476v1"}
{"created":"2024-04-04 14:26:58","title":"Performance of computer vision algorithms for fine-grained classification using crowdsourced insect images","abstract":"With fine-grained classification, we identify unique characteristics to distinguish among classes of the same super-class. We are focusing on species recognition in Insecta, as they are critical for biodiversity monitoring and at the base of many ecosystems. With citizen science campaigns, billions of images are collected in the wild. Once these are labelled, experts can use them to create distribution maps. However, the labelling process is time-consuming, which is where computer vision comes in. The field of computer vision offers a wide range of algorithms, each with its strengths and weaknesses; how do we identify the algorithm that is in line with our application? To answer this question, we provide a full and detailed evaluation of nine algorithms among deep convolutional networks (CNN), vision transformers (ViT), and locality-based vision transformers (LBVT) on 4 different aspects: classification performance, embedding quality, computational cost, and gradient activity. We offer insights that we haven't yet had in this domain proving to which extent these algorithms solve the fine-grained tasks in Insecta. We found that the ViT performs the best on inference speed and computational cost while the LBVT outperforms the others on performance and embedding quality; the CNN provide a trade-off among the metrics.","sentences":["With fine-grained classification, we identify unique characteristics to distinguish among classes of the same super-class.","We are focusing on species recognition in Insecta, as they are critical for biodiversity monitoring and at the base of many ecosystems.","With citizen science campaigns, billions of images are collected in the wild.","Once these are labelled, experts can use them to create distribution maps.","However, the labelling process is time-consuming, which is where computer vision comes in.","The field of computer vision offers a wide range of algorithms, each with its strengths and weaknesses; how do we identify the algorithm that is in line with our application?","To answer this question, we provide a full and detailed evaluation of nine algorithms among deep convolutional networks (CNN), vision transformers (ViT), and locality-based vision transformers (LBVT) on 4 different aspects: classification performance, embedding quality, computational cost, and gradient activity.","We offer insights that we haven't yet had in this domain proving to which extent these algorithms solve the fine-grained tasks in Insecta.","We found that the ViT performs the best on inference speed and computational cost while the LBVT outperforms the others on performance and embedding quality; the CNN provide a trade-off among the metrics."],"url":"http://arxiv.org/abs/2404.03474v1"}
{"created":"2024-04-04 14:26:47","title":"Generalization Bounds for Message Passing Networks on Mixture of Graphons","abstract":"We study the generalization capabilities of Message Passing Neural Networks (MPNNs), a prevalent class of Graph Neural Networks (GNN). We derive generalization bounds specifically for MPNNs with normalized sum aggregation and mean aggregation. Our analysis is based on a data generation model incorporating a finite set of template graphons. Each graph within this framework is generated by sampling from one of the graphons with a certain degree of perturbation. In particular, we extend previous MPNN generalization results to a more realistic setting, which includes the following modifications: 1) we analyze simple random graphs with Bernoulli-distributed edges instead of weighted graphs; 2) we sample both graphs and graph signals from perturbed graphons instead of clean graphons; and 3) we analyze sparse graphs instead of dense graphs. In this more realistic and challenging scenario, we provide a generalization bound that decreases as the average number of nodes in the graphs increases. Our results imply that MPNNs with higher complexity than the size of the training set can still generalize effectively, as long as the graphs are sufficiently large.","sentences":["We study the generalization capabilities of Message Passing Neural Networks (MPNNs), a prevalent class of Graph Neural Networks (GNN).","We derive generalization bounds specifically for MPNNs with normalized sum aggregation and mean aggregation.","Our analysis is based on a data generation model incorporating a finite set of template graphons.","Each graph within this framework is generated by sampling from one of the graphons with a certain degree of perturbation.","In particular, we extend previous MPNN generalization results to a more realistic setting, which includes the following modifications: 1) we analyze simple random graphs with Bernoulli-distributed edges instead of weighted graphs; 2) we sample both graphs and graph signals from perturbed graphons instead of clean graphons; and 3) we analyze sparse graphs instead of dense graphs.","In this more realistic and challenging scenario, we provide a generalization bound that decreases as the average number of nodes in the graphs increases.","Our results imply that MPNNs with higher complexity than the size of the training set can still generalize effectively, as long as the graphs are sufficiently large."],"url":"http://arxiv.org/abs/2404.03473v1"}
{"created":"2024-04-04 14:25:21","title":"Lower bounds for graph reconstruction with maximal independent set queries","abstract":"We investigate the number of maximal independent set queries required to reconstruct the edges of a hidden graph. We show that randomised adaptive algorithms need at least $\\Omega(\\Delta^2 \\log(n / \\Delta) / \\log \\Delta)$ queries to reconstruct $n$-vertex graphs of maximum degree $\\Delta$ with success probability at least $1/2$, and we further improve this lower bound to $\\Omega(\\Delta^2 \\log(n / \\Delta))$ for randomised non-adaptive algorithms. We also prove that deterministic non-adaptive algorithms require at least $\\Omega(\\Delta^3 \\log n / \\log \\Delta)$ queries.   This improves bounds of Konrad, O'Sullivan, and Traistaru, and answers one of their questions. The proof of the lower bound for deterministic non-adaptive algorithms relies on a connection to cover-free families, for which we also improve known bounds.","sentences":["We investigate the number of maximal independent set queries required to reconstruct the edges of a hidden graph.","We show that randomised adaptive algorithms need at least $\\Omega(\\Delta^2 \\log(n / \\Delta) / \\log \\Delta)$ queries to reconstruct $n$-vertex graphs of maximum degree $\\Delta$ with success probability at least $1/2$, and we further improve this lower bound to $\\Omega(\\Delta^2 \\log(n / \\Delta))$ for randomised non-adaptive algorithms.","We also prove that deterministic non-adaptive algorithms require at least $\\Omega(\\Delta^3 \\log n / \\log \\Delta)$ queries.   ","This improves bounds of Konrad, O'Sullivan, and Traistaru, and answers one of their questions.","The proof of the lower bound for deterministic non-adaptive algorithms relies on a connection to cover-free families, for which we also improve known bounds."],"url":"http://arxiv.org/abs/2404.03472v1"}
{"created":"2024-04-04 14:24:06","title":"Reevaluating Bias Detection in Language Models: The Role of Implicit Norm","abstract":"Large language models (LLMs), trained on vast datasets, can carry biases that manifest in various forms, from overt discrimination to implicit stereotypes. One facet of bias is performance disparities in LLMs, often harming underprivileged groups, such as racial minorities. A common approach to quantifying bias is to use template-based bias probes, which explicitly state group membership (e.g. White) and evaluate if the outcome of a task, sentiment analysis for instance, is invariant to the change of group membership (e.g. change White race to Black). This approach is widely used in bias quantification. However, in this work, we find evidence of an unexpectedly overlooked consequence of using template-based probes for LLM bias quantification. We find that in doing so, text examples associated with White ethnicities appear to be classified as exhibiting negative sentiment at elevated rates. We hypothesize that the scenario arises artificially through a mismatch between the pre-training text of LLMs and the templates used to measure bias through reporting bias, unstated norms that imply group membership without explicit statement. Our finding highlights the potential misleading impact of varying group membership through explicit mention in bias quantification","sentences":["Large language models (LLMs), trained on vast datasets, can carry biases that manifest in various forms, from overt discrimination to implicit stereotypes.","One facet of bias is performance disparities in LLMs, often harming underprivileged groups, such as racial minorities.","A common approach to quantifying bias is to use template-based bias probes, which explicitly state group membership (e.g. White) and evaluate if the outcome of a task, sentiment analysis for instance, is invariant to the change of group membership (e.g. change White race to Black).","This approach is widely used in bias quantification.","However, in this work, we find evidence of an unexpectedly overlooked consequence of using template-based probes for LLM bias quantification.","We find that in doing so, text examples associated with White ethnicities appear to be classified as exhibiting negative sentiment at elevated rates.","We hypothesize that the scenario arises artificially through a mismatch between the pre-training text of LLMs and the templates used to measure bias through reporting bias, unstated norms that imply group membership without explicit statement.","Our finding highlights the potential misleading impact of varying group membership through explicit mention in bias quantification"],"url":"http://arxiv.org/abs/2404.03471v1"}
{"created":"2024-04-04 14:13:56","title":"You Only Scan Once: A Dynamic Scene Reconstruction Pipeline for 6-DoF Robotic Grasping of Novel Objects","abstract":"In the realm of robotic grasping, achieving accurate and reliable interactions with the environment is a pivotal challenge. Traditional methods of grasp planning methods utilizing partial point clouds derived from depth image often suffer from reduced scene understanding due to occlusion, ultimately impeding their grasping accuracy. Furthermore, scene reconstruction methods have primarily relied upon static techniques, which are susceptible to environment change during manipulation process limits their efficacy in real-time grasping tasks. To address these limitations, this paper introduces a novel two-stage pipeline for dynamic scene reconstruction. In the first stage, our approach takes scene scanning as input to register each target object with mesh reconstruction and novel object pose tracking. In the second stage, pose tracking is still performed to provide object poses in real-time, enabling our approach to transform the reconstructed object point clouds back into the scene. Unlike conventional methodologies, which rely on static scene snapshots, our method continuously captures the evolving scene geometry, resulting in a comprehensive and up-to-date point cloud representation. By circumventing the constraints posed by occlusion, our method enhances the overall grasp planning process and empowers state-of-the-art 6-DoF robotic grasping algorithms to exhibit markedly improved accuracy.","sentences":["In the realm of robotic grasping, achieving accurate and reliable interactions with the environment is a pivotal challenge.","Traditional methods of grasp planning methods utilizing partial point clouds derived from depth image often suffer from reduced scene understanding due to occlusion, ultimately impeding their grasping accuracy.","Furthermore, scene reconstruction methods have primarily relied upon static techniques, which are susceptible to environment change during manipulation process limits their efficacy in real-time grasping tasks.","To address these limitations, this paper introduces a novel two-stage pipeline for dynamic scene reconstruction.","In the first stage, our approach takes scene scanning as input to register each target object with mesh reconstruction and novel object pose tracking.","In the second stage, pose tracking is still performed to provide object poses in real-time, enabling our approach to transform the reconstructed object point clouds back into the scene.","Unlike conventional methodologies, which rely on static scene snapshots, our method continuously captures the evolving scene geometry, resulting in a comprehensive and up-to-date point cloud representation.","By circumventing the constraints posed by occlusion, our method enhances the overall grasp planning process and empowers state-of-the-art 6-DoF robotic grasping algorithms to exhibit markedly improved accuracy."],"url":"http://arxiv.org/abs/2404.03462v1"}
{"created":"2024-04-04 13:59:04","title":"Synergy as the failure of distributivity","abstract":"A physical system is synergistic if it cannot be reduced to its constituents. Intuitively this is paraphrased into the common statement that 'the whole is greater than the sum of its parts'. In this manner, many basic parts in combination may give rise to some unexpected collective behavior. A paradigmatic example of such phenomenon is information. Several sources, which are already known individually, may provide some new knowledge when joined together. Here we take the trivial case of discrete random variables and explore whether and how it is possible to get more information out of lesser parts. Our approach is inspired by set theory as the fundamental description of part-whole relations. If taken unaltered, synergistic behavior is forbidden by the set theoretical axioms. Indeed, the union of sets cannot contain extra elements not found in any particular set. However, random variables are not a perfect analogy of sets. We formalise the distinction, finding a single broken axiom - union/intersection distributivity. Nevertheless, it remains possible to describe information using Venn-type diagrams. We directly connect the existence of synergy to the failure of distributivity for random variables. When compared to the partial information decomposition framework (PID), our technique fully reproduces previous results while resolving the self-contradictions that plagued them and providing additional constraints on the solutions. This opens the way towards quantifying emergence in large systems.","sentences":["A physical system is synergistic if it cannot be reduced to its constituents.","Intuitively this is paraphrased into the common statement that 'the whole is greater than the sum of its parts'.","In this manner, many basic parts in combination may give rise to some unexpected collective behavior.","A paradigmatic example of such phenomenon is information.","Several sources, which are already known individually, may provide some new knowledge when joined together.","Here we take the trivial case of discrete random variables and explore whether and how it is possible to get more information out of lesser parts.","Our approach is inspired by set theory as the fundamental description of part-whole relations.","If taken unaltered, synergistic behavior is forbidden by the set theoretical axioms.","Indeed, the union of sets cannot contain extra elements not found in any particular set.","However, random variables are not a perfect analogy of sets.","We formalise the distinction, finding a single broken axiom - union/intersection distributivity.","Nevertheless, it remains possible to describe information using Venn-type diagrams.","We directly connect the existence of synergy to the failure of distributivity for random variables.","When compared to the partial information decomposition framework (PID), our technique fully reproduces previous results while resolving the self-contradictions that plagued them and providing additional constraints on the solutions.","This opens the way towards quantifying emergence in large systems."],"url":"http://arxiv.org/abs/2404.03455v1"}
{"created":"2024-04-04 13:55:06","title":"How Much Data are Enough? Investigating Dataset Requirements for Patch-Based Brain MRI Segmentation Tasks","abstract":"Training deep neural networks reliably requires access to large-scale datasets. However, obtaining such datasets can be challenging, especially in the context of neuroimaging analysis tasks, where the cost associated with image acquisition and annotation can be prohibitive. To mitigate both the time and financial costs associated with model development, a clear understanding of the amount of data required to train a satisfactory model is crucial. This paper focuses on an early stage phase of deep learning research, prior to model development, and proposes a strategic framework for estimating the amount of annotated data required to train patch-based segmentation networks. This framework includes the establishment of performance expectations using a novel Minor Boundary Adjustment for Threshold (MinBAT) method, and standardizing patch selection through the ROI-based Expanded Patch Selection (REPS) method. Our experiments demonstrate that tasks involving regions of interest (ROIs) with different sizes or shapes may yield variably acceptable Dice Similarity Coefficient (DSC) scores. By setting an acceptable DSC as the target, the required amount of training data can be estimated and even predicted as data accumulates. This approach could assist researchers and engineers in estimating the cost associated with data collection and annotation when defining a new segmentation task based on deep neural networks, ultimately contributing to their efficient translation to real-world applications.","sentences":["Training deep neural networks reliably requires access to large-scale datasets.","However, obtaining such datasets can be challenging, especially in the context of neuroimaging analysis tasks, where the cost associated with image acquisition and annotation can be prohibitive.","To mitigate both the time and financial costs associated with model development, a clear understanding of the amount of data required to train a satisfactory model is crucial.","This paper focuses on an early stage phase of deep learning research, prior to model development, and proposes a strategic framework for estimating the amount of annotated data required to train patch-based segmentation networks.","This framework includes the establishment of performance expectations using a novel Minor Boundary Adjustment for Threshold (MinBAT) method, and standardizing patch selection through the ROI-based Expanded Patch Selection (REPS) method.","Our experiments demonstrate that tasks involving regions of interest (ROIs) with different sizes or shapes may yield variably acceptable Dice Similarity Coefficient (DSC) scores.","By setting an acceptable DSC as the target, the required amount of training data can be estimated and even predicted as data accumulates.","This approach could assist researchers and engineers in estimating the cost associated with data collection and annotation when defining a new segmentation task based on deep neural networks, ultimately contributing to their efficient translation to real-world applications."],"url":"http://arxiv.org/abs/2404.03451v1"}
