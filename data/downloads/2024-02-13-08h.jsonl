{"created":"2024-02-12 18:59:39","title":"FAST: Factorizable Attention for Speeding up Transformers","abstract":"Motivated by the factorization inherent in the original fast multipole method and the improved fast Gauss transform we introduce a factorable form of attention that operates efficiently in high dimensions. This approach reduces the computational and memory complexity of the attention mechanism in transformers from $O(N^2)$ to $O(N)$. In comparison to previous attempts, our work presents a linearly scaled attention mechanism that maintains the full representation of the attention matrix without compromising on sparsification and incorporates the all-to-all relationship between tokens. We explore the properties of our new attention metric and conduct tests in various standard settings. Results indicate that our attention mechanism has a robust performance and holds significant promise for diverse applications where self-attention is used.","sentences":["Motivated by the factorization inherent in the original fast multipole method and the improved fast Gauss transform we introduce a factorable form of attention that operates efficiently in high dimensions.","This approach reduces the computational and memory complexity of the attention mechanism in transformers from $O(N^2)$ to $O(N)$. In comparison to previous attempts, our work presents a linearly scaled attention mechanism that maintains the full representation of the attention matrix without compromising on sparsification and incorporates the all-to-all relationship between tokens.","We explore the properties of our new attention metric and conduct tests in various standard settings.","Results indicate that our attention mechanism has a robust performance and holds significant promise for diverse applications where self-attention is used."],"url":"http://arxiv.org/abs/2402.07901v1"}
{"created":"2024-02-12 18:59:14","title":"Wavefront Randomization Improves Deconvolution","abstract":"The performance of an imaging system is limited by optical aberrations, which cause blurriness in the resulting image. Digital correction techniques, such as deconvolution, have limited ability to correct the blur, since some spatial frequencies in the scene are not measured adequately due to the aberrations ('zeros' of the system transfer function). We prove that the addition of a random mask to an imaging system removes its dependence on aberrations, reducing the likelihood of zeros in the transfer function and consequently reducing the sensitivity to noise during deconvolution. and consequently result in lower sensitivity to noise during deconvolution. In simulation, we show that this strategy improves image quality over a range of aberration types, aberration strengths, and signal-to-noise ratios.","sentences":["The performance of an imaging system is limited by optical aberrations, which cause blurriness in the resulting image.","Digital correction techniques, such as deconvolution, have limited ability to correct the blur, since some spatial frequencies in the scene are not measured adequately due to the aberrations ('zeros' of the system transfer function).","We prove that the addition of a random mask to an imaging system removes its dependence on aberrations, reducing the likelihood of zeros in the transfer function and consequently reducing the sensitivity to noise during deconvolution.","and consequently result in lower sensitivity to noise during deconvolution.","In simulation, we show that this strategy improves image quality over a range of aberration types, aberration strengths, and signal-to-noise ratios."],"url":"http://arxiv.org/abs/2402.07900v1"}
{"created":"2024-02-12 18:58:58","title":"A systematic investigation of learnability from single child linguistic input","abstract":"Language models (LMs) have demonstrated remarkable proficiency in generating linguistically coherent text, sparking discussions about their relevance to understanding human language learnability. However, a significant gap exists between the training data for these models and the linguistic input a child receives. LMs are typically trained on data that is orders of magnitude larger and fundamentally different from child-directed speech (Warstadt and Bowman, 2022; Warstadt et al., 2023; Frank, 2023a). Addressing this discrepancy, our research focuses on training LMs on subsets of a single child's linguistic input. Previously, Wang, Vong, Kim, and Lake (2023) found that LMs trained in this setting can form syntactic and semantic word clusters and develop sensitivity to certain linguistic phenomena, but they only considered LSTMs and simpler neural networks trained from just one single-child dataset. Here, to examine the robustness of learnability from single-child input, we systematically train six different model architectures on five datasets (3 single-child and 2 baselines). We find that the models trained on single-child datasets showed consistent results that matched with previous work, underscoring the robustness of forming meaningful syntactic and semantic representations from a subset of a child's linguistic input.","sentences":["Language models (LMs) have demonstrated remarkable proficiency in generating linguistically coherent text, sparking discussions about their relevance to understanding human language learnability.","However, a significant gap exists between the training data for these models and the linguistic input a child receives.","LMs are typically trained on data that is orders of magnitude larger and fundamentally different from child-directed speech (Warstadt and Bowman, 2022; Warstadt et al., 2023; Frank, 2023a).","Addressing this discrepancy, our research focuses on training LMs on subsets of a single child's linguistic input.","Previously, Wang, Vong, Kim, and Lake (2023) found that LMs trained in this setting can form syntactic and semantic word clusters and develop sensitivity to certain linguistic phenomena, but they only considered LSTMs and simpler neural networks trained from just one single-child dataset.","Here, to examine the robustness of learnability from single-child input, we systematically train six different model architectures on five datasets (3 single-child and 2 baselines).","We find that the models trained on single-child datasets showed consistent results that matched with previous work, underscoring the robustness of forming meaningful syntactic and semantic representations from a subset of a child's linguistic input."],"url":"http://arxiv.org/abs/2402.07899v1"}
{"created":"2024-02-12 18:58:01","title":"A holographic mobile-based application for practicing pronunciation of basic English vocabulary for Spanish speaking children","abstract":"This paper describes a holographic mobile-based application designed to help Spanish-speaking children to practice the pronunciation of basic English vocabulary words. The mastery of vocabulary is a fundamental step when learning a language but is often perceived as boring. Producing the correct pronunciation is frequently regarded as the most difficult and complex skill for new learners of English. In order to address these problems this research takes advantage of the power of multi-channel stimuli (sound, image and interaction) in a mobilebased hologram application in order to motivate students and improve their experience of practicing. We adapted the prize-winning HolograFX game and developed a new mobile application to help practice English pronunciation. A 3D holographic robot that acts as a virtual teacher interacts via voice with the children. To test the tool we carried out an experiment with 70 Spanish pre-school children divided into three classes, the control group using traditional methods such as images in books and on the blackboard, and two experimental groups using our drills and practice software. One experimental group used the mobile application without the holographic game and the other experimental group used the application with the holographic game. We performed pre-test and post-test performance assessments, a satisfaction survey and emotion analysis. The results are very promising. They show that the use of the holographic mobile-based application had a significant impact on the children's motivation. It also improved their performance compared to traditional methods used in the classroom.","sentences":["This paper describes a holographic mobile-based application designed to help Spanish-speaking children to practice the pronunciation of basic English vocabulary words.","The mastery of vocabulary is a fundamental step when learning a language but is often perceived as boring.","Producing the correct pronunciation is frequently regarded as the most difficult and complex skill for new learners of English.","In order to address these problems this research takes advantage of the power of multi-channel stimuli (sound, image and interaction) in a mobilebased hologram application in order to motivate students and improve their experience of practicing.","We adapted the prize-winning HolograFX game and developed a new mobile application to help practice English pronunciation.","A 3D holographic robot that acts as a virtual teacher interacts via voice with the children.","To test the tool we carried out an experiment with 70 Spanish pre-school children divided into three classes, the control group using traditional methods such as images in books and on the blackboard, and two experimental groups using our drills and practice software.","One experimental group used the mobile application without the holographic game and the other experimental group used the application with the holographic game.","We performed pre-test and post-test performance assessments, a satisfaction survey and emotion analysis.","The results are very promising.","They show that the use of the holographic mobile-based application had a significant impact on the children's motivation.","It also improved their performance compared to traditional methods used in the classroom."],"url":"http://arxiv.org/abs/2402.07897v1"}
{"created":"2024-02-12 18:57:46","title":"Suppressing Pink Elephants with Direct Principle Feedback","abstract":"Existing methods for controlling language models, such as RLHF and Constitutional AI, involve determining which LLM behaviors are desirable and training them into a language model. However, in many cases, it is desirable for LLMs to be controllable \\textit{at inference time}, so that they can be used in multiple contexts with diverse needs. We illustrate this with the \\textbf{Pink Elephant Problem}: instructing an LLM to avoid discussing a certain entity (a ``Pink Elephant''), and instead discuss a preferred entity (``Grey Elephant''). We apply a novel simplification of Constitutional AI, \\textbf{Direct Principle Feedback}, which skips the ranking of responses and uses DPO directly on critiques and revisions. Our results show that after DPF fine-tuning on our synthetic Pink Elephants dataset, our 13B fine-tuned LLaMA 2 model significantly outperforms Llama-2-13B-Chat and a prompted baseline, and performs as well as GPT-4 in on our curated test set assessing the Pink Elephant Problem.","sentences":["Existing methods for controlling language models, such as RLHF and Constitutional AI, involve determining which LLM behaviors are desirable and training them into a language model.","However, in many cases, it is desirable for LLMs to be controllable \\textit{at inference time}, so that they can be used in multiple contexts with diverse needs.","We illustrate this with the \\textbf{Pink Elephant Problem}: instructing an LLM to avoid discussing a certain entity (a ``Pink Elephant''), and instead discuss a preferred entity (``Grey Elephant'').","We apply a novel simplification of Constitutional AI, \\textbf{Direct Principle Feedback}, which skips the ranking of responses and uses DPO directly on critiques and revisions.","Our results show that after DPF fine-tuning on our synthetic Pink Elephants dataset, our 13B fine-tuned LLaMA 2 model significantly outperforms Llama-2-13B-Chat and a prompted baseline, and performs as well as GPT-4 in on our curated test set assessing the Pink Elephant Problem."],"url":"http://arxiv.org/abs/2402.07896v1"}
{"created":"2024-02-12 18:57:06","title":"Detection of Spider Mites on Labrador Beans through Machine Learning Approaches Using Custom Datasets","abstract":"Amidst growing food production demands, early plant disease detection is essential to safeguard crops; this study proposes a visual machine learning approach for plant disease detection, harnessing RGB and NIR data collected in real-world conditions through a JAI FS-1600D-10GE camera to build an RGBN dataset. A two-stage early plant disease detection model with YOLOv8 and a sequential CNN was used to train on a dataset with partial labels, which showed a 3.6% increase in mAP compared to a single-stage end-to-end segmentation model. The sequential CNN model achieved 90.62% validation accuracy utilising RGBN data. An average of 6.25% validation accuracy increase is found using RGBN in classification compared to RGB using ResNet15 and the sequential CNN models. Further research and dataset improvements are needed to meet food production demands.","sentences":["Amidst growing food production demands, early plant disease detection is essential to safeguard crops; this study proposes a visual machine learning approach for plant disease detection, harnessing RGB and NIR data collected in real-world conditions through a JAI FS-1600D-10GE camera to build an RGBN dataset.","A two-stage early plant disease detection model with YOLOv8 and a sequential CNN was used to train on a dataset with partial labels, which showed a 3.6% increase in mAP compared to a single-stage end-to-end segmentation model.","The sequential CNN model achieved 90.62% validation accuracy utilising RGBN data.","An average of 6.25% validation accuracy increase is found using RGBN in classification compared to RGB using ResNet15 and the sequential CNN models.","Further research and dataset improvements are needed to meet food production demands."],"url":"http://arxiv.org/abs/2402.07895v1"}
{"created":"2024-02-12 18:56:53","title":"MODIPHY: Multimodal Obscured Detection for IoT using PHantom Convolution-Enabled Faster YOLO","abstract":"Low-light conditions and occluded scenarios impede object detection in real-world Internet of Things (IoT) applications like autonomous vehicles and security systems. While advanced machine learning models strive for accuracy, their computational demands clash with the limitations of resource-constrained devices, hampering real-time performance. In our current research, we tackle this challenge, by introducing \"YOLO Phantom\", one of the smallest YOLO models ever conceived. YOLO Phantom utilizes the novel Phantom Convolution block, achieving comparable accuracy to the latest YOLOv8n model while simultaneously reducing both parameters and model size by 43%, resulting in a significant 19% reduction in Giga Floating Point Operations (GFLOPs). YOLO Phantom leverages transfer learning on our multimodal RGB-infrared dataset to address low-light and occlusion issues, equipping it with robust vision under adverse conditions. Its real-world efficacy is demonstrated on an IoT platform with advanced low-light and RGB cameras, seamlessly connecting to an AWS-based notification endpoint for efficient real-time object detection. Benchmarks reveal a substantial boost of 17% and 14% in frames per second (FPS) for thermal and RGB detection, respectively, compared to the baseline YOLOv8n model. For community contribution, both the code and the multimodal dataset are available on GitHub.","sentences":["Low-light conditions","and","occluded scenarios impede object detection in real-world Internet of Things (IoT) applications like autonomous vehicles and security systems.","While advanced machine learning models strive for accuracy, their computational demands clash with the limitations of resource-constrained devices, hampering real-time performance.","In our current research, we tackle this challenge, by introducing \"YOLO Phantom\", one of the smallest YOLO models ever conceived.","YOLO Phantom utilizes the novel Phantom Convolution block, achieving comparable accuracy to the latest YOLOv8n model while simultaneously reducing both parameters and model size by 43%, resulting in a significant 19% reduction in Giga Floating Point Operations (GFLOPs).","YOLO Phantom leverages transfer learning on our multimodal RGB-infrared dataset to address low-light and occlusion issues, equipping it with robust vision under adverse conditions.","Its real-world efficacy is demonstrated on an IoT platform with advanced low-light and RGB cameras, seamlessly connecting to an AWS-based notification endpoint for efficient real-time object detection.","Benchmarks reveal a substantial boost of 17% and 14% in frames per second (FPS) for thermal and RGB detection, respectively, compared to the baseline YOLOv8n model.","For community contribution, both the code and the multimodal dataset are available on GitHub."],"url":"http://arxiv.org/abs/2402.07894v1"}
{"created":"2024-02-12 18:54:02","title":"Label-Efficient Model Selection for Text Generation","abstract":"Model selection for a given target task can be costly, as it may entail extensive annotation of the quality of outputs of different models. We introduce DiffUse, an efficient method to make an informed decision between candidate text generation models. DiffUse reduces the required amount of preference annotations, thus saving valuable time and resources in performing evaluation. DiffUse intelligently selects instances by clustering embeddings that represent the semantic differences between model outputs. Thus, it is able to identify a subset of examples that are more informative for preference decisions. Our method is model-agnostic, and can be applied to any text generation model. Moreover, we propose a practical iterative approach for dynamically determining how many instances to annotate. In a series of experiments over hundreds of model pairs, we demonstrate that DiffUse can dramatically reduce the required number of annotations -- by up to 75% -- while maintaining high evaluation reliability.","sentences":["Model selection for a given target task can be costly, as it may entail extensive annotation of the quality of outputs of different models.","We introduce DiffUse, an efficient method to make an informed decision between candidate text generation models.","DiffUse reduces the required amount of preference annotations, thus saving valuable time and resources in performing evaluation.","DiffUse intelligently selects instances by clustering embeddings that represent the semantic differences between model outputs.","Thus, it is able to identify a subset of examples that are more informative for preference decisions.","Our method is model-agnostic, and can be applied to any text generation model.","Moreover, we propose a practical iterative approach for dynamically determining how many instances to annotate.","In a series of experiments over hundreds of model pairs, we demonstrate that DiffUse can dramatically reduce the required number of annotations -- by up to 75% -- while maintaining high evaluation reliability."],"url":"http://arxiv.org/abs/2402.07891v1"}
{"created":"2024-02-12 18:53:20","title":"MAIDCRL: Semi-centralized Multi-Agent Influence Dense-CNN Reinforcement Learning","abstract":"Distributed decision-making in multi-agent systems presents difficult challenges for interactive behavior learning in both cooperative and competitive systems. To mitigate this complexity, MAIDRL presents a semi-centralized Dense Reinforcement Learning algorithm enhanced by agent influence maps (AIMs), for learning effective multi-agent control on StarCraft Multi-Agent Challenge (SMAC) scenarios. In this paper, we extend the DenseNet in MAIDRL and introduce semi-centralized Multi-Agent Dense-CNN Reinforcement Learning, MAIDCRL, by incorporating convolutional layers into the deep model architecture, and evaluate the performance on both homogeneous and heterogeneous scenarios. The results show that the CNN-enabled MAIDCRL significantly improved the learning performance and achieved a faster learning rate compared to the existing MAIDRL, especially on more complicated heterogeneous SMAC scenarios. We further investigate the stability and robustness of our model. The statistics reflect that our model not only achieves higher winning rate in all the given scenarios but also boosts the agent's learning process in fine-grained decision-making.","sentences":["Distributed decision-making in multi-agent systems presents difficult challenges for interactive behavior learning in both cooperative and competitive systems.","To mitigate this complexity, MAIDRL presents a semi-centralized Dense Reinforcement Learning algorithm enhanced by agent influence maps (AIMs), for learning effective multi-agent control on StarCraft Multi-Agent Challenge (SMAC) scenarios.","In this paper, we extend the DenseNet in MAIDRL and introduce semi-centralized Multi-Agent Dense-CNN Reinforcement Learning, MAIDCRL, by incorporating convolutional layers into the deep model architecture, and evaluate the performance on both homogeneous and heterogeneous scenarios.","The results show that the CNN-enabled MAIDCRL significantly improved the learning performance and achieved a faster learning rate compared to the existing MAIDRL, especially on more complicated heterogeneous SMAC scenarios.","We further investigate the stability and robustness of our model.","The statistics reflect that our model not only achieves higher winning rate in all the given scenarios but also boosts the agent's learning process in fine-grained decision-making."],"url":"http://arxiv.org/abs/2402.07890v1"}
{"created":"2024-02-12 18:52:39","title":"Toward an Android Static Analysis Approach for Data Protection","abstract":"Android applications collecting data from users must protect it according to the current legal frameworks. Such data protection has become even more important since the European Union rolled out the General Data Protection Regulation (GDPR). Since app developers are not legal experts, they find it difficult to write privacy-aware source code. Moreover, they have limited tool support to reason about data protection throughout their app development process.   This paper motivates the need for a static analysis approach to diagnose and explain data protection in Android apps. The analysis will recognize personal data sources in the source code, and aims to further examine the data flow originating from these sources. App developers can then address key questions about data manipulation, derived data, and the presence of technical measures. Despite challenges, we explore to what extent one can realize this analysis through static taint analysis, a common method for identifying security vulnerabilities. This is a first step towards designing a tool-based approach that aids app developers and assessors in ensuring data protection in Android apps, based on automated static program analysis.","sentences":["Android applications collecting data from users must protect it according to the current legal frameworks.","Such data protection has become even more important since the European Union rolled out the General Data Protection Regulation (GDPR).","Since app developers are not legal experts, they find it difficult to write privacy-aware source code.","Moreover, they have limited tool support to reason about data protection throughout their app development process.   ","This paper motivates the need for a static analysis approach to diagnose and explain data protection in Android apps.","The analysis will recognize personal data sources in the source code, and aims to further examine the data flow originating from these sources.","App developers can then address key questions about data manipulation, derived data, and the presence of technical measures.","Despite challenges, we explore to what extent one can realize this analysis through static taint analysis, a common method for identifying security vulnerabilities.","This is a first step towards designing a tool-based approach that aids app developers and assessors in ensuring data protection in Android apps, based on automated static program analysis."],"url":"http://arxiv.org/abs/2402.07889v1"}
{"created":"2024-02-12 18:44:02","title":"Using Graph Theory for Improving Machine Learning-based Detection of Cyber Attacks","abstract":"Early detection of network intrusions and cyber threats is one of the main pillars of cybersecurity. One of the most effective approaches for this purpose is to analyze network traffic with the help of artificial intelligence algorithms, with the aim of detecting the possible presence of an attacker by distinguishing it from a legitimate user. This is commonly done by collecting the traffic exchanged between terminals in a network and analyzing it on a per-packet or per-connection basis. In this paper, we propose instead to perform pre-processing of network traffic under analysis with the aim of extracting some new metrics on which we can perform more efficient detection and overcome some limitations of classical approaches. These new metrics are based on graph theory, and consider the network as a whole, rather than focusing on individual packets or connections. Our approach is validated through experiments performed on publicly available data sets, from which it results that it can not only overcome some of the limitations of classical approaches, but also achieve a better detection capability of cyber threats.","sentences":["Early detection of network intrusions and cyber threats is one of the main pillars of cybersecurity.","One of the most effective approaches for this purpose is to analyze network traffic with the help of artificial intelligence algorithms, with the aim of detecting the possible presence of an attacker by distinguishing it from a legitimate user.","This is commonly done by collecting the traffic exchanged between terminals in a network and analyzing it on a per-packet or per-connection basis.","In this paper, we propose instead to perform pre-processing of network traffic under analysis with the aim of extracting some new metrics on which we can perform more efficient detection and overcome some limitations of classical approaches.","These new metrics are based on graph theory, and consider the network as a whole, rather than focusing on individual packets or connections.","Our approach is validated through experiments performed on publicly available data sets, from which it results that it can not only overcome some of the limitations of classical approaches, but also achieve a better detection capability of cyber threats."],"url":"http://arxiv.org/abs/2402.07878v1"}
{"created":"2024-02-12 18:41:55","title":"WildfireGPT: Tailored Large Language Model for Wildfire Analysis","abstract":"The recent advancement of large language models (LLMs) represents a transformational capability at the frontier of artificial intelligence (AI) and machine learning (ML). However, LLMs are generalized models, trained on extensive text corpus, and often struggle to provide context-specific information, particularly in areas requiring specialized knowledge such as wildfire details within the broader context of climate change. For decision-makers and policymakers focused on wildfire resilience and adaptation, it is crucial to obtain responses that are not only precise but also domain-specific, rather than generic. To that end, we developed WildfireGPT, a prototype LLM agent designed to transform user queries into actionable insights on wildfire risks. We enrich WildfireGPT by providing additional context such as climate projections and scientific literature to ensure its information is current, relevant, and scientifically accurate. This enables WildfireGPT to be an effective tool for delivering detailed, user-specific insights on wildfire risks to support a diverse set of end users, including researchers, engineers, urban planners, emergency managers, and infrastructure operators.","sentences":["The recent advancement of large language models (LLMs) represents a transformational capability at the frontier of artificial intelligence (AI) and machine learning (ML).","However, LLMs are generalized models, trained on extensive text corpus, and often struggle to provide context-specific information, particularly in areas requiring specialized knowledge such as wildfire details within the broader context of climate change.","For decision-makers and policymakers focused on wildfire resilience and adaptation, it is crucial to obtain responses that are not only precise but also domain-specific, rather than generic.","To that end, we developed WildfireGPT, a prototype LLM agent designed to transform user queries into actionable insights on wildfire risks.","We enrich WildfireGPT by providing additional context such as climate projections and scientific literature to ensure its information is current, relevant, and scientifically accurate.","This enables WildfireGPT to be an effective tool for delivering detailed, user-specific insights on wildfire risks to support a diverse set of end users, including researchers, engineers, urban planners, emergency managers, and infrastructure operators."],"url":"http://arxiv.org/abs/2402.07877v1"}
{"created":"2024-02-12 18:41:34","title":"Policy Improvement using Language Feedback Models","abstract":"We introduce Language Feedback Models (LFMs) that identify desirable behaviour - actions that help achieve tasks specified in the instruction - for imitation learning in instruction following. To train LFMs, we obtain feedback from Large Language Models (LLMs) on visual trajectories verbalized to language descriptions. First, by using LFMs to identify desirable behaviour to imitate, we improve in task-completion rate over strong behavioural cloning baselines on three distinct language grounding environments (Touchdown, ScienceWorld, and ALFWorld). Second, LFMs outperform using LLMs as experts to directly predict actions, when controlling for the number of LLM output tokens. Third, LFMs generalize to unseen environments, improving task-completion rate by 3.5-12.0% through one round of adaptation. Finally, LFM can be modified to provide human-interpretable feedback without performance loss, allowing human verification of desirable behaviour for imitation learning.","sentences":["We introduce Language Feedback Models (LFMs) that identify desirable behaviour - actions that help achieve tasks specified in the instruction - for imitation learning in instruction following.","To train LFMs, we obtain feedback from Large Language Models (LLMs) on visual trajectories verbalized to language descriptions.","First, by using LFMs to identify desirable behaviour to imitate, we improve in task-completion rate over strong behavioural cloning baselines on three distinct language grounding environments (Touchdown, ScienceWorld, and ALFWorld).","Second, LFMs outperform using LLMs as experts to directly predict actions, when controlling for the number of LLM output tokens.","Third, LFMs generalize to unseen environments, improving task-completion rate by 3.5-12.0% through one round of adaptation.","Finally, LFM can be modified to provide human-interpretable feedback without performance loss, allowing human verification of desirable behaviour for imitation learning."],"url":"http://arxiv.org/abs/2402.07876v1"}
{"created":"2024-02-12 18:41:31","title":"Implicit Bias of Policy Gradient in Linear Quadratic Control: Extrapolation to Unseen Initial States","abstract":"In modern machine learning, models can often fit training data in numerous ways, some of which perform well on unseen (test) data, while others do not. Remarkably, in such cases gradient descent frequently exhibits an implicit bias that leads to excellent performance on unseen data. This implicit bias was extensively studied in supervised learning, but is far less understood in optimal control (reinforcement learning). There, learning a controller applied to a system via gradient descent is known as policy gradient, and a question of prime importance is the extent to which a learned controller extrapolates to unseen initial states. This paper theoretically studies the implicit bias of policy gradient in terms of extrapolation to unseen initial states. Focusing on the fundamental Linear Quadratic Regulator (LQR) problem, we establish that the extent of extrapolation depends on the degree of exploration induced by the system when commencing from initial states included in training. Experiments corroborate our theory, and demonstrate its conclusions on problems beyond LQR, where systems are non-linear and controllers are neural networks. We hypothesize that real-world optimal control may be greatly improved by developing methods for informed selection of initial states to train on.","sentences":["In modern machine learning, models can often fit training data in numerous ways, some of which perform well on unseen (test) data, while others do not.","Remarkably, in such cases gradient descent frequently exhibits an implicit bias that leads to excellent performance on unseen data.","This implicit bias was extensively studied in supervised learning, but is far less understood in optimal control (reinforcement learning).","There, learning a controller applied to a system via gradient descent is known as policy gradient, and a question of prime importance is the extent to which a learned controller extrapolates to unseen initial states.","This paper theoretically studies the implicit bias of policy gradient in terms of extrapolation to unseen initial states.","Focusing on the fundamental Linear Quadratic Regulator (LQR) problem, we establish that the extent of extrapolation depends on the degree of exploration induced by the system when commencing from initial states included in training.","Experiments corroborate our theory, and demonstrate its conclusions on problems beyond LQR, where systems are non-linear and controllers are neural networks.","We hypothesize that real-world optimal control may be greatly improved by developing methods for informed selection of initial states to train on."],"url":"http://arxiv.org/abs/2402.07875v1"}
{"created":"2024-02-12 18:33:47","title":"Scaling Laws for Fine-Grained Mixture of Experts","abstract":"Mixture of Experts (MoE) models have emerged as a primary solution for reducing the computational cost of Large Language Models. In this work, we analyze their scaling properties, incorporating an expanded range of variables. Specifically, we introduce a new hyperparameter, granularity, whose adjustment enables precise control over the size of the experts. Building on this, we establish scaling laws for fine-grained MoE, taking into account the number of training tokens, model size, and granularity. Leveraging these laws, we derive the optimal training configuration for a given computational budget. Our findings not only show that MoE models consistently outperform dense Transformers but also highlight that the efficiency gap between dense and MoE models widens as we scale up the model size and training budget. Furthermore, we demonstrate that the common practice of setting the size of experts in MoE to mirror the feed-forward layer is not optimal at almost any computational budget.","sentences":["Mixture of Experts (MoE) models have emerged as a primary solution for reducing the computational cost of Large Language Models.","In this work, we analyze their scaling properties, incorporating an expanded range of variables.","Specifically, we introduce a new hyperparameter, granularity, whose adjustment enables precise control over the size of the experts.","Building on this, we establish scaling laws for fine-grained MoE, taking into account the number of training tokens, model size, and granularity.","Leveraging these laws, we derive the optimal training configuration for a given computational budget.","Our findings not only show that MoE models consistently outperform dense Transformers but also highlight that the efficiency gap between dense and MoE models widens as we scale up the model size and training budget.","Furthermore, we demonstrate that the common practice of setting the size of experts in MoE to mirror the feed-forward layer is not optimal at almost any computational budget."],"url":"http://arxiv.org/abs/2402.07871v1"}
{"created":"2024-02-12 18:33:47","title":"PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs","abstract":"Vision language models (VLMs) have shown impressive capabilities across a variety of tasks, from logical reasoning to visual understanding. This opens the door to richer interaction with the world, for example robotic control. However, VLMs produce only textual outputs, while robotic control and other spatial tasks require outputting continuous coordinates, actions, or trajectories. How can we enable VLMs to handle such settings without fine-tuning on task-specific data?   In this paper, we propose a novel visual prompting approach for VLMs that we call Prompting with Iterative Visual Optimization (PIVOT), which casts tasks as iterative visual question answering. In each iteration, the image is annotated with a visual representation of proposals that the VLM can refer to (e.g., candidate robot actions, localizations, or trajectories). The VLM then selects the best ones for the task. These proposals are iteratively refined, allowing the VLM to eventually zero in on the best available answer. We investigate PIVOT on real-world robotic navigation, real-world manipulation from images, instruction following in simulation, and additional spatial inference tasks such as localization. We find, perhaps surprisingly, that our approach enables zero-shot control of robotic systems without any robot training data, navigation in a variety of environments, and other capabilities. Although current performance is far from perfect, our work highlights potentials and limitations of this new regime and shows a promising approach for Internet-Scale VLMs in robotic and spatial reasoning domains. Website: pivot-prompt.github.io and HuggingFace: https://huggingface.co/spaces/pivot-prompt/pivot-prompt-demo.","sentences":["Vision language models (VLMs) have shown impressive capabilities across a variety of tasks, from logical reasoning to visual understanding.","This opens the door to richer interaction with the world, for example robotic control.","However, VLMs produce only textual outputs, while robotic control and other spatial tasks require outputting continuous coordinates, actions, or trajectories.","How can we enable VLMs to handle such settings without fine-tuning on task-specific data?   ","In this paper, we propose a novel visual prompting approach for VLMs that we call Prompting with Iterative Visual Optimization (PIVOT), which casts tasks as iterative visual question answering.","In each iteration, the image is annotated with a visual representation of proposals that the VLM can refer to (e.g., candidate robot actions, localizations, or trajectories).","The VLM then selects the best ones for the task.","These proposals are iteratively refined, allowing the VLM to eventually zero in on the best available answer.","We investigate PIVOT on real-world robotic navigation, real-world manipulation from images, instruction following in simulation, and additional spatial inference tasks such as localization.","We find, perhaps surprisingly, that our approach enables zero-shot control of robotic systems without any robot training data, navigation in a variety of environments, and other capabilities.","Although current performance is far from perfect, our work highlights potentials and limitations of this new regime and shows a promising approach for Internet-Scale VLMs in robotic and spatial reasoning domains.","Website: pivot-prompt.github.io and HuggingFace: https://huggingface.co/spaces/pivot-prompt/pivot-prompt-demo."],"url":"http://arxiv.org/abs/2402.07872v1"}
{"created":"2024-02-12 18:29:17","title":"Nesting Particle Filters for Experimental Design in Dynamical Systems","abstract":"In this paper, we propose a novel approach to Bayesian Experimental Design (BED) for non-exchangeable data that formulates it as risk-sensitive policy optimization. We develop the Inside-Out SMC^2 algorithm that uses a nested sequential Monte Carlo (SMC) estimator of the expected information gain and embeds it into a particle Markov chain Monte Carlo (pMCMC) framework to perform gradient-based policy optimization. This is in contrast to recent approaches that rely on biased estimators of the expected information gain (EIG) to amortize the cost of experiments by learning a design policy in advance. Numerical validation on a set of dynamical systems showcases the efficacy of our method in comparison to other state-of-the-art strategies.","sentences":["In this paper, we propose a novel approach to Bayesian Experimental Design (BED) for non-exchangeable data that formulates it as risk-sensitive policy optimization.","We develop the Inside-Out SMC^2 algorithm that uses a nested sequential Monte Carlo (SMC) estimator of the expected information gain and embeds it into a particle Markov chain Monte Carlo (pMCMC) framework to perform gradient-based policy optimization.","This is in contrast to recent approaches that rely on biased estimators of the expected information gain (EIG) to amortize the cost of experiments by learning a design policy in advance.","Numerical validation on a set of dynamical systems showcases the efficacy of our method in comparison to other state-of-the-art strategies."],"url":"http://arxiv.org/abs/2402.07868v1"}
{"created":"2024-02-12 18:28:36","title":"PoisonedRAG: Knowledge Poisoning Attacks to Retrieval-Augmented Generation of Large Language Models","abstract":"Large language models (LLMs) have achieved remarkable success due to their exceptional generative capabilities. Despite their success, they also have inherent limitations such as a lack of up-to-date knowledge and hallucination. Retrieval-Augmented Generation (RAG) is a state-of-the-art technique to mitigate those limitations. In particular, given a question, RAG retrieves relevant knowledge from a knowledge database to augment the input of the LLM. For instance, the retrieved knowledge could be a set of top-k texts that are most semantically similar to the given question when the knowledge database contains millions of texts collected from Wikipedia. As a result, the LLM could utilize the retrieved knowledge as the context to generate an answer for the given question. Existing studies mainly focus on improving the accuracy or efficiency of RAG, leaving its security largely unexplored. We aim to bridge the gap in this work. Particularly, we propose PoisonedRAG , a set of knowledge poisoning attacks to RAG, where an attacker could inject a few poisoned texts into the knowledge database such that the LLM generates an attacker-chosen target answer for an attacker-chosen target question. We formulate knowledge poisoning attacks as an optimization problem, whose solution is a set of poisoned texts. Depending on the background knowledge (e.g., black-box and white-box settings) of an attacker on the RAG, we propose two solutions to solve the optimization problem, respectively. Our results on multiple benchmark datasets and LLMs show our attacks could achieve 90% attack success rates when injecting 5 poisoned texts for each target question into a database with millions of texts. We also evaluate recent defenses and our results show they are insufficient to defend against our attacks, highlighting the need for new defenses.","sentences":["Large language models (LLMs) have achieved remarkable success due to their exceptional generative capabilities.","Despite their success, they also have inherent limitations such as a lack of up-to-date knowledge and hallucination.","Retrieval-Augmented Generation (RAG) is a state-of-the-art technique to mitigate those limitations.","In particular, given a question, RAG retrieves relevant knowledge from a knowledge database to augment the input of the LLM.","For instance, the retrieved knowledge could be a set of top-k texts that are most semantically similar to the given question when the knowledge database contains millions of texts collected from Wikipedia.","As a result, the LLM could utilize the retrieved knowledge as the context to generate an answer for the given question.","Existing studies mainly focus on improving the accuracy or efficiency of RAG, leaving its security largely unexplored.","We aim to bridge the gap in this work.","Particularly, we propose PoisonedRAG , a set of knowledge poisoning attacks to RAG, where an attacker could inject a few poisoned texts into the knowledge database such that the LLM generates an attacker-chosen target answer for an attacker-chosen target question.","We formulate knowledge poisoning attacks as an optimization problem, whose solution is a set of poisoned texts.","Depending on the background knowledge (e.g., black-box and white-box settings) of an attacker on the RAG, we propose two solutions to solve the optimization problem, respectively.","Our results on multiple benchmark datasets and LLMs show our attacks could achieve 90% attack success rates when injecting 5 poisoned texts for each target question into a database with millions of texts.","We also evaluate recent defenses and our results show they are insufficient to defend against our attacks, highlighting the need for new defenses."],"url":"http://arxiv.org/abs/2402.07867v1"}
{"created":"2024-02-12 18:21:14","title":"Prismatic VLMs: Investigating the Design Space of Visually-Conditioned Language Models","abstract":"Visually-conditioned language models (VLMs) have seen growing adoption in applications such as visual dialogue, scene understanding, and robotic task planning; adoption that has fueled a wealth of new models such as LLaVa, InstructBLIP, and PaLI-3. Despite the volume of new releases, key design decisions around image preprocessing, architecture, and optimization are under-explored, making it challenging to understand what factors account for model performance $-$ a challenge further complicated by the lack of objective, consistent evaluations. To address these gaps, we first compile a suite of standardized evaluations spanning visual question answering, object localization from language, and targeted challenge sets that probe properties such as hallucination; evaluations that provide calibrated, fine-grained insight into a VLM's capabilities. Second, we rigorously investigate VLMs along key design axes, including pretrained visual representations and quantifying the tradeoffs of using base vs. instruct-tuned language models, amongst others. We couple our analysis with three resource contributions: (1) a unified framework for evaluating VLMs, (2) optimized, flexible code for VLM training, and (3) checkpoints for all models, including a family of VLMs at the 7-13B scale that strictly outperform InstructBLIP and LLaVa v1.5, the state-of-the-art in open-source VLMs.","sentences":["Visually-conditioned language models (VLMs) have seen growing adoption in applications such as visual dialogue, scene understanding, and robotic task planning; adoption that has fueled a wealth of new models such as LLaVa, InstructBLIP, and PaLI-3.","Despite the volume of new releases, key design decisions around image preprocessing, architecture, and optimization are under-explored, making it challenging to understand what factors account for model performance $-$ a challenge further complicated by the lack of objective, consistent evaluations.","To address these gaps, we first compile a suite of standardized evaluations spanning visual question answering, object localization from language, and targeted challenge sets that probe properties such as hallucination; evaluations that provide calibrated, fine-grained insight into a VLM's capabilities.","Second, we rigorously investigate VLMs along key design axes, including pretrained visual representations and quantifying the tradeoffs of using base vs. instruct-tuned language models, amongst others.","We couple our analysis with three resource contributions: (1) a unified framework for evaluating VLMs, (2) optimized, flexible code for VLM training, and (3) checkpoints for all models, including a family of VLMs at the 7-13B scale that strictly outperform InstructBLIP and LLaVa v1.5, the state-of-the-art in open-source VLMs."],"url":"http://arxiv.org/abs/2402.07865v1"}
{"created":"2024-02-12 18:20:07","title":"Cruising Queer HCI on the DL: A Literature Review of LGBTQ+ People in HCI","abstract":"LGBTQ+ people have received increased attention in HCI research, paralleling a greater emphasis on social justice in recent years. However, there has not been a systematic review of how LGBTQ+ people are researched or discussed in HCI. In this work, we review all research mentioning LGBTQ+ people across the HCI venues of CHI, CSCW, DIS, and TOCHI. Since 2014, we find a linear growth in the number of papers substantially about LGBTQ+ people and an exponential increase in the number of mentions. Research about LGBTQ+ people tends to center experiences of being politicized, outside the norm, stigmatized, or highly vulnerable. LGBTQ+ people are typically mentioned as a marginalized group or an area of future research. We identify gaps and opportunities for (1) research about and (2) the discussion of LGBTQ+ in HCI and provide a dataset to facilitate future Queer HCI research.","sentences":["LGBTQ+ people have received increased attention in HCI research, paralleling a greater emphasis on social justice in recent years.","However, there has not been a systematic review of how LGBTQ+ people are researched or discussed in HCI.","In this work, we review all research mentioning LGBTQ+ people across the HCI venues of CHI, CSCW, DIS, and TOCHI.","Since 2014, we find a linear growth in the number of papers substantially about LGBTQ+ people and an exponential increase in the number of mentions.","Research about LGBTQ+ people tends to center experiences of being politicized, outside the norm, stigmatized, or highly vulnerable.","LGBTQ+","people are typically mentioned as a marginalized group or an area of future research.","We identify gaps and opportunities for (1) research about and (2) the discussion of LGBTQ+ in HCI and provide a dataset to facilitate future Queer HCI research."],"url":"http://arxiv.org/abs/2402.07864v1"}
{"created":"2024-02-12 18:17:01","title":"An approximation algorithm for Maximum DiCut vs. Cut","abstract":"Goemans and Williamson designed a 0.878-approximation algorithm for Max-Cut in undirected graphs [JACM'95]. Khot, Kindler, Mosel, and O'Donnel showed that the approximation ratio of the Goemans-Williamson algorithm is optimal assuming Khot's Unique Games Conjecture [SICOMP'07]. In the problem of maximum cuts in directed graphs (Max-DiCut), in which we seek as many edges going from one particular side of the cut to the other, the situation is more complicated but the recent work of Brakensiek, Huang, Potechin, and Zwick showed that their 0.874-approximation algorithm is tight under the Unique Games Conjecture (up to a small delta)[FOCS'23].   We consider a promise version of the problem and design an SDP-based algorithm which, if given a directed graph G that has a directed cut of value rho, finds an undirected cut in G (ignoring edge directions) with value at least \\rho.","sentences":["Goemans and Williamson designed a 0.878-approximation algorithm for Max-Cut in undirected graphs [JACM'95].","Khot, Kindler, Mosel, and O'Donnel showed that the approximation ratio of the Goemans-Williamson algorithm is optimal assuming","Khot's Unique Games Conjecture","[SICOMP'07].","In the problem of maximum cuts in directed graphs (Max-DiCut), in which we seek as many edges going from one particular side of the cut to the other, the situation is more complicated but the recent work of Brakensiek, Huang, Potechin, and Zwick showed that their 0.874-approximation algorithm is tight under the Unique Games Conjecture (up to a small delta)[FOCS'23].   ","We consider a promise version of the problem and design an SDP-based algorithm which, if given a directed graph G that has a directed cut of value rho, finds an undirected cut in G (ignoring edge directions) with value at least \\rho."],"url":"http://arxiv.org/abs/2402.07863v1"}
{"created":"2024-02-12 18:14:43","title":"AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy","abstract":"Large language models (LLMs) show impressive capabilities, matching and sometimes exceeding human performance in many domains. This study explores the potential of LLMs to augment judgement in forecasting tasks. We evaluated the impact on forecasting accuracy of two GPT-4-Turbo assistants: one designed to provide high-quality advice ('superforecasting'), and the other designed to be overconfident and base-rate-neglecting. Participants (N = 991) had the option to consult their assigned LLM assistant throughout the study, in contrast to a control group that used a less advanced model (DaVinci-003) without direct forecasting support. Our preregistered analyses reveal that LLM augmentation significantly enhances forecasting accuracy by 23% across both types of assistants, compared to the control group. This improvement occurs despite the superforecasting assistant's higher accuracy in predictions, indicating the augmentation's benefit is not solely due to model prediction accuracy. Exploratory analyses showed a pronounced effect in one forecasting item, without which we find that the superforecasting assistant increased accuracy by 43%, compared with 28% for the biased assistant. We further examine whether LLM augmentation disproportionately benefits less skilled forecasters, degrades the wisdom-of-the-crowd by reducing prediction diversity, or varies in effectiveness with question difficulty. Our findings do not consistently support these hypotheses. Our results suggest that access to an LLM assistant, even a biased one, can be a helpful decision aid in cognitively demanding tasks where the answer is not known at the time of interaction.","sentences":["Large language models (LLMs) show impressive capabilities, matching and sometimes exceeding human performance in many domains.","This study explores the potential of LLMs to augment judgement in forecasting tasks.","We evaluated the impact on forecasting accuracy of two GPT-4-Turbo assistants: one designed to provide high-quality advice ('superforecasting'), and the other designed to be overconfident and base-rate-neglecting.","Participants (N = 991) had the option to consult their assigned LLM assistant throughout the study, in contrast to a control group that used a less advanced model (DaVinci-003) without direct forecasting support.","Our preregistered analyses reveal that LLM augmentation significantly enhances forecasting accuracy by 23% across both types of assistants, compared to the control group.","This improvement occurs despite the superforecasting assistant's higher accuracy in predictions, indicating the augmentation's benefit is not solely due to model prediction accuracy.","Exploratory analyses showed a pronounced effect in one forecasting item, without which we find that the superforecasting assistant increased accuracy by 43%, compared with 28% for the biased assistant.","We further examine whether LLM augmentation disproportionately benefits less skilled forecasters, degrades the wisdom-of-the-crowd by reducing prediction diversity, or varies in effectiveness with question difficulty.","Our findings do not consistently support these hypotheses.","Our results suggest that access to an LLM assistant, even a biased one, can be a helpful decision aid in cognitively demanding tasks where the answer is not known at the time of interaction."],"url":"http://arxiv.org/abs/2402.07862v1"}
{"created":"2024-02-12 18:12:09","title":"On the Detection of Reviewer-Author Collusion Rings From Paper Bidding","abstract":"A major threat to the peer-review systems of computer science conferences is the existence of \"collusion rings\" between reviewers. In such collusion rings, reviewers who have also submitted their own papers to the conference work together to manipulate the conference's paper assignment, with the aim of being assigned to review each other's papers. The most straightforward way that colluding reviewers can manipulate the paper assignment is by indicating their interest in each other's papers through strategic paper bidding. One potential approach to solve this important problem would be to detect the colluding reviewers from their manipulated bids, after which the conference can take appropriate action. While prior work has has developed effective techniques to detect other kinds of fraud, no research has yet established that detecting collusion rings is even possible. In this work, we tackle the question of whether it is feasible to detect collusion rings from the paper bidding. To answer this question, we conduct empirical analysis of two realistic conference bidding datasets, including evaluations of existing algorithms for fraud detection in other applications. We find that collusion rings can achieve considerable success at manipulating the paper assignment while remaining hidden from detection: for example, in one dataset, undetected colluders are able to achieve assignment to up to 30% of the papers authored by other colluders. In addition, when 10 colluders bid on all of each other's papers, no detection algorithm outputs a group of reviewers with more than 31% overlap with the true colluders. These results suggest that collusion cannot be effectively detected from the bidding, demonstrating the need to develop more complex detection algorithms that leverage additional metadata.","sentences":["A major threat to the peer-review systems of computer science conferences is the existence of \"collusion rings\" between reviewers.","In such collusion rings, reviewers who have also submitted their own papers to the conference work together to manipulate the conference's paper assignment, with the aim of being assigned to review each other's papers.","The most straightforward way that colluding reviewers can manipulate the paper assignment is by indicating their interest in each other's papers through strategic paper bidding.","One potential approach to solve this important problem would be to detect the colluding reviewers from their manipulated bids, after which the conference can take appropriate action.","While prior work has has developed effective techniques to detect other kinds of fraud, no research has yet established that detecting collusion rings is even possible.","In this work, we tackle the question of whether it is feasible to detect collusion rings from the paper bidding.","To answer this question, we conduct empirical analysis of two realistic conference bidding datasets, including evaluations of existing algorithms for fraud detection in other applications.","We find that collusion rings can achieve considerable success at manipulating the paper assignment while remaining hidden from detection: for example, in one dataset, undetected colluders are able to achieve assignment to up to 30% of the papers authored by other colluders.","In addition, when 10 colluders bid on all of each other's papers, no detection algorithm outputs a group of reviewers with more than 31% overlap with the true colluders.","These results suggest that collusion cannot be effectively detected from the bidding, demonstrating the need to develop more complex detection algorithms that leverage additional metadata."],"url":"http://arxiv.org/abs/2402.07860v1"}
{"created":"2024-02-12 18:10:17","title":"Lissard: Long and Simple Sequential Reasoning Datasets","abstract":"Language models are now capable of solving tasks that require dealing with long sequences consisting of hundreds of thousands of tokens. However, they often fail on tasks that require repetitive use of simple rules, even on sequences that are much shorter than those seen during training. For example, state-of-the-art LLMs can find common items in two lists with up to 20 items but fail when lists have 80 items. In this paper, we introduce Lissard, a benchmark comprising seven tasks whose goal is to assess the ability of models to process and generate wide-range sequence lengths, requiring repetitive procedural execution. Our evaluation of open-source (Mistral-7B and Mixtral-8x7B) and proprietary models (GPT-3.5 and GPT-4) show a consistent decline in performance across all models as the complexity of the sequence increases. The datasets and code are available at https://github.com/unicamp-dl/Lissard","sentences":["Language models are now capable of solving tasks that require dealing with long sequences consisting of hundreds of thousands of tokens.","However, they often fail on tasks that require repetitive use of simple rules, even on sequences that are much shorter than those seen during training.","For example, state-of-the-art LLMs can find common items in two lists with up to 20 items but fail when lists have 80 items.","In this paper, we introduce Lissard, a benchmark comprising seven tasks whose goal is to assess the ability of models to process and generate wide-range sequence lengths, requiring repetitive procedural execution.","Our evaluation of open-source (Mistral-7B and Mixtral-8x7B) and proprietary models (GPT-3.5 and GPT-4) show a consistent decline in performance across all models as the complexity of the sequence increases.","The datasets and code are available at https://github.com/unicamp-dl/Lissard"],"url":"http://arxiv.org/abs/2402.07859v1"}
{"created":"2024-02-12 18:05:03","title":"Multiscale Neuroimaging Features for the Identification of Medication Class and Non-Responders in Mood Disorder Treatment","abstract":"In the clinical treatment of mood disorders, the complex behavioral symptoms presented by patients and variability of patient response to particular medication classes can create difficulties in providing fast and reliable treatment when standard diagnostic and prescription methods are used. Increasingly, the incorporation of physiological information such as neuroimaging scans and derivatives into the clinical process promises to alleviate some of the uncertainty surrounding this process. Particularly, if neural features can help to identify patients who may not respond to standard courses of anti-depressants or mood stabilizers, clinicians may elect to avoid lengthy and side-effect-laden treatments and seek out a different, more effective course that might otherwise not have been under consideration. Previously, approaches for the derivation of relevant neuroimaging features work at only one scale in the data, potentially limiting the depth of information available for clinical decision support. In this work, we show that the utilization of multi spatial scale neuroimaging features - particularly resting state functional networks and functional network connectivity measures - provide a rich and robust basis for the identification of relevant medication class and non-responders in the treatment of mood disorders. We demonstrate that the generated features, along with a novel approach for fast and automated feature selection, can support high accuracy rates in the identification of medication class and non-responders as well as the identification of novel, multi-scale biomarkers.","sentences":["In the clinical treatment of mood disorders, the complex behavioral symptoms presented by patients and variability of patient response to particular medication classes can create difficulties in providing fast and reliable treatment when standard diagnostic and prescription methods are used.","Increasingly, the incorporation of physiological information such as neuroimaging scans and derivatives into the clinical process promises to alleviate some of the uncertainty surrounding this process.","Particularly, if neural features can help to identify patients who may not respond to standard courses of anti-depressants or mood stabilizers, clinicians may elect to avoid lengthy and side-effect-laden treatments and seek out a different, more effective course that might otherwise not have been under consideration.","Previously, approaches for the derivation of relevant neuroimaging features work at only one scale in the data, potentially limiting the depth of information available for clinical decision support.","In this work, we show that the utilization of multi spatial scale neuroimaging features - particularly resting state functional networks and functional network connectivity measures - provide a rich and robust basis for the identification of relevant medication class and non-responders in the treatment of mood disorders.","We demonstrate that the generated features, along with a novel approach for fast and automated feature selection, can support high accuracy rates in the identification of medication class and non-responders as well as the identification of novel, multi-scale biomarkers."],"url":"http://arxiv.org/abs/2402.07858v1"}
{"created":"2024-02-12 17:59:26","title":"The Complexity of Algebraic Algorithms for LWE","abstract":"Arora & Ge introduced a noise-free polynomial system to compute the secret of a Learning With Errors (LWE) instance via linearization. Albrecht et al. later utilized the Arora-Ge polynomial model to study the complexity of Gr\\\"obner basis computations on LWE polynomial systems under the assumption of semi-regularity. In this paper we revisit the Arora-Ge polynomial and prove that it satisfies a genericity condition recently introduced by Caminata & Gorla, called being in generic coordinates. For polynomial systems in generic coordinates one can always estimate the complexity of DRL Gr\\\"obner basis computations in terms of the Castelnuovo-Mumford regularity and henceforth also via the Macaulay bound.   Moreover, we generalize the Gr\\\"obner basis algorithm of Semaev & Tenti to arbitrary polynomial systems with a finite degree of regularity. In particular, existence of this algorithm yields another approach to estimate the complexity of DRL Gr\\\"obner basis computations in terms of the degree of regularity. In practice, the degree of regularity of LWE polynomial systems is not known, though one can always estimate the lowest achievable degree of regularity. Consequently, from a designer's worst case perspective this approach yields sub-exponential complexity estimates for general, binary secret, and binary error LWE.   In recent works by Dachman-Soled et al. the hardness of LWE in the presence of side information was analyzed. Utilizing their framework we discuss how hints can be incorporated into LWE polynomial systems and how they affect the complexity of Gr\\\"obner basis computations.","sentences":["Arora & Ge introduced a noise-free polynomial system to compute the secret of a Learning With Errors (LWE) instance via linearization.","Albrecht et al. later utilized the Arora-Ge polynomial model to study the complexity of Gr\\\"obner basis computations on LWE polynomial systems under the assumption of semi-regularity.","In this paper we revisit the Arora-Ge polynomial and prove that it satisfies a genericity condition recently introduced by Caminata & Gorla, called being in generic coordinates.","For polynomial systems in generic coordinates one can always estimate the complexity of DRL Gr\\\"obner basis computations in terms of the Castelnuovo-Mumford regularity and henceforth also via the Macaulay bound.   ","Moreover, we generalize the Gr\\\"obner basis algorithm of Semaev & Tenti to arbitrary polynomial systems with a finite degree of regularity.","In particular, existence of this algorithm yields another approach to estimate the complexity of DRL Gr\\\"obner basis computations in terms of the degree of regularity.","In practice, the degree of regularity of LWE polynomial systems is not known, though one can always estimate the lowest achievable degree of regularity.","Consequently, from a designer's worst case perspective this approach yields sub-exponential complexity estimates for general, binary secret, and binary error LWE.   ","In recent works by Dachman-Soled et al.","the hardness of LWE in the presence of side information was analyzed.","Utilizing their framework we discuss how hints can be incorporated into LWE polynomial systems and how they affect the complexity of Gr\\\"obner basis computations."],"url":"http://arxiv.org/abs/2402.07852v1"}
{"created":"2024-02-12 17:59:20","title":"Comparing skill of historical rainfall data based monsoon rainfall prediction in India with NCEP-NWP forecasts","abstract":"In this draft we consider the problem of forecasting rainfall across India during the four monsoon months, one day as well as three days in advance. We train neural networks using historical daily gridded precipitation data for India obtained from IMD for the time period $1901- 2022$, at a spatial resolution of $1^{\\circ} \\times 1^{\\circ}$. This is compared with the numerical weather prediction (NWP) forecasts obtained from NCEP (National Centre for Environmental Prediction) available for the period 2011-2022. We conduct a detailed country wide analysis and separately analyze some of the most populated cities in India. Our conclusion is that forecasts obtained by applying deep learning to historical rainfall data are more accurate compared to NWP forecasts as well as predictions based on persistence. On average, compared to our predictions, forecasts from NCEP-NWP model have about 34% higher error for a single day prediction, and over 68% higher error for a three day prediction. Similarly, persistence estimates report a 29% higher error in a single day forecast, and over 54% error in a three day forecast. We further observe that data up to 20 days in the past is useful in reducing errors of one and three day forecasts, when a transformer based learning architecture, and to a lesser extent when an LSTM is used. A key conclusion suggested by our preliminary analysis is that NWP forecasts can be substantially improved upon through more and diverse data relevant to monsoon prediction combined with carefully selected neural network architecture.","sentences":["In this draft we consider the problem of forecasting rainfall across India during the four monsoon months, one day as well as three days in advance.","We train neural networks using historical daily gridded precipitation data for India obtained from IMD for the time period $1901- 2022$, at a spatial resolution of $1^{\\circ} \\times 1^{\\circ}$.","This is compared with the numerical weather prediction (NWP) forecasts obtained from NCEP (National Centre for Environmental Prediction) available for the period 2011-2022.","We conduct a detailed country wide analysis and separately analyze some of the most populated cities in India.","Our conclusion is that forecasts obtained by applying deep learning to historical rainfall data are more accurate compared to NWP forecasts as well as predictions based on persistence.","On average, compared to our predictions, forecasts from NCEP-NWP model have about 34% higher error for a single day prediction, and over 68% higher error for a three day prediction.","Similarly, persistence estimates report a 29% higher error in a single day forecast, and over 54% error in a three day forecast.","We further observe that data up to 20 days in the past is useful in reducing errors of one and three day forecasts, when a transformer based learning architecture, and to a lesser extent when an LSTM is used.","A key conclusion suggested by our preliminary analysis is that NWP forecasts can be substantially improved upon through more and diverse data relevant to monsoon prediction combined with carefully selected neural network architecture."],"url":"http://arxiv.org/abs/2402.07851v1"}
{"created":"2024-02-12 17:56:52","title":"Generative Modeling of Discrete Joint Distributions by E-Geodesic Flow Matching on Assignment Manifolds","abstract":"This paper introduces a novel generative model for discrete distributions based on continuous normalizing flows on the submanifold of factorizing discrete measures. Integration of the flow gradually assigns categories and avoids issues of discretizing the latent continuous model like rounding, sample truncation etc. General non-factorizing discrete distributions capable of representing complex statistical dependencies of structured discrete data, can be approximated by embedding the submanifold into a the meta-simplex of all joint discrete distributions and data-driven averaging. Efficient training of the generative model is demonstrated by matching the flow of geodesics of factorizing discrete distributions. Various experiments underline the approach's broad applicability.","sentences":["This paper introduces a novel generative model for discrete distributions based on continuous normalizing flows on the submanifold of factorizing discrete measures.","Integration of the flow gradually assigns categories and avoids issues of discretizing the latent continuous model like rounding, sample truncation etc.","General non-factorizing discrete distributions capable of representing complex statistical dependencies of structured discrete data, can be approximated by embedding the submanifold into a the meta-simplex of all joint discrete distributions and data-driven averaging.","Efficient training of the generative model is demonstrated by matching the flow of geodesics of factorizing discrete distributions.","Various experiments underline the approach's broad applicability."],"url":"http://arxiv.org/abs/2402.07846v1"}
{"created":"2024-02-12 17:53:43","title":"An Investigation into Using Unsupervised Metrics to Optimise GNNs for Node Clustering","abstract":"Graph Neural Networks (GNNs) can be trained to detect communities within a graph by learning from the duality of feature and connectivity information. Currently, the common approach for optimisation of GNNs is to use comparisons to ground-truth for hyperparameter tuning and model selection. In this work, we show that nodes can be clustered into communities with GNNs by solely optimising for modularity, without any comparison to ground-truth. Although modularity is a graph partitioning quality metric, we show that this can be used to optimise GNNs that also encode features without a drop in performance. We take it a step further and also study whether the unsupervised metric performance can predict ground-truth performance. To investigate why modularity can be used to optimise GNNs, we design synthetic experiments that show the limitations of this approach. The synthetic graphs are created to highlight current capabilities in distinct, random and zero information space partitions in attributed graphs. We conclude that modularity can be used for hyperparameter optimisation and model selection on real-world datasets as well as being a suitable proxy for predicting ground-truth performance, however, GNNs fail to balance the information duality when the spaces contain conflicting signals.","sentences":["Graph Neural Networks (GNNs) can be trained to detect communities within a graph by learning from the duality of feature and connectivity information.","Currently, the common approach for optimisation of GNNs is to use comparisons to ground-truth for hyperparameter tuning and model selection.","In this work, we show that nodes can be clustered into communities with GNNs by solely optimising for modularity, without any comparison to ground-truth.","Although modularity is a graph partitioning quality metric, we show that this can be used to optimise GNNs that also encode features without a drop in performance.","We take it a step further and also study whether the unsupervised metric performance can predict ground-truth performance.","To investigate why modularity can be used to optimise GNNs, we design synthetic experiments that show the limitations of this approach.","The synthetic graphs are created to highlight current capabilities in distinct, random and zero information space partitions in attributed graphs.","We conclude that modularity can be used for hyperparameter optimisation and model selection on real-world datasets as well as being a suitable proxy for predicting ground-truth performance, however, GNNs fail to balance the information duality when the spaces contain conflicting signals."],"url":"http://arxiv.org/abs/2402.07845v1"}
{"created":"2024-02-12 17:53:22","title":"Mercury: An Efficiency Benchmark for LLM Code Synthesis","abstract":"Despite advancements in evaluating Large Language Models (LLMs) for code synthesis, benchmarks have predominantly focused on functional correctness, overlooking the importance of code efficiency. We present Mercury, the first benchmark designated for assessing the code efficiency of LLM code synthesis tasks. Mercury consists of 1,889 programming tasks covering diverse difficulty levels alongside test case generators generating unlimited cases for comprehensive evaluation. Unlike existing benchmarks, Mercury integrates a novel metric Beyond@K to measure normalized code efficiency based on historical submissions, leading to a new evaluation indicator for code synthesis, which encourages generating functionally correct and computationally efficient code, mirroring the real-world software development standard. Our findings reveal that while LLMs demonstrate the remarkable capability to generate functionally correct code, there still exists a substantial gap in their efficiency output, underscoring a new frontier for LLM research and development.","sentences":["Despite advancements in evaluating Large Language Models (LLMs) for code synthesis, benchmarks have predominantly focused on functional correctness, overlooking the importance of code efficiency.","We present Mercury, the first benchmark designated for assessing the code efficiency of LLM code synthesis tasks.","Mercury consists of 1,889 programming tasks covering diverse difficulty levels alongside test case generators generating unlimited cases for comprehensive evaluation.","Unlike existing benchmarks, Mercury integrates a novel metric Beyond@K to measure normalized code efficiency based on historical submissions, leading to a new evaluation indicator for code synthesis, which encourages generating functionally correct and computationally efficient code, mirroring the real-world software development standard.","Our findings reveal that while LLMs demonstrate the remarkable capability to generate functionally correct code, there still exists a substantial gap in their efficiency output, underscoring a new frontier for LLM research and development."],"url":"http://arxiv.org/abs/2402.07844v1"}
{"created":"2024-02-12 17:52:05","title":"Do Membership Inference Attacks Work on Large Language Models?","abstract":"Membership inference attacks (MIAs) attempt to predict whether a particular datapoint is a member of a target model's training data. Despite extensive research on traditional machine learning models, there has been limited work studying MIA on the pre-training data of large language models (LLMs). We perform a large-scale evaluation of MIAs over a suite of language models (LMs) trained on the Pile, ranging from 160M to 12B parameters. We find that MIAs barely outperform random guessing for most settings across varying LLM sizes and domains. Our further analyses reveal that this poor performance can be attributed to (1) the combination of a large dataset and few training iterations, and (2) an inherently fuzzy boundary between members and non-members. We identify specific settings where LLMs have been shown to be vulnerable to membership inference and show that the apparent success in such settings can be attributed to a distribution shift, such as when members and non-members are drawn from the seemingly identical domain but with different temporal ranges. We release our code and data as a unified benchmark package that includes all existing MIAs, supporting future work.","sentences":["Membership inference attacks (MIAs) attempt to predict whether a particular datapoint is a member of a target model's training data.","Despite extensive research on traditional machine learning models, there has been limited work studying MIA on the pre-training data of large language models (LLMs).","We perform a large-scale evaluation of MIAs over a suite of language models (LMs) trained on the Pile, ranging from 160M to 12B parameters.","We find that MIAs barely outperform random guessing for most settings across varying LLM sizes and domains.","Our further analyses reveal that this poor performance can be attributed to (1) the combination of a large dataset and few training iterations, and (2) an inherently fuzzy boundary between members and non-members.","We identify specific settings where LLMs have been shown to be vulnerable to membership inference and show that the apparent success in such settings can be attributed to a distribution shift, such as when members and non-members are drawn from the seemingly identical domain but with different temporal ranges.","We release our code and data as a unified benchmark package that includes all existing MIAs, supporting future work."],"url":"http://arxiv.org/abs/2402.07841v1"}
{"created":"2024-02-12 17:50:56","title":"Towards Meta-Pruning via Optimal Transport","abstract":"Structural pruning of neural networks conventionally relies on identifying and discarding less important neurons, a practice often resulting in significant accuracy loss that necessitates subsequent fine-tuning efforts. This paper introduces a novel approach named Intra-Fusion, challenging this prevailing pruning paradigm. Unlike existing methods that focus on designing meaningful neuron importance metrics, Intra-Fusion redefines the overlying pruning procedure. Through utilizing the concepts of model fusion and Optimal Transport, we leverage an agnostically given importance metric to arrive at a more effective sparse model representation. Notably, our approach achieves substantial accuracy recovery without the need for resource-intensive fine-tuning, making it an efficient and promising tool for neural network compression.   Additionally, we explore how fusion can be added to the pruning process to significantly decrease the training time while maintaining competitive performance. We benchmark our results for various networks on commonly used datasets such as CIFAR-10, CIFAR-100, and ImageNet. More broadly, we hope that the proposed Intra-Fusion approach invigorates exploration into a fresh alternative to the predominant compression approaches. Our code is available here: https://github.com/alexandertheus/Intra-Fusion.","sentences":["Structural pruning of neural networks conventionally relies on identifying and discarding less important neurons, a practice often resulting in significant accuracy loss that necessitates subsequent fine-tuning efforts.","This paper introduces a novel approach named Intra-Fusion, challenging this prevailing pruning paradigm.","Unlike existing methods that focus on designing meaningful neuron importance metrics, Intra-Fusion redefines the overlying pruning procedure.","Through utilizing the concepts of model fusion and Optimal Transport, we leverage an agnostically given importance metric to arrive at a more effective sparse model representation.","Notably, our approach achieves substantial accuracy recovery without the need for resource-intensive fine-tuning, making it an efficient and promising tool for neural network compression.   ","Additionally, we explore how fusion can be added to the pruning process to significantly decrease the training time while maintaining competitive performance.","We benchmark our results for various networks on commonly used datasets such as CIFAR-10, CIFAR-100, and ImageNet.","More broadly, we hope that the proposed Intra-Fusion approach invigorates exploration into a fresh alternative to the predominant compression approaches.","Our code is available here: https://github.com/alexandertheus/Intra-Fusion."],"url":"http://arxiv.org/abs/2402.07839v1"}
{"created":"2024-02-12 17:45:40","title":"Generalizing across Temporal Domains with Koopman Operators","abstract":"In the field of domain generalization, the task of constructing a predictive model capable of generalizing to a target domain without access to target data remains challenging. This problem becomes further complicated when considering evolving dynamics between domains. While various approaches have been proposed to address this issue, a comprehensive understanding of the underlying generalization theory is still lacking. In this study, we contribute novel theoretic results that aligning conditional distribution leads to the reduction of generalization bounds. Our analysis serves as a key motivation for solving the Temporal Domain Generalization (TDG) problem through the application of Koopman Neural Operators, resulting in Temporal Koopman Networks (TKNets). By employing Koopman Operators, we effectively address the time-evolving distributions encountered in TDG using the principles of Koopman theory, where measurement functions are sought to establish linear transition relations between evolving domains. Through empirical evaluations conducted on synthetic and real-world datasets, we validate the effectiveness of our proposed approach.","sentences":["In the field of domain generalization, the task of constructing a predictive model capable of generalizing to a target domain without access to target data remains challenging.","This problem becomes further complicated when considering evolving dynamics between domains.","While various approaches have been proposed to address this issue, a comprehensive understanding of the underlying generalization theory is still lacking.","In this study, we contribute novel theoretic results that aligning conditional distribution leads to the reduction of generalization bounds.","Our analysis serves as a key motivation for solving the Temporal Domain Generalization (TDG) problem through the application of Koopman Neural Operators, resulting in Temporal Koopman Networks (TKNets).","By employing Koopman Operators, we effectively address the time-evolving distributions encountered in TDG using the principles of Koopman theory, where measurement functions are sought to establish linear transition relations between evolving domains.","Through empirical evaluations conducted on synthetic and real-world datasets, we validate the effectiveness of our proposed approach."],"url":"http://arxiv.org/abs/2402.07834v1"}
{"created":"2024-02-12 17:43:02","title":"Best Practices for Facing the Security Challenges of Internet of Things Devices Focusing on Software Development Life Cycle","abstract":"In the past few years, the number of IoT devices has grown substantially, and this trend is likely to continue. An increasing amount of effort is being put into developing software for the ever-increasing IoT devices. Every IoT system at its core has software that enables the devices to function efficiently. But security has always been a concern in this age of information and technology. Security for IoT devices is now a top priority due to the growing number of threats. This study introduces best practices for ensuring security in the IoT, with an emphasis on guidelines to be utilized in software development for IoT devices. The objective of the study is to raise awareness of potential threats, emphasizing the secure software development lifecycle. The study will also serve as a point of reference for future developments and provide a solid foundation for securing IoT software and dealing with vulnerabilities.","sentences":["In the past few years, the number of IoT devices has grown substantially, and this trend is likely to continue.","An increasing amount of effort is being put into developing software for the ever-increasing IoT devices.","Every IoT system at its core has software that enables the devices to function efficiently.","But security has always been a concern in this age of information and technology.","Security for IoT devices is now a top priority due to the growing number of threats.","This study introduces best practices for ensuring security in the IoT, with an emphasis on guidelines to be utilized in software development for IoT devices.","The objective of the study is to raise awareness of potential threats, emphasizing the secure software development lifecycle.","The study will also serve as a point of reference for future developments and provide a solid foundation for securing IoT software and dealing with vulnerabilities."],"url":"http://arxiv.org/abs/2402.07832v1"}
{"created":"2024-02-12 17:34:13","title":"Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model","abstract":"Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50% are considered as lower-resourced. Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages. We introduce extensive new evaluation suites that broaden the state-of-art for multilingual eval across 99 languages -- including discriminative and generative tasks, human evaluation, and simulated win rates that cover both held-out tasks and in-distribution performance. Furthermore, we conduct detailed investigations on the optimal finetuning mixture composition, data pruning, as well as the toxicity, bias, and safety of our models. We open-source our instruction datasets and our model at https://hf.co/CohereForAI/aya-101","sentences":["Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages.","What does it take to broaden access to breakthroughs beyond first-class citizen languages?","Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50% are considered as lower-resourced.","Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages.","We introduce extensive new evaluation suites that broaden the state-of-art for multilingual eval across 99 languages -- including discriminative and generative tasks, human evaluation, and simulated win rates that cover both held-out tasks and in-distribution performance.","Furthermore, we conduct detailed investigations on the optimal finetuning mixture composition, data pruning, as well as the toxicity, bias, and safety of our models.","We open-source our instruction datasets and our model at https://hf.co/CohereForAI/aya-101"],"url":"http://arxiv.org/abs/2402.07827v1"}
{"created":"2024-02-12 17:26:35","title":"Understanding fitness landscapes in morpho-evolution via local optima networks","abstract":"Morpho-evolution (ME) refers to the simultaneous optimisation of a robot's design and controller to maximise performance given a task and environment. Many genetic encodings have been proposed which are capable of representing design and control. Previous research has provided empirical comparisons between encodings in terms of their performance with respect to an objective function and the diversity of designs that are evaluated, however there has been no attempt to explain the observed findings. We address this by applying Local Optima Network (LON) analysis to investigate the structure of the fitness landscapes induced by three different encodings when evolving a robot for a locomotion task, shedding new light on the ease by which different fitness landscapes can be traversed by a search process. This is the first time LON analysis has been applied in the field of ME despite its popularity in combinatorial optimisation domains; the findings will facilitate design of new algorithms or operators that are customised to ME landscapes in the future.","sentences":["Morpho-evolution (ME) refers to the simultaneous optimisation of a robot's design and controller to maximise performance given a task and environment.","Many genetic encodings have been proposed which are capable of representing design and control.","Previous research has provided empirical comparisons between encodings in terms of their performance with respect to an objective function and the diversity of designs that are evaluated, however there has been no attempt to explain the observed findings.","We address this by applying Local Optima Network (LON) analysis to investigate the structure of the fitness landscapes induced by three different encodings when evolving a robot for a locomotion task, shedding new light on the ease by which different fitness landscapes can be traversed by a search process.","This is the first time LON analysis has been applied in the field of ME despite its popularity in combinatorial optimisation domains; the findings will facilitate design of new algorithms or operators that are customised to ME landscapes in the future."],"url":"http://arxiv.org/abs/2402.07822v1"}
{"created":"2024-02-12 17:25:23","title":"On Computationally Efficient Multi-Class Calibration","abstract":"Consider a multi-class labelling problem, where the labels can take values in $[k]$, and a predictor predicts a distribution over the labels. In this work, we study the following foundational question: Are there notions of multi-class calibration that give strong guarantees of meaningful predictions and can be achieved in time and sample complexities polynomial in $k$? Prior notions of calibration exhibit a tradeoff between computational efficiency and expressivity: they either suffer from having sample complexity exponential in $k$, or needing to solve computationally intractable problems, or give rather weak guarantees.   Our main contribution is a notion of calibration that achieves all these desiderata: we formulate a robust notion of projected smooth calibration for multi-class predictions, and give new recalibration algorithms for efficiently calibrating predictors under this definition with complexity polynomial in $k$. Projected smooth calibration gives strong guarantees for all downstream decision makers who want to use the predictor for binary classification problems of the form: does the label belong to a subset $T \\subseteq [k]$: e.g. is this an image of an animal? It ensures that the probabilities predicted by summing the probabilities assigned to labels in $T$ are close to some perfectly calibrated binary predictor for that task. We also show that natural strengthenings of our definition are computationally hard to achieve: they run into information theoretic barriers or computational intractability. Underlying both our upper and lower bounds is a tight connection that we prove between multi-class calibration and the well-studied problem of agnostic learning in the (standard) binary prediction setting.","sentences":["Consider a multi-class labelling problem, where the labels can take values in $[k]$, and a predictor predicts a distribution over the labels.","In this work, we study the following foundational question: Are there notions of multi-class calibration that give strong guarantees of meaningful predictions and can be achieved in time and sample complexities polynomial in $k$?","Prior notions of calibration exhibit a tradeoff between computational efficiency and expressivity: they either suffer from having sample complexity exponential in $k$, or needing to solve computationally intractable problems, or give rather weak guarantees.   ","Our main contribution is a notion of calibration that achieves all these desiderata: we formulate a robust notion of projected smooth calibration for multi-class predictions, and give new recalibration algorithms for efficiently calibrating predictors under this definition with complexity polynomial in $k$. Projected smooth calibration gives strong guarantees for all downstream decision makers who want to use the predictor for binary classification problems of the form: does the label belong to a subset $T \\subseteq","[k]$: e.g. is this an image of an animal?","It ensures that the probabilities predicted by summing the probabilities assigned to labels in $T$ are close to some perfectly calibrated binary predictor for that task.","We also show that natural strengthenings of our definition are computationally hard to achieve: they run into information theoretic barriers or computational intractability.","Underlying both our upper and lower bounds is a tight connection that we prove between multi-class calibration and the well-studied problem of agnostic learning in the (standard) binary prediction setting."],"url":"http://arxiv.org/abs/2402.07821v1"}
{"created":"2024-02-12 17:24:35","title":"A Benchmark Grocery Dataset of Realworld Point Clouds From Single View","abstract":"Fine-grained grocery object recognition is an important computer vision problem with broad applications in automatic checkout, in-store robotic navigation, and assistive technologies for the visually impaired. Existing datasets on groceries are mainly 2D images. Models trained on these datasets are limited to learning features from the regular 2D grids. While portable 3D sensors such as Kinect were commonly available for mobile phones, sensors such as LiDAR and TrueDepth, have recently been integrated into mobile phones. Despite the availability of mobile 3D sensors, there are currently no dedicated real-world large-scale benchmark 3D datasets for grocery. In addition, existing 3D datasets lack fine-grained grocery categories and have limited training samples. Furthermore, collecting data by going around the object versus the traditional photo capture makes data collection cumbersome. Thus, we introduce a large-scale grocery dataset called 3DGrocery100. It constitutes 100 classes, with a total of 87,898 3D point clouds created from 10,755 RGB-D single-view images. We benchmark our dataset on six recent state-of-the-art 3D point cloud classification models. Additionally, we also benchmark the dataset on few-shot and continual learning point cloud classification tasks. Project Page: https://bigdatavision.org/3DGrocery100/.","sentences":["Fine-grained grocery object recognition is an important computer vision problem with broad applications in automatic checkout, in-store robotic navigation, and assistive technologies for the visually impaired.","Existing datasets on groceries are mainly 2D images.","Models trained on these datasets are limited to learning features from the regular 2D grids.","While portable 3D sensors such as Kinect were commonly available for mobile phones, sensors such as LiDAR and TrueDepth, have recently been integrated into mobile phones.","Despite the availability of mobile 3D sensors, there are currently no dedicated real-world large-scale benchmark 3D datasets for grocery.","In addition, existing 3D datasets lack fine-grained grocery categories and have limited training samples.","Furthermore, collecting data by going around the object versus the traditional photo capture makes data collection cumbersome.","Thus, we introduce a large-scale grocery dataset called 3DGrocery100.","It constitutes 100 classes, with a total of 87,898 3D point clouds created from 10,755 RGB-D single-view images.","We benchmark our dataset on six recent state-of-the-art 3D point cloud classification models.","Additionally, we also benchmark the dataset on few-shot and continual learning point cloud classification tasks.","Project Page: https://bigdatavision.org/3DGrocery100/."],"url":"http://arxiv.org/abs/2402.07819v1"}
{"created":"2024-02-12 17:24:15","title":"Differentially Private Zeroth-Order Methods for Scalable Large Language Model Finetuning","abstract":"Finetuning on task-specific datasets is a widely-embraced paradigm of harnessing the powerful capability of pretrained LLMs for various downstream tasks. Due to the popularity of LLMs finetuning and its accompanying privacy concerns, differentially private (DP) finetuning of pretrained LLMs has garnered increasing attention to safeguarding the privacy of task-specific datasets. Lying at the design core of DP LLM finetuning methods is the satisfactory tradeoff between privacy, utility, and scalability. Most existing methods build upon the seminal work of DP-SGD. Despite pushing the scalability of DP-SGD to its limit, DP-SGD-based finetuning methods are unfortunately limited by the inherent inefficiency of SGD. In this paper, we investigate the potential of DP zeroth-order methods for LLM pretraining, which avoids the scalability bottleneck of SGD by approximating the gradient with the more efficient zeroth-order gradient. Rather than treating the zeroth-order method as a drop-in replacement for SGD, this paper presents a comprehensive study both theoretically and empirically. First, we propose the stagewise DP zeroth-order method that dynamically schedules key hyperparameters. This design is grounded on the synergy between DP random perturbation and the gradient approximation error of the zeroth-order method, and its effect on finetuning trajectory. Second, we further enhance the scalability by reducing the trainable parameters that are identified by repurposing a data-free pruning technique requiring no additional data or extra privacy budget. We provide theoretical analysis for both proposed methods. We conduct extensive empirical analysis on both encoder-only masked language model and decoder-only autoregressive language model, achieving impressive results in terms of scalability and utility.","sentences":["Finetuning on task-specific datasets is a widely-embraced paradigm of harnessing the powerful capability of pretrained LLMs for various downstream tasks.","Due to the popularity of LLMs finetuning and its accompanying privacy concerns, differentially private (DP) finetuning of pretrained LLMs has garnered increasing attention to safeguarding the privacy of task-specific datasets.","Lying at the design core of DP LLM finetuning methods is the satisfactory tradeoff between privacy, utility, and scalability.","Most existing methods build upon the seminal work of DP-SGD.","Despite pushing the scalability of DP-SGD to its limit, DP-SGD-based finetuning methods are unfortunately limited by the inherent inefficiency of SGD.","In this paper, we investigate the potential of DP zeroth-order methods for LLM pretraining, which avoids the scalability bottleneck of SGD by approximating the gradient with the more efficient zeroth-order gradient.","Rather than treating the zeroth-order method as a drop-in replacement for SGD, this paper presents a comprehensive study both theoretically and empirically.","First, we propose the stagewise DP zeroth-order method that dynamically schedules key hyperparameters.","This design is grounded on the synergy between DP random perturbation and the gradient approximation error of the zeroth-order method, and its effect on finetuning trajectory.","Second, we further enhance the scalability by reducing the trainable parameters that are identified by repurposing a data-free pruning technique requiring no additional data or extra privacy budget.","We provide theoretical analysis for both proposed methods.","We conduct extensive empirical analysis on both encoder-only masked language model and decoder-only autoregressive language model, achieving impressive results in terms of scalability and utility."],"url":"http://arxiv.org/abs/2402.07818v1"}
{"created":"2024-02-12 17:22:42","title":"Injecting Wiktionary to improve token-level contextual representations using contrastive learning","abstract":"While static word embeddings are blind to context, for lexical semantics tasks context is rather too present in contextual word embeddings, vectors of same-meaning occurrences being too different (Ethayarajh, 2019). Fine-tuning pre-trained language models (PLMs) using contrastive learning was proposed, leveraging automatically self-augmented examples (Liu et al., 2021b). In this paper, we investigate how to inject a lexicon as an alternative source of supervision, using the English Wiktionary. We also test how dimensionality reduction impacts the resulting contextual word embeddings. We evaluate our approach on the Word-In-Context (WiC) task, in the unsupervised setting (not using the training set). We achieve new SoTA result on the original WiC test set. We also propose two new WiC test sets for which we show that our fine-tuning method achieves substantial improvements. We also observe improvements, although modest, for the semantic frame induction task. Although we experimented on English to allow comparison with related work, our method is adaptable to the many languages for which large Wiktionaries exist.","sentences":["While static word embeddings are blind to context, for lexical semantics tasks context is rather too present in contextual word embeddings, vectors of same-meaning occurrences being too different (Ethayarajh, 2019).","Fine-tuning pre-trained language models (PLMs) using contrastive learning was proposed, leveraging automatically self-augmented examples (Liu et al., 2021b).","In this paper, we investigate how to inject a lexicon as an alternative source of supervision, using the English Wiktionary.","We also test how dimensionality reduction impacts the resulting contextual word embeddings.","We evaluate our approach on the Word-In-Context (WiC) task, in the unsupervised setting (not using the training set).","We achieve new SoTA result on the original WiC test set.","We also propose two new WiC test sets for which we show that our fine-tuning method achieves substantial improvements.","We also observe improvements, although modest, for the semantic frame induction task.","Although we experimented on English to allow comparison with related work, our method is adaptable to the many languages for which large Wiktionaries exist."],"url":"http://arxiv.org/abs/2402.07817v1"}
{"created":"2024-02-12 17:18:51","title":"PBADet: A One-Stage Anchor-Free Approach for Part-Body Association","abstract":"The detection of human parts (e.g., hands, face) and their correct association with individuals is an essential task, e.g., for ubiquitous human-machine interfaces and action recognition. Traditional methods often employ multi-stage processes, rely on cumbersome anchor-based systems, or do not scale well to larger part sets. This paper presents PBADet, a novel one-stage, anchor-free approach for part-body association detection. Building upon the anchor-free object representation across multi-scale feature maps, we introduce a singular part-to-body center offset that effectively encapsulates the relationship between parts and their parent bodies. Our design is inherently versatile and capable of managing multiple parts-to-body associations without compromising on detection accuracy or robustness. Comprehensive experiments on various datasets underscore the efficacy of our approach, which not only outperforms existing state-of-the-art techniques but also offers a more streamlined and efficient solution to the part-body association challenge.","sentences":["The detection of human parts (e.g., hands, face) and their correct association with individuals is an essential task, e.g., for ubiquitous human-machine interfaces and action recognition.","Traditional methods often employ multi-stage processes, rely on cumbersome anchor-based systems, or do not scale well to larger part sets.","This paper presents PBADet, a novel one-stage, anchor-free approach for part-body association detection.","Building upon the anchor-free object representation across multi-scale feature maps, we introduce a singular part-to-body center offset that effectively encapsulates the relationship between parts and their parent bodies.","Our design is inherently versatile and capable of managing multiple parts-to-body associations without compromising on detection accuracy or robustness.","Comprehensive experiments on various datasets underscore the efficacy of our approach, which not only outperforms existing state-of-the-art techniques but also offers a more streamlined and efficient solution to the part-body association challenge."],"url":"http://arxiv.org/abs/2402.07814v1"}
{"created":"2024-02-12 17:17:50","title":"Retrieval-Augmented Thought Process as Sequential Decision Making","abstract":"Large Language Models (LLMs) have demonstrated their strong ability to assist people and show \"sparks of intelligence\". However, several open challenges hinder their wider application: such as concerns over privacy, tendencies to produce hallucinations, and difficulties in handling long contexts. In this work, we address those challenges by introducing the Retrieval-Augmented Thought Process (RATP). Given access to external knowledge, RATP formulates the thought generation of LLMs as a multiple-step decision process. To optimize such a thought process, RATP leverages Monte-Carlo Tree Search, and learns a Q-value estimator that permits cost-efficient inference. In addressing the task of question-answering with private data, where ethical and security concerns limit LLM training methods, RATP achieves a 50% improvement over existing in-context retrieval-augmented language models.","sentences":["Large Language Models (LLMs) have demonstrated their strong ability to assist people and show \"sparks of intelligence\".","However, several open challenges hinder their wider application: such as concerns over privacy, tendencies to produce hallucinations, and difficulties in handling long contexts.","In this work, we address those challenges by introducing the Retrieval-Augmented Thought Process (RATP).","Given access to external knowledge, RATP formulates the thought generation of LLMs as a multiple-step decision process.","To optimize such a thought process, RATP leverages Monte-Carlo Tree Search, and learns a Q-value estimator that permits cost-efficient inference.","In addressing the task of question-answering with private data, where ethical and security concerns limit LLM training methods, RATP achieves a 50% improvement over existing in-context retrieval-augmented language models."],"url":"http://arxiv.org/abs/2402.07812v1"}
{"created":"2024-02-12 17:13:02","title":"Sourcerer: Sample-based Maximum Entropy Source Distribution Estimation","abstract":"Scientific modeling applications often require estimating a distribution of parameters consistent with a dataset of observations - an inference task also known as source distribution estimation. This problem can be ill-posed, however, since many different source distributions might produce the same distribution of data-consistent simulations. To make a principled choice among many equally valid sources, we propose an approach which targets the maximum entropy distribution, i.e., prioritizes retaining as much uncertainty as possible. Our method is purely sample-based - leveraging the Sliced-Wasserstein distance to measure the discrepancy between the dataset and simulations - and thus suitable for simulators with intractable likelihoods. We benchmark our method on several tasks, and show that it can recover source distributions with substantially higher entropy without sacrificing the fidelity of the simulations. Finally, to demonstrate the utility of our approach, we infer source distributions for parameters of the Hodgkin-Huxley neuron model from experimental datasets with thousands of measurements. In summary, we propose a principled framework for inferring unique source distributions of scientific simulator parameters while retaining as much uncertainty as possible.","sentences":["Scientific modeling applications often require estimating a distribution of parameters consistent with a dataset of observations - an inference task also known as source distribution estimation.","This problem can be ill-posed, however, since many different source distributions might produce the same distribution of data-consistent simulations.","To make a principled choice among many equally valid sources, we propose an approach which targets the maximum entropy distribution, i.e., prioritizes retaining as much uncertainty as possible.","Our method is purely sample-based - leveraging the Sliced-Wasserstein distance to measure the discrepancy between the dataset and simulations - and thus suitable for simulators with intractable likelihoods.","We benchmark our method on several tasks, and show that it can recover source distributions with substantially higher entropy without sacrificing the fidelity of the simulations.","Finally, to demonstrate the utility of our approach, we infer source distributions for parameters of the Hodgkin-Huxley neuron model from experimental datasets with thousands of measurements.","In summary, we propose a principled framework for inferring unique source distributions of scientific simulator parameters while retaining as much uncertainty as possible."],"url":"http://arxiv.org/abs/2402.07808v1"}
{"created":"2024-02-12 17:03:58","title":"Generalising Planning Environment Redesign","abstract":"In Environment Design, one interested party seeks to affect another agent's decisions by applying changes to the environment. Most research on planning environment (re)design assumes the interested party's objective is to facilitate the recognition of goals and plans, and search over the space of environment modifications to find the minimal set of changes that simplify those tasks and optimise a particular metric. This search space is usually intractable, so existing approaches devise metric-dependent pruning techniques for performing search more efficiently. This results in approaches that are not able to generalise across different objectives and/or metrics. In this paper, we argue that the interested party could have objectives and metrics that are not necessarily related to recognising agents' goals or plans. Thus, to generalise the task of Planning Environment Redesign, we develop a general environment redesign approach that is metric-agnostic and leverages recent research on top-quality planning to efficiently redesign planning environments according to any interested party's objective and metric. Experiments over a set of environment redesign benchmarks show that our general approach outperforms existing approaches when using well-known metrics, such as facilitating the recognition of goals, as well as its effectiveness when solving environment redesign tasks that optimise a novel set of different metrics.","sentences":["In Environment Design, one interested party seeks to affect another agent's decisions by applying changes to the environment.","Most research on planning environment (re)design assumes the interested party's objective is to facilitate the recognition of goals and plans, and search over the space of environment modifications to find the minimal set of changes that simplify those tasks and optimise a particular metric.","This search space is usually intractable, so existing approaches devise metric-dependent pruning techniques for performing search more efficiently.","This results in approaches that are not able to generalise across different objectives and/or metrics.","In this paper, we argue that the interested party could have objectives and metrics that are not necessarily related to recognising agents' goals or plans.","Thus, to generalise the task of Planning Environment Redesign, we develop a general environment redesign approach that is metric-agnostic and leverages recent research on top-quality planning to efficiently redesign planning environments according to any interested party's objective and metric.","Experiments over a set of environment redesign benchmarks show that our general approach outperforms existing approaches when using well-known metrics, such as facilitating the recognition of goals, as well as its effectiveness when solving environment redesign tasks that optimise a novel set of different metrics."],"url":"http://arxiv.org/abs/2402.07799v1"}
{"created":"2024-02-12 17:02:24","title":"Computing Nash Equilibria in Potential Games with Private Uncoupled Constraints","abstract":"We consider the problem of computing Nash equilibria in potential games where each player's strategy set is subject to private uncoupled constraints. This scenario is frequently encountered in real-world applications like road network congestion games where individual drivers adhere to personal budget and fuel limitations. Despite the plethora of algorithms that efficiently compute Nash equilibria (NE) in potential games, the domain of constrained potential games remains largely unexplored. We introduce an algorithm that leverages the Lagrangian formulation of NE. The algorithm is implemented independently by each player and runs in polynomial time with respect to the approximation error, the sum of the size of the action-spaces, and the game's inherent parameters.","sentences":["We consider the problem of computing Nash equilibria in potential games where each player's strategy set is subject to private uncoupled constraints.","This scenario is frequently encountered in real-world applications like road network congestion games where individual drivers adhere to personal budget and fuel limitations.","Despite the plethora of algorithms that efficiently compute Nash equilibria (NE) in potential games, the domain of constrained potential games remains largely unexplored.","We introduce an algorithm that leverages the Lagrangian formulation of NE.","The algorithm is implemented independently by each player and runs in polynomial time with respect to the approximation error, the sum of the size of the action-spaces, and the game's inherent parameters."],"url":"http://arxiv.org/abs/2402.07797v1"}
{"created":"2024-02-12 16:59:05","title":"Empowering Federated Learning for Massive Models with NVIDIA FLARE","abstract":"In the ever-evolving landscape of artificial intelligence (AI) and large language models (LLMs), handling and leveraging data effectively has become a critical challenge. Most state-of-the-art machine learning algorithms are data-centric. However, as the lifeblood of model performance, necessary data cannot always be centralized due to various factors such as privacy, regulation, geopolitics, copyright issues, and the sheer effort required to move vast datasets. In this paper, we explore how federated learning enabled by NVIDIA FLARE can address these challenges with easy and scalable integration capabilities, enabling parameter-efficient and full supervised fine-tuning of LLMs for natural language processing and biopharmaceutical applications to enhance their accuracy and robustness.","sentences":["In the ever-evolving landscape of artificial intelligence (AI) and large language models (LLMs), handling and leveraging data effectively has become a critical challenge.","Most state-of-the-art machine learning algorithms are data-centric.","However, as the lifeblood of model performance, necessary data cannot always be centralized due to various factors such as privacy, regulation, geopolitics, copyright issues, and the sheer effort required to move vast datasets.","In this paper, we explore how federated learning enabled by NVIDIA FLARE can address these challenges with easy and scalable integration capabilities, enabling parameter-efficient and full supervised fine-tuning of LLMs for natural language processing and biopharmaceutical applications to enhance their accuracy and robustness."],"url":"http://arxiv.org/abs/2402.07792v1"}
{"created":"2024-02-12 16:55:58","title":"Continuous Assurance of Autonomous Vehicle Behavior Through Machine Learned Correctness Properties","abstract":"Correctness properties are critical to conducting verification and validation on software systems, especially those cyberphysical systems whose functionality changes frequently due to software updates, changes in the operating environment, or newly learned behaviors. We detail a novel method to automatically construct expressive, executable correctness properties in the form of machine-learned correctness properties which can be used to ensure that a system's behavior is correct with respect to its design and operating requirements. We propose a method to bootstrap the creation of these correctness properties using a novel simulation-based generation of training and testing data using multiple extensions to the Cross Entropy algorithm for search-based optimization. Then, we apply this method to a software-in-the-loop evaluation of an autonomous vehicle to demonstrate that such models can assert about important properties of multi-agent cyberphysical systems. We demonstrate that this process brings the task of developing robust correctness properties from the realm of formal methods experts into the domain of system developers and engineers, and that machine-learned correctness properties are expressive enough to capture the correct behavior of cyberphysical systems in their complex environments. This advancement can provide evidence of dependability to system designers and users, enhancing trust in the deployment of autonomous vehicles and other intelligent transportation systems.","sentences":["Correctness properties are critical to conducting verification and validation on software systems, especially those cyberphysical systems whose functionality changes frequently due to software updates, changes in the operating environment, or newly learned behaviors.","We detail a novel method to automatically construct expressive, executable correctness properties in the form of machine-learned correctness properties which can be used to ensure that a system's behavior is correct with respect to its design and operating requirements.","We propose a method to bootstrap the creation of these correctness properties using a novel simulation-based generation of training and testing data using multiple extensions to the Cross Entropy algorithm for search-based optimization.","Then, we apply this method to a software-in-the-loop evaluation of an autonomous vehicle to demonstrate that such models can assert about important properties of multi-agent cyberphysical systems.","We demonstrate that this process brings the task of developing robust correctness properties from the realm of formal methods experts into the domain of system developers and engineers, and that machine-learned correctness properties are expressive enough to capture the correct behavior of cyberphysical systems in their complex environments.","This advancement can provide evidence of dependability to system designers and users, enhancing trust in the deployment of autonomous vehicles and other intelligent transportation systems."],"url":"http://arxiv.org/abs/2402.07791v1"}
{"created":"2024-02-12 16:55:19","title":"From Uncertainty to Precision: Enhancing Binary Classifier Performance through Calibration","abstract":"The assessment of binary classifier performance traditionally centers on discriminative ability using metrics, such as accuracy. However, these metrics often disregard the model's inherent uncertainty, especially when dealing with sensitive decision-making domains, such as finance or healthcare. Given that model-predicted scores are commonly seen as event probabilities, calibration is crucial for accurate interpretation. In our study, we analyze the sensitivity of various calibration measures to score distortions and introduce a refined metric, the Local Calibration Score. Comparing recalibration methods, we advocate for local regressions, emphasizing their dual role as effective recalibration tools and facilitators of smoother visualizations. We apply these findings in a real-world scenario using Random Forest classifier and regressor to predict credit default while simultaneously measuring calibration during performance optimization.","sentences":["The assessment of binary classifier performance traditionally centers on discriminative ability using metrics, such as accuracy.","However, these metrics often disregard the model's inherent uncertainty, especially when dealing with sensitive decision-making domains, such as finance or healthcare.","Given that model-predicted scores are commonly seen as event probabilities, calibration is crucial for accurate interpretation.","In our study, we analyze the sensitivity of various calibration measures to score distortions and introduce a refined metric, the Local Calibration Score.","Comparing recalibration methods, we advocate for local regressions, emphasizing their dual role as effective recalibration tools and facilitators of smoother visualizations.","We apply these findings in a real-world scenario using Random Forest classifier and regressor to predict credit default while simultaneously measuring calibration during performance optimization."],"url":"http://arxiv.org/abs/2402.07790v1"}
{"created":"2024-02-12 16:54:22","title":"Multi-Intent Attribute-Aware Text Matching in Searching","abstract":"Text matching systems have become a fundamental service in most searching platforms. For instance, they are responsible for matching user queries to relevant candidate items, or rewriting the user-input query to a pre-selected high-performing one for a better search experience. In practice, both the queries and items often contain multiple attributes, such as the category of the item and the location mentioned in the query, which represent condensed key information that is helpful for matching. However, most of the existing works downplay the effectiveness of attributes by integrating them into text representations as supplementary information. Hence, in this work, we focus on exploring the relationship between the attributes from two sides. Since attributes from two ends are often not aligned in terms of number and type, we propose to exploit the benefit of attributes by multiple-intent modeling. The intents extracted from attributes summarize the diverse needs of queries and provide rich content of items, which are more refined and abstract, and can be aligned for paired inputs. Concretely, we propose a multi-intent attribute-aware matching model (MIM), which consists of three main components: attribute-aware encoder, multi-intent modeling, and intent-aware matching. In the attribute-aware encoder, the text and attributes are weighted and processed through a scaled attention mechanism with regard to the attributes' importance. Afterward, the multi-intent modeling extracts intents from two ends and aligns them. Herein, we come up with a distribution loss to ensure the learned intents are diverse but concentrated, and a kullback-leibler divergence loss that aligns the learned intents. Finally, in the intent-aware matching, the intents are evaluated by a self-supervised masking task, and then incorporated to output the final matching result.","sentences":["Text matching systems have become a fundamental service in most searching platforms.","For instance, they are responsible for matching user queries to relevant candidate items, or rewriting the user-input query to a pre-selected high-performing one for a better search experience.","In practice, both the queries and items often contain multiple attributes, such as the category of the item and the location mentioned in the query, which represent condensed key information that is helpful for matching.","However, most of the existing works downplay the effectiveness of attributes by integrating them into text representations as supplementary information.","Hence, in this work, we focus on exploring the relationship between the attributes from two sides.","Since attributes from two ends are often not aligned in terms of number and type, we propose to exploit the benefit of attributes by multiple-intent modeling.","The intents extracted from attributes summarize the diverse needs of queries and provide rich content of items, which are more refined and abstract, and can be aligned for paired inputs.","Concretely, we propose a multi-intent attribute-aware matching model (MIM), which consists of three main components: attribute-aware encoder, multi-intent modeling, and intent-aware matching.","In the attribute-aware encoder, the text and attributes are weighted and processed through a scaled attention mechanism with regard to the attributes' importance.","Afterward, the multi-intent modeling extracts intents from two ends and aligns them.","Herein, we come up with a distribution loss to ensure the learned intents are diverse but concentrated, and a kullback-leibler divergence loss that aligns the learned intents.","Finally, in the intent-aware matching, the intents are evaluated by a self-supervised masking task, and then incorporated to output the final matching result."],"url":"http://arxiv.org/abs/2402.07788v1"}
{"created":"2024-02-12 16:52:26","title":"Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis","abstract":"Aspect-based Sentiment Analysis (ABSA) evaluates sentiment expressions within a text to comprehend sentiment information. Previous studies integrated external knowledge, such as knowledge graphs, to enhance the semantic features in ABSA models. Recent research has examined the use of Graph Neural Networks (GNNs) on dependency and constituent trees for syntactic analysis. With the ongoing development of ABSA, more innovative linguistic and structural features are being incorporated (e.g. latent graph), but this also introduces complexity and confusion. As of now, a scalable framework for integrating diverse linguistic and structural features into ABSA does not exist. This paper presents the Extensible Multi-Granularity Fusion (EMGF) network, which integrates information from dependency and constituent syntactic, attention semantic , and external knowledge graphs. EMGF, equipped with multi-anchor triplet learning and orthogonal projection, efficiently harnesses the combined potential of each granularity feature and their synergistic interactions, resulting in a cumulative effect without additional computational expenses. Experimental findings on SemEval 2014 and Twitter datasets confirm EMGF's superiority over existing ABSA methods.","sentences":["Aspect-based Sentiment Analysis (ABSA) evaluates sentiment expressions within a text to comprehend sentiment information.","Previous studies integrated external knowledge, such as knowledge graphs, to enhance the semantic features in ABSA models.","Recent research has examined the use of Graph Neural Networks (GNNs) on dependency and constituent trees for syntactic analysis.","With the ongoing development of ABSA, more innovative linguistic and structural features are being incorporated (e.g. latent graph), but this also introduces complexity and confusion.","As of now, a scalable framework for integrating diverse linguistic and structural features into ABSA does not exist.","This paper presents the Extensible Multi-Granularity Fusion (EMGF) network, which integrates information from dependency and constituent syntactic, attention semantic , and external knowledge graphs.","EMGF, equipped with multi-anchor triplet learning and orthogonal projection, efficiently harnesses the combined potential of each granularity feature and their synergistic interactions, resulting in a cumulative effect without additional computational expenses.","Experimental findings on SemEval 2014 and Twitter datasets confirm EMGF's superiority over existing ABSA methods."],"url":"http://arxiv.org/abs/2402.07787v1"}
{"created":"2024-02-12 16:50:07","title":"HYPO: Hyperspherical Out-of-Distribution Generalization","abstract":"Out-of-distribution (OOD) generalization is critical for machine learning models deployed in the real world. However, achieving this can be fundamentally challenging, as it requires the ability to learn invariant features across different domains or environments. In this paper, we propose a novel framework HYPO (HYPerspherical OOD generalization) that provably learns domain-invariant representations in a hyperspherical space. In particular, our hyperspherical learning algorithm is guided by intra-class variation and inter-class separation principles -- ensuring that features from the same class (across different training domains) are closely aligned with their class prototypes, while different class prototypes are maximally separated. We further provide theoretical justifications on how our prototypical learning objective improves the OOD generalization bound. Through extensive experiments on challenging OOD benchmarks, we demonstrate that our approach outperforms competitive baselines and achieves superior performance. Code is available at https://github.com/deeplearning-wisc/hypo.","sentences":["Out-of-distribution (OOD) generalization is critical for machine learning models deployed in the real world.","However, achieving this can be fundamentally challenging, as it requires the ability to learn invariant features across different domains or environments.","In this paper, we propose a novel framework HYPO (HYPerspherical OOD generalization) that provably learns domain-invariant representations in a hyperspherical space.","In particular, our hyperspherical learning algorithm is guided by intra-class variation and inter-class separation principles -- ensuring that features from the same class (across different training domains) are closely aligned with their class prototypes, while different class prototypes are maximally separated.","We further provide theoretical justifications on how our prototypical learning objective improves the OOD generalization bound.","Through extensive experiments on challenging OOD benchmarks, we demonstrate that our approach outperforms competitive baselines and achieves superior performance.","Code is available at https://github.com/deeplearning-wisc/hypo."],"url":"http://arxiv.org/abs/2402.07785v1"}
{"created":"2024-02-12 16:47:13","title":"Solving parameter-dependent semi-algebraic systems","abstract":"We consider systems of polynomial equations and inequalities in $\\mathbb{Q}[\\boldsymbol{y}][\\boldsymbol{x}]$ where $\\boldsymbol{x} = (x_1, \\ldots, x_n)$ and $\\boldsymbol{y} = (y_1, \\ldots,y_t)$. The $\\boldsymbol{y}$ indeterminates are considered as parameters and we assume that when specialising them generically, the set of common complex solutions, to the obtained equations, is finite. We consider the problem of real root classification for such parameter-dependent problems, i.e. identifying the possible number of real solutions depending on the values of the parameters and computing a description of the regions of the space of parameters over which the number of real roots remains invariant.   We design an algorithm for solving this problem. The formulas it outputs enjoy a determinantal structure. Under genericity assumptions, we show that its arithmetic complexity is polynomial in both the maximum degree $d$ and the number $s$ of the input inequalities and exponential in $nt+t^2$. The output formulas consist of polynomials of degree bounded by $(2s+n)d^{n+1}$. This is the first algorithm with such a singly exponential complexity. We report on practical experiments showing that a first implementation of this algorithm can tackle examples which were previously out of reach.","sentences":["We consider systems of polynomial equations and inequalities in $\\mathbb{Q}[\\boldsymbol{y}][\\boldsymbol{x}]$ where $\\boldsymbol{x} = (x_1, \\ldots, x_n)$ and $\\boldsymbol{y} = (y_1, \\ldots,y_t)$. The $\\boldsymbol{y}$ indeterminates are considered as parameters and we assume that when specialising them generically, the set of common complex solutions, to the obtained equations, is finite.","We consider the problem of real root classification for such parameter-dependent problems, i.e. identifying the possible number of real solutions depending on the values of the parameters and computing a description of the regions of the space of parameters over which the number of real roots remains invariant.   ","We design an algorithm for solving this problem.","The formulas it outputs enjoy a determinantal structure.","Under genericity assumptions, we show that its arithmetic complexity is polynomial in both the maximum degree $d$ and the number $s$ of the input inequalities and exponential in $nt+t^2$. The output formulas consist of polynomials of degree bounded by $(2s+n)d^{n+1}$. This is the first algorithm with such a singly exponential complexity.","We report on practical experiments showing that a first implementation of this algorithm can tackle examples which were previously out of reach."],"url":"http://arxiv.org/abs/2402.07782v1"}
{"created":"2024-02-12 16:47:08","title":"IR-Aware ECO Timing Optimization Using Reinforcement Learning","abstract":"Engineering change orders (ECOs) in late stages make minimal design fixes to recover from timing shifts due to excessive IR drops. This paper integrates IR-drop-aware timing analysis and ECO timing optimization using reinforcement learning (RL). The method operates after physical design and power grid synthesis, and rectifies IR-drop-induced timing degradation through gate sizing. It incorporates the Lagrangian relaxation (LR) technique into a novel RL framework, which trains a relational graph convolutional network (R-GCN) agent to sequentially size gates to fix timing violations. The R-GCN agent outperforms a classical LR-only algorithm: in an open 45nm technology, it (a) moves the Pareto front of the delay-area tradeoff curve to the left and (b) saves runtime over the classical method by running fast inference using trained models at iso-quality. The RL model is transferable across timing specifications, and transferable to unseen designs with zero-shot learning or fine tuning.","sentences":["Engineering change orders (ECOs) in late stages make minimal design fixes to recover from timing shifts due to excessive IR drops.","This paper integrates IR-drop-aware timing analysis and ECO timing optimization using reinforcement learning (RL).","The method operates after physical design and power grid synthesis, and rectifies IR-drop-induced timing degradation through gate sizing.","It incorporates the Lagrangian relaxation (LR) technique into a novel RL framework, which trains a relational graph convolutional network (R-GCN) agent to sequentially size gates to fix timing violations.","The R-GCN agent outperforms a classical LR-only algorithm: in an open 45nm technology, it (a) moves the Pareto front of the delay-area tradeoff curve to the left and (b) saves runtime over the classical method by running fast inference using trained models at iso-quality.","The RL model is transferable across timing specifications, and transferable to unseen designs with zero-shot learning or fine tuning."],"url":"http://arxiv.org/abs/2402.07781v1"}
{"created":"2024-02-12 16:43:55","title":"Algorithmic Fairness and Color-blind Racism: Navigating the Intersection","abstract":"Our focus lies at the intersection between two broader research perspectives: (1) the scientific study of algorithms and (2) the scholarship on race and racism. Many streams of research related to algorithmic fairness have been born out of interest at this intersection. We think about this intersection as the product of work derived from both sides. From (1) algorithms to (2) racism, the starting place might be an algorithmic question or method connected to a conceptualization of racism. On the other hand, from (2) racism to (1) algorithms, the starting place could be recognizing a setting where a legacy of racism is known to persist and drawing connections between that legacy and the introduction of algorithms into this setting. In either direction, meaningful disconnection can occur when conducting research at the intersection of racism and algorithms. The present paper urges collective reflection on research directions at this intersection. Despite being primarily motivated by instances of racial bias, research in algorithmic fairness remains mostly disconnected from scholarship on racism. In particular, there has not been an examination connecting algorithmic fairness discussions directly to the ideology of color-blind racism; we aim to fill this gap. We begin with a review of an essential account of color-blind racism then we review racial discourse within algorithmic fairness research and underline significant patterns, shifts and disconnects. Ultimately, we argue that researchers can improve the navigation of the landscape at the intersection by recognizing ideological shifts as such and iteratively re-orienting towards maintaining meaningful connections across interdisciplinary lines.","sentences":["Our focus lies at the intersection between two broader research perspectives: (1) the scientific study of algorithms and (2) the scholarship on race and racism.","Many streams of research related to algorithmic fairness have been born out of interest at this intersection.","We think about this intersection as the product of work derived from both sides.","From (1) algorithms to (2) racism, the starting place might be an algorithmic question or method connected to a conceptualization of racism.","On the other hand, from (2) racism to (1) algorithms, the starting place could be recognizing a setting where a legacy of racism is known to persist and drawing connections between that legacy and the introduction of algorithms into this setting.","In either direction, meaningful disconnection can occur when conducting research at the intersection of racism and algorithms.","The present paper urges collective reflection on research directions at this intersection.","Despite being primarily motivated by instances of racial bias, research in algorithmic fairness remains mostly disconnected from scholarship on racism.","In particular, there has not been an examination connecting algorithmic fairness discussions directly to the ideology of color-blind racism; we aim to fill this gap.","We begin with a review of an essential account of color-blind racism then we review racial discourse within algorithmic fairness research and underline significant patterns, shifts and disconnects.","Ultimately, we argue that researchers can improve the navigation of the landscape at the intersection by recognizing ideological shifts as such and iteratively re-orienting towards maintaining meaningful connections across interdisciplinary lines."],"url":"http://arxiv.org/abs/2402.07778v1"}
{"created":"2024-02-12 16:41:54","title":"TELLER: A Trustworthy Framework for Explainable, Generalizable and Controllable Fake News Detection","abstract":"The proliferation of fake news has emerged as a severe societal problem, raising significant interest from industry and academia. While existing deep-learning based methods have made progress in detecting fake news accurately, their reliability may be compromised caused by the non-transparent reasoning processes, poor generalization abilities and inherent risks of integration with large language models (LLMs). To address this challenge, we propose {\\methodname}, a novel framework for trustworthy fake news detection that prioritizes explainability, generalizability and controllability of models. This is achieved via a dual-system framework that integrates cognition and decision systems, adhering to the principles above. The cognition system harnesses human expertise to generate logical predicates, which guide LLMs in generating human-readable logic atoms. Meanwhile, the decision system deduces generalizable logic rules to aggregate these atoms, enabling the identification of the truthfulness of the input news across diverse domains and enhancing transparency in the decision-making process. Finally, we present comprehensive evaluation results on four datasets, demonstrating the feasibility and trustworthiness of our proposed framework. Our implementation is available at \\url{https://github.com/less-and-less-bugs/Trust_TELLER}.","sentences":["The proliferation of fake news has emerged as a severe societal problem, raising significant interest from industry and academia.","While existing deep-learning based methods have made progress in detecting fake news accurately, their reliability may be compromised caused by the non-transparent reasoning processes, poor generalization abilities and inherent risks of integration with large language models (LLMs).","To address this challenge, we propose {\\methodname}, a novel framework for trustworthy fake news detection that prioritizes explainability, generalizability and controllability of models.","This is achieved via a dual-system framework that integrates cognition and decision systems, adhering to the principles above.","The cognition system harnesses human expertise to generate logical predicates, which guide LLMs in generating human-readable logic atoms.","Meanwhile, the decision system deduces generalizable logic rules to aggregate these atoms, enabling the identification of the truthfulness of the input news across diverse domains and enhancing transparency in the decision-making process.","Finally, we present comprehensive evaluation results on four datasets, demonstrating the feasibility and trustworthiness of our proposed framework.","Our implementation is available at \\url{https://github.com/less-and-less-bugs/Trust_TELLER}."],"url":"http://arxiv.org/abs/2402.07776v1"}
{"created":"2024-02-12 16:41:41","title":"Growth Rate of the Number of Empty Triangles in the Plane","abstract":"Given a set $P$ of $n$ points in the plane, in general position, denote by $N_\\Delta(P)$ the number of empty triangles with vertices in $P$. In this paper we investigate by how much $N_\\Delta(P)$ changes if a point $x$ is removed from $P$. By constructing a graph $G_P(x)$ based on the arrangement of the empty triangles incident on $x$, we transform this geometric problem to the problem of counting triangles in the graph $G_P(x)$. We study properties of the graph $G_P(x)$ and, in particular, show that it is kite-free. This relates the growth rate of the number of empty triangles to the famous Ruzsa-Szemer\\'edi problem.","sentences":["Given a set $P$ of $n$ points in the plane, in general position, denote by $N_\\Delta(P)$ the number of empty triangles with vertices in $P$. In this paper we investigate by how much $N_\\Delta(P)$ changes if a point $x$ is removed from $P$. By constructing a graph $G_P(x)$ based on the arrangement of the empty triangles incident on $x$, we transform this geometric problem to the problem of counting triangles in the graph $G_P(x)$. We study properties of the graph $G_P(x)$ and, in particular, show that it is kite-free.","This relates the growth rate of the number of empty triangles to the famous Ruzsa-Szemer\\'edi problem."],"url":"http://arxiv.org/abs/2402.07775v1"}
{"created":"2024-02-12 16:33:35","title":"End-to-End Learning for Fair Multiobjective Optimization Under Uncertainty","abstract":"Many decision processes in artificial intelligence and operations research are modeled by parametric optimization problems whose defining parameters are unknown and must be inferred from observable data. The Predict-Then-Optimize (PtO) paradigm in machine learning aims to maximize downstream decision quality by training the parametric inference model end-to-end with the subsequent constrained optimization. This requires backpropagation through the optimization problem using approximation techniques specific to the problem's form, especially for nondifferentiable linear and mixed-integer programs. This paper extends the PtO methodology to optimization problems with nondifferentiable Ordered Weighted Averaging (OWA) objectives, known for their ability to ensure properties of fairness and robustness in decision models. Through a collection of training techniques and proposed application settings, it shows how optimization of OWA functions can be effectively integrated with parametric prediction for fair and robust optimization under uncertainty.","sentences":["Many decision processes in artificial intelligence and operations research are modeled by parametric optimization problems whose defining parameters are unknown and must be inferred from observable data.","The Predict-Then-Optimize (PtO) paradigm in machine learning aims to maximize downstream decision quality by training the parametric inference model end-to-end with the subsequent constrained optimization.","This requires backpropagation through the optimization problem using approximation techniques specific to the problem's form, especially for nondifferentiable linear and mixed-integer programs.","This paper extends the PtO methodology to optimization problems with nondifferentiable Ordered Weighted Averaging (OWA) objectives, known for their ability to ensure properties of fairness and robustness in decision models.","Through a collection of training techniques and proposed application settings, it shows how optimization of OWA functions can be effectively integrated with parametric prediction for fair and robust optimization under uncertainty."],"url":"http://arxiv.org/abs/2402.07772v1"}
{"created":"2024-02-12 16:33:23","title":"Insights into $(k,\u03c1)$-shortcutting algorithms","abstract":"A graph is called a $(k,\\rho)$-graph iff every node can reach $\\rho$ of its nearest neighbors in at most k hops. This property proved useful in the analysis and design of parallel shortest-path algorithms. Any graph can be transformed into a $(k,\\rho)$-graph by adding shortcuts. Formally, the $(k,\\rho)$-Minimum-Shortcut problem asks to find an appropriate shortcut set of minimal cardinality.   We show that the $(k,\\rho)$-Minimum-Shortcut problem is NP-complete in the practical regime of $k \\ge 3$ and $\\rho = \\Theta(n^\\epsilon)$ for $\\epsilon > 0$. With a related construction, we bound the approximation factor of known $(k,\\rho)$-Minimum-Shortcut problem heuristics from below and propose algorithmic countermeasures improving the approximation quality. Further, we describe an integer linear problem (ILP) solving the $(k,\\rho)$-Minimum-Shortcut problem optimally. Finally, we compare the practical performance and quality of all algorithms in an empirical campaign.","sentences":["A graph is called a $(k,\\rho)$-graph iff every node can reach $\\rho$ of its nearest neighbors in at most k hops.","This property proved useful in the analysis and design of parallel shortest-path algorithms.","Any graph can be transformed into a $(k,\\rho)$-graph by adding shortcuts.","Formally, the $(k,\\rho)$-Minimum-Shortcut problem asks to find an appropriate shortcut set of minimal cardinality.   ","We show that the $(k,\\rho)$-Minimum-Shortcut problem is NP-complete in the practical regime of $k \\ge 3$ and $\\rho = \\Theta(n^\\epsilon)$ for $\\epsilon > 0$. With a related construction, we bound the approximation factor of known $(k,\\rho)$-Minimum-Shortcut problem heuristics from below and propose algorithmic countermeasures improving the approximation quality.","Further, we describe an integer linear problem (ILP) solving the $(k,\\rho)$-Minimum-Shortcut problem optimally.","Finally, we compare the practical performance and quality of all algorithms in an empirical campaign."],"url":"http://arxiv.org/abs/2402.07771v1"}
{"created":"2024-02-12 16:32:37","title":"Quantitative knowledge retrieval from large language models","abstract":"Large language models (LLMs) have been extensively studied for their abilities to generate convincing natural language sequences, however their utility for quantitative information retrieval is less well understood. In this paper we explore the feasibility of LLMs as a mechanism for quantitative knowledge retrieval to aid data analysis tasks such as elicitation of prior distributions for Bayesian models and imputation of missing data. We present a prompt engineering framework, treating an LLM as an interface to a latent space of scientific literature, comparing responses in different contexts and domains against more established approaches. Implications and challenges of using LLMs as 'experts' are discussed.","sentences":["Large language models (LLMs) have been extensively studied for their abilities to generate convincing natural language sequences, however their utility for quantitative information retrieval is less well understood.","In this paper we explore the feasibility of LLMs as a mechanism for quantitative knowledge retrieval to aid data analysis tasks such as elicitation of prior distributions for Bayesian models and imputation of missing data.","We present a prompt engineering framework, treating an LLM as an interface to a latent space of scientific literature, comparing responses in different contexts and domains against more established approaches.","Implications and challenges of using LLMs as 'experts' are discussed."],"url":"http://arxiv.org/abs/2402.07770v1"}
{"created":"2024-02-12 16:30:41","title":"Text Detoxification as Style Transfer in English and Hindi","abstract":"This paper focuses on text detoxification, i.e., automatically converting toxic text into non-toxic text. This task contributes to safer and more respectful online communication and can be considered a Text Style Transfer (TST) task, where the text style changes while its content is preserved. We present three approaches: knowledge transfer from a similar task, multi-task learning approach, combining sequence-to-sequence modeling with various toxicity classification tasks, and, delete and reconstruct approach. To support our research, we utilize a dataset provided by Dementieva et al.(2021), which contains multiple versions of detoxified texts corresponding to toxic texts. In our experiments, we selected the best variants through expert human annotators, creating a dataset where each toxic sentence is paired with a single, appropriate detoxified version. Additionally, we introduced a small Hindi parallel dataset, aligning with a part of the English dataset, suitable for evaluation purposes. Our results demonstrate that our approach effectively balances text detoxication while preserving the actual content and maintaining fluency.","sentences":["This paper focuses on text detoxification, i.e., automatically converting toxic text into non-toxic text.","This task contributes to safer and more respectful online communication and can be considered a Text Style Transfer (TST) task, where the text style changes while its content is preserved.","We present three approaches: knowledge transfer from a similar task, multi-task learning approach, combining sequence-to-sequence modeling with various toxicity classification tasks, and, delete and reconstruct approach.","To support our research, we utilize a dataset provided by Dementieva et al.(2021), which contains multiple versions of detoxified texts corresponding to toxic texts.","In our experiments, we selected the best variants through expert human annotators, creating a dataset where each toxic sentence is paired with a single, appropriate detoxified version.","Additionally, we introduced a small Hindi parallel dataset, aligning with a part of the English dataset, suitable for evaluation purposes.","Our results demonstrate that our approach effectively balances text detoxication while preserving the actual content and maintaining fluency."],"url":"http://arxiv.org/abs/2402.07767v1"}
{"created":"2024-02-12 16:25:47","title":"Towards an Understanding of Stepwise Inference in Transformers: A Synthetic Graph Navigation Model","abstract":"Stepwise inference protocols, such as scratchpads and chain-of-thought, help language models solve complex problems by decomposing them into a sequence of simpler subproblems. Despite the significant gain in performance achieved via these protocols, the underlying mechanisms of stepwise inference have remained elusive. To address this, we propose to study autoregressive Transformer models on a synthetic task that embodies the multi-step nature of problems where stepwise inference is generally most useful. Specifically, we define a graph navigation problem wherein a model is tasked with traversing a path from a start to a goal node on the graph. Despite is simplicity, we find we can empirically reproduce and analyze several phenomena observed at scale: (i) the stepwise inference reasoning gap, the cause of which we find in the structure of the training data; (ii) a diversity-accuracy tradeoff in model generations as sampling temperature varies; (iii) a simplicity bias in the model's output; and (iv) compositional generalization and a primacy bias with in-context exemplars. Overall, our work introduces a grounded, synthetic framework for studying stepwise inference and offers mechanistic hypotheses that can lay the foundation for a deeper understanding of this phenomenon.","sentences":["Stepwise inference protocols, such as scratchpads and chain-of-thought, help language models solve complex problems by decomposing them into a sequence of simpler subproblems.","Despite the significant gain in performance achieved via these protocols, the underlying mechanisms of stepwise inference have remained elusive.","To address this, we propose to study autoregressive Transformer models on a synthetic task that embodies the multi-step nature of problems where stepwise inference is generally most useful.","Specifically, we define a graph navigation problem wherein a model is tasked with traversing a path from a start to a goal node on the graph.","Despite is simplicity, we find we can empirically reproduce and analyze several phenomena observed at scale: (i) the stepwise inference reasoning gap, the cause of which we find in the structure of the training data; (ii) a diversity-accuracy tradeoff in model generations as sampling temperature varies; (iii) a simplicity bias in the model's output; and (iv) compositional generalization and a primacy bias with in-context exemplars.","Overall, our work introduces a grounded, synthetic framework for studying stepwise inference and offers mechanistic hypotheses that can lay the foundation for a deeper understanding of this phenomenon."],"url":"http://arxiv.org/abs/2402.07757v1"}
{"created":"2024-02-12 16:23:28","title":"Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models","abstract":"Diffusion models have gained attention in text processing, offering many potential advantages over traditional autoregressive models. This work explores the integration of diffusion models and Chain-of-Thought (CoT), a well-established technique to improve the reasoning ability in autoregressive language models. We propose Diffusion-of-Thought (DoT), allowing reasoning steps to diffuse over time through the diffusion process. In contrast to traditional autoregressive language models that make decisions in a left-to-right, token-by-token manner, DoT offers more flexibility in the trade-off between computation and reasoning performance. Our experimental results demonstrate the effectiveness of DoT in multi-digit multiplication and grade school math problems. Additionally, DoT showcases promising self-correction abilities and benefits from existing reasoning-enhancing techniques like self-consistency decoding. Our findings contribute to the understanding and development of reasoning capabilities in diffusion language models.","sentences":["Diffusion models have gained attention in text processing, offering many potential advantages over traditional autoregressive models.","This work explores the integration of diffusion models and Chain-of-Thought (CoT), a well-established technique to improve the reasoning ability in autoregressive language models.","We propose Diffusion-of-Thought (DoT), allowing reasoning steps to diffuse over time through the diffusion process.","In contrast to traditional autoregressive language models that make decisions in a left-to-right, token-by-token manner, DoT offers more flexibility in the trade-off between computation and reasoning performance.","Our experimental results demonstrate the effectiveness of DoT in multi-digit multiplication and grade school math problems.","Additionally, DoT showcases promising self-correction abilities and benefits from existing reasoning-enhancing techniques like self-consistency decoding.","Our findings contribute to the understanding and development of reasoning capabilities in diffusion language models."],"url":"http://arxiv.org/abs/2402.07754v1"}
{"created":"2024-02-12 16:23:23","title":"Engineering Weighted Connectivity Augmentation Algorithms","abstract":"Increasing the connectivity of a graph is a pivotal challenge in robust network design. The weighted connectivity augmentation problem is a common version of the problem that takes link costs into consideration. The problem is then to find a minimum cost subset of a given set of weighted links that increases the connectivity of a graph by one when the links are added to the edge set of the input instance. In this work, we give a first implementation of recently discovered better-than-2 approximations. Furthermore, we propose three new heuristic and one exact approach. These include a greedy algorithm considering link costs and the number of unique cuts covered, an approach based on minimum spanning trees and a local search algorithm that may improve a given solution by swapping links of paths. Our exact approach uses an ILP formulation with efficient cut enumeration as well as a fast initialization routine. We then perform an extensive experimental evaluation which shows that our algorithms are faster and yield the best solutions compared to the current state-of-the-art as well as the recently discovered better-than-2 approximation algorithms. Our novel local search algorithm can improve solution quality even further.","sentences":["Increasing the connectivity of a graph is a pivotal challenge in robust network design.","The weighted connectivity augmentation problem is a common version of the problem that takes link costs into consideration.","The problem is then to find a minimum cost subset of a given set of weighted links that increases the connectivity of a graph by one when the links are added to the edge set of the input instance.","In this work, we give a first implementation of recently discovered better-than-2 approximations.","Furthermore, we propose three new heuristic and one exact approach.","These include a greedy algorithm considering link costs and the number of unique cuts covered, an approach based on minimum spanning trees and a local search algorithm that may improve a given solution by swapping links of paths.","Our exact approach uses an ILP formulation with efficient cut enumeration as well as a fast initialization routine.","We then perform an extensive experimental evaluation which shows that our algorithms are faster and yield the best solutions compared to the current state-of-the-art as well as the recently discovered better-than-2 approximation algorithms.","Our novel local search algorithm can improve solution quality even further."],"url":"http://arxiv.org/abs/2402.07753v1"}
{"created":"2024-02-12 16:21:50","title":"Mixed Q-Functionals: Advancing Value-Based Methods in Cooperative MARL with Continuous Action Domains","abstract":"Tackling multi-agent learning problems efficiently is a challenging task in continuous action domains. While value-based algorithms excel in sample efficiency when applied to discrete action domains, they are usually inefficient when dealing with continuous actions. Policy-based algorithms, on the other hand, attempt to address this challenge by leveraging critic networks for guiding the learning process and stabilizing the gradient estimation. The limitations in the estimation of true return and falling into local optima in these methods result in inefficient and often sub-optimal policies. In this paper, we diverge from the trend of further enhancing critic networks, and focus on improving the effectiveness of value-based methods in multi-agent continuous domains by concurrently evaluating numerous actions. We propose a novel multi-agent value-based algorithm, Mixed Q-Functionals (MQF), inspired from the idea of Q-Functionals, that enables agents to transform their states into basis functions. Our algorithm fosters collaboration among agents by mixing their action-values. We evaluate the efficacy of our algorithm in six cooperative multi-agent scenarios. Our empirical findings reveal that MQF outperforms four variants of Deep Deterministic Policy Gradient through rapid action evaluation and increased sample efficiency.","sentences":["Tackling multi-agent learning problems efficiently is a challenging task in continuous action domains.","While value-based algorithms excel in sample efficiency when applied to discrete action domains, they are usually inefficient when dealing with continuous actions.","Policy-based algorithms, on the other hand, attempt to address this challenge by leveraging critic networks for guiding the learning process and stabilizing the gradient estimation.","The limitations in the estimation of true return and falling into local optima in these methods result in inefficient and often sub-optimal policies.","In this paper, we diverge from the trend of further enhancing critic networks, and focus on improving the effectiveness of value-based methods in multi-agent continuous domains by concurrently evaluating numerous actions.","We propose a novel multi-agent value-based algorithm, Mixed Q-Functionals (MQF), inspired from the idea of Q-Functionals, that enables agents to transform their states into basis functions.","Our algorithm fosters collaboration among agents by mixing their action-values.","We evaluate the efficacy of our algorithm in six cooperative multi-agent scenarios.","Our empirical findings reveal that MQF outperforms four variants of Deep Deterministic Policy Gradient through rapid action evaluation and increased sample efficiency."],"url":"http://arxiv.org/abs/2402.07752v1"}
{"created":"2024-02-12 16:15:25","title":"Predictive Churn with the Set of Good Models","abstract":"Machine learning models in modern mass-market applications are often updated over time. One of the foremost challenges faced is that, despite increasing overall performance, these updates may flip specific model predictions in unpredictable ways. In practice, researchers quantify the number of unstable predictions between models pre and post update -- i.e., predictive churn. In this paper, we study this effect through the lens of predictive multiplicity -- i.e., the prevalence of conflicting predictions over the set of near-optimal models (the Rashomon set). We show how traditional measures of predictive multiplicity can be used to examine expected churn over this set of prospective models -- i.e., the set of models that may be used to replace a baseline model in deployment. We present theoretical results on the expected churn between models within the Rashomon set from different perspectives. And we characterize expected churn over model updates via the Rashomon set, pairing our analysis with empirical results on real-world datasets -- showing how our approach can be used to better anticipate, reduce, and avoid churn in consumer-facing applications. Further, we show that our approach is useful even for models enhanced with uncertainty awareness.","sentences":["Machine learning models in modern mass-market applications are often updated over time.","One of the foremost challenges faced is that, despite increasing overall performance, these updates may flip specific model predictions in unpredictable ways.","In practice, researchers quantify the number of unstable predictions between models pre and post update -- i.e., predictive churn.","In this paper, we study this effect through the lens of predictive multiplicity -- i.e., the prevalence of conflicting predictions over the set of near-optimal models (the Rashomon set).","We show how traditional measures of predictive multiplicity can be used to examine expected churn over this set of prospective models -- i.e., the set of models that may be used to replace a baseline model in deployment.","We present theoretical results on the expected churn between models within the Rashomon set from different perspectives.","And we characterize expected churn over model updates via the Rashomon set, pairing our analysis with empirical results on real-world datasets -- showing how our approach can be used to better anticipate, reduce, and avoid churn in consumer-facing applications.","Further, we show that our approach is useful even for models enhanced with uncertainty awareness."],"url":"http://arxiv.org/abs/2402.07745v1"}
{"created":"2024-02-12 16:14:22","title":"Towards Unified Alignment Between Agents, Humans, and Environment","abstract":"The rapid progress of foundation models has led to the prosperity of autonomous agents, which leverage the universal capabilities of foundation models to conduct reasoning, decision-making, and environmental interaction. However, the efficacy of agents remains limited when operating in intricate, realistic environments. In this work, we introduce the principles of $\\mathbf{U}$nified $\\mathbf{A}$lignment for $\\mathbf{A}$gents ($\\mathbf{UA}^2$), which advocate for the simultaneous alignment of agents with human intentions, environmental dynamics, and self-constraints such as the limitation of monetary budgets. From the perspective of $\\mathbf{UA}^2$, we review the current agent research and highlight the neglected factors in existing agent benchmarks and method candidates. We also conduct proof-of-concept studies by introducing realistic features to WebShop, including user profiles to demonstrate intentions, personalized reranking for complex environmental dynamics, and runtime cost statistics to reflect self-constraints. We then follow the principles of $\\mathbf{UA}^2$ to propose an initial design of our agent, and benchmark its performance with several candidate baselines in the retrofitted WebShop. The extensive experimental results further prove the importance of the principles of $\\mathbf{UA}^2$. Our research sheds light on the next steps of autonomous agent research with improved general problem-solving abilities.","sentences":["The rapid progress of foundation models has led to the prosperity of autonomous agents, which leverage the universal capabilities of foundation models to conduct reasoning, decision-making, and environmental interaction.","However, the efficacy of agents remains limited when operating in intricate, realistic environments.","In this work, we introduce the principles of $\\mathbf{U}$nified $\\mathbf{A}$lignment for $\\mathbf{A}$gents ($\\mathbf{UA}^2$), which advocate for the simultaneous alignment of agents with human intentions, environmental dynamics, and self-constraints such as the limitation of monetary budgets.","From the perspective of $\\mathbf{UA}^2$, we review the current agent research and highlight the neglected factors in existing agent benchmarks and method candidates.","We also conduct proof-of-concept studies by introducing realistic features to WebShop, including user profiles to demonstrate intentions, personalized reranking for complex environmental dynamics, and runtime cost statistics to reflect self-constraints.","We then follow the principles of $\\mathbf{UA}^2$ to propose an initial design of our agent, and benchmark its performance with several candidate baselines in the retrofitted WebShop.","The extensive experimental results further prove the importance of the principles of $\\mathbf{UA}^2$. Our research sheds light on the next steps of autonomous agent research with improved general problem-solving abilities."],"url":"http://arxiv.org/abs/2402.07744v1"}
{"created":"2024-02-12 16:04:01","title":"Asking Multimodal Clarifying Questions in Mixed-Initiative Conversational Search","abstract":"In mixed-initiative conversational search systems, clarifying questions are used to help users who struggle to express their intentions in a single query. These questions aim to uncover user's information needs and resolve query ambiguities. We hypothesize that in scenarios where multimodal information is pertinent, the clarification process can be improved by using non-textual information. Therefore, we propose to add images to clarifying questions and formulate the novel task of asking multimodal clarifying questions in open-domain, mixed-initiative conversational search systems. To facilitate research into this task, we collect a dataset named Melon that contains over 4k multimodal clarifying questions, enriched with over 14k images. We also propose a multimodal query clarification model named Marto and adopt a prompt-based, generative fine-tuning strategy to perform the training of different stages with different prompts. Several analyses are conducted to understand the importance of multimodal contents during the query clarification phase. Experimental results indicate that the addition of images leads to significant improvements of up to 90% in retrieval performance when selecting the relevant images. Extensive analyses are also performed to show the superiority of Marto compared with discriminative baselines in terms of effectiveness and efficiency.","sentences":["In mixed-initiative conversational search systems, clarifying questions are used to help users who struggle to express their intentions in a single query.","These questions aim to uncover user's information needs and resolve query ambiguities.","We hypothesize that in scenarios where multimodal information is pertinent, the clarification process can be improved by using non-textual information.","Therefore, we propose to add images to clarifying questions and formulate the novel task of asking multimodal clarifying questions in open-domain, mixed-initiative conversational search systems.","To facilitate research into this task, we collect a dataset named Melon that contains over 4k multimodal clarifying questions, enriched with over 14k images.","We also propose a multimodal query clarification model named Marto and adopt a prompt-based, generative fine-tuning strategy to perform the training of different stages with different prompts.","Several analyses are conducted to understand the importance of multimodal contents during the query clarification phase.","Experimental results indicate that the addition of images leads to significant improvements of up to 90% in retrieval performance when selecting the relevant images.","Extensive analyses are also performed to show the superiority of Marto compared with discriminative baselines in terms of effectiveness and efficiency."],"url":"http://arxiv.org/abs/2402.07742v1"}
{"created":"2024-02-12 15:57:31","title":"Task-conditioned adaptation of visual features in multi-task policy learning","abstract":"Successfully addressing a wide variety of tasks is a core ability of autonomous agents, which requires flexibly adapting the underlying decision-making strategies and, as we argue in this work, also adapting the underlying perception modules. An analogical argument would be the human visual system, which uses top-down signals to focus attention determined by the current task. Similarly, in this work, we adapt pre-trained large vision models conditioned on specific downstream tasks in the context of multi-task policy learning. We introduce task-conditioned adapters that do not require finetuning any pre-trained weights, combined with a single policy trained with behavior cloning and capable of addressing multiple tasks. We condition the policy and visual adapters on task embeddings, which can be selected at inference if the task is known, or alternatively inferred from a set of example demonstrations. To this end, we propose a new optimization-based estimator. We evaluate the method on a wide variety of tasks of the CortexBench benchmark and show that, compared to existing work, it can be addressed with a single policy. In particular, we demonstrate that adapting visual features is a key design choice and that the method generalizes to unseen tasks given visual demonstrations.","sentences":["Successfully addressing a wide variety of tasks is a core ability of autonomous agents, which requires flexibly adapting the underlying decision-making strategies and, as we argue in this work, also adapting the underlying perception modules.","An analogical argument would be the human visual system, which uses top-down signals to focus attention determined by the current task.","Similarly, in this work, we adapt pre-trained large vision models conditioned on specific downstream tasks in the context of multi-task policy learning.","We introduce task-conditioned adapters that do not require finetuning any pre-trained weights, combined with a single policy trained with behavior cloning and capable of addressing multiple tasks.","We condition the policy and visual adapters on task embeddings, which can be selected at inference if the task is known, or alternatively inferred from a set of example demonstrations.","To this end, we propose a new optimization-based estimator.","We evaluate the method on a wide variety of tasks of the CortexBench benchmark and show that, compared to existing work, it can be addressed with a single policy.","In particular, we demonstrate that adapting visual features is a key design choice and that the method generalizes to unseen tasks given visual demonstrations."],"url":"http://arxiv.org/abs/2402.07739v1"}
{"created":"2024-02-12 15:52:27","title":"Universal link predictor by In-context Learning","abstract":"Link prediction is a crucial task in graph machine learning, where the goal is to infer missing or future links within a graph. Traditional approaches leverage heuristic methods based on widely observed connectivity patterns, offering broad applicability and generalizability without the need for model training. Despite their utility, these methods are limited by their reliance on human-derived heuristics and lack the adaptability of data-driven approaches. Conversely, parametric link predictors excel in automatically learning the connectivity patterns from data and achieving state-of-the-art but fail short to directly transfer across different graphs. Instead, it requires the cost of extensive training and hyperparameter optimization to adapt to the target graph. In this work, we introduce the Universal Link Predictor (UniLP), a novel model that combines the generalizability of heuristic approaches with the pattern learning capabilities of parametric models. UniLP is designed to autonomously identify connectivity patterns across diverse graphs, ready for immediate application to any unseen graph dataset without targeted training. We address the challenge of conflicting connectivity patterns-arising from the unique distributions of different graphs-through the implementation of In-context Learning (ICL). This approach allows UniLP to dynamically adjust to various target graphs based on contextual demonstrations, thereby avoiding negative transfer. Through rigorous experimentation, we demonstrate UniLP's effectiveness in adapting to new, unseen graphs at test time, showcasing its ability to perform comparably or even outperform parametric models that have been finetuned for specific datasets. Our findings highlight UniLP's potential to set a new standard in link prediction, combining the strengths of heuristic and parametric methods in a single, versatile framework.","sentences":["Link prediction is a crucial task in graph machine learning, where the goal is to infer missing or future links within a graph.","Traditional approaches leverage heuristic methods based on widely observed connectivity patterns, offering broad applicability and generalizability without the need for model training.","Despite their utility, these methods are limited by their reliance on human-derived heuristics and lack the adaptability of data-driven approaches.","Conversely, parametric link predictors excel in automatically learning the connectivity patterns from data and achieving state-of-the-art but fail short to directly transfer across different graphs.","Instead, it requires the cost of extensive training and hyperparameter optimization to adapt to the target graph.","In this work, we introduce the Universal Link Predictor (UniLP), a novel model that combines the generalizability of heuristic approaches with the pattern learning capabilities of parametric models.","UniLP is designed to autonomously identify connectivity patterns across diverse graphs, ready for immediate application to any unseen graph dataset without targeted training.","We address the challenge of conflicting connectivity patterns-arising from the unique distributions of different graphs-through the implementation of In-context Learning (ICL).","This approach allows UniLP to dynamically adjust to various target graphs based on contextual demonstrations, thereby avoiding negative transfer.","Through rigorous experimentation, we demonstrate UniLP's effectiveness in adapting to new, unseen graphs at test time, showcasing its ability to perform comparably or even outperform parametric models that have been finetuned for specific datasets.","Our findings highlight UniLP's potential to set a new standard in link prediction, combining the strengths of heuristic and parametric methods in a single, versatile framework."],"url":"http://arxiv.org/abs/2402.07738v1"}
{"created":"2024-02-12 15:49:19","title":"Multimodal Learned Sparse Retrieval for Image Suggestion","abstract":"Learned Sparse Retrieval (LSR) is a group of neural methods designed to encode queries and documents into sparse lexical vectors. These vectors can be efficiently indexed and retrieved using an inverted index. While LSR has shown promise in text retrieval, its potential in multi-modal retrieval remains largely unexplored. Motivated by this, in this work, we explore the application of LSR in the multi-modal domain, i.e., we focus on Multi-Modal Learned Sparse Retrieval (MLSR). We conduct experiments using several MLSR model configurations and evaluate the performance on the image suggestion task. We find that solving the task solely based on the image content is challenging. Enriching the image content with its caption improves the model performance significantly, implying the importance of image captions to provide fine-grained concepts and context information of images. Our approach presents a practical and effective solution for training LSR retrieval models in multi-modal settings.","sentences":["Learned Sparse Retrieval (LSR) is a group of neural methods designed to encode queries and documents into sparse lexical vectors.","These vectors can be efficiently indexed and retrieved using an inverted index.","While LSR has shown promise in text retrieval, its potential in multi-modal retrieval remains largely unexplored.","Motivated by this, in this work, we explore the application of LSR in the multi-modal domain, i.e., we focus on Multi-Modal Learned Sparse Retrieval (MLSR).","We conduct experiments using several MLSR model configurations and evaluate the performance on the image suggestion task.","We find that solving the task solely based on the image content is challenging.","Enriching the image content with its caption improves the model performance significantly, implying the importance of image captions to provide fine-grained concepts and context information of images.","Our approach presents a practical and effective solution for training LSR retrieval models in multi-modal settings."],"url":"http://arxiv.org/abs/2402.07736v1"}
{"created":"2024-02-12 15:42:50","title":"Pattern Matching with Mismatches and Wildcards","abstract":"In this work, we address the problem of approximate pattern matching with wildcards. Given a pattern $P$ of length $m$ containing $D$ wildcards, a text $T$ of length $n$, and an integer $k$, our objective is to identify all fragments of $T$ within Hamming distance $k$ from $P$.   Our primary contribution is an algorithm with runtime $O(n+(D+k)(G+k)\\cdot n/m)$ for this problem. Here, $G \\le D$ represents the number of maximal wildcard fragments in $P$. We derive this algorithm by elaborating in a non-trivial way on the ideas presented by [Charalampopoulos et al., FOCS'20] for pattern matching with mismatches (without wildcards). Our algorithm improves over the state of the art when $D$, $G$, and $k$ are small relative to $n$. For instance, if $m = n/2$, $k=G=n^{2/5}$, and $D=n^{3/5}$, our algorithm operates in $O(n)$ time, surpassing the $\\Omega(n^{6/5})$ time requirement of all previously known algorithms.   In the case of exact pattern matching with wildcards ($k=0$), we present a much simpler algorithm with runtime $O(n+DG\\cdot n/m)$ that clearly illustrates our main technical innovation: the utilisation of positions of $P$ that do not belong to any fragment of $P$ with a density of wildcards much larger than $D/m$ as anchors for the sought (approximate) occurrences. Notably, our algorithm outperforms the best-known $O(n\\log m)$-time FFT-based algorithms of [Cole and Hariharan, STOC'02] and [Clifford and Clifford, IPL'04] if $DG = o(m\\log m)$.   We complement our algorithmic results with a structural characterization of the $k$-mismatch occurrences of $P$. We demonstrate that in a text of length $O(m)$, these occurrences can be partitioned into $O((D+k)(G+k))$ arithmetic progressions. Additionally, we construct an infinite family of examples with $\\Omega((D+k)k)$ arithmetic progressions of occurrences, leveraging a combinatorial result on progression-free sets [Elkin, SODA'10].","sentences":["In this work, we address the problem of approximate pattern matching with wildcards.","Given a pattern $P$ of length $m$ containing $D$ wildcards, a text $T$ of length $n$, and an integer $k$, our objective is to identify all fragments of $T$ within Hamming distance $k$ from $P$.   Our primary contribution is an algorithm with runtime $O(n+(D+k)(G+k)\\cdot n/m)$ for this problem.","Here, $G \\le D$ represents the number of maximal wildcard fragments in $P$. We derive this algorithm by elaborating in a non-trivial way on the ideas presented by [Charalampopoulos et al., FOCS'20] for pattern matching with mismatches (without wildcards).","Our algorithm improves over the state of the art when $D$, $G$, and $k$ are small relative to $n$. For instance, if $m = n/2$, $k=G=n^{2/5}$, and $D=n^{3/5}$, our algorithm operates in $O(n)$ time, surpassing the $\\Omega(n^{6/5})$ time requirement of all previously known algorithms.   ","In the case of exact pattern matching with wildcards ($k=0$), we present a much simpler algorithm with runtime $O(n+DG\\cdot n/m)$ that clearly illustrates our main technical innovation: the utilisation of positions of $P$ that do not belong to any fragment of $P$ with a density of wildcards much larger than $D/m$ as anchors for the sought (approximate) occurrences.","Notably, our algorithm outperforms the best-known $O(n\\log m)$-time FFT-based algorithms of [Cole and Hariharan, STOC'02] and","[Clifford and Clifford, IPL'04] if $DG = o(m\\log m)$.   We complement our algorithmic results with a structural characterization of the $k$-mismatch occurrences of $P$. We demonstrate that in a text of length $O(m)$, these occurrences can be partitioned into $O((D+k)(G+k))$ arithmetic progressions.","Additionally, we construct an infinite family of examples with $\\Omega((D+k)k)$ arithmetic progressions of occurrences, leveraging a combinatorial result on progression-free sets [Elkin, SODA'10]."],"url":"http://arxiv.org/abs/2402.07732v1"}
{"created":"2024-02-12 15:39:05","title":"Unsupervised Sign Language Translation and Generation","abstract":"Motivated by the success of unsupervised neural machine translation (UNMT), we introduce an unsupervised sign language translation and generation network (USLNet), which learns from abundant single-modality (text and video) data without parallel sign language data. USLNet comprises two main components: single-modality reconstruction modules (text and video) that rebuild the input from its noisy version in the same modality and cross-modality back-translation modules (text-video-text and video-text-video) that reconstruct the input from its noisy version in the different modality using back-translation procedure.Unlike the single-modality back-translation procedure in text-based UNMT, USLNet faces the cross-modality discrepancy in feature representation, in which the length and the feature dimension mismatch between text and video sequences. We propose a sliding window method to address the issues of aligning variable-length text with video sequences. To our knowledge, USLNet is the first unsupervised sign language translation and generation model capable of generating both natural language text and sign language video in a unified manner. Experimental results on the BBC-Oxford Sign Language dataset (BOBSL) and Open-Domain American Sign Language dataset (OpenASL) reveal that USLNet achieves competitive results compared to supervised baseline models, indicating its effectiveness in sign language translation and generation.","sentences":["Motivated by the success of unsupervised neural machine translation (UNMT), we introduce an unsupervised sign language translation and generation network (USLNet), which learns from abundant single-modality (text and video) data without parallel sign language data.","USLNet comprises two main components: single-modality reconstruction modules (text and video) that rebuild the input from its noisy version in the same modality and cross-modality back-translation modules (text-video-text and video-text-video) that reconstruct the input from its noisy version in the different modality using back-translation procedure.","Unlike the single-modality back-translation procedure in text-based UNMT, USLNet faces the cross-modality discrepancy in feature representation, in which the length and the feature dimension mismatch between text and video sequences.","We propose a sliding window method to address the issues of aligning variable-length text with video sequences.","To our knowledge, USLNet is the first unsupervised sign language translation and generation model capable of generating both natural language text and sign language video in a unified manner.","Experimental results on the BBC-Oxford Sign Language dataset (BOBSL) and Open-Domain American Sign Language dataset (OpenASL) reveal that USLNet achieves competitive results compared to supervised baseline models, indicating its effectiveness in sign language translation and generation."],"url":"http://arxiv.org/abs/2402.07726v1"}
{"created":"2024-02-12 15:34:56","title":"LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation","abstract":"Low-Rank Adaptation (LoRA) introduces auxiliary parameters for each layer to fine-tune the pre-trained model under limited computing resources. But it still faces challenges of resource consumption when scaling up to larger models. Previous studies employ pruning techniques by evaluating the importance of LoRA parameters for different layers to address the problem. However, these efforts only analyzed parameter features to evaluate their importance. Indeed, the output of LoRA related to the parameters and data is the factor that directly impacts the frozen model. To this end, we propose LoRA-drop which evaluates the importance of the parameters by analyzing the LoRA output. We retain LoRA for important layers and the LoRA of the other layers share the same parameters. Abundant experiments on NLU and NLG tasks demonstrate the effectiveness of LoRA-drop.","sentences":["Low-Rank Adaptation (LoRA) introduces auxiliary parameters for each layer to fine-tune the pre-trained model under limited computing resources.","But it still faces challenges of resource consumption when scaling up to larger models.","Previous studies employ pruning techniques by evaluating the importance of LoRA parameters for different layers to address the problem.","However, these efforts only analyzed parameter features to evaluate their importance.","Indeed, the output of LoRA related to the parameters and data is the factor that directly impacts the frozen model.","To this end, we propose LoRA-drop which evaluates the importance of the parameters by analyzing the LoRA output.","We retain LoRA for important layers and the LoRA of the other layers share the same parameters.","Abundant experiments on NLU and NLG tasks demonstrate the effectiveness of LoRA-drop."],"url":"http://arxiv.org/abs/2402.07721v1"}
{"created":"2024-02-12 15:34:04","title":"Interaction-Based Driving Scenario Classification and Labeling","abstract":"Scenario data play a vital role in autonomous driving related researches, and it is essential to obtain refined descriptions and labels to extract and index scenarios with different types of interactions. However, existing methods cannot cope well with the problem of scenario classification and comparison with vehicle interactions as the core. In this paper, we propose a framework for interaction-based refined scenario classification and labeling. Based on the summarized basic types of vehicle interactions, we slice scenario data stream into a series of scenario segments via spatiotemporal scenario evolution tree. The scenario segment statistics of many published scenario datasets are further analyzed. We also propose the scenario metric Graph-DTW based on Graph Computation Tree and Dynamic Time Warping to conduct refined scenario comparison and labeling. The extreme interactive scenarios and corner cases can be efficiently filtered and extracted. Moreover, testing examples on trajectory prediction model demonstrate the effectiveness and advantages of scenario labeling and the proposed metric. The overall framework can provide solid support for the usage and indexing of scenario data.","sentences":["Scenario data play a vital role in autonomous driving related researches, and it is essential to obtain refined descriptions and labels to extract and index scenarios with different types of interactions.","However, existing methods cannot cope well with the problem of scenario classification and comparison with vehicle interactions as the core.","In this paper, we propose a framework for interaction-based refined scenario classification and labeling.","Based on the summarized basic types of vehicle interactions, we slice scenario data stream into a series of scenario segments via spatiotemporal scenario evolution tree.","The scenario segment statistics of many published scenario datasets are further analyzed.","We also propose the scenario metric Graph-DTW based on Graph Computation Tree and Dynamic Time Warping to conduct refined scenario comparison and labeling.","The extreme interactive scenarios and corner cases can be efficiently filtered and extracted.","Moreover, testing examples on trajectory prediction model demonstrate the effectiveness and advantages of scenario labeling and the proposed metric.","The overall framework can provide solid support for the usage and indexing of scenario data."],"url":"http://arxiv.org/abs/2402.07720v1"}
{"created":"2024-02-12 15:32:48","title":"Local Centrality Minimization with Quality Guarantees","abstract":"Centrality measures, quantifying the importance of vertices or edges, play a fundamental role in network analysis. To date, triggered by some positive approximability results, a large body of work has been devoted to studying centrality maximization, where the goal is to maximize the centrality score of a target vertex by manipulating the structure of a given network. On the other hand, due to the lack of such results, only very little attention has been paid to centrality minimization, despite its practical usefulness.   In this study, we introduce a novel optimization model for local centrality minimization, where the manipulation is allowed only around the target vertex. We prove the NP-hardness of our model and that the most intuitive greedy algorithm has a quite limited performance in terms of approximation ratio. Then we design two effective approximation algorithms: The first algorithm is a highly-scalable algorithm that has an approximation ratio unachievable by the greedy algorithm, while the second algorithm is a bicriteria approximation algorithm that solves a continuous relaxation based on the Lov\\'asz extension, using a projected subgradient method. To the best of our knowledge, ours are the first polynomial-time algorithms with provable approximation guarantees for centrality minimization. Experiments using a variety of real-world networks demonstrate the effectiveness of our proposed algorithms: Our first algorithm is applicable to million-scale graphs and obtains much better solutions than those of scalable baselines, while our second algorithm is rather strong against adversarial instances.","sentences":["Centrality measures, quantifying the importance of vertices or edges, play a fundamental role in network analysis.","To date, triggered by some positive approximability results, a large body of work has been devoted to studying centrality maximization, where the goal is to maximize the centrality score of a target vertex by manipulating the structure of a given network.","On the other hand, due to the lack of such results, only very little attention has been paid to centrality minimization, despite its practical usefulness.   ","In this study, we introduce a novel optimization model for local centrality minimization, where the manipulation is allowed only around the target vertex.","We prove the NP-hardness of our model and that the most intuitive greedy algorithm has a quite limited performance in terms of approximation ratio.","Then we design two effective approximation algorithms: The first algorithm is a highly-scalable algorithm that has an approximation ratio unachievable by the greedy algorithm, while the second algorithm is a bicriteria approximation algorithm that solves a continuous relaxation based on the Lov\\'asz extension, using a projected subgradient method.","To the best of our knowledge, ours are the first polynomial-time algorithms with provable approximation guarantees for centrality minimization.","Experiments using a variety of real-world networks demonstrate the effectiveness of our proposed algorithms: Our first algorithm is applicable to million-scale graphs and obtains much better solutions than those of scalable baselines, while our second algorithm is rather strong against adversarial instances."],"url":"http://arxiv.org/abs/2402.07718v1"}
{"created":"2024-02-12 15:26:37","title":"Adaptive Artificial Immune Networks for Mitigating DoS flooding Attacks","abstract":"Denial of service attacks pose a threat in constant growth. This is mainly due to their tendency to gain in sophistication, ease of implementation, obfuscation and the recent improvements in occultation of fingerprints. On the other hand, progress towards self-organizing networks, and the different techniques involved in their development, such as software-defined networking, network-function virtualization, artificial intelligence or cloud computing, facilitates the design of new defensive strategies, more complete, consistent and able to adapt the defensive deployment to the current status of the network. In order to contribute to their development, in this paper, the use of artificial immune systems to mitigate denial of service attacks is proposed. The approach is based on building networks of distributed sensors suited to the requirements of the monitored environment. These components are capable of identifying threats and reacting according to the behavior of the biological defense mechanisms in human beings. It is accomplished by emulating the different immune reactions, the establishment of quarantine areas and the construction of immune memory. For their assessment, experiments with public domain datasets (KDD'99, CAIDA'07 and CAIDA'08) and simulations on various network configurations based on traffic samples gathered by the University Complutense of Madrid and flooding attacks generated by the tool DDoSIM were performed.","sentences":["Denial of service attacks pose a threat in constant growth.","This is mainly due to their tendency to gain in sophistication, ease of implementation, obfuscation and the recent improvements in occultation of fingerprints.","On the other hand, progress towards self-organizing networks, and the different techniques involved in their development, such as software-defined networking, network-function virtualization, artificial intelligence or cloud computing, facilitates the design of new defensive strategies, more complete, consistent and able to adapt the defensive deployment to the current status of the network.","In order to contribute to their development, in this paper, the use of artificial immune systems to mitigate denial of service attacks is proposed.","The approach is based on building networks of distributed sensors suited to the requirements of the monitored environment.","These components are capable of identifying threats and reacting according to the behavior of the biological defense mechanisms in human beings.","It is accomplished by emulating the different immune reactions, the establishment of quarantine areas and the construction of immune memory.","For their assessment, experiments with public domain datasets (KDD'99, CAIDA'07 and CAIDA'08) and simulations on various network configurations based on traffic samples gathered by the University Complutense of Madrid and flooding attacks generated by the tool DDoSIM were performed."],"url":"http://arxiv.org/abs/2402.07714v1"}
{"created":"2024-02-12 15:26:01","title":"Model Collapse Demystified: The Case of Regression","abstract":"In the era of large language models like ChatGPT, the phenomenon of \"model collapse\" refers to the situation whereby as a model is trained recursively on data generated from previous generations of itself over time, its performance degrades until the model eventually becomes completely useless, i.e the model collapses. In this work, we study this phenomenon in the simplified setting of kernel regression and obtain results which show a clear crossover between where the model can cope with fake data, and a regime where the model's performance completely collapses. Under polynomial decaying spectral and source conditions, we obtain modified scaling laws which exhibit new crossover phenomena from fast to slow rates. We also propose a simple strategy based on adaptive regularization to mitigate model collapse. Our theoretical results are validated with experiments.","sentences":["In the era of large language models like ChatGPT, the phenomenon of \"model collapse\" refers to the situation whereby as a model is trained recursively on data generated from previous generations of itself over time, its performance degrades until the model eventually becomes completely useless, i.e the model collapses.","In this work, we study this phenomenon in the simplified setting of kernel regression and obtain results which show a clear crossover between where the model can cope with fake data, and a regime where the model's performance completely collapses.","Under polynomial decaying spectral and source conditions, we obtain modified scaling laws which exhibit new crossover phenomena from fast to slow rates.","We also propose a simple strategy based on adaptive regularization to mitigate model collapse.","Our theoretical results are validated with experiments."],"url":"http://arxiv.org/abs/2402.07712v1"}
{"created":"2024-02-12 15:24:44","title":"Near optimal constructions of frameproof codes","abstract":"Frameproof codes are a class of secure codes that were originally introduced in the pioneering work of Boneh and Shaw in the context of digital fingerprinting. They can be used to enhance the security and credibility of digital content. Let $M_{c,l}(q)$ denote the largest cardinality of a $q$-ary $c$-frameproof code with length $l$. Based on an intriguing observation that relates $M_{c,l}(q)$ to the renowned Erd\\H{o}s Matching Conjecture in extremal set theory, in 2003, Blackburn posed an open problem on the precise value of the limit $R_{c,l}=\\lim_{q\\rightarrow\\infty}\\frac{M_{c,l}(q)}{q^{\\lceil l/c \\rceil}}$. By combining several ideas from the probabilistic method, we present a lower bound for $M_{c,l}(q)$, which, together with an upper bound of Blackburn, completely determines $R_{c,l}$ for {\\it all} fixed $c,l$, and resolves the above open problem in the full generality. We also present an improved upper bound for $M_{c,l}(q)$.","sentences":["Frameproof codes are a class of secure codes that were originally introduced in the pioneering work of Boneh and Shaw in the context of digital fingerprinting.","They can be used to enhance the security and credibility of digital content.","Let $M_{c,l}(q)$ denote the largest cardinality of a $q$-ary $c$-frameproof code with length $l$. Based on an intriguing observation that relates $M_{c,l}(q)$ to the renowned Erd\\H{o}s","Matching Conjecture in extremal set theory, in 2003, Blackburn posed an open problem on the precise value of the limit $R_{c,l}=\\lim_{q\\rightarrow\\infty}\\frac{M_{c,l}(q)}{q^{\\lceil l/c \\rceil}}$. By combining several ideas from the probabilistic method, we present a lower bound for $M_{c,l}(q)$, which, together with an upper bound of Blackburn, completely determines $R_{c,l}$ for {\\it all} fixed $c,l$, and resolves the above open problem in the full generality.","We also present an improved upper bound for $M_{c,l}(q)$."],"url":"http://arxiv.org/abs/2402.07711v1"}
{"created":"2024-02-12 15:23:19","title":"Optimization of Sparse Convolution for 3D-Point Cloud on GPUs with CUDA","abstract":"In recent years, there has been a significant increase in the utilization of deep learning methods, particularly convolutional neural networks (CNNs), which have emerged as the dominant approach in various domains that involve structured grid data, such as picture analysis and processing. Nevertheless, the exponential growth in the utilization of LiDAR and 3D sensors across many domains has resulted in an increased need for the analysis of 3D point clouds. The utilization of 3D point clouds is crucial in various applications, including object recognition and segmentation, as they offer a spatial depiction of things within a three-dimensional environment. In contrast to photos, point clouds exhibit sparsity and lack a regular grid, hence posing distinct processing and computational issues.","sentences":["In recent years, there has been a significant increase in the utilization of deep learning methods, particularly convolutional neural networks (CNNs), which have emerged as the dominant approach in various domains that involve structured grid data, such as picture analysis and processing.","Nevertheless, the exponential growth in the utilization of LiDAR and 3D sensors across many domains has resulted in an increased need for the analysis of 3D point clouds.","The utilization of 3D point clouds is crucial in various applications, including object recognition and segmentation, as they offer a spatial depiction of things within a three-dimensional environment.","In contrast to photos, point clouds exhibit sparsity and lack a regular grid, hence posing distinct processing and computational issues."],"url":"http://arxiv.org/abs/2402.07710v1"}
{"created":"2024-02-12 15:21:58","title":"Signed Distance Field based Segmentation and Statistical Shape Modelling of the Left Atrial Appendage","abstract":"Patients with atrial fibrillation have a 5-7 fold increased risk of having an ischemic stroke. In these cases, the most common site of thrombus localization is inside the left atrial appendage (LAA) and studies have shown a correlation between the LAA shape and the risk of ischemic stroke. These studies make use of manual measurement and qualitative assessment of shape and are therefore prone to large inter-observer discrepancies, which may explain the contradictions between the conclusions in different studies. We argue that quantitative shape descriptors are necessary to robustly characterize LAA morphology and relate to other functional parameters and stroke risk.   Deep Learning methods are becoming standardly available for segmenting cardiovascular structures from high resolution images such as computed tomography (CT), but only few have been tested for LAA segmentation. Furthermore, the majority of segmentation algorithms produces non-smooth 3D models that are not ideal for further processing, such as statistical shape analysis or computational fluid modelling. In this paper we present a fully automatic pipeline for image segmentation, mesh model creation and statistical shape modelling of the LAA. The LAA anatomy is implicitly represented as a signed distance field (SDF), which is directly regressed from the CT image using Deep Learning. The SDF is further used for registering the LAA shapes to a common template and build a statistical shape model (SSM). Based on 106 automatically segmented LAAs, the built SSM reveals that the LAA shape can be quantified using approximately 5 PCA modes and allows the identification of two distinct shape clusters corresponding to the so-called chicken-wing and non-chicken-wing morphologies.","sentences":["Patients with atrial fibrillation have a 5-7 fold increased risk of having an ischemic stroke.","In these cases, the most common site of thrombus localization is inside the left atrial appendage (LAA) and studies have shown a correlation between the LAA shape and the risk of ischemic stroke.","These studies make use of manual measurement and qualitative assessment of shape and are therefore prone to large inter-observer discrepancies, which may explain the contradictions between the conclusions in different studies.","We argue that quantitative shape descriptors are necessary to robustly characterize LAA morphology and relate to other functional parameters and stroke risk.   ","Deep Learning methods are becoming standardly available for segmenting cardiovascular structures from high resolution images such as computed tomography (CT), but only few have been tested for LAA segmentation.","Furthermore, the majority of segmentation algorithms produces non-smooth 3D models that are not ideal for further processing, such as statistical shape analysis or computational fluid modelling.","In this paper we present a fully automatic pipeline for image segmentation, mesh model creation and statistical shape modelling of the LAA.","The LAA anatomy is implicitly represented as a signed distance field (SDF), which is directly regressed from the CT image using Deep Learning.","The SDF is further used for registering the LAA shapes to a common template and build a statistical shape model (SSM).","Based on 106 automatically segmented LAAs, the built SSM reveals that the LAA shape can be quantified using approximately 5 PCA modes and allows the identification of two distinct shape clusters corresponding to the so-called chicken-wing and non-chicken-wing morphologies."],"url":"http://arxiv.org/abs/2402.07708v1"}
{"created":"2024-02-12 15:17:31","title":"Online Sequential Decision-Making with Unknown Delays","abstract":"In the field of online sequential decision-making, we address the problem with delays utilizing the framework of online convex optimization (OCO), where the feedback of a decision can arrive with an unknown delay. Unlike previous research that is limited to Euclidean norm and gradient information, we propose three families of delayed algorithms based on approximate solutions to handle different types of received feedback. Our proposed algorithms are versatile and applicable to universal norms. Specifically, we introduce a family of Follow the Delayed Regularized Leader algorithms for feedback with full information on the loss function, a family of Delayed Mirror Descent algorithms for feedback with gradient information on the loss function and a family of Simplified Delayed Mirror Descent algorithms for feedback with the value information of the loss function's gradients at corresponding decision points. For each type of algorithm, we provide corresponding regret bounds under cases of general convexity and relative strong convexity, respectively. We also demonstrate the efficiency of each algorithm under different norms through concrete examples. Furthermore, our theoretical results are consistent with the current best bounds when degenerated to standard settings.","sentences":["In the field of online sequential decision-making, we address the problem with delays utilizing the framework of online convex optimization (OCO), where the feedback of a decision can arrive with an unknown delay.","Unlike previous research that is limited to Euclidean norm and gradient information, we propose three families of delayed algorithms based on approximate solutions to handle different types of received feedback.","Our proposed algorithms are versatile and applicable to universal norms.","Specifically, we introduce a family of Follow the Delayed Regularized Leader algorithms for feedback with full information on the loss function, a family of Delayed Mirror Descent algorithms for feedback with gradient information on the loss function and a family of Simplified Delayed Mirror Descent algorithms for feedback with the value information of the loss function's gradients at corresponding decision points.","For each type of algorithm, we provide corresponding regret bounds under cases of general convexity and relative strong convexity, respectively.","We also demonstrate the efficiency of each algorithm under different norms through concrete examples.","Furthermore, our theoretical results are consistent with the current best bounds when degenerated to standard settings."],"url":"http://arxiv.org/abs/2402.07703v1"}
