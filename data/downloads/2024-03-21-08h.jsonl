{"created":"2024-03-20 17:59:58","title":"On Pretraining Data Diversity for Self-Supervised Learning","abstract":"We explore the impact of training with more diverse datasets, characterized by the number of unique samples, on the performance of self-supervised learning (SSL) under a fixed computational budget. Our findings consistently demonstrate that increasing pretraining data diversity enhances SSL performance, albeit only when the distribution distance to the downstream data is minimal. Notably, even with an exceptionally large pretraining data diversity achieved through methods like web crawling or diffusion-generated data, among other ways, the distribution shift remains a challenge. Our experiments are comprehensive with seven SSL methods using large-scale datasets such as ImageNet and YFCC100M amounting to over 200 GPU days. Code and trained models will be available at https://github.com/hammoudhasan/DiversitySSL .","sentences":["We explore the impact of training with more diverse datasets, characterized by the number of unique samples, on the performance of self-supervised learning (SSL) under a fixed computational budget.","Our findings consistently demonstrate that increasing pretraining data diversity enhances SSL performance, albeit only when the distribution distance to the downstream data is minimal.","Notably, even with an exceptionally large pretraining data diversity achieved through methods like web crawling or diffusion-generated data, among other ways, the distribution shift remains a challenge.","Our experiments are comprehensive with seven SSL methods using large-scale datasets such as ImageNet and YFCC100M amounting to over 200 GPU days.","Code and trained models will be available at https://github.com/hammoudhasan/DiversitySSL ."],"url":"http://arxiv.org/abs/2403.13808v1"}
{"created":"2024-03-20 17:59:57","title":"Editing Massive Concepts in Text-to-Image Diffusion Models","abstract":"Text-to-image diffusion models suffer from the risk of generating outdated, copyrighted, incorrect, and biased content. While previous methods have mitigated the issues on a small scale, it is essential to handle them simultaneously in larger-scale real-world scenarios. We propose a two-stage method, Editing Massive Concepts In Diffusion Models (EMCID). The first stage performs memory optimization for each individual concept with dual self-distillation from text alignment loss and diffusion noise prediction loss. The second stage conducts massive concept editing with multi-layer, closed form model editing. We further propose a comprehensive benchmark, named ImageNet Concept Editing Benchmark (ICEB), for evaluating massive concept editing for T2I models with two subtasks, free-form prompts, massive concept categories, and extensive evaluation metrics. Extensive experiments conducted on our proposed benchmark and previous benchmarks demonstrate the superior scalability of EMCID for editing up to 1,000 concepts, providing a practical approach for fast adjustment and re-deployment of T2I diffusion models in real-world applications.","sentences":["Text-to-image diffusion models suffer from the risk of generating outdated, copyrighted, incorrect, and biased content.","While previous methods have mitigated the issues on a small scale, it is essential to handle them simultaneously in larger-scale real-world scenarios.","We propose a two-stage method, Editing Massive Concepts In Diffusion Models (EMCID).","The first stage performs memory optimization for each individual concept with dual self-distillation from text alignment loss and diffusion noise prediction loss.","The second stage conducts massive concept editing with multi-layer, closed form model editing.","We further propose a comprehensive benchmark, named ImageNet Concept Editing Benchmark (ICEB), for evaluating massive concept editing for T2I models with two subtasks, free-form prompts, massive concept categories, and extensive evaluation metrics.","Extensive experiments conducted on our proposed benchmark and previous benchmarks demonstrate the superior scalability of EMCID for editing up to 1,000 concepts, providing a practical approach for fast adjustment and re-deployment of T2I diffusion models in real-world applications."],"url":"http://arxiv.org/abs/2403.13807v1"}
{"created":"2024-03-20 17:59:55","title":"RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition","abstract":"CLIP (Contrastive Language-Image Pre-training) uses contrastive learning from noise image-text pairs to excel at recognizing a wide array of candidates, yet its focus on broad associations hinders the precision in distinguishing subtle differences among fine-grained items. Conversely, Multimodal Large Language Models (MLLMs) excel at classifying fine-grained categories, thanks to their substantial knowledge from pre-training on web-level corpora. However, the performance of MLLMs declines with an increase in category numbers, primarily due to growing complexity and constraints of limited context window size. To synergize the strengths of both approaches and enhance the few-shot/zero-shot recognition abilities for datasets characterized by extensive and fine-grained vocabularies, this paper introduces RAR, a Retrieving And Ranking augmented method for MLLMs. We initially establish a multi-modal retriever based on CLIP to create and store explicit memory for different categories beyond the immediate context window. During inference, RAR retrieves the top-k similar results from the memory and uses MLLMs to rank and make the final predictions. Our proposed approach not only addresses the inherent limitations in fine-grained recognition but also preserves the model's comprehensive knowledge base, significantly boosting accuracy across a range of vision-language recognition tasks. Notably, our approach demonstrates a significant improvement in performance on 5 fine-grained visual recognition benchmarks, 11 few-shot image recognition datasets, and the 2 object detection datasets under the zero-shot recognition setting.","sentences":["CLIP (Contrastive Language-Image Pre-training) uses contrastive learning from noise image-text pairs to excel at recognizing a wide array of candidates, yet its focus on broad associations hinders the precision in distinguishing subtle differences among fine-grained items.","Conversely, Multimodal Large Language Models (MLLMs) excel at classifying fine-grained categories, thanks to their substantial knowledge from pre-training on web-level corpora.","However, the performance of MLLMs declines with an increase in category numbers, primarily due to growing complexity and constraints of limited context window size.","To synergize the strengths of both approaches and enhance the few-shot/zero-shot recognition abilities for datasets characterized by extensive and fine-grained vocabularies, this paper introduces RAR, a Retrieving And Ranking augmented method for MLLMs.","We initially establish a multi-modal retriever based on CLIP to create and store explicit memory for different categories beyond the immediate context window.","During inference, RAR retrieves the top-k similar results from the memory and uses MLLMs to rank and make the final predictions.","Our proposed approach not only addresses the inherent limitations in fine-grained recognition but also preserves the model's comprehensive knowledge base, significantly boosting accuracy across a range of vision-language recognition tasks.","Notably, our approach demonstrates a significant improvement in performance on 5 fine-grained visual recognition benchmarks, 11 few-shot image recognition datasets, and the 2 object detection datasets under the zero-shot recognition setting."],"url":"http://arxiv.org/abs/2403.13805v1"}
{"created":"2024-03-20 17:59:55","title":"RadSplat: Radiance Field-Informed Gaussian Splatting for Robust Real-Time Rendering with 900+ FPS","abstract":"Recent advances in view synthesis and real-time rendering have achieved photorealistic quality at impressive rendering speeds. While Radiance Field-based methods achieve state-of-the-art quality in challenging scenarios such as in-the-wild captures and large-scale scenes, they often suffer from excessively high compute requirements linked to volumetric rendering. Gaussian Splatting-based methods, on the other hand, rely on rasterization and naturally achieve real-time rendering but suffer from brittle optimization heuristics that underperform on more challenging scenes. In this work, we present RadSplat, a lightweight method for robust real-time rendering of complex scenes. Our main contributions are threefold. First, we use radiance fields as a prior and supervision signal for optimizing point-based scene representations, leading to improved quality and more robust optimization. Next, we develop a novel pruning technique reducing the overall point count while maintaining high quality, leading to smaller and more compact scene representations with faster inference speeds. Finally, we propose a novel test-time filtering approach that further accelerates rendering and allows to scale to larger, house-sized scenes. We find that our method enables state-of-the-art synthesis of complex captures at 900+ FPS.","sentences":["Recent advances in view synthesis and real-time rendering have achieved photorealistic quality at impressive rendering speeds.","While Radiance Field-based methods achieve state-of-the-art quality in challenging scenarios such as in-the-wild captures and large-scale scenes, they often suffer from excessively high compute requirements linked to volumetric rendering.","Gaussian Splatting-based methods, on the other hand, rely on rasterization and naturally achieve real-time rendering but suffer from brittle optimization heuristics that underperform on more challenging scenes.","In this work, we present RadSplat, a lightweight method for robust real-time rendering of complex scenes.","Our main contributions are threefold.","First, we use radiance fields as a prior and supervision signal for optimizing point-based scene representations, leading to improved quality and more robust optimization.","Next, we develop a novel pruning technique reducing the overall point count while maintaining high quality, leading to smaller and more compact scene representations with faster inference speeds.","Finally, we propose a novel test-time filtering approach that further accelerates rendering and allows to scale to larger, house-sized scenes.","We find that our method enables state-of-the-art synthesis of complex captures at 900+ FPS."],"url":"http://arxiv.org/abs/2403.13806v1"}
{"created":"2024-03-20 17:59:43","title":"Learning from Models and Data for Visual Grounding","abstract":"We introduce SynGround, a novel framework that combines data-driven learning and knowledge transfer from various large-scale pretrained models to enhance the visual grounding capabilities of a pretrained vision-and-language model. The knowledge transfer from the models initiates the generation of image descriptions through an image description generator. These descriptions serve dual purposes: they act as prompts for synthesizing images through a text-to-image generator, and as queries for synthesizing text, from which phrases are extracted using a large language model. Finally, we leverage an open-vocabulary object detector to generate synthetic bounding boxes for the synthetic images and texts. We finetune a pretrained vision-and-language model on this dataset by optimizing a mask-attention consistency objective that aligns region annotations with gradient-based model explanations. The resulting model improves the grounding capabilities of an off-the-shelf vision-and-language model. Particularly, SynGround improves the pointing game accuracy of ALBEF on the Flickr30k dataset from 79.38% to 87.26%, and on RefCOCO+ Test A from 69.35% to 79.06% and on RefCOCO+ Test B from 53.77% to 63.67%.","sentences":["We introduce SynGround, a novel framework that combines data-driven learning and knowledge transfer from various large-scale pretrained models to enhance the visual grounding capabilities of a pretrained vision-and-language model.","The knowledge transfer from the models initiates the generation of image descriptions through an image description generator.","These descriptions serve dual purposes: they act as prompts for synthesizing images through a text-to-image generator, and as queries for synthesizing text, from which phrases are extracted using a large language model.","Finally, we leverage an open-vocabulary object detector to generate synthetic bounding boxes for the synthetic images and texts.","We finetune a pretrained vision-and-language model on this dataset by optimizing a mask-attention consistency objective that aligns region annotations with gradient-based model explanations.","The resulting model improves the grounding capabilities of an off-the-shelf vision-and-language model.","Particularly, SynGround improves the pointing game accuracy of ALBEF on the Flickr30k dataset from 79.38% to 87.26%, and on RefCOCO+ Test A from 69.35% to 79.06% and on RefCOCO+ Test B from 53.77% to 63.67%."],"url":"http://arxiv.org/abs/2403.13804v1"}
{"created":"2024-03-20 17:59:16","title":"Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments","abstract":"Bounding boxes uniquely characterize object detection, where a good detector gives accurate bounding boxes of categories of interest. However, in the real-world where test ground truths are not provided, it is non-trivial to find out whether bounding boxes are accurate, thus preventing us from assessing the detector generalization ability. In this work, we find under feature map dropout, good detectors tend to output bounding boxes whose locations do not change much, while bounding boxes of poor detectors will undergo noticeable position changes. We compute the box stability score (BoS score) to reflect this stability. Specifically, given an image, we compute a normal set of bounding boxes and a second set after feature map dropout. To obtain BoS score, we use bipartite matching to find the corresponding boxes between the two sets and compute the average Intersection over Union (IoU) across the entire test set. We contribute to finding that BoS score has a strong, positive correlation with detection accuracy measured by mean average precision (mAP) under various test environments. This relationship allows us to predict the accuracy of detectors on various real-world test sets without accessing test ground truths, verified on canonical detection tasks such as vehicle detection and pedestrian detection. Code and data are available at https://github.com/YangYangGirl/BoS.","sentences":["Bounding boxes uniquely characterize object detection, where a good detector gives accurate bounding boxes of categories of interest.","However, in the real-world where test ground truths are not provided, it is non-trivial to find out whether bounding boxes are accurate, thus preventing us from assessing the detector generalization ability.","In this work, we find under feature map dropout, good detectors tend to output bounding boxes whose locations do not change much, while bounding boxes of poor detectors will undergo noticeable position changes.","We compute the box stability score (BoS score) to reflect this stability.","Specifically, given an image, we compute a normal set of bounding boxes and a second set after feature map dropout.","To obtain BoS score, we use bipartite matching to find the corresponding boxes between the two sets and compute the average Intersection over Union (IoU) across the entire test set.","We contribute to finding that BoS score has a strong, positive correlation with detection accuracy measured by mean average precision (mAP) under various test environments.","This relationship allows us to predict the accuracy of detectors on various real-world test sets without accessing test ground truths, verified on canonical detection tasks such as vehicle detection and pedestrian detection.","Code and data are available at https://github.com/YangYangGirl/BoS."],"url":"http://arxiv.org/abs/2403.13803v1"}
{"created":"2024-03-20 17:59:14","title":"ZigMa: Zigzag Mamba Diffusion Model","abstract":"The diffusion model has long been plagued by scalability and quadratic complexity issues, especially within transformer-based structures. In this study, we aim to leverage the long sequence modeling capability of a State-Space Model called Mamba to extend its applicability to visual data generation. Firstly, we identify a critical oversight in most current Mamba-based vision methods, namely the lack of consideration for spatial continuity in the scan scheme of Mamba. Secondly, building upon this insight, we introduce a simple, plug-and-play, zero-parameter method named Zigzag Mamba, which outperforms Mamba-based baselines and demonstrates improved speed and memory utilization compared to transformer-based baselines. Lastly, we integrate Zigzag Mamba with the Stochastic Interpolant framework to investigate the scalability of the model on large-resolution visual datasets, such as FacesHQ $1024\\times 1024$ and UCF101, MultiModal-CelebA-HQ, and MS COCO $256\\times 256$. Code will be released at https://taohu.me/zigma/","sentences":["The diffusion model has long been plagued by scalability and quadratic complexity issues, especially within transformer-based structures.","In this study, we aim to leverage the long sequence modeling capability of a State-Space Model called Mamba to extend its applicability to visual data generation.","Firstly, we identify a critical oversight in most current Mamba-based vision methods, namely the lack of consideration for spatial continuity in the scan scheme of Mamba.","Secondly, building upon this insight, we introduce a simple, plug-and-play, zero-parameter method named Zigzag Mamba, which outperforms Mamba-based baselines and demonstrates improved speed and memory utilization compared to transformer-based baselines.","Lastly, we integrate Zigzag Mamba with the Stochastic Interpolant framework to investigate the scalability of the model on large-resolution visual datasets, such as FacesHQ $1024\\times 1024$ and UCF101, MultiModal-CelebA-HQ, and MS COCO $256\\times 256$. Code will be released at https://taohu.me/zigma/"],"url":"http://arxiv.org/abs/2403.13802v1"}
{"created":"2024-03-20 17:58:12","title":"Natural Language as Polices: Reasoning for Coordinate-Level Embodied Control with LLMs","abstract":"We demonstrate experimental results with LLMs that address robotics action planning problems. Recently, LLMs have been applied in robotics action planning, particularly using a code generation approach that converts complex high-level instructions into mid-level policy codes. In contrast, our approach acquires text descriptions of the task and scene objects, then formulates action planning through natural language reasoning, and outputs coordinate level control commands, thus reducing the necessity for intermediate representation code as policies. Our approach is evaluated on a multi-modal prompt simulation benchmark, demonstrating that our prompt engineering experiments with natural language reasoning significantly enhance success rates compared to its absence. Furthermore, our approach illustrates the potential for natural language descriptions to transfer robotics skills from known tasks to previously unseen tasks.","sentences":["We demonstrate experimental results with LLMs that address robotics action planning problems.","Recently, LLMs have been applied in robotics action planning, particularly using a code generation approach that converts complex high-level instructions into mid-level policy codes.","In contrast, our approach acquires text descriptions of the task and scene objects, then formulates action planning through natural language reasoning, and outputs coordinate level control commands, thus reducing the necessity for intermediate representation code as policies.","Our approach is evaluated on a multi-modal prompt simulation benchmark, demonstrating that our prompt engineering experiments with natural language reasoning significantly enhance success rates compared to its absence.","Furthermore, our approach illustrates the potential for natural language descriptions to transfer robotics skills from known tasks to previously unseen tasks."],"url":"http://arxiv.org/abs/2403.13801v1"}
{"created":"2024-03-20 17:57:02","title":"TimeRewind: Rewinding Time with Image-and-Events Video Diffusion","abstract":"This paper addresses the novel challenge of ``rewinding'' time from a single captured image to recover the fleeting moments missed just before the shutter button is pressed. This problem poses a significant challenge in computer vision and computational photography, as it requires predicting plausible pre-capture motion from a single static frame, an inherently ill-posed task due to the high degree of freedom in potential pixel movements. We overcome this challenge by leveraging the emerging technology of neuromorphic event cameras, which capture motion information with high temporal resolution, and integrating this data with advanced image-to-video diffusion models. Our proposed framework introduces an event motion adaptor conditioned on event camera data, guiding the diffusion model to generate videos that are visually coherent and physically grounded in the captured events. Through extensive experimentation, we demonstrate the capability of our approach to synthesize high-quality videos that effectively ``rewind'' time, showcasing the potential of combining event camera technology with generative models. Our work opens new avenues for research at the intersection of computer vision, computational photography, and generative modeling, offering a forward-thinking solution to capturing missed moments and enhancing future consumer cameras and smartphones. Please see the project page at https://timerewind.github.io/ for video results and code release.","sentences":["This paper addresses the novel challenge of ``rewinding'' time from a single captured image to recover the fleeting moments missed just before the shutter button is pressed.","This problem poses a significant challenge in computer vision and computational photography, as it requires predicting plausible pre-capture motion from a single static frame, an inherently ill-posed task due to the high degree of freedom in potential pixel movements.","We overcome this challenge by leveraging the emerging technology of neuromorphic event cameras, which capture motion information with high temporal resolution, and integrating this data with advanced image-to-video diffusion models.","Our proposed framework introduces an event motion adaptor conditioned on event camera data, guiding the diffusion model to generate videos that are visually coherent and physically grounded in the captured events.","Through extensive experimentation, we demonstrate the capability of our approach to synthesize high-quality videos that effectively ``rewind'' time, showcasing the potential of combining event camera technology with generative models.","Our work opens new avenues for research at the intersection of computer vision, computational photography, and generative modeling, offering a forward-thinking solution to capturing missed moments and enhancing future consumer cameras and smartphones.","Please see the project page at https://timerewind.github.io/ for video results and code release."],"url":"http://arxiv.org/abs/2403.13800v1"}
{"created":"2024-03-20 17:55:35","title":"Reverse Training to Nurse the Reversal Curse","abstract":"Large language models (LLMs) have a surprising failure: when trained on \"A has a feature B\", they do not generalize to \"B is a feature of A\", which is termed the Reversal Curse. Even when training with trillions of tokens this issue still appears due to Zipf's law - hence even if we train on the entire internet. This work proposes an alternative training scheme, called reverse training, whereby all words are used twice, doubling the amount of available tokens. The LLM is trained in both forward and reverse directions by reversing the training strings while preserving (i.e., not reversing) chosen substrings, such as entities. We show that data-matched reverse-trained models provide superior performance to standard models on standard tasks, and compute-matched reverse-trained models provide far superior performance on reversal tasks, helping resolve the reversal curse issue.","sentences":["Large language models (LLMs) have a surprising failure: when trained on \"A has a feature B\", they do not generalize to \"B is a feature of A\", which is termed the Reversal Curse.","Even when training with trillions of tokens this issue still appears due to Zipf's law - hence even if we train on the entire internet.","This work proposes an alternative training scheme, called reverse training, whereby all words are used twice, doubling the amount of available tokens.","The LLM is trained in both forward and reverse directions by reversing the training strings while preserving (i.e., not reversing) chosen substrings, such as entities.","We show that data-matched reverse-trained models provide superior performance to standard models on standard tasks, and compute-matched reverse-trained models provide far superior performance on reversal tasks, helping resolve the reversal curse issue."],"url":"http://arxiv.org/abs/2403.13799v1"}
{"created":"2024-03-20 17:55:21","title":"Hierarchical NeuroSymbolic Approach for Action Quality Assessment","abstract":"Action quality assessment (AQA) applies computer vision to quantitatively assess the performance or execution of a human action. Current AQA approaches are end-to-end neural models, which lack transparency and tend to be biased because they are trained on subjective human judgements as ground-truth. To address these issues, we introduce a neuro-symbolic paradigm for AQA, which uses neural networks to abstract interpretable symbols from video data and makes quality assessments by applying rules to those symbols. We take diving as the case study. We found that domain experts prefer our system and find it more informative than purely neural approaches to AQA in diving. Our system also achieves state-of-the-art action recognition and temporal segmentation, and automatically generates a detailed report that breaks the dive down into its elements and provides objective scoring with visual evidence. As verified by a group of domain experts, this report may be used to assist judges in scoring, help train judges, and provide feedback to divers. We will open-source all of our annotated training data and code for ease of reproducibility.","sentences":["Action quality assessment (AQA) applies computer vision to quantitatively assess the performance or execution of a human action.","Current AQA approaches are end-to-end neural models, which lack transparency and tend to be biased because they are trained on subjective human judgements as ground-truth.","To address these issues, we introduce a neuro-symbolic paradigm for AQA, which uses neural networks to abstract interpretable symbols from video data and makes quality assessments by applying rules to those symbols.","We take diving as the case study.","We found that domain experts prefer our system and find it more informative than purely neural approaches to AQA in diving.","Our system also achieves state-of-the-art action recognition and temporal segmentation, and automatically generates a detailed report that breaks the dive down into its elements and provides objective scoring with visual evidence.","As verified by a group of domain experts, this report may be used to assist judges in scoring, help train judges, and provide feedback to divers.","We will open-source all of our annotated training data and code for ease of reproducibility."],"url":"http://arxiv.org/abs/2403.13798v1"}
{"created":"2024-03-20 17:54:58","title":"Bridge the Modality and Capacity Gaps in Vision-Language Model Selection","abstract":"Vision Language Models (VLMs) excel in zero-shot image classification by pairing images with textual category names. The expanding variety of Pre-Trained VLMs enhances the likelihood of identifying a suitable VLM for specific tasks. Thus, a promising zero-shot image classification strategy is selecting the most appropriate Pre-Trained VLM from the VLM Zoo, relying solely on the text data of the target dataset without access to the dataset's images. In this paper, we analyze two inherent challenges in assessing the ability of a VLM in this Language-Only VLM selection: the \"Modality Gap\" -- the disparity in VLM's embeddings across two different modalities, making text a less reliable substitute for images; and the \"Capability Gap\" -- the discrepancy between the VLM's overall ranking and its ranking for target dataset, hindering direct prediction of a model's dataset-specific performance from its general performance. We propose VLM Selection With gAp Bridging (SWAB) to mitigate the negative impact of these two gaps. SWAB first adopts optimal transport to capture the relevance between open-source datasets and target dataset with a transportation matrix. It then uses this matrix to transfer useful statistics of VLMs from open-source datasets to the target dataset for bridging those two gaps and enhancing the VLM's capacity estimation for VLM selection. Experiments across various VLMs and image classification datasets validate SWAB's effectiveness.","sentences":["Vision Language Models (VLMs) excel in zero-shot image classification by pairing images with textual category names.","The expanding variety of Pre-Trained VLMs enhances the likelihood of identifying a suitable VLM for specific tasks.","Thus, a promising zero-shot image classification strategy is selecting the most appropriate Pre-Trained VLM from the VLM Zoo, relying solely on the text data of the target dataset without access to the dataset's images.","In this paper, we analyze two inherent challenges in assessing the ability of a VLM in this Language-Only VLM selection: the \"Modality Gap\" -- the disparity in VLM's embeddings across two different modalities, making text a less reliable substitute for images; and the \"Capability Gap\" -- the discrepancy between the VLM's overall ranking and its ranking for target dataset, hindering direct prediction of a model's dataset-specific performance from its general performance.","We propose VLM Selection With gAp Bridging (SWAB) to mitigate the negative impact of these two gaps.","SWAB first adopts optimal transport to capture the relevance between open-source datasets and target dataset with a transportation matrix.","It then uses this matrix to transfer useful statistics of VLMs from open-source datasets to the target dataset for bridging those two gaps and enhancing the VLM's capacity estimation for VLM selection.","Experiments across various VLMs and image classification datasets validate SWAB's effectiveness."],"url":"http://arxiv.org/abs/2403.13797v1"}
{"created":"2024-03-20 17:54:26","title":"Evaluating Frontier Models for Dangerous Capabilities","abstract":"To understand the risks posed by a new AI system, we must understand what it can and cannot do. Building on prior work, we introduce a programme of new \"dangerous capability\" evaluations and pilot them on Gemini 1.0 models. Our evaluations cover four areas: (1) persuasion and deception; (2) cyber-security; (3) self-proliferation; and (4) self-reasoning. We do not find evidence of strong dangerous capabilities in the models we evaluated, but we flag early warning signs. Our goal is to help advance a rigorous science of dangerous capability evaluation, in preparation for future models.","sentences":["To understand the risks posed by a new AI system, we must understand what it can and cannot do.","Building on prior work, we introduce a programme of new \"dangerous capability\" evaluations and pilot them on Gemini 1.0 models.","Our evaluations cover four areas: (1) persuasion and deception; (2) cyber-security; (3) self-proliferation; and (4) self-reasoning.","We do not find evidence of strong dangerous capabilities in the models we evaluated, but we flag early warning signs.","Our goal is to help advance a rigorous science of dangerous capability evaluation, in preparation for future models."],"url":"http://arxiv.org/abs/2403.13793v1"}
{"created":"2024-03-20 17:51:53","title":"DepthFM: Fast Monocular Depth Estimation with Flow Matching","abstract":"Monocular depth estimation is crucial for numerous downstream vision tasks and applications. Current discriminative approaches to this problem are limited due to blurry artifacts, while state-of-the-art generative methods suffer from slow sampling due to their SDE nature. Rather than starting from noise, we seek a direct mapping from input image to depth map. We observe that this can be effectively framed using flow matching, since its straight trajectories through solution space offer efficiency and high quality. Our study demonstrates that a pre-trained image diffusion model can serve as an adequate prior for a flow matching depth model, allowing efficient training on only synthetic data to generalize to real images. We find that an auxiliary surface normals loss further improves the depth estimates. Due to the generative nature of our approach, our model reliably predicts the confidence of its depth estimates. On standard benchmarks of complex natural scenes, our lightweight approach exhibits state-of-the-art performance at favorable low computational cost despite only being trained on little synthetic data.","sentences":["Monocular depth estimation is crucial for numerous downstream vision tasks and applications.","Current discriminative approaches to this problem are limited due to blurry artifacts, while state-of-the-art generative methods suffer from slow sampling due to their SDE nature.","Rather than starting from noise, we seek a direct mapping from input image to depth map.","We observe that this can be effectively framed using flow matching, since its straight trajectories through solution space offer efficiency and high quality.","Our study demonstrates that a pre-trained image diffusion model can serve as an adequate prior for a flow matching depth model, allowing efficient training on only synthetic data to generalize to real images.","We find that an auxiliary surface normals loss further improves the depth estimates.","Due to the generative nature of our approach, our model reliably predicts the confidence of its depth estimates.","On standard benchmarks of complex natural scenes, our lightweight approach exhibits state-of-the-art performance at favorable low computational cost despite only being trained on little synthetic data."],"url":"http://arxiv.org/abs/2403.13788v1"}
{"created":"2024-03-20 17:49:54","title":"RewardBench: Evaluating Reward Models for Language Modeling","abstract":"Reward models (RMs) are at the crux of successful RLHF to align pretrained models to human preferences, yet there has been relatively little study that focuses on evaluation of those reward models. Evaluating reward models presents an opportunity to understand the opaque technologies used for alignment of language models and which values are embedded in them. To date, very few descriptors of capabilities, training methods, or open-source reward models exist. In this paper, we present RewardBench, a benchmark dataset and code-base for evaluation, to enhance scientific understanding of reward models. The RewardBench dataset is a collection of prompt-win-lose trios spanning chat, reasoning, and safety, to benchmark how reward models perform on challenging, structured and out-of-distribution queries. We created specific comparison datasets for RMs that have subtle, but verifiable reasons (e.g. bugs, incorrect facts) why one answer should be preferred to another. On the RewardBench leaderboard, we evaluate reward models trained with a variety of methods, such as the direct MLE training of classifiers and the implicit reward modeling of Direct Preference Optimization (DPO), and on a spectrum of datasets. We present many findings on propensity for refusals, reasoning limitations, and instruction following shortcomings of various reward models towards a better understanding of the RLHF process.","sentences":["Reward models (RMs) are at the crux of successful RLHF to align pretrained models to human preferences, yet there has been relatively little study that focuses on evaluation of those reward models.","Evaluating reward models presents an opportunity to understand the opaque technologies used for alignment of language models and which values are embedded in them.","To date, very few descriptors of capabilities, training methods, or open-source reward models exist.","In this paper, we present RewardBench, a benchmark dataset and code-base for evaluation, to enhance scientific understanding of reward models.","The RewardBench dataset is a collection of prompt-win-lose trios spanning chat, reasoning, and safety, to benchmark how reward models perform on challenging, structured and out-of-distribution queries.","We created specific comparison datasets for RMs that have subtle, but verifiable reasons (e.g. bugs, incorrect facts) why one answer should be preferred to another.","On the RewardBench leaderboard, we evaluate reward models trained with a variety of methods, such as the direct MLE training of classifiers and the implicit reward modeling of Direct Preference Optimization (DPO), and on a spectrum of datasets.","We present many findings on propensity for refusals, reasoning limitations, and instruction following shortcomings of various reward models towards a better understanding of the RLHF process."],"url":"http://arxiv.org/abs/2403.13787v1"}
{"created":"2024-03-20 17:47:49","title":"Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts","abstract":"Automatic coding patient behaviors is essential to support decision making for psychotherapists during the motivational interviewing (MI), a collaborative communication intervention approach to address psychiatric issues, such as alcohol and drug addiction. While the behavior coding task has rapidly adapted machine learning to predict patient states during the MI sessions, lacking of domain-specific knowledge and overlooking patient-therapist interactions are major challenges in developing and deploying those models in real practice. To encounter those challenges, we introduce the Chain-of-Interaction (CoI) prompting method aiming to contextualize large language models (LLMs) for psychiatric decision support by the dyadic interactions. The CoI prompting approach systematically breaks down the coding task into three key reasoning steps, extract patient engagement, learn therapist question strategies, and integrates dyadic interactions between patients and therapists. This approach enables large language models to leverage the coding scheme, patient state, and domain knowledge for patient behavioral coding. Experiments on real-world datasets can prove the effectiveness and flexibility of our prompting method with multiple state-of-the-art LLMs over existing prompting baselines. We have conducted extensive ablation analysis and demonstrate the critical role of dyadic interactions in applying LLMs for psychotherapy behavior understanding.","sentences":["Automatic coding patient behaviors is essential to support decision making for psychotherapists during the motivational interviewing (MI), a collaborative communication intervention approach to address psychiatric issues, such as alcohol and drug addiction.","While the behavior coding task has rapidly adapted machine learning to predict patient states during the MI sessions, lacking of domain-specific knowledge and overlooking patient-therapist interactions are major challenges in developing and deploying those models in real practice.","To encounter those challenges, we introduce the Chain-of-Interaction (CoI) prompting method aiming to contextualize large language models (LLMs) for psychiatric decision support by the dyadic interactions.","The CoI prompting approach systematically breaks down the coding task into three key reasoning steps, extract patient engagement, learn therapist question strategies, and integrates dyadic interactions between patients and therapists.","This approach enables large language models to leverage the coding scheme, patient state, and domain knowledge for patient behavioral coding.","Experiments on real-world datasets can prove the effectiveness and flexibility of our prompting method with multiple state-of-the-art LLMs over existing prompting baselines.","We have conducted extensive ablation analysis and demonstrate the critical role of dyadic interactions in applying LLMs for psychotherapy behavior understanding."],"url":"http://arxiv.org/abs/2403.13786v1"}
{"created":"2024-03-20 17:47:25","title":"Towards an extension of Fault Trees in the Predictive Maintenance Scenario","abstract":"One of the most appreciated features of Fault Trees (FTs) is their simplicity, making them fit into industrial processes. As such processes evolve in time, considering new aspects of large modern systems, modelling techniques based on FTs have adapted to these needs. This paper proposes an extension of FTs to take into account the problem of Predictive Maintenance, one of the challenges of the modern dependability field of study. The paper sketches the Predictive Fault Tree language and proposes some use cases to support their modelling and analysis in concrete industrial settings.","sentences":["One of the most appreciated features of Fault Trees (FTs) is their simplicity, making them fit into industrial processes.","As such processes evolve in time, considering new aspects of large modern systems, modelling techniques based on FTs have adapted to these needs.","This paper proposes an extension of FTs to take into account the problem of Predictive Maintenance, one of the challenges of the modern dependability field of study.","The paper sketches the Predictive Fault Tree language and proposes some use cases to support their modelling and analysis in concrete industrial settings."],"url":"http://arxiv.org/abs/2403.13785v1"}
{"created":"2024-03-20 17:47:08","title":"The Model Openness Framework: Promoting Completeness and Openness for Reproducibility, Transparency and Usability in AI","abstract":"Generative AI (GAI) offers unprecedented possibilities but its commercialization has raised concerns about transparency, reproducibility, bias, and safety. Many \"open-source\" GAI models lack the necessary components for full understanding and reproduction, and some use restrictive licenses, a practice known as \"openwashing.\" We propose the Model Openness Framework (MOF), a ranked classification system that rates machine learning models based on their completeness and openness, following principles of open science, open source, open data, and open access. The MOF requires specific components of the model development lifecycle to be included and released under appropriate open licenses. This framework aims to prevent misrepresentation of models claiming to be open, guide researchers and developers in providing all model components under permissive licenses, and help companies, academia, and hobbyists identify models that can be safely adopted without restrictions. Wide adoption of the MOF will foster a more open AI ecosystem, accelerating research, innovation, and adoption.","sentences":["Generative AI (GAI) offers unprecedented possibilities but its commercialization has raised concerns about transparency, reproducibility, bias, and safety.","Many \"open-source\" GAI models lack the necessary components for full understanding and reproduction, and some use restrictive licenses, a practice known as \"openwashing.\"","We propose the Model Openness Framework (MOF), a ranked classification system that rates machine learning models based on their completeness and openness, following principles of open science, open source, open data, and open access.","The MOF requires specific components of the model development lifecycle to be included and released under appropriate open licenses.","This framework aims to prevent misrepresentation of models claiming to be open, guide researchers and developers in providing all model components under permissive licenses, and help companies, academia, and hobbyists identify models that can be safely adopted without restrictions.","Wide adoption of the MOF will foster a more open AI ecosystem, accelerating research, innovation, and adoption."],"url":"http://arxiv.org/abs/2403.13784v1"}
{"created":"2024-03-20 17:44:33","title":"A Convex Formulation of Frictional Contact for the Material Point Method and Rigid Bodies","abstract":"In this paper, we introduce a novel convex formulation that seamlessly integrates the Material Point Method (MPM) with articulated rigid body dynamics in frictional contact scenarios. We extend the linear corotational hyperelastic model into the realm of elastoplasticity and include an efficient return mapping algorithm. This approach is particularly effective for MPM simulations involving significant deformation and topology changes, while preserving the convexity of the optimization problem. Our method ensures global convergence, enabling the use of large simulation time steps without compromising robustness. We have validated our approach through rigorous testing and performance evaluations, highlighting its superior capabilities in managing complex simulations relevant to robotics. Compared to previous MPM based robotic simulators, our method significantly improves the stability of contact resolution -- a critical factor in robot manipulation tasks. We make our method available in the open-source robotics toolkit, Drake.","sentences":["In this paper, we introduce a novel convex formulation that seamlessly integrates the Material Point Method (MPM) with articulated rigid body dynamics in frictional contact scenarios.","We extend the linear corotational hyperelastic model into the realm of elastoplasticity and include an efficient return mapping algorithm.","This approach is particularly effective for MPM simulations involving significant deformation and topology changes, while preserving the convexity of the optimization problem.","Our method ensures global convergence, enabling the use of large simulation time steps without compromising robustness.","We have validated our approach through rigorous testing and performance evaluations, highlighting its superior capabilities in managing complex simulations relevant to robotics.","Compared to previous MPM based robotic simulators, our method significantly improves the stability of contact resolution -- a critical factor in robot manipulation tasks.","We make our method available in the open-source robotics toolkit, Drake."],"url":"http://arxiv.org/abs/2403.13783v1"}
{"created":"2024-03-20 17:43:58","title":"Sparse Implementation of Versatile Graph-Informed Layers","abstract":"Graph Neural Networks (GNNs) have emerged as effective tools for learning tasks on graph-structured data. Recently, Graph-Informed (GI) layers were introduced to address regression tasks on graph nodes, extending their applicability beyond classic GNNs. However, existing implementations of GI layers lack efficiency due to dense memory allocation. This paper presents a sparse implementation of GI layers, leveraging the sparsity of adjacency matrices to reduce memory usage significantly. Additionally, a versatile general form of GI layers is introduced, enabling their application to subsets of graph nodes. The proposed sparse implementation improves the concrete computational efficiency and scalability of the GI layers, permitting to build deeper Graph-Informed Neural Networks (GINNs) and facilitating their scalability to larger graphs.","sentences":["Graph Neural Networks (GNNs) have emerged as effective tools for learning tasks on graph-structured data.","Recently, Graph-Informed (GI) layers were introduced to address regression tasks on graph nodes, extending their applicability beyond classic GNNs.","However, existing implementations of GI layers lack efficiency due to dense memory allocation.","This paper presents a sparse implementation of GI layers, leveraging the sparsity of adjacency matrices to reduce memory usage significantly.","Additionally, a versatile general form of GI layers is introduced, enabling their application to subsets of graph nodes.","The proposed sparse implementation improves the concrete computational efficiency and scalability of the GI layers, permitting to build deeper Graph-Informed Neural Networks (GINNs) and facilitating their scalability to larger graphs."],"url":"http://arxiv.org/abs/2403.13781v1"}
{"created":"2024-03-20 17:42:08","title":"Information-Theoretic Distillation for Reference-less Summarization","abstract":"The current winning recipe for automatic summarization is using proprietary large-scale language models (LLMs) such as ChatGPT as is, or imitation learning from them as teacher models. While increasingly ubiquitous dependence on such large-scale language models is convenient, there remains an important question of whether small-scale models could have achieved competitive results, if we were to seek an alternative learning method -- that allows for a more cost-efficient, controllable, yet powerful summarizer. We present InfoSumm, a novel framework to distill a powerful summarizer based on the information-theoretic objective for summarization, without relying on either the LLM's capability or human-written references. To achieve this, we first propose a novel formulation of the desiderata of summarization (saliency, faithfulness and brevity) through the lens of mutual information between the original document and the summary. Based on this formulation, we start off from Pythia-2.8B as the teacher model, which is not yet capable of summarization, then self-train the model to optimize for the information-centric measures of ideal summaries. Distilling from the improved teacher, we arrive at a compact but powerful summarizer with only 568M parameters that performs competitively against ChatGPT, without ever relying on ChatGPT's capabilities. Extensive analysis demonstrates that our approach outperforms in-domain supervised models in human evaluation, let alone state-of-the-art unsupervised methods, and wins over ChatGPT in controllable summarization.","sentences":["The current winning recipe for automatic summarization is using proprietary large-scale language models (LLMs) such as ChatGPT as is, or imitation learning from them as teacher models.","While increasingly ubiquitous dependence on such large-scale language models is convenient, there remains an important question of whether small-scale models could have achieved competitive results, if we were to seek an alternative learning method -- that allows for a more cost-efficient, controllable, yet powerful summarizer.","We present InfoSumm, a novel framework to distill a powerful summarizer based on the information-theoretic objective for summarization, without relying on either the LLM's capability or human-written references.","To achieve this, we first propose a novel formulation of the desiderata of summarization (saliency, faithfulness and brevity) through the lens of mutual information between the original document and the summary.","Based on this formulation, we start off from Pythia-2.8B as the teacher model, which is not yet capable of summarization, then self-train the model to optimize for the information-centric measures of ideal summaries.","Distilling from the improved teacher, we arrive at a compact but powerful summarizer with only 568M parameters that performs competitively against ChatGPT, without ever relying on ChatGPT's capabilities.","Extensive analysis demonstrates that our approach outperforms in-domain supervised models in human evaluation, let alone state-of-the-art unsupervised methods, and wins over ChatGPT in controllable summarization."],"url":"http://arxiv.org/abs/2403.13780v1"}
{"created":"2024-03-20 17:41:35","title":"Certified Human Trajectory Prediction","abstract":"Trajectory prediction plays an essential role in autonomous vehicles. While numerous strategies have been developed to enhance the robustness of trajectory prediction models, these methods are predominantly heuristic and do not offer guaranteed robustness against adversarial attacks and noisy observations. In this work, we propose a certification approach tailored for the task of trajectory prediction. To this end, we address the inherent challenges associated with trajectory prediction, including unbounded outputs, and mutli-modality, resulting in a model that provides guaranteed robustness. Furthermore, we integrate a denoiser into our method to further improve the performance. Through comprehensive evaluations, we demonstrate the effectiveness of the proposed technique across various baselines and using standard trajectory prediction datasets. The code will be made available online: https://s-attack.github.io/","sentences":["Trajectory prediction plays an essential role in autonomous vehicles.","While numerous strategies have been developed to enhance the robustness of trajectory prediction models, these methods are predominantly heuristic and do not offer guaranteed robustness against adversarial attacks and noisy observations.","In this work, we propose a certification approach tailored for the task of trajectory prediction.","To this end, we address the inherent challenges associated with trajectory prediction, including unbounded outputs, and mutli-modality, resulting in a model that provides guaranteed robustness.","Furthermore, we integrate a denoiser into our method to further improve the performance.","Through comprehensive evaluations, we demonstrate the effectiveness of the proposed technique across various baselines and using standard trajectory prediction datasets.","The code will be made available online: https://s-attack.github.io/"],"url":"http://arxiv.org/abs/2403.13778v1"}
{"created":"2024-03-20 17:41:21","title":"Embedding Pose Graph, Enabling 3D Foundation Model Capabilities with a Compact Representation","abstract":"This paper presents the Embedding Pose Graph (EPG), an innovative method that combines the strengths of foundation models with a simple 3D representation suitable for robotics applications. Addressing the need for efficient spatial understanding in robotics, EPG provides a compact yet powerful approach by attaching foundation model features to the nodes of a pose graph. Unlike traditional methods that rely on bulky data formats like voxel grids or point clouds, EPG is lightweight and scalable. It facilitates a range of robotic tasks, including open-vocabulary querying, disambiguation, image-based querying, language-directed navigation, and re-localization in 3D environments. We showcase the effectiveness of EPG in handling these tasks, demonstrating its capacity to improve how robots interact with and navigate through complex spaces. Through both qualitative and quantitative assessments, we illustrate EPG's strong performance and its ability to outperform existing methods in re-localization. Our work introduces a crucial step forward in enabling robots to efficiently understand and operate within large-scale 3D spaces.","sentences":["This paper presents the Embedding Pose Graph (EPG), an innovative method that combines the strengths of foundation models with a simple 3D representation suitable for robotics applications.","Addressing the need for efficient spatial understanding in robotics, EPG provides a compact yet powerful approach by attaching foundation model features to the nodes of a pose graph.","Unlike traditional methods that rely on bulky data formats like voxel grids or point clouds, EPG is lightweight and scalable.","It facilitates a range of robotic tasks, including open-vocabulary querying, disambiguation, image-based querying, language-directed navigation, and re-localization in 3D environments.","We showcase the effectiveness of EPG in handling these tasks, demonstrating its capacity to improve how robots interact with and navigate through complex spaces.","Through both qualitative and quantitative assessments, we illustrate EPG's strong performance and its ability to outperform existing methods in re-localization.","Our work introduces a crucial step forward in enabling robots to efficiently understand and operate within large-scale 3D spaces."],"url":"http://arxiv.org/abs/2403.13777v1"}
{"created":"2024-03-20 17:33:02","title":"Describe-and-Dissect: Interpreting Neurons in Vision Networks with Language Models","abstract":"In this paper, we propose Describe-and-Dissect (DnD), a novel method to describe the roles of hidden neurons in vision networks. DnD utilizes recent advancements in multimodal deep learning to produce complex natural language descriptions, without the need for labeled training data or a predefined set of concepts to choose from. Additionally, DnD is training-free, meaning we don't train any new models and can easily leverage more capable general purpose models in the future. We have conducted extensive qualitative and quantitative analysis to show that DnD outperforms prior work by providing higher quality neuron descriptions. Specifically, our method on average provides the highest quality labels and is more than 2 times as likely to be selected as the best explanation for a neuron than the best baseline.","sentences":["In this paper, we propose Describe-and-Dissect (DnD), a novel method to describe the roles of hidden neurons in vision networks.","DnD utilizes recent advancements in multimodal deep learning to produce complex natural language descriptions, without the need for labeled training data or a predefined set of concepts to choose from.","Additionally, DnD is training-free, meaning we don't train any new models and can easily leverage more capable general purpose models in the future.","We have conducted extensive qualitative and quantitative analysis to show that DnD outperforms prior work by providing higher quality neuron descriptions.","Specifically, our method on average provides the highest quality labels and is more than 2 times as likely to be selected as the best explanation for a neuron than the best baseline."],"url":"http://arxiv.org/abs/2403.13771v1"}
{"created":"2024-03-20 17:28:17","title":"Towards Principled Representation Learning from Videos for Reinforcement Learning","abstract":"We study pre-training representations for decision-making using video data, which is abundantly available for tasks such as game agents and software testing. Even though significant empirical advances have been made on this problem, a theoretical understanding remains absent. We initiate the theoretical investigation into principled approaches for representation learning and focus on learning the latent state representations of the underlying MDP using video data. We study two types of settings: one where there is iid noise in the observation, and a more challenging setting where there is also the presence of exogenous noise, which is non-iid noise that is temporally correlated, such as the motion of people or cars in the background. We study three commonly used approaches: autoencoding, temporal contrastive learning, and forward modeling. We prove upper bounds for temporal contrastive learning and forward modeling in the presence of only iid noise. We show that these approaches can learn the latent state and use it to do efficient downstream RL with polynomial sample complexity. When exogenous noise is also present, we establish a lower bound result showing that the sample complexity of learning from video data can be exponentially worse than learning from action-labeled trajectory data. This partially explains why reinforcement learning with video pre-training is hard. We evaluate these representational learning methods in two visual domains, yielding results that are consistent with our theoretical findings.","sentences":["We study pre-training representations for decision-making using video data, which is abundantly available for tasks such as game agents and software testing.","Even though significant empirical advances have been made on this problem, a theoretical understanding remains absent.","We initiate the theoretical investigation into principled approaches for representation learning and focus on learning the latent state representations of the underlying MDP using video data.","We study two types of settings: one where there is iid noise in the observation, and a more challenging setting where there is also the presence of exogenous noise, which is non-iid noise that is temporally correlated, such as the motion of people or cars in the background.","We study three commonly used approaches: autoencoding, temporal contrastive learning, and forward modeling.","We prove upper bounds for temporal contrastive learning and forward modeling in the presence of only iid noise.","We show that these approaches can learn the latent state and use it to do efficient downstream RL with polynomial sample complexity.","When exogenous noise is also present, we establish a lower bound result showing that the sample complexity of learning from video data can be exponentially worse than learning from action-labeled trajectory data.","This partially explains why reinforcement learning with video pre-training is hard.","We evaluate these representational learning methods in two visual domains, yielding results that are consistent with our theoretical findings."],"url":"http://arxiv.org/abs/2403.13765v1"}
{"created":"2024-03-20 17:26:22","title":"Practical End-to-End Optical Music Recognition for Pianoform Music","abstract":"The majority of recent progress in Optical Music Recognition (OMR) has been achieved with Deep Learning methods, especially models following the end-to-end paradigm, reading input images and producing a linear sequence of tokens. Unfortunately, many music scores, especially piano music, cannot be easily converted to a linear sequence. This has led OMR researchers to use custom linearized encodings, instead of broadly accepted structured formats for music notation. Their diversity makes it difficult to compare the performance of OMR systems directly. To bring recent OMR model progress closer to useful results: (a) We define a sequential format called Linearized MusicXML, allowing to train an end-to-end model directly and maintaining close cohesion and compatibility with the industry-standard MusicXML format. (b) We create a dev and test set for benchmarking typeset OMR with MusicXML ground truth based on the OpenScore Lieder corpus. They contain 1,438 and 1,493 pianoform systems, each with an image from IMSLP. (c) We train and fine-tune an end-to-end model to serve as a baseline on the dataset and employ the TEDn metric to evaluate the model. We also test our model against the recently published synthetic pianoform dataset GrandStaff and surpass the state-of-the-art results.","sentences":["The majority of recent progress in Optical Music Recognition (OMR) has been achieved with Deep Learning methods, especially models following the end-to-end paradigm, reading input images and producing a linear sequence of tokens.","Unfortunately, many music scores, especially piano music, cannot be easily converted to a linear sequence.","This has led OMR researchers to use custom linearized encodings, instead of broadly accepted structured formats for music notation.","Their diversity makes it difficult to compare the performance of OMR systems directly.","To bring recent OMR model progress closer to useful results: (a) We define a sequential format called Linearized MusicXML, allowing to train an end-to-end model directly and maintaining close cohesion and compatibility with the industry-standard MusicXML format.","(b) We create a dev and test set for benchmarking typeset","OMR with MusicXML ground truth based on the OpenScore Lieder corpus.","They contain 1,438 and 1,493 pianoform systems, each with an image from IMSLP.","(c) We train and fine-tune an end-to-end model to serve as a baseline on the dataset and employ the TEDn metric to evaluate the model.","We also test our model against the recently published synthetic pianoform dataset GrandStaff and surpass the state-of-the-art results."],"url":"http://arxiv.org/abs/2403.13763v1"}
{"created":"2024-03-20 17:20:48","title":"HierCode: A Lightweight Hierarchical Codebook for Zero-shot Chinese Text Recognition","abstract":"Text recognition, especially for complex scripts like Chinese, faces unique challenges due to its intricate character structures and vast vocabulary. Traditional one-hot encoding methods struggle with the representation of hierarchical radicals, recognition of Out-Of-Vocabulary (OOV) characters, and on-device deployment due to their computational intensity. To address these challenges, we propose HierCode, a novel and lightweight codebook that exploits the innate hierarchical nature of Chinese characters. HierCode employs a multi-hot encoding strategy, leveraging hierarchical binary tree encoding and prototype learning to create distinctive, informative representations for each character. This approach not only facilitates zero-shot recognition of OOV characters by utilizing shared radicals and structures but also excels in line-level recognition tasks by computing similarity with visual features, a notable advantage over existing methods. Extensive experiments across diverse benchmarks, including handwritten, scene, document, web, and ancient text, have showcased HierCode's superiority for both conventional and zero-shot Chinese character or text recognition, exhibiting state-of-the-art performance with significantly fewer parameters and fast inference speed.","sentences":["Text recognition, especially for complex scripts like Chinese, faces unique challenges due to its intricate character structures and vast vocabulary.","Traditional one-hot encoding methods struggle with the representation of hierarchical radicals, recognition of Out-Of-Vocabulary (OOV) characters, and on-device deployment due to their computational intensity.","To address these challenges, we propose HierCode, a novel and lightweight codebook that exploits the innate hierarchical nature of Chinese characters.","HierCode employs a multi-hot encoding strategy, leveraging hierarchical binary tree encoding and prototype learning to create distinctive, informative representations for each character.","This approach not only facilitates zero-shot recognition of OOV characters by utilizing shared radicals and structures but also excels in line-level recognition tasks by computing similarity with visual features, a notable advantage over existing methods.","Extensive experiments across diverse benchmarks, including handwritten, scene, document, web, and ancient text, have showcased HierCode's superiority for both conventional and zero-shot Chinese character or text recognition, exhibiting state-of-the-art performance with significantly fewer parameters and fast inference speed."],"url":"http://arxiv.org/abs/2403.13761v1"}
{"created":"2024-03-20 17:20:48","title":"When Cars meet Drones: Hyperbolic Federated Learning for Source-Free Domain Adaptation in Adverse Weather","abstract":"In Federated Learning (FL), multiple clients collaboratively train a global model without sharing private data. In semantic segmentation, the Federated source Free Domain Adaptation (FFreeDA) setting is of particular interest, where clients undergo unsupervised training after supervised pretraining at the server side. While few recent works address FL for autonomous vehicles, intrinsic real-world challenges such as the presence of adverse weather conditions and the existence of different autonomous agents are still unexplored. To bridge this gap, we address both problems and introduce a new federated semantic segmentation setting where both car and drone clients co-exist and collaborate. Specifically, we propose a novel approach for this setting which exploits a batch-norm weather-aware strategy to dynamically adapt the model to the different weather conditions, while hyperbolic space prototypes are used to align the heterogeneous client representations. Finally, we introduce FLYAWARE, the first semantic segmentation dataset with adverse weather data for aerial vehicles.","sentences":["In Federated Learning (FL), multiple clients collaboratively train a global model without sharing private data.","In semantic segmentation, the Federated source Free Domain Adaptation (FFreeDA) setting is of particular interest, where clients undergo unsupervised training after supervised pretraining at the server side.","While few recent works address FL for autonomous vehicles, intrinsic real-world challenges such as the presence of adverse weather conditions and the existence of different autonomous agents are still unexplored.","To bridge this gap, we address both problems and introduce a new federated semantic segmentation setting where both car and drone clients co-exist and collaborate.","Specifically, we propose a novel approach for this setting which exploits a batch-norm weather-aware strategy to dynamically adapt the model to the different weather conditions, while hyperbolic space prototypes are used to align the heterogeneous client representations.","Finally, we introduce FLYAWARE, the first semantic segmentation dataset with adverse weather data for aerial vehicles."],"url":"http://arxiv.org/abs/2403.13762v1"}
{"created":"2024-03-20 17:03:38","title":"Enhancing Gait Video Analysis in Neurodegenerative Diseases by Knowledge Augmentation in Vision Language Model","abstract":"We present a knowledge augmentation strategy for assessing the diagnostic groups and gait impairment from monocular gait videos. Based on a large-scale pre-trained Vision Language Model (VLM), our model learns and improves visual, textual, and numerical representations of patient gait videos, through a collective learning across three distinct modalities: gait videos, class-specific descriptions, and numerical gait parameters. Our specific contributions are two-fold: First, we adopt a knowledge-aware prompt tuning strategy to utilize the class-specific medical description in guiding the text prompt learning. Second, we integrate the paired gait parameters in the form of numerical texts to enhance the numeracy of the textual representation. Results demonstrate that our model not only significantly outperforms state-of-the-art (SOTA) in video-based classification tasks but also adeptly decodes the learned class-specific text features into natural language descriptions using the vocabulary of quantitative gait parameters. The code and the model will be made available at our project page.","sentences":["We present a knowledge augmentation strategy for assessing the diagnostic groups and gait impairment from monocular gait videos.","Based on a large-scale pre-trained Vision Language Model (VLM), our model learns and improves visual, textual, and numerical representations of patient gait videos, through a collective learning across three distinct modalities: gait videos, class-specific descriptions, and numerical gait parameters.","Our specific contributions are two-fold: First, we adopt a knowledge-aware prompt tuning strategy to utilize the class-specific medical description in guiding the text prompt learning.","Second, we integrate the paired gait parameters in the form of numerical texts to enhance the numeracy of the textual representation.","Results demonstrate that our model not only significantly outperforms state-of-the-art (SOTA) in video-based classification tasks but also adeptly decodes the learned class-specific text features into natural language descriptions using the vocabulary of quantitative gait parameters.","The code and the model will be made available at our project page."],"url":"http://arxiv.org/abs/2403.13756v1"}
{"created":"2024-03-20 17:01:56","title":"Different Tokenization Schemes Lead to Comparable Performance in Spanish Number Agreement","abstract":"The relationship between language model tokenization and performance is an open area of research. Here, we investigate how different tokenization schemes impact number agreement in Spanish plurals. We find that morphologically-aligned tokenization performs similarly to other tokenization schemes, even when induced artificially for words that would not be tokenized that way during training. We then present exploratory analyses demonstrating that language model embeddings for different plural tokenizations have similar distributions along the embedding space axis that maximally distinguishes singular and plural nouns. Our results suggest that morphologically-aligned tokenization is a viable tokenization approach, and existing models already generalize some morphological patterns to new items. However, our results indicate that morphological tokenization is not strictly required for performance.","sentences":["The relationship between language model tokenization and performance is an open area of research.","Here, we investigate how different tokenization schemes impact number agreement in Spanish plurals.","We find that morphologically-aligned tokenization performs similarly to other tokenization schemes, even when induced artificially for words that would not be tokenized that way during training.","We then present exploratory analyses demonstrating that language model embeddings for different plural tokenizations have similar distributions along the embedding space axis that maximally distinguishes singular and plural nouns.","Our results suggest that morphologically-aligned tokenization is a viable tokenization approach, and existing models already generalize some morphological patterns to new items.","However, our results indicate that morphological tokenization is not strictly required for performance."],"url":"http://arxiv.org/abs/2403.13754v1"}
{"created":"2024-03-20 16:58:28","title":"Weisfeiler and Leman Go Loopy: A New Hierarchy for Graph Representational Learning","abstract":"We introduce $r$-loopy Weisfeiler-Leman ($r$-$\\ell{}$WL), a novel hierarchy of graph isomorphism tests and a corresponding GNN framework, $r$-$\\ell{}$MPNN, that can count cycles up to length $r + 2$. Most notably, we show that $r$-$\\ell{}$WL can count homomorphisms of cactus graphs. This strictly extends classical 1-WL, which can only count homomorphisms of trees and, in fact, is incomparable to $k$-WL for any fixed $k$. We empirically validate the expressive and counting power of the proposed $r$-$\\ell{}$MPNN on several synthetic datasets and present state-of-the-art predictive performance on various real-world datasets. The code is available at https://github.com/RPaolino/loopy","sentences":["We introduce $r$-loopy Weisfeiler-Leman ($r$-$\\ell{}$WL), a novel hierarchy of graph isomorphism tests and a corresponding GNN framework, $r$-$\\ell{}$MPNN, that can count cycles up to length $r + 2$. Most notably, we show that $r$-$\\ell{}$WL can count homomorphisms of cactus graphs.","This strictly extends classical 1-WL, which can only count homomorphisms of trees and, in fact, is incomparable to $k$-WL for any fixed $k$. We empirically validate the expressive and counting power of the proposed $r$-$\\ell{}$MPNN on several synthetic datasets and present state-of-the-art predictive performance on various real-world datasets.","The code is available at https://github.com/RPaolino/loopy"],"url":"http://arxiv.org/abs/2403.13749v1"}
{"created":"2024-03-20 16:54:55","title":"Leveraging High-Resolution Features for Improved Deep Hashing-based Image Retrieval","abstract":"Deep hashing techniques have emerged as the predominant approach for efficient image retrieval. Traditionally, these methods utilize pre-trained convolutional neural networks (CNNs) such as AlexNet and VGG-16 as feature extractors. However, the increasing complexity of datasets poses challenges for these backbone architectures in capturing meaningful features essential for effective image retrieval. In this study, we explore the efficacy of employing high-resolution features learned through state-of-the-art techniques for image retrieval tasks. Specifically, we propose a novel methodology that utilizes High-Resolution Networks (HRNets) as the backbone for the deep hashing task, termed High-Resolution Hashing Network (HHNet). Our approach demonstrates superior performance compared to existing methods across all tested benchmark datasets, including CIFAR-10, NUS-WIDE, MS COCO, and ImageNet. This performance improvement is more pronounced for complex datasets, which highlights the need to learn high-resolution features for intricate image retrieval tasks. Furthermore, we conduct a comprehensive analysis of different HRNet configurations and provide insights into the optimal architecture for the deep hashing task","sentences":["Deep hashing techniques have emerged as the predominant approach for efficient image retrieval.","Traditionally, these methods utilize pre-trained convolutional neural networks (CNNs) such as AlexNet and VGG-16 as feature extractors.","However, the increasing complexity of datasets poses challenges for these backbone architectures in capturing meaningful features essential for effective image retrieval.","In this study, we explore the efficacy of employing high-resolution features learned through state-of-the-art techniques for image retrieval tasks.","Specifically, we propose a novel methodology that utilizes High-Resolution Networks (HRNets) as the backbone for the deep hashing task, termed High-Resolution Hashing Network (HHNet).","Our approach demonstrates superior performance compared to existing methods across all tested benchmark datasets, including CIFAR-10, NUS-WIDE, MS COCO, and ImageNet.","This performance improvement is more pronounced for complex datasets, which highlights the need to learn high-resolution features for intricate image retrieval tasks.","Furthermore, we conduct a comprehensive analysis of different HRNet configurations and provide insights into the optimal architecture for the deep hashing task"],"url":"http://arxiv.org/abs/2403.13747v1"}
{"created":"2024-03-20 16:53:45","title":"Be-Your-Outpainter: Mastering Video Outpainting through Input-Specific Adaptation","abstract":"Video outpainting is a challenging task, aiming at generating video content outside the viewport of the input video while maintaining inter-frame and intra-frame consistency. Existing methods fall short in either generation quality or flexibility. We introduce MOTIA Mastering Video Outpainting Through Input-Specific Adaptation, a diffusion-based pipeline that leverages both the intrinsic data-specific patterns of the source video and the image/video generative prior for effective outpainting. MOTIA comprises two main phases: input-specific adaptation and pattern-aware outpainting. The input-specific adaptation phase involves conducting efficient and effective pseudo outpainting learning on the single-shot source video. This process encourages the model to identify and learn patterns within the source video, as well as bridging the gap between standard generative processes and outpainting. The subsequent phase, pattern-aware outpainting, is dedicated to the generalization of these learned patterns to generate outpainting outcomes. Additional strategies including spatial-aware insertion and noise travel are proposed to better leverage the diffusion model's generative prior and the acquired video patterns from source videos. Extensive evaluations underscore MOTIA's superiority, outperforming existing state-of-the-art methods in widely recognized benchmarks. Notably, these advancements are achieved without necessitating extensive, task-specific tuning.","sentences":["Video outpainting is a challenging task, aiming at generating video content outside the viewport of the input video while maintaining inter-frame and intra-frame consistency.","Existing methods fall short in either generation quality or flexibility.","We introduce MOTIA Mastering Video","Outpainting Through Input-Specific Adaptation, a diffusion-based pipeline that leverages both the intrinsic data-specific patterns of the source video and the image/video generative prior for effective outpainting.","MOTIA comprises two main phases: input-specific adaptation and pattern-aware outpainting.","The input-specific adaptation phase involves conducting efficient and effective pseudo outpainting learning on the single-shot source video.","This process encourages the model to identify and learn patterns within the source video, as well as bridging the gap between standard generative processes and outpainting.","The subsequent phase, pattern-aware outpainting, is dedicated to the generalization of these learned patterns to generate outpainting outcomes.","Additional strategies including spatial-aware insertion and noise travel are proposed to better leverage the diffusion model's generative prior and the acquired video patterns from source videos.","Extensive evaluations underscore MOTIA's superiority, outperforming existing state-of-the-art methods in widely recognized benchmarks.","Notably, these advancements are achieved without necessitating extensive, task-specific tuning."],"url":"http://arxiv.org/abs/2403.13745v1"}
{"created":"2024-03-20 16:50:36","title":"Quantum-Secure Certificate-Less Conditional Privacy-Preserving Authentication for VANET","abstract":"Vehicular Ad-hoc Networks (VANETs) marked a pronounced change in the Intelligent Transport System and Smart Cities through seamless vehicle communication to intensify safety and efficacy. However, a few authentication schemes have been devised in the literature to ensure the authenticity of the source and information in the post-quantum era. The most popular base for such construction is lattice-based cryptography. However, existing lattice-based authentication schemes fall short of addressing the potential challenges of the leakage of the master secret key and key-escrow problem. By ingeniously addressing both issues, the paper proposes the \\emph{first} quantum secure authentication scheme to eliminate the flaws while maintaining the system's overall efficiency intact. Compared to the state-of-the-art schemes, the provable security and overall performance assessment highlight the suitability of the proposed approach.","sentences":["Vehicular Ad-hoc Networks (VANETs) marked a pronounced change in the Intelligent Transport System and Smart Cities through seamless vehicle communication to intensify safety and efficacy.","However, a few authentication schemes have been devised in the literature to ensure the authenticity of the source and information in the post-quantum era.","The most popular base for such construction is lattice-based cryptography.","However, existing lattice-based authentication schemes fall short of addressing the potential challenges of the leakage of the master secret key and key-escrow problem.","By ingeniously addressing both issues, the paper proposes the \\emph{first} quantum secure authentication scheme to eliminate the flaws while maintaining the system's overall efficiency intact.","Compared to the state-of-the-art schemes, the provable security and overall performance assessment highlight the suitability of the proposed approach."],"url":"http://arxiv.org/abs/2403.13743v1"}
{"created":"2024-03-20 16:47:53","title":"Hyper Strategy Logic","abstract":"Strategy logic (SL) is a powerful temporal logic that enables strategic reasoning in multi-agent systems. SL supports explicit (first-order) quantification over strategies and provides a logical framework to express many important properties such as Nash equilibria, dominant strategies, etc. While in SL the same strategy can be used in multiple strategy profiles, each such profile is evaluated w.r.t. a path-property, i.e., a property that considers the single path resulting from a particular strategic interaction. In this paper, we present Hyper Strategy Logic (HyperSL), a strategy logic where the outcome of multiple strategy profiles can be compared w.r.t. a hyperproperty, i.e., a property that relates multiple paths. We show that HyperSL can capture important properties that cannot be expressed in SL, including non-interference, quantitative Nash equilibria, optimal adversarial planning, and reasoning under imperfect information. On the algorithmic side, we identify an expressive fragment of HyperSL with decidable model checking and present a model-checking algorithm. We contribute a prototype implementation of our algorithm and report on encouraging experimental results.","sentences":["Strategy logic (SL) is a powerful temporal logic that enables strategic reasoning in multi-agent systems.","SL supports explicit (first-order) quantification over strategies and provides a logical framework to express many important properties such as Nash equilibria, dominant strategies, etc.","While in SL the same strategy can be used in multiple strategy profiles, each such profile is evaluated w.r.t.","a path-property, i.e., a property that considers the single path resulting from a particular strategic interaction.","In this paper, we present Hyper Strategy Logic (HyperSL), a strategy logic where the outcome of multiple strategy profiles can be compared w.r.t.","a hyperproperty, i.e., a property that relates multiple paths.","We show that HyperSL can capture important properties that cannot be expressed in SL, including non-interference, quantitative Nash equilibria, optimal adversarial planning, and reasoning under imperfect information.","On the algorithmic side, we identify an expressive fragment of HyperSL with decidable model checking and present a model-checking algorithm.","We contribute a prototype implementation of our algorithm and report on encouraging experimental results."],"url":"http://arxiv.org/abs/2403.13741v1"}
{"created":"2024-03-20 16:47:28","title":"Uncertainty-Aware Explanations Through Probabilistic Self-Explainable Neural Networks","abstract":"The lack of transparency of Deep Neural Networks continues to be a limitation that severely undermines their reliability and usage in high-stakes applications. Promising approaches to overcome such limitations are Prototype-Based Self-Explainable Neural Networks (PSENNs), whose predictions rely on the similarity between the input at hand and a set of prototypical representations of the output classes, offering therefore a deep, yet transparent-by-design, architecture. So far, such models have been designed by considering pointwise estimates for the prototypes, which remain fixed after the learning phase of the model. In this paper, we introduce a probabilistic reformulation of PSENNs, called Prob-PSENN, which replaces point estimates for the prototypes with probability distributions over their values. This provides not only a more flexible framework for an end-to-end learning of prototypes, but can also capture the explanatory uncertainty of the model, which is a missing feature in previous approaches. In addition, since the prototypes determine both the explanation and the prediction, Prob-PSENNs allow us to detect when the model is making uninformed or uncertain predictions, and to obtain valid explanations for them. Our experiments demonstrate that Prob-PSENNs provide more meaningful and robust explanations than their non-probabilistic counterparts, thus enhancing the explainability and reliability of the models.","sentences":["The lack of transparency of Deep Neural Networks continues to be a limitation that severely undermines their reliability and usage in high-stakes applications.","Promising approaches to overcome such limitations are Prototype-Based Self-Explainable Neural Networks (PSENNs), whose predictions rely on the similarity between the input at hand and a set of prototypical representations of the output classes, offering therefore a deep, yet transparent-by-design, architecture.","So far, such models have been designed by considering pointwise estimates for the prototypes, which remain fixed after the learning phase of the model.","In this paper, we introduce a probabilistic reformulation of PSENNs, called Prob-PSENN, which replaces point estimates for the prototypes with probability distributions over their values.","This provides not only a more flexible framework for an end-to-end learning of prototypes, but can also capture the explanatory uncertainty of the model, which is a missing feature in previous approaches.","In addition, since the prototypes determine both the explanation and the prediction, Prob-PSENNs allow us to detect when the model is making uninformed or uncertain predictions, and to obtain valid explanations for them.","Our experiments demonstrate that Prob-PSENNs provide more meaningful and robust explanations than their non-probabilistic counterparts, thus enhancing the explainability and reliability of the models."],"url":"http://arxiv.org/abs/2403.13740v1"}
{"created":"2024-03-20 16:43:42","title":"EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation","abstract":"Large language models (LLMs) have gained popularity recently due to their outstanding performance in various downstream Natural Language Processing (NLP) tasks. However, low-resource languages are still lagging behind current state-of-the-art (SOTA) developments in the field of NLP due to insufficient resources to train LLMs. Ethiopian languages exhibit remarkable linguistic diversity, encompassing a wide array of scripts, and are imbued with profound religious and cultural significance. This paper introduces EthioLLM -- multilingual large language models for five Ethiopian languages (Amharic, Ge'ez, Afan Oromo, Somali, and Tigrinya) and English, and Ethiobenchmark -- a new benchmark dataset for various downstream NLP tasks. We evaluate the performance of these models across five downstream NLP tasks. We open-source our multilingual language models, new benchmark datasets for various downstream tasks, and task-specific fine-tuned language models and discuss the performance of the models. Our dataset and models are available at the https://huggingface.co/EthioNLP repository.","sentences":["Large language models (LLMs) have gained popularity recently due to their outstanding performance in various downstream Natural Language Processing (NLP) tasks.","However, low-resource languages are still lagging behind current state-of-the-art (SOTA) developments in the field of NLP due to insufficient resources to train LLMs.","Ethiopian languages exhibit remarkable linguistic diversity, encompassing a wide array of scripts, and are imbued with profound religious and cultural significance.","This paper introduces EthioLLM -- multilingual large language models for five Ethiopian languages (Amharic, Ge'ez, Afan Oromo, Somali, and Tigrinya) and English, and Ethiobenchmark -- a new benchmark dataset for various downstream NLP tasks.","We evaluate the performance of these models across five downstream NLP tasks.","We open-source our multilingual language models, new benchmark datasets for various downstream tasks, and task-specific fine-tuned language models and discuss the performance of the models.","Our dataset and models are available at the https://huggingface.co/EthioNLP repository."],"url":"http://arxiv.org/abs/2403.13737v1"}
{"created":"2024-03-20 16:43:30","title":"Statistical Confidence in Mining Power Estimates for PoW Blockchains","abstract":"The security of blockchain systems depends on the distribution of mining power across participants. If sufficient mining power is controlled by one entity, they can force their own version of events. This may allow them to double spend coins, for example. For Proof of Work (PoW) blockchains, however, the distribution of mining power cannot be read directly from the blockchain and must instead be inferred from the number of blocks mined in a specific sample window. We introduce a framework to quantify this statistical uncertainty for the Nakamoto coefficient, which is a commonly-used measure of blockchain decentralization. We show that aggregating blocks over a day can lead to considerable uncertainty, with Bitcoin failing more than half the hypothesis tests ({\\alpha} = 0.05) when using a daily granularity. For these reasons, we recommend that blocks are aggregated over a sample window of at least 7 days. Instead of reporting a single value, our approach produces a range of possible Nakamoto coefficient values that have statistical support at a particular significance level {\\alpha}.","sentences":["The security of blockchain systems depends on the distribution of mining power across participants.","If sufficient mining power is controlled by one entity, they can force their own version of events.","This may allow them to double spend coins, for example.","For Proof of Work (PoW) blockchains, however, the distribution of mining power cannot be read directly from the blockchain and must instead be inferred from the number of blocks mined in a specific sample window.","We introduce a framework to quantify this statistical uncertainty for the Nakamoto coefficient, which is a commonly-used measure of blockchain decentralization.","We show that aggregating blocks over a day can lead to considerable uncertainty, with Bitcoin failing more than half the hypothesis tests ({\\alpha} = 0.05) when using a daily granularity.","For these reasons, we recommend that blocks are aggregated over a sample window of at least 7 days.","Instead of reporting a single value, our approach produces a range of possible Nakamoto coefficient values that have statistical support at a particular significance level {\\alpha}."],"url":"http://arxiv.org/abs/2403.13736v1"}
{"created":"2024-03-20 16:39:17","title":"Reinforcement Learning for Online Testing of Autonomous Driving Systems: a Replication and Extension Study","abstract":"In a recent study, Reinforcement Learning (RL) used in combination with many-objective search, has been shown to outperform alternative techniques (random search and many-objective search) for online testing of Deep Neural Network-enabled systems. The empirical evaluation of these techniques was conducted on a state-of-the-art Autonomous Driving System (ADS). This work is a replication and extension of that empirical study. Our replication shows that RL does not outperform pure random test generation in a comparison conducted under the same settings of the original study, but with no confounding factor coming from the way collisions are measured. Our extension aims at eliminating some of the possible reasons for the poor performance of RL observed in our replication: (1) the presence of reward components providing contrasting or useless feedback to the RL agent; (2) the usage of an RL algorithm (Q-learning) which requires discretization of an intrinsically continuous state space. Results show that our new RL agent is able to converge to an effective policy that outperforms random testing. Results also highlight other possible improvements, which open to further investigations on how to best leverage RL for online ADS testing.","sentences":["In a recent study, Reinforcement Learning (RL) used in combination with many-objective search, has been shown to outperform alternative techniques (random search and many-objective search) for online testing of Deep Neural Network-enabled systems.","The empirical evaluation of these techniques was conducted on a state-of-the-art Autonomous Driving System (ADS).","This work is a replication and extension of that empirical study.","Our replication shows that RL does not outperform pure random test generation in a comparison conducted under the same settings of the original study, but with no confounding factor coming from the way collisions are measured.","Our extension aims at eliminating some of the possible reasons for the poor performance of RL observed in our replication: (1) the presence of reward components providing contrasting or useless feedback to the RL agent; (2) the usage of an RL algorithm (Q-learning) which requires discretization of an intrinsically continuous state space.","Results show that our new RL agent is able to converge to an effective policy that outperforms random testing.","Results also highlight other possible improvements, which open to further investigations on how to best leverage RL for online ADS testing."],"url":"http://arxiv.org/abs/2403.13729v1"}
{"created":"2024-03-20 16:38:26","title":"M-HOF-Opt: Multi-Objective Hierarchical Output Feedback Optimization via Multiplier Induced Loss Landscape Scheduling","abstract":"When a neural network parameterized loss function consists of many terms, the combinatorial choice of weight multipliers during the optimization process forms a challenging problem. To address this, we proposed a probabilistic graphical model (PGM) for the joint model parameter and multiplier evolution process, with a hypervolume based likelihood that promotes multi-objective descent of each loss term. The corresponding parameter and multiplier estimation as a sequential decision process is then cast into an optimal control problem, where the multi-objective descent goal is dispatched hierarchically into a series of constraint optimization sub-problems. The sub-problem constraint automatically adapts itself according to Pareto dominance and serves as the setpoint for the low level multiplier controller to schedule loss landscapes via output feedback of each loss term. Our method is multiplier-free and operates at the timescale of epochs, thus saves tremendous computational resources compared to full training cycle multiplier tuning. We applied it to domain invariant variational auto-encoding with 6 loss terms on the PACS domain generalization task, and observed robust performance across a range of controller hyperparameters, as well as different multiplier initial conditions, outperforming other multiplier scheduling methods. We offered modular implementation of our method, admitting custom definition of many loss terms for applying our multi-objective hierarchical output feedback training scheme to other deep learning fields.","sentences":["When a neural network parameterized loss function consists of many terms, the combinatorial choice of weight multipliers during the optimization process forms a challenging problem.","To address this, we proposed a probabilistic graphical model (PGM) for the joint model parameter and multiplier evolution process, with a hypervolume based likelihood that promotes multi-objective descent of each loss term.","The corresponding parameter and multiplier estimation as a sequential decision process is then cast into an optimal control problem, where the multi-objective descent goal is dispatched hierarchically into a series of constraint optimization sub-problems.","The sub-problem constraint automatically adapts itself according to Pareto dominance and serves as the setpoint for the low level multiplier controller to schedule loss landscapes via output feedback of each loss term.","Our method is multiplier-free and operates at the timescale of epochs, thus saves tremendous computational resources compared to full training cycle multiplier tuning.","We applied it to domain invariant variational auto-encoding with 6 loss terms on the PACS domain generalization task, and observed robust performance across a range of controller hyperparameters, as well as different multiplier initial conditions, outperforming other multiplier scheduling methods.","We offered modular implementation of our method, admitting custom definition of many loss terms for applying our multi-objective hierarchical output feedback training scheme to other deep learning fields."],"url":"http://arxiv.org/abs/2403.13728v1"}
{"created":"2024-03-20 16:33:06","title":"Probabilistic Forecasting with Stochastic Interpolants and F\u00f6llmer Processes","abstract":"We propose a framework for probabilistic forecasting of dynamical systems based on generative modeling. Given observations of the system state over time, we formulate the forecasting problem as sampling from the conditional distribution of the future system state given its current state. To this end, we leverage the framework of stochastic interpolants, which facilitates the construction of a generative model between an arbitrary base distribution and the target. We design a fictitious, non-physical stochastic dynamics that takes as initial condition the current system state and produces as output a sample from the target conditional distribution in finite time and without bias. This process therefore maps a point mass centered at the current state onto a probabilistic ensemble of forecasts. We prove that the drift coefficient entering the stochastic differential equation (SDE) achieving this task is non-singular, and that it can be learned efficiently by square loss regression over the time-series data. We show that the drift and the diffusion coefficients of this SDE can be adjusted after training, and that a specific choice that minimizes the impact of the estimation error gives a F\\\"ollmer process. We highlight the utility of our approach on several complex, high-dimensional forecasting problems, including stochastically forced Navier-Stokes and video prediction on the KTH and CLEVRER datasets.","sentences":["We propose a framework for probabilistic forecasting of dynamical systems based on generative modeling.","Given observations of the system state over time, we formulate the forecasting problem as sampling from the conditional distribution of the future system state given its current state.","To this end, we leverage the framework of stochastic interpolants, which facilitates the construction of a generative model between an arbitrary base distribution and the target.","We design a fictitious, non-physical stochastic dynamics that takes as initial condition the current system state and produces as output a sample from the target conditional distribution in finite time and without bias.","This process therefore maps a point mass centered at the current state onto a probabilistic ensemble of forecasts.","We prove that the drift coefficient entering the stochastic differential equation (SDE) achieving this task is non-singular, and that it can be learned efficiently by square loss regression over the time-series data.","We show that the drift and the diffusion coefficients of this SDE can be adjusted after training, and that a specific choice that minimizes the impact of the estimation error gives a F\\\"ollmer process.","We highlight the utility of our approach on several complex, high-dimensional forecasting problems, including stochastically forced Navier-Stokes and video prediction on the KTH and CLEVRER datasets."],"url":"http://arxiv.org/abs/2403.13724v1"}
{"created":"2024-03-20 16:29:52","title":"Large Language Models meet Network Slicing Management and Orchestration","abstract":"Network slicing, a cornerstone technology for future networks, enables the creation of customized virtual networks on a shared physical infrastructure. This fosters innovation and agility by providing dedicated resources tailored to specific applications. However, current orchestration and management approaches face limitations in handling the complexity of new service demands within multi-administrative domain environments. This paper proposes a future vision for network slicing powered by Large Language Models (LLMs) and multi-agent systems, offering a framework that can be integrated with existing Management and Orchestration (MANO) frameworks. This framework leverages LLMs to translate user intent into technical requirements, map network functions to infrastructure, and manage the entire slice lifecycle, while multi-agent systems facilitate collaboration across different administrative domains. We also discuss the challenges associated with implementing this framework and potential solutions to mitigate them.","sentences":["Network slicing, a cornerstone technology for future networks, enables the creation of customized virtual networks on a shared physical infrastructure.","This fosters innovation and agility by providing dedicated resources tailored to specific applications.","However, current orchestration and management approaches face limitations in handling the complexity of new service demands within multi-administrative domain environments.","This paper proposes a future vision for network slicing powered by Large Language Models (LLMs) and multi-agent systems, offering a framework that can be integrated with existing Management and Orchestration (MANO) frameworks.","This framework leverages LLMs to translate user intent into technical requirements, map network functions to infrastructure, and manage the entire slice lifecycle, while multi-agent systems facilitate collaboration across different administrative domains.","We also discuss the challenges associated with implementing this framework and potential solutions to mitigate them."],"url":"http://arxiv.org/abs/2403.13721v1"}
{"created":"2024-03-20 16:27:13","title":"UTDUSS: UTokyo-SaruLab System for Interspeech2024 Speech Processing Using Discrete Speech Unit Challenge","abstract":"We present UTDUSS, the UTokyo-SaruLab system submitted to Interspeech2024 Speech Processing Using Discrete Speech Unit Challenge. The challenge focuses on using discrete speech unit learned from large speech corpora for some tasks. We submitted our UTDUSS system to two text-to-speech tracks: Vocoder and Acoustic+Vocoder. Our system incorporates neural audio codec (NAC) pre-trained on only speech corpora, which makes the learned codec represent rich acoustic features that are necessary for high-fidelity speech reconstruction. For the acoustic+vocoder track, we trained an acoustic model based on Transformer encoder-decoder that predicted the pre-trained NAC tokens from text input. We describe our strategies to build these models, such as data selection, downsampling, and hyper-parameter tuning. Our system ranked in second and first for the Vocoder and Acoustic+Vocoder tracks, respectively.","sentences":["We present UTDUSS, the UTokyo-SaruLab system submitted to Interspeech2024","Speech Processing Using Discrete Speech Unit Challenge.","The challenge focuses on using discrete speech unit learned from large speech corpora for some tasks.","We submitted our UTDUSS system to two text-to-speech tracks: Vocoder and Acoustic+Vocoder.","Our system incorporates neural audio codec (NAC) pre-trained on only speech corpora, which makes the learned codec represent rich acoustic features that are necessary for high-fidelity speech reconstruction.","For the acoustic+vocoder track, we trained an acoustic model based on Transformer encoder-decoder that predicted the pre-trained NAC tokens from text input.","We describe our strategies to build these models, such as data selection, downsampling, and hyper-parameter tuning.","Our system ranked in second and first for the Vocoder and Acoustic+Vocoder tracks, respectively."],"url":"http://arxiv.org/abs/2403.13720v1"}
{"created":"2024-03-20 16:22:53","title":"Agent-based MST Construction","abstract":"{\\em Minimum-weight spanning tree} (MST) is one of the fundamental and well-studied problems in distributed computing. In this paper, we initiate the study of constructing MST using mobile agents (aka robots). Suppose $n$ agents are positioned initially arbitrarily on the nodes of a connected, undirected, arbitrary, anonymous, port-labeled, weighted $n$-node, $m$-edge graph $G$ of diameter $D$ and maximum degree $\\Delta$. The agents relocate themselves autonomously and compute an MST of $G$ such that exactly one agent positions on a node and tracks in its memory which of its adjacent edges belong to the MST. The objective is to minimize time and memory requirements. Following the literature, we consider the synchronous setting in which each agent performs its operations synchronously with others and hence time can be measured in rounds. We first establish a generic result: if $n$ and $\\Delta$ are known a priori and memory per agent is as much as node memory in the message-passing model (of distributed computing), agents can simulate any $O(T)$-round deterministic algorithm for any problem in the message-passing model to the agent model in $O(\\Delta T \\log n+n\\log^2n)$ rounds. As a corollary, MST can be constructed in the agent model in $O(\\max\\{\\Delta \\sqrt{n} \\log n \\log^*n, \\Delta D \\log n,n\\log^2n\\})$ rounds simulating the celebrated $O(\\sqrt{n} \\log^*n +D)$-round GKP algorithm for MST in the message-passing model. We then establish that, without knowing any graph parameter a priori, there exists a deterministic algorithm to construct MST in the agent model in $O(m+n\\log n)$ rounds with $O(n \\log n)$ bits memory at each agent. The presented algorithm needs to overcome highly non-trivial challenges on how to synchronize agents in computing MST as they may initially be positioned arbitrarily on the graph nodes.","sentences":["{\\em Minimum-weight spanning tree} (MST) is one of the fundamental and well-studied problems in distributed computing.","In this paper, we initiate the study of constructing MST using mobile agents (aka robots).","Suppose $n$ agents are positioned initially arbitrarily on the nodes of a connected, undirected, arbitrary, anonymous, port-labeled, weighted $n$-node, $m$-edge graph $G$ of diameter $D$ and maximum degree $\\Delta$.","The agents relocate themselves autonomously and compute an MST of $G$ such that exactly one agent positions on a node and tracks in its memory which of its adjacent edges belong to the MST.","The objective is to minimize time and memory requirements.","Following the literature, we consider the synchronous setting in which each agent performs its operations synchronously with others and hence time can be measured in rounds.","We first establish a generic result: if $n$ and $\\Delta$ are known a priori and memory per agent is as much as node memory in the message-passing model (of distributed computing), agents can simulate any $O(T)$-round deterministic algorithm for any problem in the message-passing model to the agent model in $O(\\Delta T \\log n+n\\log^2n)$ rounds.","As a corollary, MST can be constructed in the agent model in $O(\\max\\{\\Delta \\sqrt{n} \\log n \\log^*n, \\Delta D \\log n,n\\log^2n\\})$ rounds simulating the celebrated $O(\\sqrt{n} \\log^*n +D)$-round GKP algorithm for MST in the message-passing model.","We then establish that, without knowing any graph parameter a priori, there exists a deterministic algorithm to construct MST in the agent model in $O(m+n\\log n)$ rounds with $O(n \\log n)$ bits memory at each agent.","The presented algorithm needs to overcome highly non-trivial challenges on how to synchronize agents in computing MST as they may initially be positioned arbitrarily on the graph nodes."],"url":"http://arxiv.org/abs/2403.13716v1"}
{"created":"2024-03-20 16:20:54","title":"DBA-Fusion: Tightly Integrating Deep Dense Visual Bundle Adjustment with Multiple Sensors for Large-Scale Localization and Mapping","abstract":"Visual simultaneous localization and mapping (VSLAM) has broad applications, with state-of-the-art methods leveraging deep neural networks for better robustness and applicability. However, there is a lack of research in fusing these learning-based methods with multi-sensor information, which could be indispensable to push related applications to large-scale and complex scenarios. In this paper, we tightly integrate the trainable deep dense bundle adjustment (DBA) with multi-sensor information through a factor graph. In the framework, recurrent optical flow and DBA are performed among sequential images. The Hessian information derived from DBA is fed into a generic factor graph for multi-sensor fusion, which employs a sliding window and supports probabilistic marginalization. A pipeline for visual-inertial integration is firstly developed, which provides the minimum ability of metric-scale localization and mapping. Furthermore, other sensors (e.g., global navigation satellite system) are integrated for driftless and geo-referencing functionality. Extensive tests are conducted on both public datasets and self-collected datasets. The results validate the superior localization performance of our approach, which enables real-time dense mapping in large-scale environments. The code has been made open-source (https://github.com/GREAT-WHU/DBA-Fusion).","sentences":["Visual simultaneous localization and mapping (VSLAM) has broad applications, with state-of-the-art methods leveraging deep neural networks for better robustness and applicability.","However, there is a lack of research in fusing these learning-based methods with multi-sensor information, which could be indispensable to push related applications to large-scale and complex scenarios.","In this paper, we tightly integrate the trainable deep dense bundle adjustment (DBA) with multi-sensor information through a factor graph.","In the framework, recurrent optical flow and DBA are performed among sequential images.","The Hessian information derived from DBA is fed into a generic factor graph for multi-sensor fusion, which employs a sliding window and supports probabilistic marginalization.","A pipeline for visual-inertial integration is firstly developed, which provides the minimum ability of metric-scale localization and mapping.","Furthermore, other sensors (e.g., global navigation satellite system) are integrated for driftless and geo-referencing functionality.","Extensive tests are conducted on both public datasets and self-collected datasets.","The results validate the superior localization performance of our approach, which enables real-time dense mapping in large-scale environments.","The code has been made open-source (https://github.com/GREAT-WHU/DBA-Fusion)."],"url":"http://arxiv.org/abs/2403.13714v1"}
{"created":"2024-03-20 16:14:00","title":"HyLiMo: A Hybrid Live-Synchronized Modular Diagramming Editor as IDE Extension for Technical and Scientific Publications","abstract":"Creating suitable diagrams for technical and scientific publications is challenging and time-consuming, as manual control over the layout is required to communicate information effectively. Existing diagramming tools usually allow modeling the diagrams via a textual domain-specific language (DSL) that can be rendered and auto-layouted or via a graphical editor. While auto-layout is fast, the results are often not satisfying for most publications. However, graphical editors are time-consuming to create large diagrams. The blended or hybrid modeling concept enables creating diagrams efficiently using a DSL and editing the rendered diagram via the graphical editor for fine-tuning. However, hybrid modeling editors are limited to individual diagram types and do not save the layout and style information in the textual description. Therefore, we propose HyLiMo, a hybrid live-synchronized modular diagramming editor. In HyLiMo, diagrams are created using an internal DSL and live synchronized with an interactive graphical editor for the rendered diagram, allowing a straightforward layout and style change, which is stored in the DSL code. HyLiMo is independent of specific diagram types, but we offer specific functionality for UML class diagrams. Using the language server protocol, we implement it as a web app and IDE extension. The results of our user study indicate that such an approach enables fast and precise diagramming.","sentences":["Creating suitable diagrams for technical and scientific publications is challenging and time-consuming, as manual control over the layout is required to communicate information effectively.","Existing diagramming tools usually allow modeling the diagrams via a textual domain-specific language (DSL) that can be rendered and auto-layouted or via a graphical editor.","While auto-layout is fast, the results are often not satisfying for most publications.","However, graphical editors are time-consuming to create large diagrams.","The blended or hybrid modeling concept enables creating diagrams efficiently using a DSL and editing the rendered diagram via the graphical editor for fine-tuning.","However, hybrid modeling editors are limited to individual diagram types and do not save the layout and style information in the textual description.","Therefore, we propose HyLiMo, a hybrid live-synchronized modular diagramming editor.","In HyLiMo, diagrams are created using an internal DSL and live synchronized with an interactive graphical editor for the rendered diagram, allowing a straightforward layout and style change, which is stored in the DSL code.","HyLiMo is independent of specific diagram types, but we offer specific functionality for UML class diagrams.","Using the language server protocol, we implement it as a web app and IDE extension.","The results of our user study indicate that such an approach enables fast and precise diagramming."],"url":"http://arxiv.org/abs/2403.13711v1"}
{"created":"2024-03-20 16:08:57","title":"Research Re: search & Re-search","abstract":"Search algorithms are often categorized by their node expansion strategy. One option is the depth-first strategy, a simple backtracking strategy that traverses the search space in the order in which successor nodes are generated. An alternative is the best-first strategy, which was designed to make it possible to use domain-specific heuristic information. By exploring promising parts of the search space first, best-first algorithms are usually more efficient than depth-first algorithms.   In programs that play minimax games such as chess and checkers, the efficiency of the search is of crucial importance. Given the success of best-first algorithms in other domains, one would expect them to be used for minimax games too. However, all high-performance game-playing programs are based on a depth-first algorithm.   This study takes a closer look at a depth-first algorithm, AB, and a best-first algorithm, SSS. The prevailing opinion on these algorithms is that SSS offers the potential for a more efficient search, but that its complicated formulation and exponential memory requirements render it impractical. The theoretical part of this work shows that there is a surprisingly straightforward link between the two algorithms -- for all practical purposes, SSS is a special case of AB. Subsequent empirical evidence proves the prevailing opinion on SSS to be wrong: it is not a complicated algorithm, it does not need too much memory, and it is also not more efficient than depth-first search.","sentences":["Search algorithms are often categorized by their node expansion strategy.","One option is the depth-first strategy, a simple backtracking strategy that traverses the search space in the order in which successor nodes are generated.","An alternative is the best-first strategy, which was designed to make it possible to use domain-specific heuristic information.","By exploring promising parts of the search space first, best-first algorithms are usually more efficient than depth-first algorithms.   ","In programs that play minimax games such as chess and checkers, the efficiency of the search is of crucial importance.","Given the success of best-first algorithms in other domains, one would expect them to be used for minimax games too.","However, all high-performance game-playing programs are based on a depth-first algorithm.   ","This study takes a closer look at a depth-first algorithm, AB, and a best-first algorithm, SSS.","The prevailing opinion on these algorithms is that SSS offers the potential for a more efficient search, but that its complicated formulation and exponential memory requirements render it impractical.","The theoretical part of this work shows that there is a surprisingly straightforward link between the two algorithms -- for all practical purposes, SSS is a special case of AB.","Subsequent empirical evidence proves the prevailing opinion on SSS to be wrong: it is not a complicated algorithm, it does not need too much memory, and it is also not more efficient than depth-first search."],"url":"http://arxiv.org/abs/2403.13705v1"}
{"created":"2024-03-20 16:08:27","title":"Improving the Adaptive Moment Estimation (ADAM) stochastic optimizer through an Implicit-Explicit (IMEX) time-stepping approach","abstract":"The Adam optimizer, often used in Machine Learning for neural network training, corresponds to an underlying ordinary differential equation (ODE) in the limit of very small learning rates. This work shows that the classical Adam algorithm is a first order implicit-explicit (IMEX) Euler discretization of the underlying ODE. Employing the time discretization point of view, we propose new extensions of the Adam scheme obtained by using higher order IMEX methods to solve the ODE. Based on this approach, we derive a new optimization algorithm for neural network training that performs better than classical Adam on several regression and classification problems.","sentences":["The Adam optimizer, often used in Machine Learning for neural network training, corresponds to an underlying ordinary differential equation (ODE) in the limit of very small learning rates.","This work shows that the classical Adam algorithm is a first order implicit-explicit (IMEX) Euler discretization of the underlying ODE.","Employing the time discretization point of view, we propose new extensions of the Adam scheme obtained by using higher order IMEX methods to solve the ODE.","Based on this approach, we derive a new optimization algorithm for neural network training that performs better than classical Adam on several regression and classification problems."],"url":"http://arxiv.org/abs/2403.13704v1"}
{"created":"2024-03-20 16:07:04","title":"Fostc3net:A Lightweight YOLOv5 Based On the Network Structure Optimization","abstract":"Transmission line detection technology is crucial for automatic monitoring and ensuring the safety of electrical facilities. The YOLOv5 series is currently one of the most advanced and widely used methods for object detection. However, it faces inherent challenges, such as high computational load on devices and insufficient detection accuracy. To address these concerns, this paper presents an enhanced lightweight YOLOv5 technique customized for mobile devices, specifically intended for identifying objects associated with transmission lines. The C3Ghost module is integrated into the convolutional network of YOLOv5 to reduce floating point operations per second (FLOPs) in the feature channel fusion process and improve feature expression performance. In addition, a FasterNet module is introduced to replace the c3 module in the YOLOv5 Backbone. The FasterNet module uses Partial Convolutions to process only a portion of the input channels, improving feature extraction efficiency and reducing computational overhead. To address the imbalance between simple and challenging samples in the dataset and the diversity of aspect ratios of bounding boxes, the wIoU v3 LOSS is adopted as the loss function. To validate the performance of the proposed approach, Experiments are conducted on a custom dataset of transmission line poles. The results show that the proposed model achieves a 1% increase in detection accuracy, a 13% reduction in FLOPs, and a 26% decrease in model parameters compared to the existing YOLOv5.In the ablation experiment, it was also discovered that while the Fastnet module and the CSghost module improved the precision of the original YOLOv5 baseline model, they caused a decrease in the mAP@.5-.95 metric. However, the improvement of the wIoUv3 loss function significantly mitigated the decline of the mAP@.5-.95 metric.","sentences":["Transmission line detection technology is crucial for automatic monitoring and ensuring the safety of electrical facilities.","The YOLOv5 series is currently one of the most advanced and widely used methods for object detection.","However, it faces inherent challenges, such as high computational load on devices and insufficient detection accuracy.","To address these concerns, this paper presents an enhanced lightweight YOLOv5 technique customized for mobile devices, specifically intended for identifying objects associated with transmission lines.","The C3Ghost module is integrated into the convolutional network of YOLOv5 to reduce floating point operations per second (FLOPs) in the feature channel fusion process and improve feature expression performance.","In addition, a FasterNet module is introduced to replace the c3 module in the YOLOv5 Backbone.","The FasterNet module uses Partial Convolutions to process only a portion of the input channels, improving feature extraction efficiency and reducing computational overhead.","To address the imbalance between simple and challenging samples in the dataset and the diversity of aspect ratios of bounding boxes, the wIoU v3 LOSS is adopted as the loss function.","To validate the performance of the proposed approach, Experiments are conducted on a custom dataset of transmission line poles.","The results show that the proposed model achieves a 1% increase in detection accuracy, a 13% reduction in FLOPs, and a 26% decrease in model parameters compared to the existing YOLOv5.In the ablation experiment, it was also discovered that while the Fastnet module and the CSghost module improved the precision of the original YOLOv5 baseline model, they caused a decrease in the mAP@.5-.95 metric.","However, the improvement of the wIoUv3 loss function significantly mitigated the decline of the mAP@.5-.95 metric."],"url":"http://arxiv.org/abs/2403.13703v1"}
{"created":"2024-03-20 16:06:45","title":"Constrained and Ordered Level Planarity Parameterized by the Number of Levels","abstract":"The problem Level Planarity asks for a crossing-free drawing of a graph in the plane such that vertices are placed at prescribed y-coordinates (called levels) and such that every edge is realized as a y-monotone curve. In the variant Constrained Level Planarity (CLP), each level $y$ is equipped with a partial order $\\prec_y$ on its vertices and in the desired drawing the left-to-right order of vertices on level $y$ has to be a linear extension of $\\prec_y$. Ordered Level Planarity (OLP) corresponds to the special case of CLP where the given partial orders $\\prec_y$ are total orders. Previous results by Br\\\"uckner and Rutter [SODA 2017] and Klemz and Rote [ACM Trans. Alg. 2019] state that both CLP and OLP are NP-hard even in severely restricted cases. In particular, they remain NP-hard even when restricted to instances whose width (the maximum number of vertices that may share a common level) is at most two. In this paper, we focus on the other dimension: we study the parameterized complexity of CLP and OLP with respect to the height (the number of levels).   We show that OLP parameterized by the height is complete with respect to the complexity class XNLP, which was first studied by Elberfeld et al. [Algorithmica 2015] (under a different name) and recently made more prominent by Bodlaender et al. [FOCS 2021]. It contains all parameterized problems that can be solved nondeterministically in time $f(k) n^{O(1)}$ and space $f(k) \\log n$ (where $f$ is a computable function, $n$ is the input size, and $k$ is the parameter). If a problem is XNLP-complete, it lies in XP, but is W[$t$]-hard for every $t$.   In contrast to the fact that OLP parameterized by the height lies in XP, it turns out that CLP is NP-hard even when restricted to instances of height 4. We complement this result by showing that CLP can be solved in polynomial time for instances of height at most 3.","sentences":["The problem Level Planarity asks for a crossing-free drawing of a graph in the plane such that vertices are placed at prescribed y-coordinates (called levels) and such that every edge is realized as a y-monotone curve.","In the variant Constrained Level Planarity (CLP), each level $y$ is equipped with a partial order $\\prec_y$ on its vertices and in the desired drawing the left-to-right order of vertices on level $y$ has to be a linear extension of $\\prec_y$. Ordered Level Planarity (OLP) corresponds to the special case of CLP where the given partial orders $\\prec_y$ are total orders.","Previous results by Br\\\"uckner and Rutter [SODA 2017] and Klemz and Rote [ACM Trans.","Alg. 2019]","state that both CLP and OLP are NP-hard even in severely restricted cases.","In particular, they remain NP-hard even when restricted to instances whose width (the maximum number of vertices that may share a common level) is at most two.","In this paper, we focus on the other dimension: we study the parameterized complexity of CLP and OLP with respect to the height (the number of levels).   ","We show that OLP parameterized by the height is complete with respect to the complexity class XNLP, which was first studied by Elberfeld et al.","[Algorithmica 2015] (under a different name) and recently made more prominent by Bodlaender et al.","[FOCS 2021].","It contains all parameterized problems that can be solved nondeterministically in time $f(k) n^{O(1)}$ and space $f(k) \\log n$ (where $f$ is a computable function, $n$ is the input size, and $k$ is the parameter).","If a problem is XNLP-complete, it lies in XP, but is W[$t$]-hard for every $t$.   ","In contrast to the fact that OLP parameterized by the height lies in XP, it turns out that CLP is NP-hard even when restricted to instances of height 4.","We complement this result by showing that CLP can be solved in polynomial time for instances of height at most 3."],"url":"http://arxiv.org/abs/2403.13702v1"}
{"created":"2024-03-20 16:06:01","title":"What Matters for Active Texture Recognition With Vision-Based Tactile Sensors","abstract":"This paper explores active sensing strategies that employ vision-based tactile sensors for robotic perception and classification of fabric textures. We formalize the active sampling problem in the context of tactile fabric recognition and provide an implementation of information-theoretic exploration strategies based on minimizing predictive entropy and variance of probabilistic models. Through ablation studies and human experiments, we investigate which components are crucial for quick and reliable texture recognition. Along with the active sampling strategies, we evaluate neural network architectures, representations of uncertainty, influence of data augmentation, and dataset variability. By evaluating our method on a previously published Active Clothing Perception Dataset and on a real robotic system, we establish that the choice of the active exploration strategy has only a minor influence on the recognition accuracy, whereas data augmentation and dropout rate play a significantly larger role. In a comparison study, while humans achieve 66.9% recognition accuracy, our best approach reaches 90.0% in under 5 touches, highlighting that vision-based tactile sensors are highly effective for fabric texture recognition.","sentences":["This paper explores active sensing strategies that employ vision-based tactile sensors for robotic perception and classification of fabric textures.","We formalize the active sampling problem in the context of tactile fabric recognition and provide an implementation of information-theoretic exploration strategies based on minimizing predictive entropy and variance of probabilistic models.","Through ablation studies and human experiments, we investigate which components are crucial for quick and reliable texture recognition.","Along with the active sampling strategies, we evaluate neural network architectures, representations of uncertainty, influence of data augmentation, and dataset variability.","By evaluating our method on a previously published Active Clothing Perception Dataset and on a real robotic system, we establish that the choice of the active exploration strategy has only a minor influence on the recognition accuracy, whereas data augmentation and dropout rate play a significantly larger role.","In a comparison study, while humans achieve 66.9% recognition accuracy, our best approach reaches 90.0% in under 5 touches, highlighting that vision-based tactile sensors are highly effective for fabric texture recognition."],"url":"http://arxiv.org/abs/2403.13701v1"}
{"created":"2024-03-20 16:04:57","title":"Taming Differentiable Logics with Coq Formalisation","abstract":"For performance and verification in machine learning, new methods have recently been proposed that optimise learning systems to satisfy formally expressed logical properties. Among these methods, differentiable logics (DLs) are used to translate propositional or first-order formulae into loss functions deployed for optimisation in machine learning. At the same time, recent attempts to give programming language support for verification of neural networks showed that DLs can be used to compile verification properties to machine-learning backends. This situation is calling for stronger guarantees about the soundness of such compilers, the soundness and compositionality of DLs, and the differentiability and performance of the resulting loss functions. In this paper, we propose an approach to formalise existing DLs using the Mathematical Components library in the Coq proof assistant. Thanks to this formalisation, we are able to give uniform semantics to otherwise disparate DLs, give formal proofs to existing informal arguments, find errors in previous work, and provide formal proofs to missing conjectured properties. This work is meant as a stepping stone for the development of programming language support for verification of machine learning.","sentences":["For performance and verification in machine learning, new methods have recently been proposed that optimise learning systems to satisfy formally expressed logical properties.","Among these methods, differentiable logics (DLs) are used to translate propositional or first-order formulae into loss functions deployed for optimisation in machine learning.","At the same time, recent attempts to give programming language support for verification of neural networks showed that DLs can be used to compile verification properties to machine-learning backends.","This situation is calling for stronger guarantees about the soundness of such compilers, the soundness and compositionality of DLs, and the differentiability and performance of the resulting loss functions.","In this paper, we propose an approach to formalise existing DLs using the Mathematical Components library in the Coq proof assistant.","Thanks to this formalisation, we are able to give uniform semantics to otherwise disparate DLs, give formal proofs to existing informal arguments, find errors in previous work, and provide formal proofs to missing conjectured properties.","This work is meant as a stepping stone for the development of programming language support for verification of machine learning."],"url":"http://arxiv.org/abs/2403.13700v1"}
{"created":"2024-03-20 16:03:01","title":"Insight Into the Collocation of Multi-Source Satellite Imagery for Multi-Scale Vessel Detection","abstract":"Ship detection from satellite imagery using Deep Learning (DL) is an indispensable solution for maritime surveillance. However, applying DL models trained on one dataset to others having differences in spatial resolution and radiometric features requires many adjustments. To overcome this issue, this paper focused on the DL models trained on datasets that consist of different optical images and a combination of radar and optical data. When dealing with a limited number of training images, the performance of DL models via this approach was satisfactory. They could improve 5-20% of average precision, depending on the optical images tested. Likewise, DL models trained on the combined optical and radar dataset could be applied to both optical and radar images. Our experiments showed that the models trained on an optical dataset could be used for radar images, while those trained on a radar dataset offered very poor scores when applied to optical images.","sentences":["Ship detection from satellite imagery using Deep Learning (DL) is an indispensable solution for maritime surveillance.","However, applying DL models trained on one dataset to others having differences in spatial resolution and radiometric features requires many adjustments.","To overcome this issue, this paper focused on the DL models trained on datasets that consist of different optical images and a combination of radar and optical data.","When dealing with a limited number of training images, the performance of DL models via this approach was satisfactory.","They could improve 5-20% of average precision, depending on the optical images tested.","Likewise, DL models trained on the combined optical and radar dataset could be applied to both optical and radar images.","Our experiments showed that the models trained on an optical dataset could be used for radar images, while those trained on a radar dataset offered very poor scores when applied to optical images."],"url":"http://arxiv.org/abs/2403.13698v1"}
{"created":"2024-03-20 15:57:44","title":"Loss Regularizing Robotic Terrain Classification","abstract":"Locomotion mechanics of legged robots are suitable when pacing through difficult terrains. Recognising terrains for such robots are important to fully yoke the versatility of their movements. Consequently, robotic terrain classification becomes significant to classify terrains in real time with high accuracy. The conventional classifiers suffer from overfitting problem, low accuracy problem, high variance problem, and not suitable for live dataset. On the other hand, classifying a growing dataset is difficult for convolution based terrain classification. Supervised recurrent models are also not practical for this classification. Further, the existing recurrent architectures are still evolving to improve accuracy of terrain classification based on live variable-length sensory data collected from legged robots. This paper proposes a new semi-supervised method for terrain classification of legged robots, avoiding preprocessing of long variable-length dataset. The proposed method has a stacked Long Short-Term Memory architecture, including a new loss regularization. The proposed method solves the existing problems and improves accuracy. Comparison with the existing architectures show the improvements.","sentences":["Locomotion mechanics of legged robots are suitable when pacing through difficult terrains.","Recognising terrains for such robots are important to fully yoke the versatility of their movements.","Consequently, robotic terrain classification becomes significant to classify terrains in real time with high accuracy.","The conventional classifiers suffer from overfitting problem, low accuracy problem, high variance problem, and not suitable for live dataset.","On the other hand, classifying a growing dataset is difficult for convolution based terrain classification.","Supervised recurrent models are also not practical for this classification.","Further, the existing recurrent architectures are still evolving to improve accuracy of terrain classification based on live variable-length sensory data collected from legged robots.","This paper proposes a new semi-supervised method for terrain classification of legged robots, avoiding preprocessing of long variable-length dataset.","The proposed method has a stacked Long Short-Term Memory architecture, including a new loss regularization.","The proposed method solves the existing problems and improves accuracy.","Comparison with the existing architectures show the improvements."],"url":"http://arxiv.org/abs/2403.13695v1"}
{"created":"2024-03-20 15:56:31","title":"Overview of Publicly Available Degradation Data Sets for Tasks within Prognostics and Health Management","abstract":"Central to the efficacy of prognostics and health management methods is the acquisition and analysis of degradation data, which encapsulates the evolving health condition of engineering systems over time. Degradation data serves as a rich source of information, offering invaluable insights into the underlying degradation processes, failure modes, and performance trends of engineering systems. This paper provides an overview of publicly available degradation data sets.","sentences":["Central to the efficacy of prognostics and health management methods is the acquisition and analysis of degradation data, which encapsulates the evolving health condition of engineering systems over time.","Degradation data serves as a rich source of information, offering invaluable insights into the underlying degradation processes, failure modes, and performance trends of engineering systems.","This paper provides an overview of publicly available degradation data sets."],"url":"http://arxiv.org/abs/2403.13694v1"}
{"created":"2024-03-20 15:53:07","title":"MotorEase: Automated Detection of Motor Impairment Accessibility Issues in Mobile App UIs","abstract":"Recent research has begun to examine the potential of automatically finding and fixing accessibility issues that manifest in software. However, while recent work makes important progress, it has generally been skewed toward identifying issues that affect users with certain disabilities, such as those with visual or hearing impairments. However, there are other groups of users with different types of disabilities that also need software tooling support to improve their experience. As such, this paper aims to automatically identify accessibility issues that affect users with motor-impairments.   To move toward this goal, this paper introduces a novel approach, called MotorEase, capable of identifying accessibility issues in mobile app UIs that impact motor-impaired users. Motor-impaired users often have limited ability to interact with touch-based devices, and instead may make use of a switch or other assistive mechanism -- hence UIs must be designed to support both limited touch gestures and the use of assistive devices. MotorEase adapts computer vision and text processing techniques to enable a semantic understanding of app UI screens, enabling the detection of violations related to four popular, previously unexplored UI design guidelines that support motor-impaired users, including: (i) visual touch target size, (ii) expanding sections, (iii) persisting elements, and (iv) adjacent icon visual distance. We evaluate MotorEase on a newly derived benchmark, called MotorCheck, that contains 555 manually annotated examples of violations to the above accessibility guidelines, across 1599 screens collected from 70 applications via a mobile app testing tool. Our experiments illustrate that MotorEase is able to identify violations with an average accuracy of ~90%, and a false positive rate of less than 9%, outperforming baseline techniques.","sentences":["Recent research has begun to examine the potential of automatically finding and fixing accessibility issues that manifest in software.","However, while recent work makes important progress, it has generally been skewed toward identifying issues that affect users with certain disabilities, such as those with visual or hearing impairments.","However, there are other groups of users with different types of disabilities that also need software tooling support to improve their experience.","As such, this paper aims to automatically identify accessibility issues that affect users with motor-impairments.   ","To move toward this goal, this paper introduces a novel approach, called MotorEase, capable of identifying accessibility issues in mobile app UIs that impact motor-impaired users.","Motor-impaired users often have limited ability to interact with touch-based devices, and instead may make use of a switch or other assistive mechanism -- hence UIs must be designed to support both limited touch gestures and the use of assistive devices.","MotorEase adapts computer vision and text processing techniques to enable a semantic understanding of app UI screens, enabling the detection of violations related to four popular, previously unexplored UI design guidelines that support motor-impaired users, including: (i) visual touch target size, (ii) expanding sections, (iii) persisting elements, and (iv) adjacent icon visual distance.","We evaluate MotorEase on a newly derived benchmark, called MotorCheck, that contains 555 manually annotated examples of violations to the above accessibility guidelines, across 1599 screens collected from 70 applications via a mobile app testing tool.","Our experiments illustrate that MotorEase is able to identify violations with an average accuracy of ~90%, and a false positive rate of less than 9%, outperforming baseline techniques."],"url":"http://arxiv.org/abs/2403.13690v1"}
{"created":"2024-03-20 15:41:39","title":"SPTNet: An Efficient Alternative Framework for Generalized Category Discovery with Spatial Prompt Tuning","abstract":"Generalized Category Discovery (GCD) aims to classify unlabelled images from both `seen' and `unseen' classes by transferring knowledge from a set of labelled `seen' class images. A key theme in existing GCD approaches is adapting large-scale pre-trained models for the GCD task. An alternate perspective, however, is to adapt the data representation itself for better alignment with the pre-trained model. As such, in this paper, we introduce a two-stage adaptation approach termed SPTNet, which iteratively optimizes model parameters (i.e., model-finetuning) and data parameters (i.e., prompt learning). Furthermore, we propose a novel spatial prompt tuning method (SPT) which considers the spatial property of image data, enabling the method to better focus on object parts, which can transfer between seen and unseen classes. We thoroughly evaluate our SPTNet on standard benchmarks and demonstrate that our method outperforms existing GCD methods. Notably, we find our method achieves an average accuracy of 61.4% on the SSB, surpassing prior state-of-the-art methods by approximately 10%. The improvement is particularly remarkable as our method yields extra parameters amounting to only 0.117% of those in the backbone architecture. Project page: https://visual-ai.github.io/sptnet.","sentences":["Generalized Category Discovery (GCD) aims to classify unlabelled images from both `seen' and `unseen' classes by transferring knowledge from a set of labelled `seen' class images.","A key theme in existing GCD approaches is adapting large-scale pre-trained models for the GCD task.","An alternate perspective, however, is to adapt the data representation itself for better alignment with the pre-trained model.","As such, in this paper, we introduce a two-stage adaptation approach termed SPTNet, which iteratively optimizes model parameters (i.e., model-finetuning) and data parameters (i.e., prompt learning).","Furthermore, we propose a novel spatial prompt tuning method (SPT) which considers the spatial property of image data, enabling the method to better focus on object parts, which can transfer between seen and unseen classes.","We thoroughly evaluate our SPTNet on standard benchmarks and demonstrate that our method outperforms existing GCD methods.","Notably, we find our method achieves an average accuracy of 61.4% on the SSB, surpassing prior state-of-the-art methods by approximately 10%.","The improvement is particularly remarkable as our method yields extra parameters amounting to only 0.117% of those in the backbone architecture.","Project page: https://visual-ai.github.io/sptnet."],"url":"http://arxiv.org/abs/2403.13684v1"}
{"created":"2024-03-20 15:41:32","title":"DVMNet: Computing Relative Pose for Unseen Objects Beyond Hypotheses","abstract":"Determining the relative pose of an object between two images is pivotal to the success of generalizable object pose estimation. Existing approaches typically approximate the continuous pose representation with a large number of discrete pose hypotheses, which incurs a computationally expensive process of scoring each hypothesis at test time. By contrast, we present a Deep Voxel Matching Network (DVMNet) that eliminates the need for pose hypotheses and computes the relative object pose in a single pass. To this end, we map the two input RGB images, reference and query, to their respective voxelized 3D representations. We then pass the resulting voxels through a pose estimation module, where the voxels are aligned and the pose is computed in an end-to-end fashion by solving a least-squares problem. To enhance robustness, we introduce a weighted closest voxel algorithm capable of mitigating the impact of noisy voxels. We conduct extensive experiments on the CO3D, LINEMOD, and Objaverse datasets, demonstrating that our method delivers more accurate relative pose estimates for novel objects at a lower computational cost compared to state-of-the-art methods. Our code is released at: https://github.com/sailor-z/DVMNet/.","sentences":["Determining the relative pose of an object between two images is pivotal to the success of generalizable object pose estimation.","Existing approaches typically approximate the continuous pose representation with a large number of discrete pose hypotheses, which incurs a computationally expensive process of scoring each hypothesis at test time.","By contrast, we present a Deep Voxel Matching Network (DVMNet) that eliminates the need for pose hypotheses and computes the relative object pose in a single pass.","To this end, we map the two input RGB images, reference and query, to their respective voxelized 3D representations.","We then pass the resulting voxels through a pose estimation module, where the voxels are aligned and the pose is computed in an end-to-end fashion by solving a least-squares problem.","To enhance robustness, we introduce a weighted closest voxel algorithm capable of mitigating the impact of noisy voxels.","We conduct extensive experiments on the CO3D, LINEMOD, and Objaverse datasets, demonstrating that our method delivers more accurate relative pose estimates for novel objects at a lower computational cost compared to state-of-the-art methods.","Our code is released at: https://github.com/sailor-z/DVMNet/."],"url":"http://arxiv.org/abs/2403.13683v1"}
{"created":"2024-03-20 15:40:18","title":"Threats, Attacks, and Defenses in Machine Unlearning: A Survey","abstract":"Recently, Machine Unlearning (MU) has gained considerable attention for its potential to improve AI safety by removing the influence of specific data from trained Machine Learning (ML) models. This process, known as knowledge removal, addresses concerns about data such as sensitivity, copyright restrictions, obsolescence, or low quality. This capability is also crucial for ensuring compliance with privacy regulations such as the Right To Be Forgotten (RTBF). Therefore, strategic knowledge removal mitigates the risk of harmful outcomes, safeguarding against biases, misinformation, and unauthorized data exploitation, thereby enhancing the ethical use and reliability of AI systems. Efforts have been made to design efficient unlearning approaches, with MU services being examined for integration with existing machine learning as a service (MLaaS), allowing users to submit requests to erase data. However, recent research highlights vulnerabilities in machine unlearning systems, such as information leakage and malicious unlearning requests, that can lead to significant security and privacy concerns. Moreover, extensive research indicates that unlearning methods and prevalent attacks fulfill diverse roles within MU systems. For instance, unlearning can act as a mechanism to recover models from backdoor attacks, while backdoor attacks themselves can serve as an evaluation metric for unlearning effectiveness. This underscores the intricate relationship and complex interplay between these elements in maintaining system functionality and safety. Therefore, this survey seeks to bridge the gap between the extensive number of studies on threats, attacks, and defenses in machine unlearning and the absence of a comprehensive review that categorizes their taxonomy, methods, and solutions, thus offering valuable insights for future research directions and practical implementations.","sentences":["Recently, Machine Unlearning (MU) has gained considerable attention for its potential to improve AI safety by removing the influence of specific data from trained Machine Learning (ML) models.","This process, known as knowledge removal, addresses concerns about data such as sensitivity, copyright restrictions, obsolescence, or low quality.","This capability is also crucial for ensuring compliance with privacy regulations such as the Right To Be Forgotten (RTBF).","Therefore, strategic knowledge removal mitigates the risk of harmful outcomes, safeguarding against biases, misinformation, and unauthorized data exploitation, thereby enhancing the ethical use and reliability of AI systems.","Efforts have been made to design efficient unlearning approaches, with MU services being examined for integration with existing machine learning as a service (MLaaS), allowing users to submit requests to erase data.","However, recent research highlights vulnerabilities in machine unlearning systems, such as information leakage and malicious unlearning requests, that can lead to significant security and privacy concerns.","Moreover, extensive research indicates that unlearning methods and prevalent attacks fulfill diverse roles within MU systems.","For instance, unlearning can act as a mechanism to recover models from backdoor attacks, while backdoor attacks themselves can serve as an evaluation metric for unlearning effectiveness.","This underscores the intricate relationship and complex interplay between these elements in maintaining system functionality and safety.","Therefore, this survey seeks to bridge the gap between the extensive number of studies on threats, attacks, and defenses in machine unlearning and the absence of a comprehensive review that categorizes their taxonomy, methods, and solutions, thus offering valuable insights for future research directions and practical implementations."],"url":"http://arxiv.org/abs/2403.13682v1"}
{"created":"2024-03-20 15:39:54","title":"PARAMANU-AYN: An Efficient Novel Generative and Instruction-tuned Language Model for Indian Legal Case Documents","abstract":"In this paper, we present PARAMANU-AYN, a language model based exclusively on case documents of the Supreme Court of India, the Constitution of India, and the Indian Penal Code. The novel Auto Regressive (AR) decoder based model is pretrained from scratch at a context size of 8192. We evaluated our pretrained legal model on perplexity metrics. We also instruction-tuned our pretrained model on a set of 10,763 instructions covering various legal tasks such as legal reasoning, judgement explanation, legal clause generation, legal drafting, legal contract drafting, case summarization, constitutional question-answering, etc. We also evaluated the responses of prompts for instruction-tuned models by GPT-3.5-Turbo on clarity, relevance, completeness, and legal reasoning metrics in a scale of 10. Our model can be run on CPU and achieved 42.46 tokens/sec CPU inference speed. We found that our models, despite not being pretrained on legal books, various legal contracts, and legal documents, were able to learn the domain knowledge required for drafting various legal contracts and legal clauses, and generalize to draft legal contracts and legal clauses with limited instruction tuning. Hence, we conclude that for a strong domain-specialized generative language model (such as legal), very large amounts of data are not required to develop models from scratch. We believe that this work is the first attempt to make a dedicated generative legal language model from scratch for Indian Supreme Court jurisdiction or in legal NLP overall. We plan to release our Paramanu-Ayn model at https://www.bharatgpts.com.","sentences":["In this paper, we present PARAMANU-AYN, a language model based exclusively on case documents of the Supreme Court of India, the Constitution of India, and the Indian Penal Code.","The novel Auto Regressive (AR) decoder based model is pretrained from scratch at a context size of 8192.","We evaluated our pretrained legal model on perplexity metrics.","We also instruction-tuned our pretrained model on a set of 10,763 instructions covering various legal tasks such as legal reasoning, judgement explanation, legal clause generation, legal drafting, legal contract drafting, case summarization, constitutional question-answering, etc.","We also evaluated the responses of prompts for instruction-tuned models by GPT-3.5-Turbo on clarity, relevance, completeness, and legal reasoning metrics in a scale of 10.","Our model can be run on CPU and achieved 42.46 tokens/sec CPU inference speed.","We found that our models, despite not being pretrained on legal books, various legal contracts, and legal documents, were able to learn the domain knowledge required for drafting various legal contracts and legal clauses, and generalize to draft legal contracts and legal clauses with limited instruction tuning.","Hence, we conclude that for a strong domain-specialized generative language model (such as legal), very large amounts of data are not required to develop models from scratch.","We believe that this work is the first attempt to make a dedicated generative legal language model from scratch for Indian Supreme Court jurisdiction or in legal NLP overall.","We plan to release our Paramanu-Ayn model at https://www.bharatgpts.com."],"url":"http://arxiv.org/abs/2403.13681v1"}
{"created":"2024-03-20 15:38:36","title":"RoleInteract: Evaluating the Social Interaction of Role-Playing Agents","abstract":"Large language models (LLMs) have advanced the development of various AI conversational agents, including role-playing conversational agents that mimic diverse characters and human behaviors. While prior research has predominantly focused on enhancing the conversational capability, role-specific knowledge, and stylistic attributes of these agents, there has been a noticeable gap in assessing their social intelligence. In this paper, we introduce RoleInteract, the first benchmark designed to systematically evaluate the sociality of role-playing conversational agents at both individual and group levels of social interactions. The benchmark is constructed from a variety of sources and covers a wide range of 500 characters and over 6,000 question prompts and 30,800 multi-turn role-playing utterances. We conduct comprehensive evaluations on this benchmark using mainstream open-source and closed-source LLMs. We find that agents excelling in individual level does not imply their proficiency in group level. Moreover, the behavior of individuals may drift as a result of the influence exerted by other agents within the group. Experimental results on RoleInteract confirm its significance as a testbed for assessing the social interaction of role-playing conversational agents. The benchmark is publicly accessible at https://github.com/X-PLUG/RoleInteract.","sentences":["Large language models (LLMs) have advanced the development of various AI conversational agents, including role-playing conversational agents that mimic diverse characters and human behaviors.","While prior research has predominantly focused on enhancing the conversational capability, role-specific knowledge, and stylistic attributes of these agents, there has been a noticeable gap in assessing their social intelligence.","In this paper, we introduce RoleInteract, the first benchmark designed to systematically evaluate the sociality of role-playing conversational agents at both individual and group levels of social interactions.","The benchmark is constructed from a variety of sources and covers a wide range of 500 characters and over 6,000 question prompts and 30,800 multi-turn role-playing utterances.","We conduct comprehensive evaluations on this benchmark using mainstream open-source and closed-source LLMs.","We find that agents excelling in individual level does not imply their proficiency in group level.","Moreover, the behavior of individuals may drift as a result of the influence exerted by other agents within the group.","Experimental results on RoleInteract confirm its significance as a testbed for assessing the social interaction of role-playing conversational agents.","The benchmark is publicly accessible at https://github.com/X-PLUG/RoleInteract."],"url":"http://arxiv.org/abs/2403.13679v1"}
{"created":"2024-03-20 15:37:19","title":"AUD-TGN: Advancing Action Unit Detection with Temporal Convolution and GPT-2 in Wild Audiovisual Contexts","abstract":"Leveraging the synergy of both audio data and visual data is essential for understanding human emotions and behaviors, especially in in-the-wild setting. Traditional methods for integrating such multimodal information often stumble, leading to less-than-ideal outcomes in the task of facial action unit detection. To overcome these shortcomings, we propose a novel approach utilizing audio-visual multimodal data. This method enhances audio feature extraction by leveraging Mel Frequency Cepstral Coefficients (MFCC) and Log-Mel spectrogram features alongside a pre-trained VGGish network. Moreover, this paper adaptively captures fusion features across modalities by modeling the temporal relationships, and ultilizes a pre-trained GPT-2 model for sophisticated context-aware fusion of multimodal information. Our method notably improves the accuracy of AU detection by understanding the temporal and contextual nuances of the data, showcasing significant advancements in the comprehension of intricate scenarios. These findings underscore the potential of integrating temporal dynamics and contextual interpretation, paving the way for future research endeavors.","sentences":["Leveraging the synergy of both audio data and visual data is essential for understanding human emotions and behaviors, especially in in-the-wild setting.","Traditional methods for integrating such multimodal information often stumble, leading to less-than-ideal outcomes in the task of facial action unit detection.","To overcome these shortcomings, we propose a novel approach utilizing audio-visual multimodal data.","This method enhances audio feature extraction by leveraging Mel Frequency Cepstral Coefficients (MFCC) and Log-Mel spectrogram features alongside a pre-trained VGGish network.","Moreover, this paper adaptively captures fusion features across modalities by modeling the temporal relationships, and ultilizes a pre-trained GPT-2 model for sophisticated context-aware fusion of multimodal information.","Our method notably improves the accuracy of AU detection by understanding the temporal and contextual nuances of the data, showcasing significant advancements in the comprehension of intricate scenarios.","These findings underscore the potential of integrating temporal dynamics and contextual interpretation, paving the way for future research endeavors."],"url":"http://arxiv.org/abs/2403.13678v1"}
{"created":"2024-03-20 15:35:36","title":"Retina Vision Transformer (RetinaViT): Introducing Scaled Patches into Vision Transformers","abstract":"Humans see low and high spatial frequency components at the same time, and combine the information from both to form a visual scene. Drawing on this neuroscientific inspiration, we propose an altered Vision Transformer architecture where patches from scaled down versions of the input image are added to the input of the first Transformer Encoder layer. We name this model Retina Vision Transformer (RetinaViT) due to its inspiration from the human visual system. Our experiments show that when trained on the ImageNet-1K dataset with a moderate configuration, RetinaViT achieves a 3.3% performance improvement over the original ViT. We hypothesize that this improvement can be attributed to the inclusion of low spatial frequency components in the input, which improves the ability to capture structural features, and to select and forward important features to deeper layers. RetinaViT thereby opens doors to further investigations into vertical pathways and attention patterns.","sentences":["Humans see low and high spatial frequency components at the same time, and combine the information from both to form a visual scene.","Drawing on this neuroscientific inspiration, we propose an altered Vision Transformer architecture where patches from scaled down versions of the input image are added to the input of the first Transformer Encoder layer.","We name this model Retina Vision Transformer (RetinaViT) due to its inspiration from the human visual system.","Our experiments show that when trained on the ImageNet-1K dataset with a moderate configuration, RetinaViT achieves a 3.3% performance improvement over the original ViT.","We hypothesize that this improvement can be attributed to the inclusion of low spatial frequency components in the input, which improves the ability to capture structural features, and to select and forward important features to deeper layers.","RetinaViT thereby opens doors to further investigations into vertical pathways and attention patterns."],"url":"http://arxiv.org/abs/2403.13677v1"}
{"created":"2024-03-20 15:32:56","title":"Reward-Driven Automated Curriculum Learning for Interaction-Aware Self-Driving at Unsignalized Intersections","abstract":"In this work, we present a reward-driven automated curriculum reinforcement learning approach for interaction-aware self-driving at unsignalized intersections, taking into account the uncertainties associated with surrounding vehicles (SVs). These uncertainties encompass the uncertainty of SVs' driving intention and also the quantity of SVs. To deal with this problem, the curriculum set is specifically designed to accommodate a progressively increasing number of SVs. By implementing an automated curriculum selection mechanism, the importance weights are rationally allocated across various curricula, thereby facilitating improved sample efficiency and training outcomes. Furthermore, the reward function is meticulously designed to guide the agent towards effective policy exploration. Thus the proposed framework could proactively address the above uncertainties at unsignalized intersections by employing the automated curriculum learning technique that progressively increases task difficulty, and this ensures safe self-driving through effective interaction with SVs. Comparative experiments are conducted in $Highway\\_Env$, and the results indicate that our approach achieves the highest task success rate, attains strong robustness to initialization parameters of the curriculum selection module, and exhibits superior adaptability to diverse situational configurations at unsignalized intersections. Furthermore, the effectiveness of the proposed method is validated using the high-fidelity CARLA simulator.","sentences":["In this work, we present a reward-driven automated curriculum reinforcement learning approach for interaction-aware self-driving at unsignalized intersections, taking into account the uncertainties associated with surrounding vehicles (SVs).","These uncertainties encompass the uncertainty of SVs' driving intention and also the quantity of SVs.","To deal with this problem, the curriculum set is specifically designed to accommodate a progressively increasing number of SVs.","By implementing an automated curriculum selection mechanism, the importance weights are rationally allocated across various curricula, thereby facilitating improved sample efficiency and training outcomes.","Furthermore, the reward function is meticulously designed to guide the agent towards effective policy exploration.","Thus the proposed framework could proactively address the above uncertainties at unsignalized intersections by employing the automated curriculum learning technique that progressively increases task difficulty, and this ensures safe self-driving through effective interaction with SVs.","Comparative experiments are conducted in $Highway\\_Env$, and the results indicate that our approach achieves the highest task success rate, attains strong robustness to initialization parameters of the curriculum selection module, and exhibits superior adaptability to diverse situational configurations at unsignalized intersections.","Furthermore, the effectiveness of the proposed method is validated using the high-fidelity CARLA simulator."],"url":"http://arxiv.org/abs/2403.13674v1"}
{"created":"2024-03-20 15:29:59","title":"Machine Learning Optimized Approach for Parameter Selection in MESHFREE Simulations","abstract":"Meshfree simulation methods are emerging as compelling alternatives to conventional mesh-based approaches, particularly in the fields of Computational Fluid Dynamics (CFD) and continuum mechanics. In this publication, we provide a comprehensive overview of our research combining Machine Learning (ML) and Fraunhofer's MESHFREE software (www.meshfree.eu), a powerful tool utilizing a numerical point cloud in a Generalized Finite Difference Method (GFDM). This tool enables the effective handling of complex flow domains, moving geometries, and free surfaces, while allowing users to finely tune local refinement and quality parameters for an optimal balance between computation time and results accuracy. However, manually determining the optimal parameter combination poses challenges, especially for less experienced users. We introduce a novel ML-optimized approach, using active learning, regression trees, and visualization on MESHFREE simulation data, demonstrating the impact of input combinations on results quality and computation time. This research contributes valuable insights into parameter optimization in meshfree simulations, enhancing accessibility and usability for a broader user base in scientific and engineering applications.","sentences":["Meshfree simulation methods are emerging as compelling alternatives to conventional mesh-based approaches, particularly in the fields of Computational Fluid Dynamics (CFD) and continuum mechanics.","In this publication, we provide a comprehensive overview of our research combining Machine Learning (ML) and Fraunhofer's MESHFREE software (www.meshfree.eu), a powerful tool utilizing a numerical point cloud in a Generalized Finite Difference Method (GFDM).","This tool enables the effective handling of complex flow domains, moving geometries, and free surfaces, while allowing users to finely tune local refinement and quality parameters for an optimal balance between computation time and results accuracy.","However, manually determining the optimal parameter combination poses challenges, especially for less experienced users.","We introduce a novel ML-optimized approach, using active learning, regression trees, and visualization on MESHFREE simulation data, demonstrating the impact of input combinations on results quality and computation time.","This research contributes valuable insights into parameter optimization in meshfree simulations, enhancing accessibility and usability for a broader user base in scientific and engineering applications."],"url":"http://arxiv.org/abs/2403.13672v1"}
{"created":"2024-03-20 15:24:57","title":"DanceCamera3D: 3D Camera Movement Synthesis with Music and Dance","abstract":"Choreographers determine what the dances look like, while cameramen determine the final presentation of dances. Recently, various methods and datasets have showcased the feasibility of dance synthesis. However, camera movement synthesis with music and dance remains an unsolved challenging problem due to the scarcity of paired data. Thus, we present DCM, a new multi-modal 3D dataset, which for the first time combines camera movement with dance motion and music audio. This dataset encompasses 108 dance sequences (3.2 hours) of paired dance-camera-music data from the anime community, covering 4 music genres. With this dataset, we uncover that dance camera movement is multifaceted and human-centric, and possesses multiple influencing factors, making dance camera synthesis a more challenging task compared to camera or dance synthesis alone. To overcome these difficulties, we propose DanceCamera3D, a transformer-based diffusion model that incorporates a novel body attention loss and a condition separation strategy. For evaluation, we devise new metrics measuring camera movement quality, diversity, and dancer fidelity. Utilizing these metrics, we conduct extensive experiments on our DCM dataset, providing both quantitative and qualitative evidence showcasing the effectiveness of our DanceCamera3D model. Code and video demos are available at https://github.com/Carmenw1203/DanceCamera3D-Official.","sentences":["Choreographers determine what the dances look like, while cameramen determine the final presentation of dances.","Recently, various methods and datasets have showcased the feasibility of dance synthesis.","However, camera movement synthesis with music and dance remains an unsolved challenging problem due to the scarcity of paired data.","Thus, we present DCM, a new multi-modal 3D dataset, which for the first time combines camera movement with dance motion and music audio.","This dataset encompasses 108 dance sequences (3.2 hours) of paired dance-camera-music data from the anime community, covering 4 music genres.","With this dataset, we uncover that dance camera movement is multifaceted and human-centric, and possesses multiple influencing factors, making dance camera synthesis a more challenging task compared to camera or dance synthesis alone.","To overcome these difficulties, we propose DanceCamera3D, a transformer-based diffusion model that incorporates a novel body attention loss and a condition separation strategy.","For evaluation, we devise new metrics measuring camera movement quality, diversity, and dancer fidelity.","Utilizing these metrics, we conduct extensive experiments on our DCM dataset, providing both quantitative and qualitative evidence showcasing the effectiveness of our DanceCamera3D model.","Code and video demos are available at https://github.com/Carmenw1203/DanceCamera3D-Official."],"url":"http://arxiv.org/abs/2403.13667v1"}
{"created":"2024-03-20 15:20:30","title":"Grounding Spatial Relations in Text-Only Language Models","abstract":"This paper shows that text-only Language Models (LM) can learn to ground spatial relations like \"left of\" or \"below\" if they are provided with explicit location information of objects and they are properly trained to leverage those locations. We perform experiments on a verbalized version of the Visual Spatial Reasoning (VSR) dataset, where images are coupled with textual statements which contain real or fake spatial relations between two objects of the image. We verbalize the images using an off-the-shelf object detector, adding location tokens to every object label to represent their bounding boxes in textual form. Given the small size of VSR, we do not observe any improvement when using locations, but pretraining the LM over a synthetic dataset automatically derived by us improves results significantly when using location tokens. We thus show that locations allow LMs to ground spatial relations, with our text-only LMs outperforming Vision-and-Language Models and setting the new state-of-the-art for the VSR dataset. Our analysis show that our text-only LMs can generalize beyond the relations seen in the synthetic dataset to some extent, learning also more useful information than that encoded in the spatial rules we used to create the synthetic dataset itself.","sentences":["This paper shows that text-only Language Models (LM) can learn to ground spatial relations like \"left of\" or \"below\" if they are provided with explicit location information of objects and they are properly trained to leverage those locations.","We perform experiments on a verbalized version of the Visual Spatial Reasoning (VSR) dataset, where images are coupled with textual statements which contain real or fake spatial relations between two objects of the image.","We verbalize the images using an off-the-shelf object detector, adding location tokens to every object label to represent their bounding boxes in textual form.","Given the small size of VSR, we do not observe any improvement when using locations, but pretraining the LM over a synthetic dataset automatically derived by us improves results significantly when using location tokens.","We thus show that locations allow LMs to ground spatial relations, with our text-only LMs outperforming Vision-and-Language Models and setting the new state-of-the-art for the VSR dataset.","Our analysis show that our text-only LMs can generalize beyond the relations seen in the synthetic dataset to some extent, learning also more useful information than that encoded in the spatial rules we used to create the synthetic dataset itself."],"url":"http://arxiv.org/abs/2403.13666v1"}
{"created":"2024-03-20 15:14:22","title":"T-Pixel2Mesh: Combining Global and Local Transformer for 3D Mesh Generation from a Single Image","abstract":"Pixel2Mesh (P2M) is a classical approach for reconstructing 3D shapes from a single color image through coarse-to-fine mesh deformation. Although P2M is capable of generating plausible global shapes, its Graph Convolution Network (GCN) often produces overly smooth results, causing the loss of fine-grained geometry details. Moreover, P2M generates non-credible features for occluded regions and struggles with the domain gap from synthetic data to real-world images, which is a common challenge for single-view 3D reconstruction methods. To address these challenges, we propose a novel Transformer-boosted architecture, named T-Pixel2Mesh, inspired by the coarse-to-fine approach of P2M. Specifically, we use a global Transformer to control the holistic shape and a local Transformer to progressively refine the local geometry details with graph-based point upsampling. To enhance real-world reconstruction, we present the simple yet effective Linear Scale Search (LSS), which serves as prompt tuning during the input preprocessing. Our experiments on ShapeNet demonstrate state-of-the-art performance, while results on real-world data show the generalization capability.","sentences":["Pixel2Mesh (P2M) is a classical approach for reconstructing 3D shapes from a single color image through coarse-to-fine mesh deformation.","Although P2M is capable of generating plausible global shapes, its Graph Convolution Network (GCN) often produces overly smooth results, causing the loss of fine-grained geometry details.","Moreover, P2M generates non-credible features for occluded regions and struggles with the domain gap from synthetic data to real-world images, which is a common challenge for single-view 3D reconstruction methods.","To address these challenges, we propose a novel Transformer-boosted architecture, named T-Pixel2Mesh, inspired by the coarse-to-fine approach of P2M. Specifically, we use a global Transformer to control the holistic shape and a local Transformer to progressively refine the local geometry details with graph-based point upsampling.","To enhance real-world reconstruction, we present the simple yet effective Linear Scale Search (LSS), which serves as prompt tuning during the input preprocessing.","Our experiments on ShapeNet demonstrate state-of-the-art performance, while results on real-world data show the generalization capability."],"url":"http://arxiv.org/abs/2403.13663v1"}
{"created":"2024-03-20 15:08:57","title":"ProMamba: Prompt-Mamba for polyp segmentation","abstract":"Detecting polyps through colonoscopy is an important task in medical image segmentation, which provides significant assistance and reference value for clinical surgery. However, accurate segmentation of polyps is a challenging task due to two main reasons. Firstly, polyps exhibit various shapes and colors. Secondly, the boundaries between polyps and their normal surroundings are often unclear. Additionally, significant differences between different datasets lead to limited generalization capabilities of existing methods. To address these issues, we propose a segmentation model based on Prompt-Mamba, which incorporates the latest Vision-Mamba and prompt technologies. Compared to previous models trained on the same dataset, our model not only maintains high segmentation accuracy on the validation part of the same dataset but also demonstrates superior accuracy on unseen datasets, exhibiting excellent generalization capabilities. Notably, we are the first to apply the Vision-Mamba architecture to polyp segmentation and the first to utilize prompt technology in a polyp segmentation model. Our model efficiently accomplishes segmentation tasks, surpassing previous state-of-the-art methods by an average of 5% across six datasets. Furthermore, we have developed multiple versions of our model with scaled parameter counts, achieving better performance than previous models even with fewer parameters. Our code and trained weights will be released soon.","sentences":["Detecting polyps through colonoscopy is an important task in medical image segmentation, which provides significant assistance and reference value for clinical surgery.","However, accurate segmentation of polyps is a challenging task due to two main reasons.","Firstly, polyps exhibit various shapes and colors.","Secondly, the boundaries between polyps and their normal surroundings are often unclear.","Additionally, significant differences between different datasets lead to limited generalization capabilities of existing methods.","To address these issues, we propose a segmentation model based on Prompt-Mamba, which incorporates the latest Vision-Mamba and prompt technologies.","Compared to previous models trained on the same dataset, our model not only maintains high segmentation accuracy on the validation part of the same dataset but also demonstrates superior accuracy on unseen datasets, exhibiting excellent generalization capabilities.","Notably, we are the first to apply the Vision-Mamba architecture to polyp segmentation and the first to utilize prompt technology in a polyp segmentation model.","Our model efficiently accomplishes segmentation tasks, surpassing previous state-of-the-art methods by an average of 5% across six datasets.","Furthermore, we have developed multiple versions of our model with scaled parameter counts, achieving better performance than previous models even with fewer parameters.","Our code and trained weights will be released soon."],"url":"http://arxiv.org/abs/2403.13660v1"}
{"created":"2024-03-20 15:08:43","title":"Recursive Cross-Modal Attention for Multimodal Fusion in Dimensional Emotion Recognition","abstract":"Multi-modal emotion recognition has recently gained a lot of attention since it can leverage diverse and complementary relationships over multiple modalities, such as audio, visual, and text. Most state-of-the-art methods for multimodal fusion rely on recurrent networks or conventional attention mechanisms that do not effectively leverage the complementary nature of the modalities. In this paper, we focus on dimensional emotion recognition based on the fusion of facial, vocal, and text modalities extracted from videos. Specifically, we propose a recursive cross-modal attention (RCMA) to effectively capture the complementary relationships across the modalities in a recursive fashion. The proposed model is able to effectively capture the inter-modal relationships by computing the cross-attention weights across the individual modalities and the joint representation of the other two modalities. To further improve the inter-modal relationships, the obtained attended features of the individual modalities are again fed as input to the cross-modal attention to refine the feature representations of the individual modalities. In addition to that, we have used Temporal convolution networks (TCNs) to capture the temporal modeling (intra-modal relationships) of the individual modalities. By deploying the TCNs as well cross-modal attention in a recursive fashion, we are able to effectively capture both intra- and inter-modal relationships across the audio, visual, and text modalities. Experimental results on validation-set videos from the AffWild2 dataset indicate that our proposed fusion model is able to achieve significant improvement over the baseline for the sixth challenge of Affective Behavior Analysis in-the-Wild 2024 (ABAW6) competition.","sentences":["Multi-modal emotion recognition has recently gained a lot of attention since it can leverage diverse and complementary relationships over multiple modalities, such as audio, visual, and text.","Most state-of-the-art methods for multimodal fusion rely on recurrent networks or conventional attention mechanisms that do not effectively leverage the complementary nature of the modalities.","In this paper, we focus on dimensional emotion recognition based on the fusion of facial, vocal, and text modalities extracted from videos.","Specifically, we propose a recursive cross-modal attention (RCMA) to effectively capture the complementary relationships across the modalities in a recursive fashion.","The proposed model is able to effectively capture the inter-modal relationships by computing the cross-attention weights across the individual modalities and the joint representation of the other two modalities.","To further improve the inter-modal relationships, the obtained attended features of the individual modalities are again fed as input to the cross-modal attention to refine the feature representations of the individual modalities.","In addition to that, we have used Temporal convolution networks (TCNs) to capture the temporal modeling (intra-modal relationships) of the individual modalities.","By deploying the TCNs as well cross-modal attention in a recursive fashion, we are able to effectively capture both intra- and inter-modal relationships across the audio, visual, and text modalities.","Experimental results on validation-set videos from the AffWild2 dataset indicate that our proposed fusion model is able to achieve significant improvement over the baseline for the sixth challenge of Affective Behavior Analysis in-the-Wild 2024 (ABAW6) competition."],"url":"http://arxiv.org/abs/2403.13659v1"}
{"created":"2024-03-20 15:06:49","title":"Multimodal Variational Autoencoder for Low-cost Cardiac Hemodynamics Instability Detection","abstract":"Recent advancements in non-invasive detection of cardiac hemodynamic instability (CHDI) primarily focus on applying machine learning techniques to a single data modality, e.g. cardiac magnetic resonance imaging (MRI). Despite their potential, these approaches often fall short especially when the size of labeled patient data is limited, a common challenge in the medical domain. Furthermore, only a few studies have explored multimodal methods to study CHDI, which mostly rely on costly modalities such as cardiac MRI and echocardiogram. In response to these limitations, we propose a novel multimodal variational autoencoder ($\\text{CardioVAE}_\\text{X,G}$) to integrate low-cost chest X-ray (CXR) and electrocardiogram (ECG) modalities with pre-training on a large unlabeled dataset. Specifically, $\\text{CardioVAE}_\\text{X,G}$ introduces a novel tri-stream pre-training strategy to learn both shared and modality-specific features, thus enabling fine-tuning with both unimodal and multimodal datasets. We pre-train $\\text{CardioVAE}_\\text{X,G}$ on a large, unlabeled dataset of $50,982$ subjects from a subset of MIMIC database and then fine-tune the pre-trained model on a labeled dataset of $795$ subjects from the ASPIRE registry. Comprehensive evaluations against existing methods show that $\\text{CardioVAE}_\\text{X,G}$ offers promising performance (AUROC $=0.79$ and Accuracy $=0.77$), representing a significant step forward in non-invasive prediction of CHDI. Our model also excels in producing fine interpretations of predictions directly associated with clinical features, thereby supporting clinical decision-making.","sentences":["Recent advancements in non-invasive detection of cardiac hemodynamic instability (CHDI) primarily focus on applying machine learning techniques to a single data modality, e.g. cardiac magnetic resonance imaging (MRI).","Despite their potential, these approaches often fall short especially when the size of labeled patient data is limited, a common challenge in the medical domain.","Furthermore, only a few studies have explored multimodal methods to study CHDI, which mostly rely on costly modalities such as cardiac MRI and echocardiogram.","In response to these limitations, we propose a novel multimodal variational autoencoder ($\\text{CardioVAE}_\\text{X,G}$) to integrate low-cost chest X-ray (CXR) and electrocardiogram (ECG) modalities with pre-training on a large unlabeled dataset.","Specifically, $\\text{CardioVAE}_\\text{X,G}$ introduces a novel tri-stream pre-training strategy to learn both shared and modality-specific features, thus enabling fine-tuning with both unimodal and multimodal datasets.","We pre-train $\\text{CardioVAE}_\\text{X,G}$ on a large, unlabeled dataset of $50,982$ subjects from a subset of MIMIC database and then fine-tune the pre-trained model on a labeled dataset of $795$ subjects from the ASPIRE registry.","Comprehensive evaluations against existing methods show that $\\text{CardioVAE}_\\text{X,G}$ offers promising performance (AUROC $=0.79$ and Accuracy $=0.77$), representing a significant step forward in non-invasive prediction of CHDI.","Our model also excels in producing fine interpretations of predictions directly associated with clinical features, thereby supporting clinical decision-making."],"url":"http://arxiv.org/abs/2403.13658v1"}
{"created":"2024-03-20 15:03:49","title":"NELA-PS: A Dataset of Pink Slime News Articles for the Study of Local News Ecosystems","abstract":"Pink slime news outlets automatically produce low-quality, often partisan content that is framed as authentic local news. Given that local news is trusted by Americans and is increasingly shutting down due to financial distress, pink slime news outlets have the potential to exploit local information voids. Yet, there are gaps in understanding of pink slime production practices and tactics, particularly over time. Hence, to support future research in this area, we built a dataset of over 7.9M articles from 1093 pink slime sources over 2.5 years.","sentences":["Pink slime news outlets automatically produce low-quality, often partisan content that is framed as authentic local news.","Given that local news is trusted by Americans and is increasingly shutting down due to financial distress, pink slime news outlets have the potential to exploit local information voids.","Yet, there are gaps in understanding of pink slime production practices and tactics, particularly over time.","Hence, to support future research in this area, we built a dataset of over 7.9M articles from 1093 pink slime sources over 2.5 years."],"url":"http://arxiv.org/abs/2403.13657v1"}
{"created":"2024-03-20 15:01:40","title":"Network Calculus Bounds for Time-Sensitive Networks: A Revisit","abstract":"Network calculus (NC), particularly its min-plus branch, has been extensively utilized to construct service models and compute delay bounds for time-sensitive networks (TSNs). This paper provides a revisit to the fundamental results. In particular, counterexamples to the most basic min-plus service models, which have been proposed for TSNs and used for computing delay bounds, indicate that the packetization effect has often been overlooked. To address, the max-plus branch of NC is also considered in this paper, whose models handle packetized traffic more explicitly. It is found that mapping the min-plus models to the max-plus models may bring in an immediate improvement over delay bounds derived from the min-plus analysis. In addition, an integrated analytical approach that combines models from both the min-plus and the max-plus NC branches is introduced. In this approach, the max-plus $g$-server model is extended and the extended model, called $g^{x}$-server, is used together with the min-plus arrival curve traffic model. By applying the integrated NC approach, service and delay bounds are derived for several settings that are fundamental in TSNs.","sentences":["Network calculus (NC), particularly its min-plus branch, has been extensively utilized to construct service models and compute delay bounds for time-sensitive networks (TSNs).","This paper provides a revisit to the fundamental results.","In particular, counterexamples to the most basic min-plus service models, which have been proposed for TSNs and used for computing delay bounds, indicate that the packetization effect has often been overlooked.","To address, the max-plus branch of NC is also considered in this paper, whose models handle packetized traffic more explicitly.","It is found that mapping the min-plus models to the max-plus models may bring in an immediate improvement over delay bounds derived from the min-plus analysis.","In addition, an integrated analytical approach that combines models from both the min-plus and the max-plus NC branches is introduced.","In this approach, the max-plus $g$-server model is extended and the extended model, called $g^{x}$-server, is used together with the min-plus arrival curve traffic model.","By applying the integrated NC approach, service and delay bounds are derived for several settings that are fundamental in TSNs."],"url":"http://arxiv.org/abs/2403.13656v1"}
{"created":"2024-03-20 15:01:05","title":"A Fully Automated Platform for Evaluating ReRAM Crossbars","abstract":"Resistive Random Access Memory (ReRAM) is a promising candidate for implementing Computing-in-Memory (CIM) architectures and neuromorphic circuits. ReRAM cells exhibit significant variability across different memristive devices and cycles, necessitating further improvements in the areas of devices, algorithms, and applications. To achieve this, understanding the stochastic behavior of the different ReRAM technologies is essential. The NeuroBreakoutBoard (NBB) is a versatile instrumentation platform to characterize Non-Volatile Memories (NVMs). However, the NBB itself does not provide any functionality in the form of software or a controller. In this paper, we present a control board for the NBB able to perform reliability assessments of 1T1R ReRAM crossbars. In more detail, an interface that allows a host PC to communicate with the NBB via the new control board is implemented. In a case study, we analyze the Cycle-to-Cycle (C2C) variation and read disturb TiN/Ti/HfO2/TiN cells for different read voltages to gain an understanding of their operational behavior.","sentences":["Resistive Random Access Memory (ReRAM) is a promising candidate for implementing Computing-in-Memory (CIM) architectures and neuromorphic circuits.","ReRAM cells exhibit significant variability across different memristive devices and cycles, necessitating further improvements in the areas of devices, algorithms, and applications.","To achieve this, understanding the stochastic behavior of the different ReRAM technologies is essential.","The NeuroBreakoutBoard (NBB) is a versatile instrumentation platform to characterize Non-Volatile Memories (NVMs).","However, the NBB itself does not provide any functionality in the form of software or a controller.","In this paper, we present a control board for the NBB able to perform reliability assessments of 1T1R ReRAM crossbars.","In more detail, an interface that allows a host PC to communicate with the NBB via the new control board is implemented.","In a case study, we analyze the Cycle-to-Cycle (C2C) variation and read disturb TiN/Ti/HfO2/TiN cells for different read voltages to gain an understanding of their operational behavior."],"url":"http://arxiv.org/abs/2403.13655v1"}
{"created":"2024-03-20 14:59:10","title":"A globalized and preconditioned Newton-CG solver for metric-aware curved high-order mesh optimization","abstract":"We present a specific-purpose globalized and preconditioned Newton-CG solver to minimize a metric-aware curved high-order mesh distortion. The solver is specially devised to optimize curved high-order meshes for high polynomial degrees with a target metric featuring non-uniform sizing, high stretching ratios, and curved alignment -- exactly the features that stiffen the optimization problem. To this end, we consider two ingredients: a specific-purpose globalization and a specific-purpose Jacobi-$\\text{iLDL}^{\\text{T}}(0)$ preconditioning with varying accuracy and curvature tolerances (dynamic forcing terms) for the CG method. These improvements are critical in stiff problems because, without them, the large number of non-linear and linear iterations makes curved optimization impractical. Finally, to analyze the performance of our method, the results compare the specific-purpose solver with standard optimization methods. For this, we measure the matrix-vector products indicating the solver computational cost and the line-search iterations indicating the total amount of objective function evaluations. When we combine the globalization and the linear solver ingredients, we conclude that the specific-purpose Newton-CG solver reduces the total number of matrix-vector products by one order of magnitude. Moreover, the number of non-linear and line-search iterations is mainly smaller but of similar magnitude.","sentences":["We present a specific-purpose globalized and preconditioned Newton-CG solver to minimize a metric-aware curved high-order mesh distortion.","The solver is specially devised to optimize curved high-order meshes for high polynomial degrees with a target metric featuring non-uniform sizing, high stretching ratios, and curved alignment -- exactly the features that stiffen the optimization problem.","To this end, we consider two ingredients: a specific-purpose globalization and a specific-purpose Jacobi-$\\text{iLDL}^{\\text{T}}(0)$ preconditioning with varying accuracy and curvature tolerances (dynamic forcing terms) for the CG method.","These improvements are critical in stiff problems because, without them, the large number of non-linear and linear iterations makes curved optimization impractical.","Finally, to analyze the performance of our method, the results compare the specific-purpose solver with standard optimization methods.","For this, we measure the matrix-vector products indicating the solver computational cost and the line-search iterations indicating the total amount of objective function evaluations.","When we combine the globalization and the linear solver ingredients, we conclude that the specific-purpose Newton-CG solver reduces the total number of matrix-vector products by one order of magnitude.","Moreover, the number of non-linear and line-search iterations is mainly smaller but of similar magnitude."],"url":"http://arxiv.org/abs/2403.13654v1"}
{"created":"2024-03-20 14:58:40","title":"Learning User Embeddings from Human Gaze for Personalised Saliency Prediction","abstract":"Reusable embeddings of user behaviour have shown significant performance improvements for the personalised saliency prediction task. However, prior works require explicit user characteristics and preferences as input, which are often difficult to obtain. We present a novel method to extract user embeddings from pairs of natural images and corresponding saliency maps generated from a small amount of user-specific eye tracking data. At the core of our method is a Siamese convolutional neural encoder that learns the user embeddings by contrasting the image and personal saliency map pairs of different users. Evaluations on two public saliency datasets show that the generated embeddings have high discriminative power, are effective at refining universal saliency maps to the individual users, and generalise well across users and images. Finally, based on our model's ability to encode individual user characteristics, our work points towards other applications that can benefit from reusable embeddings of gaze behaviour.","sentences":["Reusable embeddings of user behaviour have shown significant performance improvements for the personalised saliency prediction task.","However, prior works require explicit user characteristics and preferences as input, which are often difficult to obtain.","We present a novel method to extract user embeddings from pairs of natural images and corresponding saliency maps generated from a small amount of user-specific eye tracking data.","At the core of our method is a Siamese convolutional neural encoder that learns the user embeddings by contrasting the image and personal saliency map pairs of different users.","Evaluations on two public saliency datasets show that the generated embeddings have high discriminative power, are effective at refining universal saliency maps to the individual users, and generalise well across users and images.","Finally, based on our model's ability to encode individual user characteristics, our work points towards other applications that can benefit from reusable embeddings of gaze behaviour."],"url":"http://arxiv.org/abs/2403.13653v1"}
{"created":"2024-03-20 14:58:09","title":"ZoDi: Zero-Shot Domain Adaptation with Diffusion-Based Image Transfer","abstract":"Deep learning models achieve high accuracy in segmentation tasks among others, yet domain shift often degrades the models' performance, which can be critical in real-world scenarios where no target images are available. This paper proposes a zero-shot domain adaptation method based on diffusion models, called ZoDi, which is two-fold by the design: zero-shot image transfer and model adaptation. First, we utilize an off-the-shelf diffusion model to synthesize target-like images by transferring the domain of source images to the target domain. In this we specifically try to maintain the layout and content by utilising layout-to-image diffusion models with stochastic inversion. Secondly, we train the model using both source images and synthesized images with the original segmentation maps while maximizing the feature similarity of images from the two domains to learn domain-robust representations. Through experiments we show benefits of ZoDi in the task of image segmentation over state-of-the-art methods. It is also more applicable than existing CLIP-based methods because it assumes no specific backbone or models, and it enables to estimate the model's performance without target images by inspecting generated images. Our implementation will be publicly available.","sentences":["Deep learning models achieve high accuracy in segmentation tasks among others, yet domain shift often degrades the models' performance, which can be critical in real-world scenarios where no target images are available.","This paper proposes a zero-shot domain adaptation method based on diffusion models, called ZoDi, which is two-fold by the design: zero-shot image transfer and model adaptation.","First, we utilize an off-the-shelf diffusion model to synthesize target-like images by transferring the domain of source images to the target domain.","In this we specifically try to maintain the layout and content by utilising layout-to-image diffusion models with stochastic inversion.","Secondly, we train the model using both source images and synthesized images with the original segmentation maps while maximizing the feature similarity of images from the two domains to learn domain-robust representations.","Through experiments we show benefits of ZoDi in the task of image segmentation over state-of-the-art methods.","It is also more applicable than existing CLIP-based methods because it assumes no specific backbone or models, and it enables to estimate the model's performance without target images by inspecting generated images.","Our implementation will be publicly available."],"url":"http://arxiv.org/abs/2403.13652v1"}
{"created":"2024-03-20 14:54:33","title":"Meta-Point Learning and Refining for Category-Agnostic Pose Estimation","abstract":"Category-agnostic pose estimation (CAPE) aims to predict keypoints for arbitrary classes given a few support images annotated with keypoints. Existing methods only rely on the features extracted at support keypoints to predict or refine the keypoints on query image, but a few support feature vectors are local and inadequate for CAPE. Considering that human can quickly perceive potential keypoints of arbitrary objects, we propose a novel framework for CAPE based on such potential keypoints (named as meta-points). Specifically, we maintain learnable embeddings to capture inherent information of various keypoints, which interact with image feature maps to produce meta-points without any support. The produced meta-points could serve as meaningful potential keypoints for CAPE. Due to the inevitable gap between inherency and annotation, we finally utilize the identities and details offered by support keypoints to assign and refine meta-points to desired keypoints in query image. In addition, we propose a progressive deformable point decoder and a slacked regression loss for better prediction and supervision. Our novel framework not only reveals the inherency of keypoints but also outperforms existing methods of CAPE. Comprehensive experiments and in-depth studies on large-scale MP-100 dataset demonstrate the effectiveness of our framework.","sentences":["Category-agnostic pose estimation (CAPE) aims to predict keypoints for arbitrary classes given a few support images annotated with keypoints.","Existing methods only rely on the features extracted at support keypoints to predict or refine the keypoints on query image, but a few support feature vectors are local and inadequate for CAPE.","Considering that human can quickly perceive potential keypoints of arbitrary objects, we propose a novel framework for CAPE based on such potential keypoints (named as meta-points).","Specifically, we maintain learnable embeddings to capture inherent information of various keypoints, which interact with image feature maps to produce meta-points without any support.","The produced meta-points could serve as meaningful potential keypoints for CAPE.","Due to the inevitable gap between inherency and annotation, we finally utilize the identities and details offered by support keypoints to assign and refine meta-points to desired keypoints in query image.","In addition, we propose a progressive deformable point decoder and a slacked regression loss for better prediction and supervision.","Our novel framework not only reveals the inherency of keypoints but also outperforms existing methods of CAPE.","Comprehensive experiments and in-depth studies on large-scale MP-100 dataset demonstrate the effectiveness of our framework."],"url":"http://arxiv.org/abs/2403.13647v1"}
{"created":"2024-03-20 14:50:54","title":"How to Relax Instantly: Elastic Relaxation of Concurrent Data Structures","abstract":"The sequential semantics of many concurrent data structures, such as stacks and queues, inevitably lead to memory contention in parallel environments, thus limiting scalability. Semantic relaxation has the potential to address this issue, increasing the parallelism at the expense of weakened semantics. Although prior research has shown that improved performance can be attained by relaxing concurrent data structure semantics, there is no one-size-fits-all relaxation that adequately addresses the varying needs of dynamic executions.   In this paper, we first introduce the concept of elastic relaxation and consequently present the Lateral structure, which is an algorithmic component capable of supporting the design of elastically relaxed concurrent data structures. Using the Lateral , we design novel elastically relaxed, lock-free queues and stacks capable of reconfiguring relaxation during run time. We establish linearizability and define upper bounds for relaxation errors in our designs. Experimental evaluations show that our elastic designs hold up against state-of-the-art statically relaxed designs, while also swiftly managing trade-offs between relaxation and operational latency. We also outline how to use the Lateral to design elastically relaxed lock-free counters and deques.","sentences":["The sequential semantics of many concurrent data structures, such as stacks and queues, inevitably lead to memory contention in parallel environments, thus limiting scalability.","Semantic relaxation has the potential to address this issue, increasing the parallelism at the expense of weakened semantics.","Although prior research has shown that improved performance can be attained by relaxing concurrent data structure semantics, there is no one-size-fits-all relaxation that adequately addresses the varying needs of dynamic executions.   ","In this paper, we first introduce the concept of elastic relaxation and consequently present the Lateral structure, which is an algorithmic component capable of supporting the design of elastically relaxed concurrent data structures.","Using the Lateral , we design novel elastically relaxed, lock-free queues and stacks capable of reconfiguring relaxation during run time.","We establish linearizability and define upper bounds for relaxation errors in our designs.","Experimental evaluations show that our elastic designs hold up against state-of-the-art statically relaxed designs, while also swiftly managing trade-offs between relaxation and operational latency.","We also outline how to use the Lateral to design elastically relaxed lock-free counters and deques."],"url":"http://arxiv.org/abs/2403.13644v1"}
{"created":"2024-03-20 14:49:52","title":"H-vmunet: High-order Vision Mamba UNet for Medical Image Segmentation","abstract":"In the field of medical image segmentation, variant models based on Convolutional Neural Networks (CNNs) and Visual Transformers (ViTs) as the base modules have been very widely developed and applied. However, CNNs are often limited in their ability to deal with long sequences of information, while the low sensitivity of ViTs to local feature information and the problem of secondary computational complexity limit their development. Recently, the emergence of state-space models (SSMs), especially 2D-selective-scan (SS2D), has had an impact on the longtime dominance of traditional CNNs and ViTs as the foundational modules of visual neural networks. In this paper, we extend the adaptability of SS2D by proposing a High-order Vision Mamba UNet (H-vmunet) for medical image segmentation. Among them, the proposed High-order 2D-selective-scan (H-SS2D) progressively reduces the introduction of redundant information during SS2D operations through higher-order interactions. In addition, the proposed Local-SS2D module improves the learning ability of local features of SS2D at each order of interaction. We conducted comparison and ablation experiments on three publicly available medical image datasets (ISIC2017, Spleen, and CVC-ClinicDB), and the results all demonstrate the strong competitiveness of H-vmunet in medical image segmentation tasks. The code is available from https://github.com/wurenkai/H-vmunet .","sentences":["In the field of medical image segmentation, variant models based on Convolutional Neural Networks (CNNs) and Visual Transformers (ViTs) as the base modules have been very widely developed and applied.","However, CNNs are often limited in their ability to deal with long sequences of information, while the low sensitivity of ViTs to local feature information and the problem of secondary computational complexity limit their development.","Recently, the emergence of state-space models (SSMs), especially 2D-selective-scan (SS2D), has had an impact on the longtime dominance of traditional CNNs and ViTs as the foundational modules of visual neural networks.","In this paper, we extend the adaptability of SS2D by proposing a High-order Vision Mamba UNet (H-vmunet) for medical image segmentation.","Among them, the proposed High-order 2D-selective-scan (H-SS2D) progressively reduces the introduction of redundant information during SS2D operations through higher-order interactions.","In addition, the proposed Local-SS2D module improves the learning ability of local features of SS2D at each order of interaction.","We conducted comparison and ablation experiments on three publicly available medical image datasets (ISIC2017, Spleen, and CVC-ClinicDB), and the results all demonstrate the strong competitiveness of H-vmunet in medical image segmentation tasks.","The code is available from https://github.com/wurenkai/H-vmunet ."],"url":"http://arxiv.org/abs/2403.13642v1"}
{"created":"2024-03-20 14:43:51","title":"LaCE-LHMP: Airflow Modelling-Inspired Long-Term Human Motion Prediction By Enhancing Laminar Characteristics in Human Flow","abstract":"Long-term human motion prediction (LHMP) is essential for safely operating autonomous robots and vehicles in populated environments. It is fundamental for various applications, including motion planning, tracking, human-robot interaction and safety monitoring. However, accurate prediction of human trajectories is challenging due to complex factors, including, for example, social norms and environmental conditions. The influence of such factors can be captured through Maps of Dynamics (MoDs), which encode spatial motion patterns learned from (possibly scattered and partial) past observations of motion in the environment and which can be used for data-efficient, interpretable motion prediction (MoD-LHMP). To address the limitations of prior work, especially regarding accuracy and sensitivity to anomalies in long-term prediction, we propose the Laminar Component Enhanced LHMP approach (LaCE-LHMP). Our approach is inspired by data-driven airflow modelling, which estimates laminar and turbulent flow components and uses predominantly the laminar components to make flow predictions. Based on the hypothesis that human trajectory patterns also manifest laminar flow (that represents predictable motion) and turbulent flow components (that reflect more unpredictable and arbitrary motion), LaCE-LHMP extracts the laminar patterns in human dynamics and uses them for human motion prediction. We demonstrate the superior prediction performance of LaCE-LHMP through benchmark comparisons with state-of-the-art LHMP methods, offering an unconventional perspective and a more intuitive understanding of human movement patterns.","sentences":["Long-term human motion prediction (LHMP) is essential for safely operating autonomous robots and vehicles in populated environments.","It is fundamental for various applications, including motion planning, tracking, human-robot interaction and safety monitoring.","However, accurate prediction of human trajectories is challenging due to complex factors, including, for example, social norms and environmental conditions.","The influence of such factors can be captured through Maps of Dynamics (MoDs), which encode spatial motion patterns learned from (possibly scattered and partial) past observations of motion in the environment and which can be used for data-efficient, interpretable motion prediction (MoD-LHMP).","To address the limitations of prior work, especially regarding accuracy and sensitivity to anomalies in long-term prediction, we propose the Laminar Component Enhanced LHMP approach (LaCE-LHMP).","Our approach is inspired by data-driven airflow modelling, which estimates laminar and turbulent flow components and uses predominantly the laminar components to make flow predictions.","Based on the hypothesis that human trajectory patterns also manifest laminar flow (that represents predictable motion) and turbulent flow components (that reflect more unpredictable and arbitrary motion), LaCE-LHMP extracts the laminar patterns in human dynamics and uses them for human motion prediction.","We demonstrate the superior prediction performance of LaCE-LHMP through benchmark comparisons with state-of-the-art LHMP methods, offering an unconventional perspective and a more intuitive understanding of human movement patterns."],"url":"http://arxiv.org/abs/2403.13640v1"}
{"created":"2024-03-20 14:43:23","title":"Multi-agent Reinforcement Traffic Signal Control based on Interpretable Influence Mechanism and Biased ReLU Approximation","abstract":"Traffic signal control is important in intelligent transportation system, of which cooperative control is difficult to realize but yet vital. Many methods model multi-intersection traffic networks as grids and address the problem using multi-agent reinforcement learning (RL). Despite these existing studies, there is an opportunity to further enhance our understanding of the connectivity and globality of the traffic networks by capturing the spatiotemporal traffic information with efficient neural networks in deep RL. In this paper, we propose a novel multi-agent actor-critic framework based on an interpretable influence mechanism with a centralized learning and decentralized execution method. Specifically, we first construct an actor-critic framework, for which the piecewise linear neural network (PWLNN), named biased ReLU (BReLU), is used as the function approximator to obtain a more accurate and theoretically grounded approximation. Finally, our proposed framework is validated on two synthetic traffic networks to coordinate signal control between intersections, achieving lower traffic delays across the entire traffic network compared to state-of-the-art (SOTA) performance.","sentences":["Traffic signal control is important in intelligent transportation system, of which cooperative control is difficult to realize but yet vital.","Many methods model multi-intersection traffic networks as grids and address the problem using multi-agent reinforcement learning (RL).","Despite these existing studies, there is an opportunity to further enhance our understanding of the connectivity and globality of the traffic networks by capturing the spatiotemporal traffic information with efficient neural networks in deep RL.","In this paper, we propose a novel multi-agent actor-critic framework based on an interpretable influence mechanism with a centralized learning and decentralized execution method.","Specifically, we first construct an actor-critic framework, for which the piecewise linear neural network (PWLNN), named biased ReLU (BReLU), is used as the function approximator to obtain a more accurate and theoretically grounded approximation.","Finally, our proposed framework is validated on two synthetic traffic networks to coordinate signal control between intersections, achieving lower traffic delays across the entire traffic network compared to state-of-the-art (SOTA) performance."],"url":"http://arxiv.org/abs/2403.13639v1"}
{"created":"2024-03-20 14:41:01","title":"Do Not Worry if You Do Not Have Data: Building Pretrained Language Models Using Translationese","abstract":"In this paper, we explore the utility of \\textit{Translationese} as synthetic data created using machine translation for pre-training language models (LMs). Pre-training requires vast amounts of monolingual data, which is mostly unavailable for languages other than English. Recently, there has been a growing interest in using synthetic data to address this data scarcity. We take the case of English and Indic languages and translate web-crawled monolingual documents (clean) into the target language. Then, we train language models containing 28M and 85M parameters on this translationese data (synthetic). We show that their performance on downstream natural language understanding and generative tasks is only 3.56\\% poorer on NLU tasks and 1.51\\% on NLG tasks than LMs pre-trained on clean data. Further, we propose the use of lightweight \\textit{TinyLMs} pre-trained on clean data to filter synthetic data efficiently which significantly improves the performance of our models. We also find that LMs trained on synthetic data strongly benefit from extended pretraining on a tiny fraction (10\\%) of clean data. We release the data we collected and created as a part of this work, \\textit{IndicMonoDoc}, the largest collection of monolingual document-level corpora, which we hope will help bridge the gap between English and non-English performance for large language models.","sentences":["In this paper, we explore the utility of \\textit{Translationese} as synthetic data created using machine translation for pre-training language models (LMs).","Pre-training requires vast amounts of monolingual data, which is mostly unavailable for languages other than English.","Recently, there has been a growing interest in using synthetic data to address this data scarcity.","We take the case of English and Indic languages and translate web-crawled monolingual documents (clean) into the target language.","Then, we train language models containing 28M and 85M parameters on this translationese data (synthetic).","We show that their performance on downstream natural language understanding and generative tasks is only 3.56\\% poorer on NLU tasks and 1.51\\% on NLG tasks than LMs pre-trained on clean data.","Further, we propose the use of lightweight \\textit{TinyLMs} pre-trained on clean data to filter synthetic data efficiently which significantly improves the performance of our models.","We also find that LMs trained on synthetic data strongly benefit from extended pretraining on a tiny fraction (10\\%) of clean data.","We release the data we collected and created as a part of this work, \\textit{IndicMonoDoc}, the largest collection of monolingual document-level corpora, which we hope will help bridge the gap between English and non-English performance for large language models."],"url":"http://arxiv.org/abs/2403.13638v1"}
{"created":"2024-03-20 14:27:49","title":"CheckMate: Evaluating Checkpointing Protocols for Streaming Dataflows","abstract":"Stream processing in the last decade has seen broad adoption in both commercial and research settings. One key element for this success is the ability of modern stream processors to handle failures while ensuring exactly-once processing guarantees. At the moment of writing, virtually all stream processors that guarantee exactly-once processing implement a variant of Apache Flink's coordinated checkpoints - an extension of the original Chandy-Lamport checkpoints from 1985. However, the reasons behind this prevalence of the coordinated approach remain anecdotal, as reported by practitioners of the stream processing community. At the same time, common checkpointing approaches, such as the uncoordinated and the communication-induced ones, remain largely unexplored.   This paper is the first to address this gap by i) shedding light on why practitioners have favored the coordinated approach and ii) by investigating whether there are viable alternatives. To this end, we implement three checkpointing approaches that we surveyed and adapted for the distinct needs of streaming dataflows. Our analysis shows that the coordinated approach outperforms the uncoordinated and communication-induced protocols under uniformly distributed workloads. To our surprise, however, the uncoordinated approach is not only competitive to the coordinated one in uniformly distributed workloads, but it also outperforms the coordinated approach in skewed workloads. We conclude that rather than blindly employing coordinated checkpointing, research should focus on optimizing the very promising uncoordinated approach, as it can address issues with skew and support prevalent cyclic queries. We believe that our findings can trigger further research into checkpointing mechanisms.","sentences":["Stream processing in the last decade has seen broad adoption in both commercial and research settings.","One key element for this success is the ability of modern stream processors to handle failures while ensuring exactly-once processing guarantees.","At the moment of writing, virtually all stream processors that guarantee exactly-once processing implement a variant of Apache Flink's coordinated checkpoints - an extension of the original Chandy-Lamport checkpoints from 1985.","However, the reasons behind this prevalence of the coordinated approach remain anecdotal, as reported by practitioners of the stream processing community.","At the same time, common checkpointing approaches, such as the uncoordinated and the communication-induced ones, remain largely unexplored.   ","This paper is the first to address this gap by i) shedding light on why practitioners have favored the coordinated approach and ii) by investigating whether there are viable alternatives.","To this end, we implement three checkpointing approaches that we surveyed and adapted for the distinct needs of streaming dataflows.","Our analysis shows that the coordinated approach outperforms the uncoordinated and communication-induced protocols under uniformly distributed workloads.","To our surprise, however, the uncoordinated approach is not only competitive to the coordinated one in uniformly distributed workloads, but it also outperforms the coordinated approach in skewed workloads.","We conclude that rather than blindly employing coordinated checkpointing, research should focus on optimizing the very promising uncoordinated approach, as it can address issues with skew and support prevalent cyclic queries.","We believe that our findings can trigger further research into checkpointing mechanisms."],"url":"http://arxiv.org/abs/2403.13629v1"}
{"created":"2024-03-20 14:22:19","title":"Enhancing Law Enforcement Training: A Gamified Approach to Detecting Terrorism Financing","abstract":"Tools for fighting cyber-criminal activities using new technologies are promoted and deployed every day. However, too often, they are unnecessarily complex and hard to use, requiring deep domain and technical knowledge. These characteristics often limit the engagement of law enforcement and end-users in these technologies that, despite their potential, remain misunderstood. For this reason, in this study, we describe our experience in combining learning and training methods and the potential benefits of gamification to enhance technology transfer and increase adult learning. In fact, in this case, participants are experienced practitioners in professions/industries that are exposed to terrorism financing (such as Law Enforcement Officers, Financial Investigation Officers, private investigators, etc.) We define training activities on different levels for increasing the exchange of information about new trends and criminal modus operandi among and within law enforcement agencies, intensifying cross-border cooperation and supporting efforts to combat and prevent terrorism funding activities. On the other hand, a game (hackathon) is designed to address realistic challenges related to the dark net, crypto assets, new payment systems and dark web marketplaces that could be used for terrorist activities. The entire methodology was evaluated using quizzes, contest results, and engagement metrics. In particular, training events show about 60% of participants complete the 11-week training course, while the Hackathon results, gathered in two pilot studies (Madrid and The Hague), show increasing expertise among the participants (progression in the achieved points on average). At the same time, more than 70% of participants positively evaluate the use of the gamification approach, and more than 85% of them consider the implemented Use Cases suitable for their investigations.","sentences":["Tools for fighting cyber-criminal activities using new technologies are promoted and deployed every day.","However, too often, they are unnecessarily complex and hard to use, requiring deep domain and technical knowledge.","These characteristics often limit the engagement of law enforcement and end-users in these technologies that, despite their potential, remain misunderstood.","For this reason, in this study, we describe our experience in combining learning and training methods and the potential benefits of gamification to enhance technology transfer and increase adult learning.","In fact, in this case, participants are experienced practitioners in professions/industries that are exposed to terrorism financing (such as Law Enforcement Officers, Financial Investigation Officers, private investigators, etc.)","We define training activities on different levels for increasing the exchange of information about new trends and criminal modus operandi among and within law enforcement agencies, intensifying cross-border cooperation and supporting efforts to combat and prevent terrorism funding activities.","On the other hand, a game (hackathon) is designed to address realistic challenges related to the dark net, crypto assets, new payment systems and dark web marketplaces that could be used for terrorist activities.","The entire methodology was evaluated using quizzes, contest results, and engagement metrics.","In particular, training events show about 60% of participants complete the 11-week training course, while the Hackathon results, gathered in two pilot studies (Madrid and The Hague), show increasing expertise among the participants (progression in the achieved points on average).","At the same time, more than 70% of participants positively evaluate the use of the gamification approach, and more than 85% of them consider the implemented Use Cases suitable for their investigations."],"url":"http://arxiv.org/abs/2403.13625v1"}
{"created":"2024-03-20 14:13:44","title":"Dynamic Resource Allocation for Virtual Machine Migration Optimization using Machine Learning","abstract":"The paragraph is grammatically correct and logically coherent. It discusses the importance of mobile terminal cloud computing migration technology in meeting the demands of evolving computer and cloud computing technologies. It emphasizes the need for efficient data access and storage, as well as the utilization of cloud computing migration technology to prevent additional time delays. The paragraph also highlights the contributions of cloud computing migration technology to expanding cloud computing services. Additionally, it acknowledges the role of virtualization as a fundamental capability of cloud computing while emphasizing that cloud computing and virtualization are not inherently interconnected. Finally, it introduces machine learning-based virtual machine migration optimization and dynamic resource allocation as a critical research direction in cloud computing, citing the limitations of static rules or manual settings in traditional cloud computing environments. Overall, the paragraph effectively communicates the importance of machine learning technology in addressing resource allocation and virtual machine migration challenges in cloud computing.","sentences":["The paragraph is grammatically correct and logically coherent.","It discusses the importance of mobile terminal cloud computing migration technology in meeting the demands of evolving computer and cloud computing technologies.","It emphasizes the need for efficient data access and storage, as well as the utilization of cloud computing migration technology to prevent additional time delays.","The paragraph also highlights the contributions of cloud computing migration technology to expanding cloud computing services.","Additionally, it acknowledges the role of virtualization as a fundamental capability of cloud computing while emphasizing that cloud computing and virtualization are not inherently interconnected.","Finally, it introduces machine learning-based virtual machine migration optimization and dynamic resource allocation as a critical research direction in cloud computing, citing the limitations of static rules or manual settings in traditional cloud computing environments.","Overall, the paragraph effectively communicates the importance of machine learning technology in addressing resource allocation and virtual machine migration challenges in cloud computing."],"url":"http://arxiv.org/abs/2403.13619v1"}
{"created":"2024-03-20 14:05:17","title":"MIMO Channel as a Neural Function: Implicit Neural Representations for Extreme CSI Compression in Massive MIMO Systems","abstract":"Acquiring and utilizing accurate channel state information (CSI) can significantly improve transmission performance, thereby holding a crucial role in realizing the potential advantages of massive multiple-input multiple-output (MIMO) technology. Current prevailing CSI feedback approaches improve precision by employing advanced deep-learning methods to learn representative CSI features for a subsequent compression process. Diverging from previous works, we treat the CSI compression problem in the context of implicit neural representations. Specifically, each CSI matrix is viewed as a neural function that maps the CSI coordinates (antenna number and subchannel) to the corresponding channel gains. Instead of transmitting the parameters of the implicit neural functions directly, we transmit modulations based on the CSI matrix derived through a meta-learning algorithm. Modulations are then applied to a shared base network to generate the elements of the CSI matrix. Modulations corresponding to the CSI matrix are quantized and entropy-coded to further reduce the communication bandwidth, thus achieving extreme CSI compression ratios. Numerical results show that our proposed approach achieves state-of-the-art performance and showcases flexibility in feedback strategies.","sentences":["Acquiring and utilizing accurate channel state information (CSI) can significantly improve transmission performance, thereby holding a crucial role in realizing the potential advantages of massive multiple-input multiple-output (MIMO) technology.","Current prevailing CSI feedback approaches improve precision by employing advanced deep-learning methods to learn representative CSI features for a subsequent compression process.","Diverging from previous works, we treat the CSI compression problem in the context of implicit neural representations.","Specifically, each CSI matrix is viewed as a neural function that maps the CSI coordinates (antenna number and subchannel) to the corresponding channel gains.","Instead of transmitting the parameters of the implicit neural functions directly, we transmit modulations based on the CSI matrix derived through a meta-learning algorithm.","Modulations are then applied to a shared base network to generate the elements of the CSI matrix.","Modulations corresponding to the CSI matrix are quantized and entropy-coded to further reduce the communication bandwidth, thus achieving extreme CSI compression ratios.","Numerical results show that our proposed approach achieves state-of-the-art performance and showcases flexibility in feedback strategies."],"url":"http://arxiv.org/abs/2403.13615v1"}
{"created":"2024-03-20 14:03:57","title":"Does Differentially Private Synthetic Data Lead to Synthetic Discoveries?","abstract":"Background: Synthetic data has been proposed as a solution for sharing anonymized versions of sensitive biomedical datasets. Ideally, synthetic data should preserve the structure and statistical properties of the original data, while protecting the privacy of the individual subjects. Differential privacy (DP) is currently considered the gold standard approach for balancing this trade-off.   Objectives: The aim of this study is to evaluate the Mann-Whitney U test on DP-synthetic biomedical data in terms of Type I and Type II errors, in order to establish whether statistical hypothesis testing performed on privacy preserving synthetic data is likely to lead to loss of test's validity or decreased power.   Methods: We evaluate the Mann-Whitney U test on DP-synthetic data generated from real-world data, including a prostate cancer dataset (n=500) and a cardiovascular dataset (n=70 000), as well as on data drawn from two Gaussian distributions. Five different DP-synthetic data generation methods are evaluated, including two basic DP histogram release methods and MWEM, Private-PGM, and DP GAN algorithms.   Conclusion: Most of the tested DP-synthetic data generation methods showed inflated Type I error, especially at privacy budget levels of $\\epsilon\\leq 1$. This result calls for caution when releasing and analyzing DP-synthetic data: low p-values may be obtained in statistical tests simply as a byproduct of the noise added to protect privacy. A DP smoothed histogram-based synthetic data generation method was shown to produce valid Type I error for all privacy levels tested but required a large original dataset size and a modest privacy budget ($\\epsilon\\geq 5$) in order to have reasonable Type II error levels.","sentences":["Background: Synthetic data has been proposed as a solution for sharing anonymized versions of sensitive biomedical datasets.","Ideally, synthetic data should preserve the structure and statistical properties of the original data, while protecting the privacy of the individual subjects.","Differential privacy (DP) is currently considered the gold standard approach for balancing this trade-off.   ","Objectives:","The aim of this study is to evaluate the Mann-Whitney U test on DP-synthetic biomedical data in terms of Type I and Type II errors, in order to establish whether statistical hypothesis testing performed on privacy preserving synthetic data is likely to lead to loss of test's validity or decreased power.   ","Methods: We evaluate the Mann-Whitney U test on DP-synthetic data generated from real-world data, including a prostate cancer dataset (n=500) and a cardiovascular dataset (n=70 000), as well as on data drawn from two Gaussian distributions.","Five different DP-synthetic data generation methods are evaluated, including two basic DP histogram release methods and MWEM, Private-PGM, and DP GAN algorithms.   ","Conclusion: Most of the tested DP-synthetic data generation methods showed inflated Type I error, especially at privacy budget levels of $\\epsilon\\leq 1$.","This result calls for caution when releasing and analyzing DP-synthetic data: low p-values may be obtained in statistical tests simply as a byproduct of the noise added to protect privacy.","A DP smoothed histogram-based synthetic data generation method was shown to produce valid Type I error for all privacy levels tested but required a large original dataset size and a modest privacy budget ($\\epsilon\\geq 5$) in order to have reasonable Type II error levels."],"url":"http://arxiv.org/abs/2403.13612v1"}
{"created":"2024-03-20 14:03:15","title":"Densify & Conquer: Densified, smaller base-stations can conquer the increasing carbon footprint problem in nextG wireless","abstract":"Connectivity on-the-go has been one of the most impressive technological achievements in the 2010s decade. However, multiple studies show that this has come at an expense of increased carbon footprint, that also rivals the entire aviation sector's carbon footprint. The two major contributors of this increased footprint are (a) smartphone batteries which affect the embodied footprint and (b) base-stations that occupy ever-increasing energy footprint to provide the last mile wireless connectivity to smartphones. The root-cause of both these turn out to be the same, which is communicating over the last-mile lossy wireless medium. We show in this paper, titled DensQuer, how base-station densification, which is to replace a single larger base-station with multiple smaller ones, reduces the effect of the last-mile wireless, and in effect conquers both these adverse sources of increased carbon footprint. Backed by a open-source ray-tracing computation framework (Sionna), we show how a strategic densification strategy can minimize the number of required smaller base-stations to practically achievable numbers, which lead to about 3x power-savings in the base-station network. Also, DensQuer is able to also reduce the required deployment height of base-stations to as low as 15m, that makes the smaller cells easily deployable on trees/street poles instead of requiring a dedicated tower. Further, by utilizing newly introduced hardware power rails in Google Pixel 7a and above phones, we also show that this strategic densified network leads to reduction in mobile transmit power by 10-15 dB, leading to about 3x reduction in total cellular power consumption, and about 50% increase in smartphone battery life when it communicates data via the cellular network.","sentences":["Connectivity on-the-go has been one of the most impressive technological achievements in the 2010s decade.","However, multiple studies show that this has come at an expense of increased carbon footprint, that also rivals the entire aviation sector's carbon footprint.","The two major contributors of this increased footprint are (a) smartphone batteries which affect the embodied footprint and (b) base-stations that occupy ever-increasing energy footprint to provide the last mile wireless connectivity to smartphones.","The root-cause of both these turn out to be the same, which is communicating over the last-mile lossy wireless medium.","We show in this paper, titled DensQuer, how base-station densification, which is to replace a single larger base-station with multiple smaller ones, reduces the effect of the last-mile wireless, and in effect conquers both these adverse sources of increased carbon footprint.","Backed by a open-source ray-tracing computation framework (Sionna), we show how a strategic densification strategy can minimize the number of required smaller base-stations to practically achievable numbers, which lead to about 3x power-savings in the base-station network.","Also, DensQuer is able to also reduce the required deployment height of base-stations to as low as 15m, that makes the smaller cells easily deployable on trees/street poles instead of requiring a dedicated tower.","Further, by utilizing newly introduced hardware power rails in Google Pixel 7a and above phones, we also show that this strategic densified network leads to reduction in mobile transmit power by 10-15 dB, leading to about 3x reduction in total cellular power consumption, and about 50% increase in smartphone battery life when it communicates data via the cellular network."],"url":"http://arxiv.org/abs/2403.13611v1"}
