{"created":"2024-04-11 17:59:59","title":"GoMVS: Geometrically Consistent Cost Aggregation for Multi-View Stereo","abstract":"Matching cost aggregation plays a fundamental role in learning-based multi-view stereo networks. However, directly aggregating adjacent costs can lead to suboptimal results due to local geometric inconsistency. Related methods either seek selective aggregation or improve aggregated depth in the 2D space, both are unable to handle geometric inconsistency in the cost volume effectively. In this paper, we propose GoMVS to aggregate geometrically consistent costs, yielding better utilization of adjacent geometries. More specifically, we correspond and propagate adjacent costs to the reference pixel by leveraging the local geometric smoothness in conjunction with surface normals. We achieve this by the geometric consistent propagation (GCP) module. It computes the correspondence from the adjacent depth hypothesis space to the reference depth space using surface normals, then uses the correspondence to propagate adjacent costs to the reference geometry, followed by a convolution for aggregation. Our method achieves new state-of-the-art performance on DTU, Tanks & Temple, and ETH3D datasets. Notably, our method ranks 1st on the Tanks & Temple Advanced benchmark.","sentences":["Matching cost aggregation plays a fundamental role in learning-based multi-view stereo networks.","However, directly aggregating adjacent costs can lead to suboptimal results due to local geometric inconsistency.","Related methods either seek selective aggregation or improve aggregated depth in the 2D space, both are unable to handle geometric inconsistency in the cost volume effectively.","In this paper, we propose GoMVS to aggregate geometrically consistent costs, yielding better utilization of adjacent geometries.","More specifically, we correspond and propagate adjacent costs to the reference pixel by leveraging the local geometric smoothness in conjunction with surface normals.","We achieve this by the geometric consistent propagation (GCP) module.","It computes the correspondence from the adjacent depth hypothesis space to the reference depth space using surface normals, then uses the correspondence to propagate adjacent costs to the reference geometry, followed by a convolution for aggregation.","Our method achieves new state-of-the-art performance on DTU, Tanks & Temple, and ETH3D datasets.","Notably, our method ranks 1st on the Tanks & Temple Advanced benchmark."],"url":"http://arxiv.org/abs/2404.07992v1"}
{"created":"2024-04-11 17:59:59","title":"Connecting NeRFs, Images, and Text","abstract":"Neural Radiance Fields (NeRFs) have emerged as a standard framework for representing 3D scenes and objects, introducing a novel data type for information exchange and storage. Concurrently, significant progress has been made in multimodal representation learning for text and image data. This paper explores a novel research direction that aims to connect the NeRF modality with other modalities, similar to established methodologies for images and text. To this end, we propose a simple framework that exploits pre-trained models for NeRF representations alongside multimodal models for text and image processing. Our framework learns a bidirectional mapping between NeRF embeddings and those obtained from corresponding images and text. This mapping unlocks several novel and useful applications, including NeRF zero-shot classification and NeRF retrieval from images or text.","sentences":["Neural Radiance Fields (NeRFs) have emerged as a standard framework for representing 3D scenes and objects, introducing a novel data type for information exchange and storage.","Concurrently, significant progress has been made in multimodal representation learning for text and image data.","This paper explores a novel research direction that aims to connect the NeRF modality with other modalities, similar to established methodologies for images and text.","To this end, we propose a simple framework that exploits pre-trained models for NeRF representations alongside multimodal models for text and image processing.","Our framework learns a bidirectional mapping between NeRF embeddings and those obtained from corresponding images and text.","This mapping unlocks several novel and useful applications, including NeRF zero-shot classification and NeRF retrieval from images or text."],"url":"http://arxiv.org/abs/2404.07993v1"}
{"created":"2024-04-11 17:59:57","title":"GoMAvatar: Efficient Animatable Human Modeling from Monocular Video Using Gaussians-on-Mesh","abstract":"We introduce GoMAvatar, a novel approach for real-time, memory-efficient, high-quality animatable human modeling. GoMAvatar takes as input a single monocular video to create a digital avatar capable of re-articulation in new poses and real-time rendering from novel viewpoints, while seamlessly integrating with rasterization-based graphics pipelines. Central to our method is the Gaussians-on-Mesh representation, a hybrid 3D model combining rendering quality and speed of Gaussian splatting with geometry modeling and compatibility of deformable meshes. We assess GoMAvatar on ZJU-MoCap data and various YouTube videos. GoMAvatar matches or surpasses current monocular human modeling algorithms in rendering quality and significantly outperforms them in computational efficiency (43 FPS) while being memory-efficient (3.63 MB per subject).","sentences":["We introduce GoMAvatar, a novel approach for real-time, memory-efficient, high-quality animatable human modeling.","GoMAvatar takes as input a single monocular video to create a digital avatar capable of re-articulation in new poses and real-time rendering from novel viewpoints, while seamlessly integrating with rasterization-based graphics pipelines.","Central to our method is the Gaussians-on-Mesh representation, a hybrid 3D model combining rendering quality and speed of Gaussian splatting with geometry modeling and compatibility of deformable meshes.","We assess GoMAvatar on ZJU-MoCap data and various YouTube videos.","GoMAvatar matches or surpasses current monocular human modeling algorithms in rendering quality and significantly outperforms them in computational efficiency (43 FPS) while being memory-efficient (3.63 MB per subject)."],"url":"http://arxiv.org/abs/2404.07991v1"}
{"created":"2024-04-11 17:59:56","title":"OpenBias: Open-set Bias Detection in Text-to-Image Generative Models","abstract":"Text-to-image generative models are becoming increasingly popular and accessible to the general public. As these models see large-scale deployments, it is necessary to deeply investigate their safety and fairness to not disseminate and perpetuate any kind of biases. However, existing works focus on detecting closed sets of biases defined a priori, limiting the studies to well-known concepts. In this paper, we tackle the challenge of open-set bias detection in text-to-image generative models presenting OpenBias, a new pipeline that identifies and quantifies the severity of biases agnostically, without access to any precompiled set. OpenBias has three stages. In the first phase, we leverage a Large Language Model (LLM) to propose biases given a set of captions. Secondly, the target generative model produces images using the same set of captions. Lastly, a Vision Question Answering model recognizes the presence and extent of the previously proposed biases. We study the behavior of Stable Diffusion 1.5, 2, and XL emphasizing new biases, never investigated before. Via quantitative experiments, we demonstrate that OpenBias agrees with current closed-set bias detection methods and human judgement.","sentences":["Text-to-image generative models are becoming increasingly popular and accessible to the general public.","As these models see large-scale deployments, it is necessary to deeply investigate their safety and fairness to not disseminate and perpetuate any kind of biases.","However, existing works focus on detecting closed sets of biases defined a priori, limiting the studies to well-known concepts.","In this paper, we tackle the challenge of open-set bias detection in text-to-image generative models presenting OpenBias, a new pipeline that identifies and quantifies the severity of biases agnostically, without access to any precompiled set.","OpenBias has three stages.","In the first phase, we leverage a Large Language Model (LLM) to propose biases given a set of captions.","Secondly, the target generative model produces images using the same set of captions.","Lastly, a Vision Question Answering model recognizes the presence and extent of the previously proposed biases.","We study the behavior of Stable Diffusion 1.5, 2, and XL emphasizing new biases, never investigated before.","Via quantitative experiments, we demonstrate that OpenBias agrees with current closed-set bias detection methods and human judgement."],"url":"http://arxiv.org/abs/2404.07990v1"}
{"created":"2024-04-11 17:59:45","title":"Any2Point: Empowering Any-modality Large Models for Efficient 3D Understanding","abstract":"Large foundation models have recently emerged as a prominent focus of interest, attaining superior performance in widespread scenarios. Due to the scarcity of 3D data, many efforts have been made to adapt pre-trained transformers from vision to 3D domains. However, such 2D-to-3D approaches are still limited, due to the potential loss of spatial geometries and high computation cost. More importantly, their frameworks are mainly designed for 2D models, lacking a general any-to-3D paradigm. In this paper, we introduce Any2Point, a parameter-efficient method to empower any-modality large models (vision, language, audio) for 3D understanding. Given a frozen transformer from any source modality, we propose a 3D-to-any (1D or 2D) virtual projection strategy that correlates the input 3D points to the original 1D or 2D positions within the source modality. This mechanism enables us to assign each 3D token with a positional encoding paired with the pre-trained model, which avoids 3D geometry loss caused by the true projection and better motivates the transformer for 3D learning with 1D/2D positional priors. Then, within each transformer block, we insert an any-to-3D guided adapter module for parameter-efficient fine-tuning. The adapter incorporates prior spatial knowledge from the source modality to guide the local feature aggregation of 3D tokens, compelling the semantic adaption of any-modality transformers. We conduct extensive experiments to showcase the effectiveness and efficiency of our method. Code and models are released at https://github.com/Ivan-Tang-3D/Any2Point.","sentences":["Large foundation models have recently emerged as a prominent focus of interest, attaining superior performance in widespread scenarios.","Due to the scarcity of 3D data, many efforts have been made to adapt pre-trained transformers from vision to 3D domains.","However, such 2D-to-3D approaches are still limited, due to the potential loss of spatial geometries and high computation cost.","More importantly, their frameworks are mainly designed for 2D models, lacking a general any-to-3D paradigm.","In this paper, we introduce Any2Point, a parameter-efficient method to empower any-modality large models (vision, language, audio) for 3D understanding.","Given a frozen transformer from any source modality, we propose a 3D-to-any (1D or 2D) virtual projection strategy that correlates the input 3D points to the original 1D or 2D positions within the source modality.","This mechanism enables us to assign each 3D token with a positional encoding paired with the pre-trained model, which avoids 3D geometry loss caused by the true projection and better motivates the transformer for 3D learning with 1D/2D positional priors.","Then, within each transformer block, we insert an any-to-3D guided adapter module for parameter-efficient fine-tuning.","The adapter incorporates prior spatial knowledge from the source modality to guide the local feature aggregation of 3D tokens, compelling the semantic adaption of any-modality transformers.","We conduct extensive experiments to showcase the effectiveness and efficiency of our method.","Code and models are released at https://github.com/Ivan-Tang-3D/Any2Point."],"url":"http://arxiv.org/abs/2404.07989v1"}
{"created":"2024-04-11 17:59:40","title":"QuasiSim: Parameterized Quasi-Physical Simulators for Dexterous Manipulations Transfer","abstract":"We explore the dexterous manipulation transfer problem by designing simulators. The task wishes to transfer human manipulations to dexterous robot hand simulations and is inherently difficult due to its intricate, highly-constrained, and discontinuous dynamics and the need to control a dexterous hand with a DoF to accurately replicate human manipulations. Previous approaches that optimize in high-fidelity black-box simulators or a modified one with relaxed constraints only demonstrate limited capabilities or are restricted by insufficient simulation fidelity. We introduce parameterized quasi-physical simulators and a physics curriculum to overcome these limitations. The key ideas are 1) balancing between fidelity and optimizability of the simulation via a curriculum of parameterized simulators, and 2) solving the problem in each of the simulators from the curriculum, with properties ranging from high task optimizability to high fidelity. We successfully enable a dexterous hand to track complex and diverse manipulations in high-fidelity simulated environments, boosting the success rate by 11\\%+ from the best-performed baseline. The project website is available at https://meowuu7.github.io/QuasiSim/.","sentences":["We explore the dexterous manipulation transfer problem by designing simulators.","The task wishes to transfer human manipulations to dexterous robot hand simulations and is inherently difficult due to its intricate, highly-constrained, and discontinuous dynamics and the need to control a dexterous hand with a DoF to accurately replicate human manipulations.","Previous approaches that optimize in high-fidelity black-box simulators or a modified one with relaxed constraints only demonstrate limited capabilities or are restricted by insufficient simulation fidelity.","We introduce parameterized quasi-physical simulators and a physics curriculum to overcome these limitations.","The key ideas are 1) balancing between fidelity and optimizability of the simulation via a curriculum of parameterized simulators, and 2) solving the problem in each of the simulators from the curriculum, with properties ranging from high task optimizability to high fidelity.","We successfully enable a dexterous hand to track complex and diverse manipulations in high-fidelity simulated environments, boosting the success rate by 11\\%+ from the best-performed baseline.","The project website is available at https://meowuu7.github.io/QuasiSim/."],"url":"http://arxiv.org/abs/2404.07988v1"}
{"created":"2024-04-11 17:59:09","title":"ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback","abstract":"To enhance the controllability of text-to-image diffusion models, existing efforts like ControlNet incorporated image-based conditional controls. In this paper, we reveal that existing methods still face significant challenges in generating images that align with the image conditional controls. To this end, we propose ControlNet++, a novel approach that improves controllable generation by explicitly optimizing pixel-level cycle consistency between generated images and conditional controls. Specifically, for an input conditional control, we use a pre-trained discriminative reward model to extract the corresponding condition of the generated images, and then optimize the consistency loss between the input conditional control and extracted condition. A straightforward implementation would be generating images from random noises and then calculating the consistency loss, but such an approach requires storing gradients for multiple sampling timesteps, leading to considerable time and memory costs. To address this, we introduce an efficient reward strategy that deliberately disturbs the input images by adding noise, and then uses the single-step denoised images for reward fine-tuning. This avoids the extensive costs associated with image sampling, allowing for more efficient reward fine-tuning. Extensive experiments show that ControlNet++ significantly improves controllability under various conditional controls. For example, it achieves improvements over ControlNet by 7.9% mIoU, 13.4% SSIM, and 7.6% RMSE, respectively, for segmentation mask, line-art edge, and depth conditions.","sentences":["To enhance the controllability of text-to-image diffusion models, existing efforts like ControlNet incorporated image-based conditional controls.","In this paper, we reveal that existing methods still face significant challenges in generating images that align with the image conditional controls.","To this end, we propose ControlNet++, a novel approach that improves controllable generation by explicitly optimizing pixel-level cycle consistency between generated images and conditional controls.","Specifically, for an input conditional control, we use a pre-trained discriminative reward model to extract the corresponding condition of the generated images, and then optimize the consistency loss between the input conditional control and extracted condition.","A straightforward implementation would be generating images from random noises and then calculating the consistency loss, but such an approach requires storing gradients for multiple sampling timesteps, leading to considerable time and memory costs.","To address this, we introduce an efficient reward strategy that deliberately disturbs the input images by adding noise, and then uses the single-step denoised images for reward fine-tuning.","This avoids the extensive costs associated with image sampling, allowing for more efficient reward fine-tuning.","Extensive experiments show that ControlNet++ significantly improves controllability under various conditional controls.","For example, it achieves improvements over ControlNet by 7.9% mIoU, 13.4% SSIM, and 7.6% RMSE, respectively, for segmentation mask, line-art edge, and depth conditions."],"url":"http://arxiv.org/abs/2404.07987v1"}
{"created":"2024-04-11 17:59:07","title":"Trading Determinism for Noncommutativity in Edmonds' Problem","abstract":"Let $X=X_1\\sqcup X_2\\sqcup\\ldots\\sqcup X_k$ be a partitioned set of variables such that the variables in each part $X_i$ are noncommuting but for any $i\\neq j$, the variables $x\\in X_i$ commute with the variables $x'\\in X_j$. Given as input a square matrix $T$ whose entries are linear forms over $\\mathbb{Q}\\langle{X}\\rangle$, we consider the problem of checking if $T$ is invertible or not over the universal skew field of fractions of the partially commutative polynomial ring $\\mathbb{Q}\\langle{X}\\rangle$ [Klep-Vinnikov-Volcic (2020)]. In this paper, we design a deterministic polynomial-time algorithm for this problem for constant $k$. The special case $k=1$ is the noncommutative Edmonds' problem (NSINGULAR) which has a deterministic polynomial-time algorithm by recent results [Garg-Gurvits-Oliveira-Wigderson (2016), Ivanyos-Qiao-Subrahmanyam (2018), Hamada-Hirai (2021)].   En-route, we obtain the first deterministic polynomial-time algorithm for the equivalence testing problem of $k$-tape \\emph{weighted} automata (for constant $k$) resolving a long-standing open problem [Harju and Karhum\"{a}ki(1991), Worrell (2013)]. Algebraically, the equivalence problem reduces to testing whether a partially commutative rational series over the partitioned set $X$ is zero or not [Worrell (2013)]. Decidability of this problem was established by Harju and Karhum\\\"{a}ki (1991). Prior to this work, a \\emph{randomized} polynomial-time algorithm for this problem was given by Worrell (2013) and, subsequently, a deterministic quasipolynomial-time algorithm was also developed [Arvind et al. (2021)].","sentences":["Let $X=X_1\\sqcup X_2\\sqcup\\ldots\\sqcup X_k$ be a partitioned set of variables such that the variables in each part $X_i$ are noncommuting but for any $i\\neq j$, the variables $x\\in X_i$ commute with the variables $x'\\in X_j$. Given as input a square matrix $T$ whose entries are linear forms over $\\mathbb{Q}\\langle{X}\\rangle$, we consider the problem of checking if $T$ is invertible or not over the universal skew field of fractions of the partially commutative polynomial ring $\\mathbb{Q}\\langle{X}\\rangle$","[Klep-Vinnikov-Volcic (2020)].","In this paper, we design a deterministic polynomial-time algorithm for this problem for constant $k$. The special case $k=1$ is the noncommutative Edmonds' problem (NSINGULAR) which has a deterministic polynomial-time algorithm by recent results","[Garg-Gurvits-Oliveira-Wigderson (2016), Ivanyos-Qiao-Subrahmanyam (2018), Hamada-Hirai (2021)].   ","En-route, we obtain the first deterministic polynomial-time algorithm for the equivalence testing problem of $k$-tape \\emph{weighted} automata (for constant $k$) resolving a long-standing open problem [Harju and Karhum\"{a}ki(1991), Worrell (2013)].","Algebraically, the equivalence problem reduces to testing whether a partially commutative rational series over the partitioned set $X$ is zero or not","[Worrell (2013)].","Decidability of this problem was established by Harju and Karhum\\\"{a}ki (1991).","Prior to this work, a \\emph{randomized} polynomial-time algorithm for this problem was given by Worrell (2013) and, subsequently, a deterministic quasipolynomial-time algorithm was also developed","[Arvind et al. (2021)]."],"url":"http://arxiv.org/abs/2404.07986v1"}
{"created":"2024-04-11 17:58:44","title":"WaveMo: Learning Wavefront Modulations to See Through Scattering","abstract":"Imaging through scattering media is a fundamental and pervasive challenge in fields ranging from medical diagnostics to astronomy. A promising strategy to overcome this challenge is wavefront modulation, which induces measurement diversity during image acquisition. Despite its importance, designing optimal wavefront modulations to image through scattering remains under-explored. This paper introduces a novel learning-based framework to address the gap. Our approach jointly optimizes wavefront modulations and a computationally lightweight feedforward \"proxy\" reconstruction network. This network is trained to recover scenes obscured by scattering, using measurements that are modified by these modulations. The learned modulations produced by our framework generalize effectively to unseen scattering scenarios and exhibit remarkable versatility. During deployment, the learned modulations can be decoupled from the proxy network to augment other more computationally expensive restoration algorithms. Through extensive experiments, we demonstrate our approach significantly advances the state of the art in imaging through scattering media. Our project webpage is at https://wavemo-2024.github.io/.","sentences":["Imaging through scattering media is a fundamental and pervasive challenge in fields ranging from medical diagnostics to astronomy.","A promising strategy to overcome this challenge is wavefront modulation, which induces measurement diversity during image acquisition.","Despite its importance, designing optimal wavefront modulations to image through scattering remains under-explored.","This paper introduces a novel learning-based framework to address the gap.","Our approach jointly optimizes wavefront modulations and a computationally lightweight feedforward \"proxy\" reconstruction network.","This network is trained to recover scenes obscured by scattering, using measurements that are modified by these modulations.","The learned modulations produced by our framework generalize effectively to unseen scattering scenarios and exhibit remarkable versatility.","During deployment, the learned modulations can be decoupled from the proxy network to augment other more computationally expensive restoration algorithms.","Through extensive experiments, we demonstrate our approach significantly advances the state of the art in imaging through scattering media.","Our project webpage is at https://wavemo-2024.github.io/."],"url":"http://arxiv.org/abs/2404.07985v1"}
{"created":"2024-04-11 17:58:11","title":"View Selection for 3D Captioning via Diffusion Ranking","abstract":"Scalable annotation approaches are crucial for constructing extensive 3D-text datasets, facilitating a broader range of applications. However, existing methods sometimes lead to the generation of hallucinated captions, compromising caption quality. This paper explores the issue of hallucination in 3D object captioning, with a focus on Cap3D method, which renders 3D objects into 2D views for captioning using pre-trained models. We pinpoint a major challenge: certain rendered views of 3D objects are atypical, deviating from the training data of standard image captioning models and causing hallucinations. To tackle this, we present DiffuRank, a method that leverages a pre-trained text-to-3D model to assess the alignment between 3D objects and their 2D rendered views, where the view with high alignment closely represent the object's characteristics. By ranking all rendered views and feeding the top-ranked ones into GPT4-Vision, we enhance the accuracy and detail of captions, enabling the correction of 200k captions in the Cap3D dataset and extending it to 1 million captions across Objaverse and Objaverse-XL datasets. Additionally, we showcase the adaptability of DiffuRank by applying it to pre-trained text-to-image models for a Visual Question Answering task, where it outperforms the CLIP model.","sentences":["Scalable annotation approaches are crucial for constructing extensive 3D-text datasets, facilitating a broader range of applications.","However, existing methods sometimes lead to the generation of hallucinated captions, compromising caption quality.","This paper explores the issue of hallucination in 3D object captioning, with a focus on Cap3D method, which renders 3D objects into 2D views for captioning using pre-trained models.","We pinpoint a major challenge: certain rendered views of 3D objects are atypical, deviating from the training data of standard image captioning models and causing hallucinations.","To tackle this, we present DiffuRank, a method that leverages a pre-trained text-to-3D model to assess the alignment between 3D objects and their 2D rendered views, where the view with high alignment closely represent the object's characteristics.","By ranking all rendered views and feeding the top-ranked ones into GPT4-Vision, we enhance the accuracy and detail of captions, enabling the correction of 200k captions in the Cap3D dataset and extending it to 1 million captions across Objaverse and Objaverse-XL datasets.","Additionally, we showcase the adaptability of DiffuRank by applying it to pre-trained text-to-image models for a Visual Question Answering task, where it outperforms the CLIP model."],"url":"http://arxiv.org/abs/2404.07984v1"}
{"created":"2024-04-11 17:58:06","title":"Two Effects, One Trigger: On the Modality Gap, Object Bias, and Information Imbalance in Contrastive Vision-Language Representation Learning","abstract":"Contrastive vision-language models like CLIP have gained popularity for their versatile applicable learned representations in various downstream tasks. Despite their successes in some tasks, like zero-shot image recognition, they also perform surprisingly poor on other tasks, like attribute detection. Previous work has attributed these challenges to the modality gap, a separation of image and text in the shared representation space, and a bias towards objects over other factors, such as attributes. In this work we investigate both phenomena. We find that only a few embedding dimensions drive the modality gap. Further, we propose a measure for object bias and find that object bias does not lead to worse performance on other concepts, such as attributes. But what leads to the emergence of the modality gap and object bias? To answer this question we carefully designed an experimental setting which allows us to control the amount of shared information between the modalities. This revealed that the driving factor behind both, the modality gap and the object bias, is the information imbalance between images and captions.","sentences":["Contrastive vision-language models like CLIP have gained popularity for their versatile applicable learned representations in various downstream tasks.","Despite their successes in some tasks, like zero-shot image recognition, they also perform surprisingly poor on other tasks, like attribute detection.","Previous work has attributed these challenges to the modality gap, a separation of image and text in the shared representation space, and a bias towards objects over other factors, such as attributes.","In this work we investigate both phenomena.","We find that only a few embedding dimensions drive the modality gap.","Further, we propose a measure for object bias and find that object bias does not lead to worse performance on other concepts, such as attributes.","But what leads to the emergence of the modality gap and object bias?","To answer this question we carefully designed an experimental setting which allows us to control the amount of shared information between the modalities.","This revealed that the driving factor behind both, the modality gap and the object bias, is the information imbalance between images and captions."],"url":"http://arxiv.org/abs/2404.07983v1"}
{"created":"2024-04-11 17:58:05","title":"Language Imbalance Can Boost Cross-lingual Generalisation","abstract":"Multilinguality is crucial for extending recent advancements in language modelling to diverse linguistic communities. To maintain high performance while representing multiple languages, multilingual models ideally align representations, allowing what is learned in one language to generalise to others. Prior research has emphasised the importance of parallel data and shared vocabulary elements as key factors for such alignment. In this study, we investigate an unintuitive novel driver of cross-lingual generalisation: language imbalance. In controlled experiments on perfectly equivalent cloned languages, we observe that the existence of a predominant language during training boosts the performance of less frequent languages and leads to stronger alignment of model representations across languages. Furthermore, we find that this trend is amplified with scale: with large enough models or long enough training, we observe that bilingual training data with a 90/10 language split yields better performance on both languages than a balanced 50/50 split. Building on these insights, we design training schemes that can improve performance in all cloned languages, even without altering the training data. As we extend our analysis to real languages, we find that infrequent languages still benefit from frequent ones, yet whether language imbalance causes cross-lingual generalisation there is not conclusive.","sentences":["Multilinguality is crucial for extending recent advancements in language modelling to diverse linguistic communities.","To maintain high performance while representing multiple languages, multilingual models ideally align representations, allowing what is learned in one language to generalise to others.","Prior research has emphasised the importance of parallel data and shared vocabulary elements as key factors for such alignment.","In this study, we investigate an unintuitive novel driver of cross-lingual generalisation: language imbalance.","In controlled experiments on perfectly equivalent cloned languages, we observe that the existence of a predominant language during training boosts the performance of less frequent languages and leads to stronger alignment of model representations across languages.","Furthermore, we find that this trend is amplified with scale: with large enough models or long enough training, we observe that bilingual training data with a 90/10 language split yields better performance on both languages than a balanced 50/50 split.","Building on these insights, we design training schemes that can improve performance in all cloned languages, even without altering the training data.","As we extend our analysis to real languages, we find that infrequent languages still benefit from frequent ones, yet whether language imbalance causes cross-lingual generalisation there is not conclusive."],"url":"http://arxiv.org/abs/2404.07982v1"}
{"created":"2024-04-11 17:57:32","title":"Manipulating Large Language Models to Increase Product Visibility","abstract":"Large language models (LLMs) are increasingly being integrated into search engines to provide natural language responses tailored to user queries. Customers and end-users are also becoming more dependent on these models for quick and easy purchase decisions. In this work, we investigate whether recommendations from LLMs can be manipulated to enhance a product's visibility. We demonstrate that adding a strategic text sequence (STS) -- a carefully crafted message -- to a product's information page can significantly increase its likelihood of being listed as the LLM's top recommendation. To understand the impact of STS, we use a catalog of fictitious coffee machines and analyze its effect on two target products: one that seldom appears in the LLM's recommendations and another that usually ranks second. We observe that the strategic text sequence significantly enhances the visibility of both products by increasing their chances of appearing as the top recommendation. This ability to manipulate LLM-generated search responses provides vendors with a considerable competitive advantage and has the potential to disrupt fair market competition. Just as search engine optimization (SEO) revolutionized how webpages are customized to rank higher in search engine results, influencing LLM recommendations could profoundly impact content optimization for AI-driven search services. Code for our experiments is available at https://github.com/aounon/llm-rank-optimizer.","sentences":["Large language models (LLMs) are increasingly being integrated into search engines to provide natural language responses tailored to user queries.","Customers and end-users are also becoming more dependent on these models for quick and easy purchase decisions.","In this work, we investigate whether recommendations from LLMs can be manipulated to enhance a product's visibility.","We demonstrate that adding a strategic text sequence (STS) -- a carefully crafted message -- to a product's information page can significantly increase its likelihood of being listed as the LLM's top recommendation.","To understand the impact of STS, we use a catalog of fictitious coffee machines and analyze its effect on two target products: one that seldom appears in the LLM's recommendations and another that usually ranks second.","We observe that the strategic text sequence significantly enhances the visibility of both products by increasing their chances of appearing as the top recommendation.","This ability to manipulate LLM-generated search responses provides vendors with a considerable competitive advantage and has the potential to disrupt fair market competition.","Just as search engine optimization (SEO) revolutionized how webpages are customized to rank higher in search engine results, influencing LLM recommendations could profoundly impact content optimization for AI-driven search services.","Code for our experiments is available at https://github.com/aounon/llm-rank-optimizer."],"url":"http://arxiv.org/abs/2404.07981v1"}
{"created":"2024-04-11 17:57:22","title":"LLoCO: Learning Long Contexts Offline","abstract":"Processing long contexts remains a challenge for large language models (LLMs) due to the quadratic computational and memory overhead of the self-attention mechanism and the substantial KV cache sizes during generation. We propose a novel approach to address this problem by learning contexts offline through context compression and in-domain parameter-efficient finetuning. Our method enables an LLM to create a concise representation of the original context and efficiently retrieve relevant information to answer questions accurately. We introduce LLoCO, a technique that combines context compression, retrieval, and parameter-efficient finetuning using LoRA. Our approach extends the effective context window of a 4k token LLaMA2-7B model to handle up to 128k tokens. We evaluate our approach on several long-context question-answering datasets, demonstrating that LLoCO significantly outperforms in-context learning while using $30\\times$ fewer tokens during inference. LLoCO achieves up to $7.62\\times$ speed-up and substantially reduces the cost of long document question answering, making it a promising solution for efficient long context processing. Our code is publicly available at https://github.com/jeffreysijuntan/lloco.","sentences":["Processing long contexts remains a challenge for large language models (LLMs) due to the quadratic computational and memory overhead of the self-attention mechanism and the substantial KV cache sizes during generation.","We propose a novel approach to address this problem by learning contexts offline through context compression and in-domain parameter-efficient finetuning.","Our method enables an LLM to create a concise representation of the original context and efficiently retrieve relevant information to answer questions accurately.","We introduce LLoCO, a technique that combines context compression, retrieval, and parameter-efficient finetuning using LoRA.","Our approach extends the effective context window of a 4k token LLaMA2-7B model to handle up to 128k tokens.","We evaluate our approach on several long-context question-answering datasets, demonstrating that LLoCO significantly outperforms in-context learning while using $30\\times$ fewer tokens during inference.","LLoCO achieves up to $7.62\\times$ speed-up and substantially reduces the cost of long document question answering, making it a promising solution for efficient long context processing.","Our code is publicly available at https://github.com/jeffreysijuntan/lloco."],"url":"http://arxiv.org/abs/2404.07979v1"}
{"created":"2024-04-11 17:57:19","title":"Gaga: Group Any Gaussians via 3D-aware Memory Bank","abstract":"We introduce Gaga, a framework that reconstructs and segments open-world 3D scenes by leveraging inconsistent 2D masks predicted by zero-shot segmentation models. Contrasted to prior 3D scene segmentation approaches that heavily rely on video object tracking, Gaga utilizes spatial information and effectively associates object masks across diverse camera poses. By eliminating the assumption of continuous view changes in training images, Gaga demonstrates robustness to variations in camera poses, particularly beneficial for sparsely sampled images, ensuring precise mask label consistency. Furthermore, Gaga accommodates 2D segmentation masks from diverse sources and demonstrates robust performance with different open-world zero-shot segmentation models, enhancing its versatility. Extensive qualitative and quantitative evaluations demonstrate that Gaga performs favorably against state-of-the-art methods, emphasizing its potential for real-world applications such as scene understanding and manipulation.","sentences":["We introduce Gaga, a framework that reconstructs and segments open-world 3D scenes by leveraging inconsistent 2D masks predicted by zero-shot segmentation models.","Contrasted to prior 3D scene segmentation approaches that heavily rely on video object tracking, Gaga utilizes spatial information and effectively associates object masks across diverse camera poses.","By eliminating the assumption of continuous view changes in training images, Gaga demonstrates robustness to variations in camera poses, particularly beneficial for sparsely sampled images, ensuring precise mask label consistency.","Furthermore, Gaga accommodates 2D segmentation masks from diverse sources and demonstrates robust performance with different open-world zero-shot segmentation models, enhancing its versatility.","Extensive qualitative and quantitative evaluations demonstrate that Gaga performs favorably against state-of-the-art methods, emphasizing its potential for real-world applications such as scene understanding and manipulation."],"url":"http://arxiv.org/abs/2404.07977v1"}
{"created":"2024-04-11 17:56:40","title":"Self-supervised Dataset Distillation: A Good Compression Is All You Need","abstract":"Dataset distillation aims to compress information from a large-scale original dataset to a new compact dataset while striving to preserve the utmost degree of the original data informational essence. Previous studies have predominantly concentrated on aligning the intermediate statistics between the original and distilled data, such as weight trajectory, features, gradient, BatchNorm, etc. In this work, we consider addressing this task through the new lens of model informativeness in the compression stage on the original dataset pretraining. We observe that with the prior state-of-the-art SRe$^2$L, as model sizes increase, it becomes increasingly challenging for supervised pretrained models to recover learned information during data synthesis, as the channel-wise mean and variance inside the model are flatting and less informative. We further notice that larger variances in BN statistics from self-supervised models enable larger loss signals to update the recovered data by gradients, enjoying more informativeness during synthesis. Building on this observation, we introduce SC-DD, a simple yet effective Self-supervised Compression framework for Dataset Distillation that facilitates diverse information compression and recovery compared to traditional supervised learning schemes, further reaps the potential of large pretrained models with enhanced capabilities. Extensive experiments are conducted on CIFAR-100, Tiny-ImageNet and ImageNet-1K datasets to demonstrate the superiority of our proposed approach. The proposed SC-DD outperforms all previous state-of-the-art supervised dataset distillation methods when employing larger models, such as SRe$^2$L, MTT, TESLA, DC, CAFE, etc., by large margins under the same recovery and post-training budgets. Code is available at https://github.com/VILA-Lab/SRe2L/tree/main/SCDD/.","sentences":["Dataset distillation aims to compress information from a large-scale original dataset to a new compact dataset while striving to preserve the utmost degree of the original data informational essence.","Previous studies have predominantly concentrated on aligning the intermediate statistics between the original and distilled data, such as weight trajectory, features, gradient, BatchNorm, etc.","In this work, we consider addressing this task through the new lens of model informativeness in the compression stage on the original dataset pretraining.","We observe that with the prior state-of-the-art SRe$^2$L, as model sizes increase, it becomes increasingly challenging for supervised pretrained models to recover learned information during data synthesis, as the channel-wise mean and variance inside the model are flatting and less informative.","We further notice that larger variances in BN statistics from self-supervised models enable larger loss signals to update the recovered data by gradients, enjoying more informativeness during synthesis.","Building on this observation, we introduce SC-DD, a simple yet effective Self-supervised Compression framework for Dataset Distillation that facilitates diverse information compression and recovery compared to traditional supervised learning schemes, further reaps the potential of large pretrained models with enhanced capabilities.","Extensive experiments are conducted on CIFAR-100, Tiny-ImageNet and ImageNet-1K datasets to demonstrate the superiority of our proposed approach.","The proposed SC-DD outperforms all previous state-of-the-art supervised dataset distillation methods when employing larger models, such as SRe$^2$L, MTT, TESLA, DC, CAFE, etc., by large margins under the same recovery and post-training budgets.","Code is available at https://github.com/VILA-Lab/SRe2L/tree/main/SCDD/."],"url":"http://arxiv.org/abs/2404.07976v1"}
{"created":"2024-04-11 17:56:05","title":"OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments","abstract":"Autonomous agents that accomplish complex computer tasks with minimal human interventions have the potential to transform human-computer interaction, significantly enhancing accessibility and productivity. However, existing benchmarks either lack an interactive environment or are limited to environments specific to certain applications or domains, failing to reflect the diverse and complex nature of real-world computer use, thereby limiting the scope of tasks and agent scalability. To address this issue, we introduce OSWorld, the first-of-its-kind scalable, real computer environment for multimodal agents, supporting task setup, execution-based evaluation, and interactive learning across various operating systems such as Ubuntu, Windows, and macOS. OSWorld can serve as a unified, integrated computer environment for assessing open-ended computer tasks that involve arbitrary applications. Building upon OSWorld, we create a benchmark of 369 computer tasks involving real web and desktop apps in open domains, OS file I/O, and workflows spanning multiple applications. Each task example is derived from real-world computer use cases and includes a detailed initial state setup configuration and a custom execution-based evaluation script for reliable, reproducible evaluation. Extensive evaluation of state-of-the-art LLM/VLM-based agents on OSWorld reveals significant deficiencies in their ability to serve as computer assistants. While humans can accomplish over 72.36% of the tasks, the best model achieves only 12.24% success, primarily struggling with GUI grounding and operational knowledge. Comprehensive analysis using OSWorld provides valuable insights for developing multimodal generalist agents that were not possible with previous benchmarks. Our code, environment, baseline models, and data are publicly available at https://os-world.github.io.","sentences":["Autonomous agents that accomplish complex computer tasks with minimal human interventions have the potential to transform human-computer interaction, significantly enhancing accessibility and productivity.","However, existing benchmarks either lack an interactive environment or are limited to environments specific to certain applications or domains, failing to reflect the diverse and complex nature of real-world computer use, thereby limiting the scope of tasks and agent scalability.","To address this issue, we introduce OSWorld, the first-of-its-kind scalable, real computer environment for multimodal agents, supporting task setup, execution-based evaluation, and interactive learning across various operating systems such as Ubuntu, Windows, and macOS.","OSWorld can serve as a unified, integrated computer environment for assessing open-ended computer tasks that involve arbitrary applications.","Building upon OSWorld, we create a benchmark of 369 computer tasks involving real web and desktop apps in open domains, OS file I/O, and workflows spanning multiple applications.","Each task example is derived from real-world computer use cases and includes a detailed initial state setup configuration and a custom execution-based evaluation script for reliable, reproducible evaluation.","Extensive evaluation of state-of-the-art LLM/VLM-based agents on OSWorld reveals significant deficiencies in their ability to serve as computer assistants.","While humans can accomplish over 72.36% of the tasks, the best model achieves only 12.24% success, primarily struggling with GUI grounding and operational knowledge.","Comprehensive analysis using OSWorld provides valuable insights for developing multimodal generalist agents that were not possible with previous benchmarks.","Our code, environment, baseline models, and data are publicly available at https://os-world.github.io."],"url":"http://arxiv.org/abs/2404.07972v1"}
{"created":"2024-04-11 17:56:05","title":"Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models","abstract":"While Ferret seamlessly integrates regional understanding into the Large Language Model (LLM) to facilitate its referring and grounding capability, it poses certain limitations: constrained by the pre-trained fixed visual encoder and failed to perform well on broader tasks. In this work, we unveil Ferret-v2, a significant upgrade to Ferret, with three key designs. (1) Any resolution grounding and referring: A flexible approach that effortlessly handles higher image resolution, improving the model's ability to process and understand images in greater detail. (2) Multi-granularity visual encoding: By integrating the additional DINOv2 encoder, the model learns better and diverse underlying contexts for global and fine-grained visual information. (3) A three-stage training paradigm: Besides image-caption alignment, an additional stage is proposed for high-resolution dense alignment before the final instruction tuning. Experiments show that Ferret-v2 provides substantial improvements over Ferret and other state-of-the-art methods, thanks to its high-resolution scaling and fine-grained visual processing.","sentences":["While Ferret seamlessly integrates regional understanding into the Large Language Model (LLM) to facilitate its referring and grounding capability, it poses certain limitations: constrained by the pre-trained fixed visual encoder and failed to perform well on broader tasks.","In this work, we unveil Ferret-v2, a significant upgrade to Ferret, with three key designs.","(1) Any resolution grounding and referring: A flexible approach that effortlessly handles higher image resolution, improving the model's ability to process and understand images in greater detail.","(2) Multi-granularity visual encoding:","By integrating the additional DINOv2 encoder, the model learns better and diverse underlying contexts for global and fine-grained visual information.","(3) A three-stage training paradigm:","Besides image-caption alignment, an additional stage is proposed for high-resolution dense alignment before the final instruction tuning.","Experiments show that Ferret-v2 provides substantial improvements over Ferret and other state-of-the-art methods, thanks to its high-resolution scaling and fine-grained visual processing."],"url":"http://arxiv.org/abs/2404.07973v1"}
{"created":"2024-04-11 17:52:01","title":"Rho-1: Not All Tokens Are What You Need","abstract":"Previous language model pre-training methods have uniformly applied a next-token prediction loss to all training tokens. Challenging this norm, we posit that \"Not all tokens in a corpus are equally important for language model training\". Our initial analysis delves into token-level training dynamics of language model, revealing distinct loss patterns for different tokens. Leveraging these insights, we introduce a new language model called Rho-1. Unlike traditional LMs that learn to predict every next token in a corpus, Rho-1 employs Selective Language Modeling (SLM), which selectively trains on useful tokens that aligned with the desired distribution. This approach involves scoring pretraining tokens using a reference model, and then training the language model with a focused loss on tokens with higher excess loss. When continual pretraining on 15B OpenWebMath corpus, Rho-1 yields an absolute improvement in few-shot accuracy of up to 30% in 9 math tasks. After fine-tuning, Rho-1-1B and 7B achieved state-of-the-art results of 40.6% and 51.8% on MATH dataset, respectively - matching DeepSeekMath with only 3% of the pretraining tokens. Furthermore, when pretraining on 80B general tokens, Rho-1 achieves 6.8% average enhancement across 15 diverse tasks, increasing both efficiency and performance of the language model pre-training.","sentences":["Previous language model pre-training methods have uniformly applied a next-token prediction loss to all training tokens.","Challenging this norm, we posit that \"Not all tokens in a corpus are equally important for language model training\".","Our initial analysis delves into token-level training dynamics of language model, revealing distinct loss patterns for different tokens.","Leveraging these insights, we introduce a new language model called Rho-1.","Unlike traditional LMs that learn to predict every next token in a corpus, Rho-1 employs Selective Language Modeling (SLM), which selectively trains on useful tokens that aligned with the desired distribution.","This approach involves scoring pretraining tokens using a reference model, and then training the language model with a focused loss on tokens with higher excess loss.","When continual pretraining on 15B OpenWebMath corpus, Rho-1 yields an absolute improvement in few-shot accuracy of up to 30% in 9 math tasks.","After fine-tuning, Rho-1-1B and 7B achieved state-of-the-art results of 40.6% and 51.8% on MATH dataset, respectively - matching DeepSeekMath with only 3% of the pretraining tokens.","Furthermore, when pretraining on 80B general tokens, Rho-1 achieves 6.8% average enhancement across 15 diverse tasks, increasing both efficiency and performance of the language model pre-training."],"url":"http://arxiv.org/abs/2404.07965v1"}
{"created":"2024-04-11 17:49:15","title":"Lyapunov-stable Neural Control for State and Output Feedback: A Novel Formulation for Efficient Synthesis and Verification","abstract":"Learning-based neural network (NN) control policies have shown impressive empirical performance in a wide range of tasks in robotics and control. However, formal (Lyapunov) stability guarantees over the region-of-attraction (ROA) for NN controllers with nonlinear dynamical systems are challenging to obtain, and most existing approaches rely on expensive solvers such as sums-of-squares (SOS), mixed-integer programming (MIP), or satisfiability modulo theories (SMT). In this paper, we demonstrate a new framework for learning NN controllers together with Lyapunov certificates using fast empirical falsification and strategic regularizations. We propose a novel formulation that defines a larger verifiable region-of-attraction (ROA) than shown in the literature, and refines the conventional restrictive constraints on Lyapunov derivatives to focus only on certifiable ROAs. The Lyapunov condition is rigorously verified post-hoc using branch-and-bound with scalable linear bound propagation-based NN verification techniques. The approach is efficient and flexible, and the full training and verification procedure is accelerated on GPUs without relying on expensive solvers for SOS, MIP, nor SMT. The flexibility and efficiency of our framework allow us to demonstrate Lyapunov-stable output feedback control with synthesized NN-based controllers and NN-based observers with formal stability guarantees, for the first time in literature. Source code at https://github.com/Verified-Intelligence/Lyapunov_Stable_NN_Controllers.","sentences":["Learning-based neural network (NN) control policies have shown impressive empirical performance in a wide range of tasks in robotics and control.","However, formal (Lyapunov) stability guarantees over the region-of-attraction (ROA) for NN controllers with nonlinear dynamical systems are challenging to obtain, and most existing approaches rely on expensive solvers such as sums-of-squares (SOS), mixed-integer programming (MIP), or satisfiability modulo theories (SMT).","In this paper, we demonstrate a new framework for learning NN controllers together with Lyapunov certificates using fast empirical falsification and strategic regularizations.","We propose a novel formulation that defines a larger verifiable region-of-attraction (ROA) than shown in the literature, and refines the conventional restrictive constraints on Lyapunov derivatives to focus only on certifiable ROAs.","The Lyapunov condition is rigorously verified post-hoc using branch-and-bound with scalable linear bound propagation-based NN verification techniques.","The approach is efficient and flexible, and the full training and verification procedure is accelerated on GPUs without relying on expensive solvers for SOS, MIP, nor SMT.","The flexibility and efficiency of our framework allow us to demonstrate Lyapunov-stable output feedback control with synthesized NN-based controllers and NN-based observers with formal stability guarantees, for the first time in literature.","Source code at https://github.com/Verified-Intelligence/Lyapunov_Stable_NN_Controllers."],"url":"http://arxiv.org/abs/2404.07956v1"}
{"created":"2024-04-11 17:46:14","title":"Taming Stable Diffusion for Text to 360\u00b0 Panorama Image Generation","abstract":"Generative models, e.g., Stable Diffusion, have enabled the creation of photorealistic images from text prompts. Yet, the generation of 360-degree panorama images from text remains a challenge, particularly due to the dearth of paired text-panorama data and the domain gap between panorama and perspective images. In this paper, we introduce a novel dual-branch diffusion model named PanFusion to generate a 360-degree image from a text prompt. We leverage the stable diffusion model as one branch to provide prior knowledge in natural image generation and register it to another panorama branch for holistic image generation. We propose a unique cross-attention mechanism with projection awareness to minimize distortion during the collaborative denoising process. Our experiments validate that PanFusion surpasses existing methods and, thanks to its dual-branch structure, can integrate additional constraints like room layout for customized panorama outputs. Code is available at https://chengzhag.github.io/publication/panfusion.","sentences":["Generative models, e.g., Stable Diffusion, have enabled the creation of photorealistic images from text prompts.","Yet, the generation of 360-degree panorama images from text remains a challenge, particularly due to the dearth of paired text-panorama data and the domain gap between panorama and perspective images.","In this paper, we introduce a novel dual-branch diffusion model named PanFusion to generate a 360-degree image from a text prompt.","We leverage the stable diffusion model as one branch to provide prior knowledge in natural image generation and register it to another panorama branch for holistic image generation.","We propose a unique cross-attention mechanism with projection awareness to minimize distortion during the collaborative denoising process.","Our experiments validate that PanFusion surpasses existing methods and, thanks to its dual-branch structure, can integrate additional constraints like room layout for customized panorama outputs.","Code is available at https://chengzhag.github.io/publication/panfusion."],"url":"http://arxiv.org/abs/2404.07949v1"}
{"created":"2024-04-11 17:41:28","title":"On Unified Prompt Tuning for Request Quality Assurance in Public Code Review","abstract":"Public Code Review (PCR) can be implemented through a Software Question Answering (SQA) community, which facilitates high knowledge dissemination. Current methods mainly focus on the reviewer's perspective, including finding a capable reviewer, predicting comment quality, and recommending/generating review comments. Our intuition is that satisfying review necessity requests can increase their visibility, which in turn is a prerequisite for better review responses. To this end, we propose a unified framework called UniPCR to complete developer-based request quality assurance (i.e., predicting request necessity and recommending tags subtask) under a Masked Language Model (MLM). Specifically, we reformulate both subtasks via 1) text prompt tuning, which converts two subtasks into MLM by constructing prompt templates using hard prompt; 2) code prefix tuning, which optimizes a small segment of generated continuous vectors as the prefix of the code representation using soft prompt. Experimental results on the Public Code Review dataset for the time span 2011-2022 demonstrate that our UniPCR framework adapts to the two subtasks and outperforms comparable accuracy-based results with state-of-the-art methods for request quality assurance. These conclusions highlight the effectiveness of our unified framework from the developer's perspective in public code review.","sentences":["Public Code Review (PCR) can be implemented through a Software Question Answering (SQA) community, which facilitates high knowledge dissemination.","Current methods mainly focus on the reviewer's perspective, including finding a capable reviewer, predicting comment quality, and recommending/generating review comments.","Our intuition is that satisfying review necessity requests can increase their visibility, which in turn is a prerequisite for better review responses.","To this end, we propose a unified framework called UniPCR to complete developer-based request quality assurance (i.e., predicting request necessity and recommending tags subtask) under a Masked Language Model (MLM).","Specifically, we reformulate both subtasks via 1) text prompt tuning, which converts two subtasks into MLM by constructing prompt templates using hard prompt; 2) code prefix tuning, which optimizes a small segment of generated continuous vectors as the prefix of the code representation using soft prompt.","Experimental results on the Public Code Review dataset for the time span 2011-2022 demonstrate that our UniPCR framework adapts to the two subtasks and outperforms comparable accuracy-based results with state-of-the-art methods for request quality assurance.","These conclusions highlight the effectiveness of our unified framework from the developer's perspective in public code review."],"url":"http://arxiv.org/abs/2404.07942v1"}
{"created":"2024-04-11 17:34:35","title":"Goal Recognition via Linear Programming","abstract":"Goal Recognition is the task by which an observer aims to discern the goals that correspond to plans that comply with the perceived behavior of subject agents given as a sequence of observations. Research on Goal Recognition as Planning encompasses reasoning about the model of a planning task, the observations, and the goals using planning techniques, resulting in very efficient recognition approaches. In this article, we design novel recognition approaches that rely on the Operator-Counting framework, proposing new constraints, and analyze their constraints' properties both theoretically and empirically. The Operator-Counting framework is a technique that efficiently computes heuristic estimates of cost-to-goal using Integer/Linear Programming (IP/LP). In the realm of theory, we prove that the new constraints provide lower bounds on the cost of plans that comply with observations. We also provide an extensive empirical evaluation to assess how the new constraints improve the quality of the solution, and we found that they are especially informed in deciding which goals are unlikely to be part of the solution. Our novel recognition approaches have two pivotal advantages: first, they employ new IP/LP constraints for efficiently recognizing goals; second, we show how the new IP/LP constraints can improve the recognition of goals under both partial and noisy observability.","sentences":["Goal Recognition is the task by which an observer aims to discern the goals that correspond to plans that comply with the perceived behavior of subject agents given as a sequence of observations.","Research on Goal Recognition as Planning encompasses reasoning about the model of a planning task, the observations, and the goals using planning techniques, resulting in very efficient recognition approaches.","In this article, we design novel recognition approaches that rely on the Operator-Counting framework, proposing new constraints, and analyze their constraints' properties both theoretically and empirically.","The Operator-Counting framework is a technique that efficiently computes heuristic estimates of cost-to-goal using Integer/Linear Programming (IP/LP).","In the realm of theory, we prove that the new constraints provide lower bounds on the cost of plans that comply with observations.","We also provide an extensive empirical evaluation to assess how the new constraints improve the quality of the solution, and we found that they are especially informed in deciding which goals are unlikely to be part of the solution.","Our novel recognition approaches have two pivotal advantages: first, they employ new IP/LP constraints for efficiently recognizing goals; second, we show how the new IP/LP constraints can improve the recognition of goals under both partial and noisy observability."],"url":"http://arxiv.org/abs/2404.07934v1"}
{"created":"2024-04-11 17:30:24","title":"Boosting Self-Supervision for Single-View Scene Completion via Knowledge Distillation","abstract":"Inferring scene geometry from images via Structure from Motion is a long-standing and fundamental problem in computer vision. While classical approaches and, more recently, depth map predictions only focus on the visible parts of a scene, the task of scene completion aims to reason about geometry even in occluded regions. With the popularity of neural radiance fields (NeRFs), implicit representations also became popular for scene completion by predicting so-called density fields. Unlike explicit approaches. e.g. voxel-based methods, density fields also allow for accurate depth prediction and novel-view synthesis via image-based rendering. In this work, we propose to fuse the scene reconstruction from multiple images and distill this knowledge into a more accurate single-view scene reconstruction. To this end, we propose Multi-View Behind the Scenes (MVBTS) to fuse density fields from multiple posed images, trained fully self-supervised only from image data. Using knowledge distillation, we use MVBTS to train a single-view scene completion network via direct supervision called KDBTS. It achieves state-of-the-art performance on occupancy prediction, especially in occluded regions.","sentences":["Inferring scene geometry from images via Structure from Motion is a long-standing and fundamental problem in computer vision.","While classical approaches and, more recently, depth map predictions only focus on the visible parts of a scene, the task of scene completion aims to reason about geometry even in occluded regions.","With the popularity of neural radiance fields (NeRFs), implicit representations also became popular for scene completion by predicting so-called density fields.","Unlike explicit approaches.","e.g. voxel-based methods, density fields also allow for accurate depth prediction and novel-view synthesis via image-based rendering.","In this work, we propose to fuse the scene reconstruction from multiple images and distill this knowledge into a more accurate single-view scene reconstruction.","To this end, we propose Multi-View Behind the Scenes (MVBTS) to fuse density fields from multiple posed images, trained fully self-supervised only from image data.","Using knowledge distillation, we use MVBTS to train a single-view scene completion network via direct supervision called KDBTS.","It achieves state-of-the-art performance on occupancy prediction, especially in occluded regions."],"url":"http://arxiv.org/abs/2404.07933v1"}
{"created":"2024-04-11 17:29:56","title":"FusionMamba: Efficient Image Fusion with State Space Model","abstract":"Image fusion aims to generate a high-resolution multi/hyper-spectral image by combining a high-resolution image with limited spectral information and a low-resolution image with abundant spectral data. Current deep learning (DL)-based methods for image fusion primarily rely on CNNs or Transformers to extract features and merge different types of data. While CNNs are efficient, their receptive fields are limited, restricting their capacity to capture global context. Conversely, Transformers excel at learning global information but are hindered by their quadratic complexity. Fortunately, recent advancements in the State Space Model (SSM), particularly Mamba, offer a promising solution to this issue by enabling global awareness with linear complexity. However, there have been few attempts to explore the potential of SSM in information fusion, which is a crucial ability in domains like image fusion. Therefore, we propose FusionMamba, an innovative method for efficient image fusion. Our contributions mainly focus on two aspects. Firstly, recognizing that images from different sources possess distinct properties, we incorporate Mamba blocks into two U-shaped networks, presenting a novel architecture that extracts spatial and spectral features in an efficient, independent, and hierarchical manner. Secondly, to effectively combine spatial and spectral information, we extend the Mamba block to accommodate dual inputs. This expansion leads to the creation of a new module called the FusionMamba block, which outperforms existing fusion techniques such as concatenation and cross-attention. To validate FusionMamba's effectiveness, we conduct a series of experiments on five datasets related to three image fusion tasks. The quantitative and qualitative evaluation results demonstrate that our method achieves state-of-the-art (SOTA) performance, underscoring the superiority of FusionMamba.","sentences":["Image fusion aims to generate a high-resolution multi/hyper-spectral image by combining a high-resolution image with limited spectral information and a low-resolution image with abundant spectral data.","Current deep learning (DL)-based methods for image fusion primarily rely on CNNs or Transformers to extract features and merge different types of data.","While CNNs are efficient, their receptive fields are limited, restricting their capacity to capture global context.","Conversely, Transformers excel at learning global information but are hindered by their quadratic complexity.","Fortunately, recent advancements in the State Space Model (SSM), particularly Mamba, offer a promising solution to this issue by enabling global awareness with linear complexity.","However, there have been few attempts to explore the potential of SSM in information fusion, which is a crucial ability in domains like image fusion.","Therefore, we propose FusionMamba, an innovative method for efficient image fusion.","Our contributions mainly focus on two aspects.","Firstly, recognizing that images from different sources possess distinct properties, we incorporate Mamba blocks into two U-shaped networks, presenting a novel architecture that extracts spatial and spectral features in an efficient, independent, and hierarchical manner.","Secondly, to effectively combine spatial and spectral information, we extend the Mamba block to accommodate dual inputs.","This expansion leads to the creation of a new module called the FusionMamba block, which outperforms existing fusion techniques such as concatenation and cross-attention.","To validate FusionMamba's effectiveness, we conduct a series of experiments on five datasets related to three image fusion tasks.","The quantitative and qualitative evaluation results demonstrate that our method achieves state-of-the-art (SOTA) performance, underscoring the superiority of FusionMamba."],"url":"http://arxiv.org/abs/2404.07932v1"}
{"created":"2024-04-11 17:27:39","title":"Parameter Hierarchical Optimization for Visible-Infrared Person Re-Identification","abstract":"Visible-infrared person re-identification (VI-reID) aims at matching cross-modality pedestrian images captured by disjoint visible or infrared cameras. Existing methods alleviate the cross-modality discrepancies via designing different kinds of network architectures. Different from available methods, in this paper, we propose a novel parameter optimizing paradigm, parameter hierarchical optimization (PHO) method, for the task of VI-ReID. It allows part of parameters to be directly optimized without any training, which narrows the search space of parameters and makes the whole network more easier to be trained. Specifically, we first divide the parameters into different types, and then introduce a self-adaptive alignment strategy (SAS) to automatically align the visible and infrared images through transformation. Considering that features in different dimension have varying importance, we develop an auto-weighted alignment learning (AAL) module that can automatically weight features according to their importance. Importantly, in the alignment process of SAS and AAL, all the parameters are immediately optimized with optimization principles rather than training the whole network, which yields a better parameter training manner. Furthermore, we establish the cross-modality consistent learning (CCL) loss to extract discriminative person representations with translation consistency. We provide both theoretical justification and empirical evidence that our proposed PHO method outperform existing VI-reID approaches.","sentences":["Visible-infrared person re-identification (VI-reID) aims at matching cross-modality pedestrian images captured by disjoint visible or infrared cameras.","Existing methods alleviate the cross-modality discrepancies via designing different kinds of network architectures.","Different from available methods, in this paper, we propose a novel parameter optimizing paradigm, parameter hierarchical optimization (PHO) method, for the task of VI-ReID.","It allows part of parameters to be directly optimized without any training, which narrows the search space of parameters and makes the whole network more easier to be trained.","Specifically, we first divide the parameters into different types, and then introduce a self-adaptive alignment strategy (SAS) to automatically align the visible and infrared images through transformation.","Considering that features in different dimension have varying importance, we develop an auto-weighted alignment learning (AAL) module that can automatically weight features according to their importance.","Importantly, in the alignment process of SAS and AAL, all the parameters are immediately optimized with optimization principles rather than training the whole network, which yields a better parameter training manner.","Furthermore, we establish the cross-modality consistent learning (CCL) loss to extract discriminative person representations with translation consistency.","We provide both theoretical justification and empirical evidence that our proposed PHO method outperform existing VI-reID approaches."],"url":"http://arxiv.org/abs/2404.07930v1"}
{"created":"2024-04-11 17:20:57","title":"Leveraging Large Language Models (LLMs) to Support Collaborative Human-AI Online Risk Data Annotation","abstract":"In this position paper, we discuss the potential for leveraging LLMs as interactive research tools to facilitate collaboration between human coders and AI to effectively annotate online risk data at scale. Collaborative human-AI labeling is a promising approach to annotating large-scale and complex data for various tasks. Yet, tools and methods to support effective human-AI collaboration for data annotation are under-studied. This gap is pertinent because co-labeling tasks need to support a two-way interactive discussion that can add nuance and context, particularly in the context of online risk, which is highly subjective and contextualized. Therefore, we provide some of the early benefits and challenges of using LLMs-based tools for risk annotation and suggest future directions for the HCI research community to leverage LLMs as research tools to facilitate human-AI collaboration in contextualized online data annotation. Our research interests align very well with the purposes of the LLMs as Research Tools workshop to identify ongoing applications and challenges of using LLMs to work with data in HCI research. We anticipate learning valuable insights from organizers and participants into how LLMs can help reshape the HCI community's methods for working with data.","sentences":["In this position paper, we discuss the potential for leveraging LLMs as interactive research tools to facilitate collaboration between human coders and AI to effectively annotate online risk data at scale.","Collaborative human-AI labeling is a promising approach to annotating large-scale and complex data for various tasks.","Yet, tools and methods to support effective human-AI collaboration for data annotation are under-studied.","This gap is pertinent because co-labeling tasks need to support a two-way interactive discussion that can add nuance and context, particularly in the context of online risk, which is highly subjective and contextualized.","Therefore, we provide some of the early benefits and challenges of using LLMs-based tools for risk annotation and suggest future directions for the HCI research community to leverage LLMs as research tools to facilitate human-AI collaboration in contextualized online data annotation.","Our research interests align very well with the purposes of the LLMs as Research Tools workshop to identify ongoing applications and challenges of using LLMs to work with data in HCI research.","We anticipate learning valuable insights from organizers and participants into how LLMs can help reshape the HCI community's methods for working with data."],"url":"http://arxiv.org/abs/2404.07926v1"}
{"created":"2024-04-11 17:10:57","title":"A Parsimonious Setup for Streamflow Forecasting using CNN-LSTM","abstract":"Significant strides have been made in advancing streamflow predictions, notably with the introduction of cutting-edge machine-learning models. Predominantly, Long Short-Term Memories (LSTMs) and Convolution Neural Networks (CNNs) have been widely employed in this domain. While LSTMs are applicable in both rainfall-runoff and time series settings, CNN-LSTMs have primarily been utilized in rainfall-runoff scenarios. In this study, we extend the application of CNN-LSTMs to time series settings, leveraging lagged streamflow data in conjunction with precipitation and temperature data to predict streamflow. Our results show a substantial improvement in predictive performance in 21 out of 32 HUC8 basins in Nebraska, showcasing noteworthy increases in the Kling-Gupta Efficiency (KGE) values. These results highlight the effectiveness of CNN-LSTMs in time series settings, particularly for spatiotemporal hydrological modeling, for more accurate and robust streamflow predictions.","sentences":["Significant strides have been made in advancing streamflow predictions, notably with the introduction of cutting-edge machine-learning models.","Predominantly, Long Short-Term Memories (LSTMs) and Convolution Neural Networks (CNNs) have been widely employed in this domain.","While LSTMs are applicable in both rainfall-runoff and time series settings, CNN-LSTMs have primarily been utilized in rainfall-runoff scenarios.","In this study, we extend the application of CNN-LSTMs to time series settings, leveraging lagged streamflow data in conjunction with precipitation and temperature data to predict streamflow.","Our results show a substantial improvement in predictive performance in 21 out of 32 HUC8 basins in Nebraska, showcasing noteworthy increases in the Kling-Gupta Efficiency (KGE) values.","These results highlight the effectiveness of CNN-LSTMs in time series settings, particularly for spatiotemporal hydrological modeling, for more accurate and robust streamflow predictions."],"url":"http://arxiv.org/abs/2404.07924v1"}
{"created":"2024-04-11 17:09:28","title":"LaVy: Vietnamese Multimodal Large Language Model","abstract":"Large Language Models (LLMs) and Multimodal Large language models (MLLMs) have taken the world by storm with impressive abilities in complex reasoning and linguistic comprehension. Meanwhile there are plethora of works related to Vietnamese Large Language Models, the lack of high-quality resources in multimodality limits the progress of Vietnamese MLLMs. In this paper, we pioneer in address this by introducing LaVy, a state-of-the-art Vietnamese MLLM, and we also introduce LaVy-Bench benchmark designated for evaluating MLLMs's understanding on Vietnamese visual language tasks. All code and model weights are public at https://github.com/baochi0212/LaVy","sentences":["Large Language Models (LLMs) and Multimodal Large language models (MLLMs) have taken the world by storm with impressive abilities in complex reasoning and linguistic comprehension.","Meanwhile there are plethora of works related to Vietnamese Large Language Models, the lack of high-quality resources in multimodality limits the progress of Vietnamese MLLMs.","In this paper, we pioneer in address this by introducing LaVy, a state-of-the-art Vietnamese MLLM, and we also introduce LaVy-Bench benchmark designated for evaluating MLLMs's understanding on Vietnamese visual language tasks.","All code and model weights are public at https://github.com/baochi0212/LaVy"],"url":"http://arxiv.org/abs/2404.07922v1"}
{"created":"2024-04-11 17:05:50","title":"AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs","abstract":"As large language models (LLMs) become increasingly prevalent and integrated into autonomous systems, ensuring their safety is imperative. Despite significant strides toward safety alignment, recent work GCG~\\citep{zou2023universal} proposes a discrete token optimization algorithm and selects the single suffix with the lowest loss to successfully jailbreak aligned LLMs. In this work, we first discuss the drawbacks of solely picking the suffix with the lowest loss during GCG optimization for jailbreaking and uncover the missed successful suffixes during the intermediate steps. Moreover, we utilize those successful suffixes as training data to learn a generative model, named AmpleGCG, which captures the distribution of adversarial suffixes given a harmful query and enables the rapid generation of hundreds of suffixes for any harmful queries in seconds. AmpleGCG achieves near 100\\% attack success rate (ASR) on two aligned LLMs (Llama-2-7B-chat and Vicuna-7B), surpassing two strongest attack baselines. More interestingly, AmpleGCG also transfers seamlessly to attack different models, including closed-source LLMs, achieving a 99\\% ASR on the latest GPT-3.5. To summarize, our work amplifies the impact of GCG by training a generative model of adversarial suffixes that is universal to any harmful queries and transferable from attacking open-source LLMs to closed-source LLMs. In addition, it can generate 200 adversarial suffixes for one harmful query in only 4 seconds, rendering it more challenging to defend.","sentences":["As large language models (LLMs) become increasingly prevalent and integrated into autonomous systems, ensuring their safety is imperative.","Despite significant strides toward safety alignment, recent work GCG~\\citep{zou2023universal} proposes a discrete token optimization algorithm and selects the single suffix with the lowest loss to successfully jailbreak aligned LLMs.","In this work, we first discuss the drawbacks of solely picking the suffix with the lowest loss during GCG optimization for jailbreaking and uncover the missed successful suffixes during the intermediate steps.","Moreover, we utilize those successful suffixes as training data to learn a generative model, named AmpleGCG, which captures the distribution of adversarial suffixes given a harmful query and enables the rapid generation of hundreds of suffixes for any harmful queries in seconds.","AmpleGCG achieves near 100\\% attack success rate (ASR) on two aligned LLMs (Llama-2-7B-chat and Vicuna-7B), surpassing two strongest attack baselines.","More interestingly, AmpleGCG also transfers seamlessly to attack different models, including closed-source LLMs, achieving a 99\\% ASR on the latest GPT-3.5.","To summarize, our work amplifies the impact of GCG by training a generative model of adversarial suffixes that is universal to any harmful queries and transferable from attacking open-source LLMs to closed-source LLMs.","In addition, it can generate 200 adversarial suffixes for one harmful query in only 4 seconds, rendering it more challenging to defend."],"url":"http://arxiv.org/abs/2404.07921v1"}
{"created":"2024-04-11 17:04:55","title":"Low-rank Adaptation for Spatio-Temporal Forecasting","abstract":"Spatio-temporal forecasting is crucial in real-world dynamic systems, predicting future changes using historical data from diverse locations. Existing methods often prioritize the development of intricate neural networks to capture the complex dependencies of the data, yet their accuracy fails to show sustained improvement. Besides, these methods also overlook node heterogeneity, hindering customized prediction modules from handling diverse regional nodes effectively. In this paper, our goal is not to propose a new model but to present a novel low-rank adaptation framework as an off-the-shelf plugin for existing spatial-temporal prediction models, termed ST-LoRA, which alleviates the aforementioned problems through node-level adjustments. Specifically, we first tailor a node adaptive low-rank layer comprising multiple trainable low-rank matrices. Additionally, we devise a multi-layer residual fusion stacking module, injecting the low-rank adapters into predictor modules of various models. Across six real-world traffic datasets and six different types of spatio-temporal prediction models, our approach minimally increases the parameters and training time of the original models by less than 4%, still achieving consistent and sustained performance enhancement.","sentences":["Spatio-temporal forecasting is crucial in real-world dynamic systems, predicting future changes using historical data from diverse locations.","Existing methods often prioritize the development of intricate neural networks to capture the complex dependencies of the data, yet their accuracy fails to show sustained improvement.","Besides, these methods also overlook node heterogeneity, hindering customized prediction modules from handling diverse regional nodes effectively.","In this paper, our goal is not to propose a new model but to present a novel low-rank adaptation framework as an off-the-shelf plugin for existing spatial-temporal prediction models, termed ST-LoRA, which alleviates the aforementioned problems through node-level adjustments.","Specifically, we first tailor a node adaptive low-rank layer comprising multiple trainable low-rank matrices.","Additionally, we devise a multi-layer residual fusion stacking module, injecting the low-rank adapters into predictor modules of various models.","Across six real-world traffic datasets and six different types of spatio-temporal prediction models, our approach minimally increases the parameters and training time of the original models by less than 4%, still achieving consistent and sustained performance enhancement."],"url":"http://arxiv.org/abs/2404.07919v1"}
{"created":"2024-04-11 16:59:54","title":"DesignQA: A Multimodal Benchmark for Evaluating Large Language Models' Understanding of Engineering Documentation","abstract":"This research introduces DesignQA, a novel benchmark aimed at evaluating the proficiency of multimodal large language models (MLLMs) in comprehending and applying engineering requirements in technical documentation. Developed with a focus on real-world engineering challenges, DesignQA uniquely combines multimodal data-including textual design requirements, CAD images, and engineering drawings-derived from the Formula SAE student competition. Different from many existing MLLM benchmarks, DesignQA contains document-grounded visual questions where the input image and input document come from different sources. The benchmark features automatic evaluation metrics and is divided into segments-Rule Comprehension, Rule Compliance, and Rule Extraction-based on tasks that engineers perform when designing according to requirements. We evaluate state-of-the-art models like GPT4 and LLaVA against the benchmark, and our study uncovers the existing gaps in MLLMs' abilities to interpret complex engineering documentation. Key findings suggest that while MLLMs demonstrate potential in navigating technical documents, substantial limitations exist, particularly in accurately extracting and applying detailed requirements to engineering designs. This benchmark sets a foundation for future advancements in AI-supported engineering design processes. DesignQA is publicly available at: https://github.com/anniedoris/design_qa/.","sentences":["This research introduces DesignQA, a novel benchmark aimed at evaluating the proficiency of multimodal large language models (MLLMs) in comprehending and applying engineering requirements in technical documentation.","Developed with a focus on real-world engineering challenges, DesignQA uniquely combines multimodal data-including textual design requirements, CAD images, and engineering drawings-derived from the Formula SAE student competition.","Different from many existing MLLM benchmarks, DesignQA contains document-grounded visual questions where the input image and input document come from different sources.","The benchmark features automatic evaluation metrics and is divided into segments-Rule Comprehension, Rule Compliance, and Rule Extraction-based on tasks that engineers perform when designing according to requirements.","We evaluate state-of-the-art models like GPT4 and LLaVA against the benchmark, and our study uncovers the existing gaps in MLLMs' abilities to interpret complex engineering documentation.","Key findings suggest that while MLLMs demonstrate potential in navigating technical documents, substantial limitations exist, particularly in accurately extracting and applying detailed requirements to engineering designs.","This benchmark sets a foundation for future advancements in AI-supported engineering design processes.","DesignQA is publicly available at: https://github.com/anniedoris/design_qa/."],"url":"http://arxiv.org/abs/2404.07917v1"}
{"created":"2024-04-11 16:59:31","title":"A Novel Optimization-Based Collision Avoidance For Autonomous On-Orbit Assembly","abstract":"The collision avoidance constraints are prominent as non-convex, non-differentiable, and challenging when defined in optimization-based motion planning problems. To overcome these issues, this paper presents a novel non-conservative collision avoidance technique using the notion of convex optimization to establish the distance between robotic spacecraft and space structures for autonomous on-orbit assembly operations. The proposed technique defines each ellipsoidal- and polyhedral-shaped object as the union of convex compact sets, each represented non-conservatively by a real-valued convex function. Then, the functions are introduced as a set of constraints to a convex optimization problem to produce a new set of differentiable constraints resulting from the optimality conditions. These new constraints are later fed into an optimal control problem to enforce collision avoidance where the motion planning for the autonomous on-orbit assembly takes place. Numerical experiments for two assembly scenarios in tight environments are presented to demonstrate the capability and effectiveness of the proposed technique. The results show that this framework leads to optimal non-conservative trajectories for robotic spacecraft in tight environments. Although developed for autonomous on-orbit assembly, this technique could be used for any generic motion planning problem where collision avoidance is crucial.","sentences":["The collision avoidance constraints are prominent as non-convex, non-differentiable, and challenging when defined in optimization-based motion planning problems.","To overcome these issues, this paper presents a novel non-conservative collision avoidance technique using the notion of convex optimization to establish the distance between robotic spacecraft and space structures for autonomous on-orbit assembly operations.","The proposed technique defines each ellipsoidal- and polyhedral-shaped object as the union of convex compact sets, each represented non-conservatively by a real-valued convex function.","Then, the functions are introduced as a set of constraints to a convex optimization problem to produce a new set of differentiable constraints resulting from the optimality conditions.","These new constraints are later fed into an optimal control problem to enforce collision avoidance where the motion planning for the autonomous on-orbit assembly takes place.","Numerical experiments for two assembly scenarios in tight environments are presented to demonstrate the capability and effectiveness of the proposed technique.","The results show that this framework leads to optimal non-conservative trajectories for robotic spacecraft in tight environments.","Although developed for autonomous on-orbit assembly, this technique could be used for any generic motion planning problem where collision avoidance is crucial."],"url":"http://arxiv.org/abs/2404.07916v1"}
{"created":"2024-04-11 16:43:03","title":"HGRN2: Gated Linear RNNs with State Expansion","abstract":"Hierarchically gated linear RNN (HGRN,Qin et al. 2023) has demonstrated competitive training speed and performance in language modeling, while offering efficient inference. However, the recurrent state size of HGRN remains relatively small, which limits its expressiveness.To address this issue, inspired by linear attention, we introduce a simple outer-product-based state expansion mechanism so that the recurrent state size can be significantly enlarged without introducing any additional parameters. The linear attention form also allows for hardware-efficient training.Our extensive experiments verify the advantage of HGRN2 over HGRN1 in language modeling, image classification, and Long Range Arena.Our largest 3B HGRN2 model slightly outperforms Mamba and LLaMa Architecture Transformer for language modeling in a controlled experiment setting; and performs competitively with many open-source 3B models in downstream evaluation while using much fewer total training tokens.","sentences":["Hierarchically gated linear RNN (HGRN,Qin et al. 2023) has demonstrated competitive training speed and performance in language modeling, while offering efficient inference.","However, the recurrent state size of HGRN remains relatively small, which limits its expressiveness.","To address this issue, inspired by linear attention, we introduce a simple outer-product-based state expansion mechanism so that the recurrent state size can be significantly enlarged without introducing any additional parameters.","The linear attention form also allows for hardware-efficient training.","Our extensive experiments verify the advantage of HGRN2 over HGRN1 in language modeling, image classification, and Long Range Arena.","Our largest 3B HGRN2 model slightly outperforms Mamba and LLaMa Architecture Transformer for language modeling in a controlled experiment setting; and performs competitively with many open-source 3B models in downstream evaluation while using much fewer total training tokens."],"url":"http://arxiv.org/abs/2404.07904v1"}
{"created":"2024-04-11 16:41:08","title":"Q-ITAGS: Quality-Optimized Spatio-Temporal Heterogeneous Task Allocation with a Time Budget","abstract":"Complex multi-objective missions require the coordination of heterogeneous robots at multiple inter-connected levels, such as coalition formation, scheduling, and motion planning. The associated challenges are exacerbated when solutions to these interconnected problems need to both maximize task performance and respect practical constraints on time and resources. In this work, we formulate a new class of spatio-temporal heterogeneous task allocation problems that consider these complexities. We contribute a novel framework, named Quality-Optimized Incremental Task Allocation Graph Search (Q-ITAGS), to solve such problems. Q-ITAGS builds upon our prior work in trait-based coordination and offers a flexible interleaved framework that i) explicitly models and optimizes the effect of collective capabilities on task performance via learnable trait-quality maps, and ii) respects both resource constraints and spatio-temporal constraints, including a user-specified time budget (i.e., maximum makespan). In addition to algorithmic contributions, we derive theoretical suboptimality bounds in terms of task performance that varies as a function of a single hyperparameter. Our detailed experiments involving a simulated emergency response task and a real-world video game dataset reveal that i) Q-ITAGS results in superior team performance compared to a state-of-the-art method, while also respecting complex spatio-temporal and resource constraints, ii) Q-ITAGS efficiently learns trait-quality maps to enable effective trade-off between task performance and resource constraints, and iii) Q-ITAGS' suboptimality bounds consistently hold in practice.","sentences":["Complex multi-objective missions require the coordination of heterogeneous robots at multiple inter-connected levels, such as coalition formation, scheduling, and motion planning.","The associated challenges are exacerbated when solutions to these interconnected problems need to both maximize task performance and respect practical constraints on time and resources.","In this work, we formulate a new class of spatio-temporal heterogeneous task allocation problems that consider these complexities.","We contribute a novel framework, named Quality-Optimized Incremental Task Allocation Graph Search (Q-ITAGS), to solve such problems.","Q-ITAGS builds upon our prior work in trait-based coordination and offers a flexible interleaved framework that i) explicitly models and optimizes the effect of collective capabilities on task performance via learnable trait-quality maps, and ii) respects both resource constraints and spatio-temporal constraints, including a user-specified time budget (i.e., maximum makespan).","In addition to algorithmic contributions, we derive theoretical suboptimality bounds in terms of task performance that varies as a function of a single hyperparameter.","Our detailed experiments involving a simulated emergency response task and a real-world video game dataset reveal that i) Q-ITAGS results in superior team performance compared to a state-of-the-art method, while also respecting complex spatio-temporal and resource constraints, ii) Q-ITAGS efficiently learns trait-quality maps to enable effective trade-off between task performance and resource constraints, and iii) Q-ITAGS' suboptimality bounds consistently hold in practice."],"url":"http://arxiv.org/abs/2404.07902v1"}
{"created":"2024-04-11 16:40:24","title":"Snake Story: Exploring Game Mechanics for Mixed-Initiative Co-creative Storytelling Games","abstract":"Mixed-initiative co-creative storytelling games have existed for some time as a way to merge storytelling with play. However, modern mixed-initiative co-creative storytelling games predominantly prioritize story creation over gameplay mechanics, which might not resonate with all players. As such, there is untapped potential for creating mixed-initiative games with more complex mechanics in which players can engage with both co-creation and gameplay goals. To explore the potential of more prominent gameplay in mixed-initiative co-creative storytelling games, we created Snake Story, a variation of the classic Snake game featuring a human-AI co-writing element. To explore how players interact with the mixed-initiative game, we conducted a qualitative playtest with 11 participants. Analysis of both think-aloud and interview data revealed that players' strategies and experiences were affected by their perception of Snake Story as either a collaborative tool, a traditional game, or a combination of both. Based on these findings, we present design considerations for future development in mixed-initiative co-creative gaming.","sentences":["Mixed-initiative co-creative storytelling games have existed for some time as a way to merge storytelling with play.","However, modern mixed-initiative co-creative storytelling games predominantly prioritize story creation over gameplay mechanics, which might not resonate with all players.","As such, there is untapped potential for creating mixed-initiative games with more complex mechanics in which players can engage with both co-creation and gameplay goals.","To explore the potential of more prominent gameplay in mixed-initiative co-creative storytelling games, we created Snake Story, a variation of the classic Snake game featuring a human-AI co-writing element.","To explore how players interact with the mixed-initiative game, we conducted a qualitative playtest with 11 participants.","Analysis of both think-aloud and interview data revealed that players' strategies and experiences were affected by their perception of Snake Story as either a collaborative tool, a traditional game, or a combination of both.","Based on these findings, we present design considerations for future development in mixed-initiative co-creative gaming."],"url":"http://arxiv.org/abs/2404.07901v1"}
{"created":"2024-04-11 16:39:00","title":"High-Dimension Human Value Representation in Large Language Models","abstract":"The widespread application of Large Language Models (LLMs) across various tasks and fields has necessitated the alignment of these models with human values and preferences. Given various approaches of human value alignment, ranging from Reinforcement Learning with Human Feedback (RLHF), to constitutional learning, etc. there is an urgent need to understand the scope and nature of human values injected into these models before their release. There is also a need for model alignment without a costly large scale human annotation effort. We propose UniVaR, a high-dimensional representation of human value distributions in LLMs, orthogonal to model architecture and training data. Trained from the value-relevant output of eight multilingual LLMs and tested on the output from four multilingual LLMs, namely LlaMA2, ChatGPT, JAIS and Yi, we show that UniVaR is a powerful tool to compare the distribution of human values embedded in different LLMs with different langauge sources. Through UniVaR, we explore how different LLMs prioritize various values in different languages and cultures, shedding light on the complex interplay between human values and language modeling.","sentences":["The widespread application of Large Language Models (LLMs) across various tasks and fields has necessitated the alignment of these models with human values and preferences.","Given various approaches of human value alignment, ranging from Reinforcement Learning with Human Feedback (RLHF), to constitutional learning, etc. there is an urgent need to understand the scope and nature of human values injected into these models before their release.","There is also a need for model alignment without a costly large scale human annotation effort.","We propose UniVaR, a high-dimensional representation of human value distributions in LLMs, orthogonal to model architecture and training data.","Trained from the value-relevant output of eight multilingual LLMs and tested on the output from four multilingual LLMs, namely LlaMA2, ChatGPT, JAIS and Yi, we show that UniVaR is a powerful tool to compare the distribution of human values embedded in different LLMs with different langauge sources.","Through UniVaR, we explore how different LLMs prioritize various values in different languages and cultures, shedding light on the complex interplay between human values and language modeling."],"url":"http://arxiv.org/abs/2404.07900v1"}
{"created":"2024-04-11 16:37:01","title":"Anomaly Detection in Power Grids via Context-Agnostic Learning","abstract":"An important tool grid operators use to safeguard against failures, whether naturally occurring or malicious, involves detecting anomalies in the power system SCADA data. In this paper, we aim to solve a real-time anomaly detection problem. Given time-series measurement values coming from a fixed set of sensors on the grid, can we identify anomalies in the network topology or measurement data? Existing methods, primarily optimization-based, mostly use only a single snapshot of the measurement values and do not scale well with the network size. Recent data-driven ML techniques have shown promise by using a combination of current and historical data for anomaly detection but generally do not consider physical attributes like the impact of topology or load/generation changes on sensor measurements and thus cannot accommodate regular context-variability in the historical data. To address this gap, we propose a novel context-aware anomaly detection algorithm, GridCAL, that considers the effect of regular topology and load/generation changes. This algorithm converts the real-time power flow measurements to context-agnostic values, which allows us to analyze measurement coming from different grid contexts in an aggregate fashion, enabling us to derive a unified statistical model that becomes the basis of anomaly detection. Through numerical simulations on networks up to 2383 nodes, we show that our approach is accurate, outperforming state-of-the-art approaches, and is computationally efficient.","sentences":["An important tool grid operators use to safeguard against failures, whether naturally occurring or malicious, involves detecting anomalies in the power system SCADA data.","In this paper, we aim to solve a real-time anomaly detection problem.","Given time-series measurement values coming from a fixed set of sensors on the grid, can we identify anomalies in the network topology or measurement data?","Existing methods, primarily optimization-based, mostly use only a single snapshot of the measurement values and do not scale well with the network size.","Recent data-driven ML techniques have shown promise by using a combination of current and historical data for anomaly detection but generally do not consider physical attributes like the impact of topology or load/generation changes on sensor measurements and thus cannot accommodate regular context-variability in the historical data.","To address this gap, we propose a novel context-aware anomaly detection algorithm, GridCAL, that considers the effect of regular topology and load/generation changes.","This algorithm converts the real-time power flow measurements to context-agnostic values, which allows us to analyze measurement coming from different grid contexts in an aggregate fashion, enabling us to derive a unified statistical model that becomes the basis of anomaly detection.","Through numerical simulations on networks up to 2383 nodes, we show that our approach is accurate, outperforming state-of-the-art approaches, and is computationally efficient."],"url":"http://arxiv.org/abs/2404.07898v1"}
{"created":"2024-04-11 16:31:35","title":"Auditing health-related recommendations in social media: A Case Study of Abortion on YouTube","abstract":"Recommendation algorithms (RS) used by social media, like YouTube, significantly shape our information consumption across various domains, especially in healthcare. Hence, algorithmic auditing becomes crucial to uncover their potential bias and misinformation, particularly in the context of controversial topics like abortion. We introduce a simple yet effective sock puppet auditing approach to investigate how YouTube recommends abortion-related videos to individuals with different backgrounds. Our framework allows for efficient auditing of RS, regardless of the complexity of the underlying algorithms","sentences":["Recommendation algorithms (RS) used by social media, like YouTube, significantly shape our information consumption across various domains, especially in healthcare.","Hence, algorithmic auditing becomes crucial to uncover their potential bias and misinformation, particularly in the context of controversial topics like abortion.","We introduce a simple yet effective sock puppet auditing approach to investigate how YouTube recommends abortion-related videos to individuals with different backgrounds.","Our framework allows for efficient auditing of RS, regardless of the complexity of the underlying algorithms"],"url":"http://arxiv.org/abs/2404.07896v1"}
{"created":"2024-04-11 16:24:49","title":"A Measurement of Genuine Tor Traces for Realistic Website Fingerprinting","abstract":"Website fingerprinting (WF) is a dangerous attack on web privacy because it enables an adversary to predict the website a user is visiting, despite the use of encryption, VPNs, or anonymizing networks such as Tor. Previous WF work almost exclusively uses synthetic datasets to evaluate the performance and estimate the feasibility of WF attacks despite evidence that synthetic data misrepresents the real world. In this paper we present GTT23, the first WF dataset of genuine Tor traces, which we obtain through a large-scale measurement of the Tor network. GTT23 represents real Tor user behavior better than any existing WF dataset, is larger than any existing WF dataset by at least an order of magnitude, and will help ground the future study of realistic WF attacks and defenses. In a detailed evaluation, we survey 25 WF datasets published over the last 15 years and compare their characteristics to those of GTT23. We discover common deficiencies of synthetic datasets that make them inferior to GTT23 for drawing meaningful conclusions about the effectiveness of WF attacks directed at real Tor users. We have made GTT23 available to promote reproducible research and to help inspire new directions for future work.","sentences":["Website fingerprinting (WF) is a dangerous attack on web privacy because it enables an adversary to predict the website a user is visiting, despite the use of encryption, VPNs, or anonymizing networks such as Tor.","Previous WF work almost exclusively uses synthetic datasets to evaluate the performance and estimate the feasibility of WF attacks despite evidence that synthetic data misrepresents the real world.","In this paper we present GTT23, the first WF dataset of genuine Tor traces, which we obtain through a large-scale measurement of the Tor network.","GTT23 represents real Tor user behavior better than any existing WF dataset, is larger than any existing WF dataset by at least an order of magnitude, and will help ground the future study of realistic WF attacks and defenses.","In a detailed evaluation, we survey 25 WF datasets published over the last 15 years and compare their characteristics to those of GTT23.","We discover common deficiencies of synthetic datasets that make them inferior to GTT23 for drawing meaningful conclusions about the effectiveness of WF attacks directed at real Tor users.","We have made GTT23 available to promote reproducible research and to help inspire new directions for future work."],"url":"http://arxiv.org/abs/2404.07892v1"}
{"created":"2024-04-11 16:18:37","title":"On the Performance of Jerk-Constrained Time-Optimal Trajectory Planning for Industrial Manipulators","abstract":"Jerk-constrained trajectories offer a wide range of advantages that collectively improve the performance of robotic systems, including increased energy efficiency, durability, and safety. In this paper, we present a novel approach to jerk-constrained time-optimal trajectory planning (TOTP), which follows a specified path while satisfying up to third-order constraints to ensure safety and smooth motion. One significant challenge in jerk-constrained TOTP is a non-convex formulation arising from the inclusion of third-order constraints. Approximating inequality constraints can be particularly challenging because the resulting solutions may violate the actual constraints. We address this problem by leveraging convexity within the proposed formulation to form conservative inequality constraints. We then obtain the desired trajectories by solving an $\\boldsymbol n$-dimensional Sequential Linear Program (SLP) iteratively until convergence. Lastly, we evaluate in a real robot the performance of trajectories generated with and without jerk limits in terms of peak power, torque efficiency, and tracking capability.","sentences":["Jerk-constrained trajectories offer a wide range of advantages that collectively improve the performance of robotic systems, including increased energy efficiency, durability, and safety.","In this paper, we present a novel approach to jerk-constrained time-optimal trajectory planning (TOTP), which follows a specified path while satisfying up to third-order constraints to ensure safety and smooth motion.","One significant challenge in jerk-constrained TOTP is a non-convex formulation arising from the inclusion of third-order constraints.","Approximating inequality constraints can be particularly challenging because the resulting solutions may violate the actual constraints.","We address this problem by leveraging convexity within the proposed formulation to form conservative inequality constraints.","We then obtain the desired trajectories by solving an $\\boldsymbol n$-dimensional Sequential Linear Program (SLP) iteratively until convergence.","Lastly, we evaluate in a real robot the performance of trajectories generated with and without jerk limits in terms of peak power, torque efficiency, and tracking capability."],"url":"http://arxiv.org/abs/2404.07889v1"}
{"created":"2024-04-11 16:17:36","title":"Context-aware Video Anomaly Detection in Long-Term Datasets","abstract":"Video anomaly detection research is generally evaluated on short, isolated benchmark videos only a few minutes long. However, in real-world environments, security cameras observe the same scene for months or years at a time, and the notion of anomalous behavior critically depends on context, such as the time of day, day of week, or schedule of events. Here, we propose a context-aware video anomaly detection algorithm, Trinity, specifically targeted to these scenarios. Trinity is especially well-suited to crowded scenes in which individuals cannot be easily tracked, and anomalies are due to speed, direction, or absence of group motion. Trinity is a contrastive learning framework that aims to learn alignments between context, appearance, and motion, and uses alignment quality to classify videos as normal or anomalous. We evaluate our algorithm on both conventional benchmarks and a public webcam-based dataset we collected that spans more than three months of activity.","sentences":["Video anomaly detection research is generally evaluated on short, isolated benchmark videos only a few minutes long.","However, in real-world environments, security cameras observe the same scene for months or years at a time, and the notion of anomalous behavior critically depends on context, such as the time of day, day of week, or schedule of events.","Here, we propose a context-aware video anomaly detection algorithm, Trinity, specifically targeted to these scenarios.","Trinity is especially well-suited to crowded scenes in which individuals cannot be easily tracked, and anomalies are due to speed, direction, or absence of group motion.","Trinity is a contrastive learning framework that aims to learn alignments between context, appearance, and motion, and uses alignment quality to classify videos as normal or anomalous.","We evaluate our algorithm on both conventional benchmarks and a public webcam-based dataset we collected that spans more than three months of activity."],"url":"http://arxiv.org/abs/2404.07887v1"}
{"created":"2024-04-11 16:14:23","title":"Apprentice Tutor Builder: A Platform For Users to Create and Personalize Intelligent Tutors","abstract":"Intelligent tutoring systems (ITS) are effective for improving students' learning outcomes. However, their development is often complex, time-consuming, and requires specialized programming and tutor design knowledge, thus hindering their widespread application and personalization. We present the Apprentice Tutor Builder (ATB) , a platform that simplifies tutor creation and personalization. Instructors can utilize ATB's drag-and-drop tool to build tutor interfaces. Instructors can then interactively train the tutors' underlying AI agent to produce expert models that can solve problems. Training is achieved via using multiple interaction modalities including demonstrations, feedback, and user labels. We conducted a user study with 14 instructors to evaluate the effectiveness of ATB's design with end users. We found that users enjoyed the flexibility of the interface builder and ease and speed of agent teaching, but often desired additional time-saving features. With these insights, we identified a set of design recommendations for our platform and others that utilize interactive AI agents for tutor creation and customization.","sentences":["Intelligent tutoring systems (ITS) are effective for improving students' learning outcomes.","However, their development is often complex, time-consuming, and requires specialized programming and tutor design knowledge, thus hindering their widespread application and personalization.","We present the Apprentice Tutor Builder (ATB) , a platform that simplifies tutor creation and personalization.","Instructors can utilize ATB's drag-and-drop tool to build tutor interfaces.","Instructors can then interactively train the tutors' underlying AI agent to produce expert models that can solve problems.","Training is achieved via using multiple interaction modalities including demonstrations, feedback, and user labels.","We conducted a user study with 14 instructors to evaluate the effectiveness of ATB's design with end users.","We found that users enjoyed the flexibility of the interface builder and ease and speed of agent teaching, but often desired additional time-saving features.","With these insights, we identified a set of design recommendations for our platform and others that utilize interactive AI agents for tutor creation and customization."],"url":"http://arxiv.org/abs/2404.07883v1"}
{"created":"2024-04-11 16:12:01","title":"On Reducing the Execution Latency of Superconducting Quantum Processors via Quantum Program Scheduling","abstract":"Quantum computing has gained considerable attention, especially after the arrival of the Noisy Intermediate-Scale Quantum (NISQ) era. Quantum processors and cloud services have been made world-wide increasingly available. Unfortunately, programs on existing quantum processors are often executed in series, and the workload could be heavy to the processor. Typically, one has to wait for hours or even longer to obtain the result of a single quantum program on public quantum cloud due to long queue time. In fact, as the scale grows, the qubit utilization rate of the serial execution mode will further diminish, causing the waste of quantum resources. In this paper, to our best knowledge for the first time, the Quantum Program Scheduling Problem (QPSP) is formulated and introduced to improve the utility efficiency of quantum resources. Specifically, a quantum program scheduling method concerning the circuit width, number of measurement shots, and submission time of quantum programs is proposed to reduce the execution latency. We conduct extensive experiments on a simulated Qiskit noise model, as well as on the Xiaohong (from QuantumCTek) superconducting quantum processor. Numerical results show the effectiveness in both QPU time and turnaround time.","sentences":["Quantum computing has gained considerable attention, especially after the arrival of the Noisy Intermediate-Scale Quantum (NISQ) era.","Quantum processors and cloud services have been made world-wide increasingly available.","Unfortunately, programs on existing quantum processors are often executed in series, and the workload could be heavy to the processor.","Typically, one has to wait for hours or even longer to obtain the result of a single quantum program on public quantum cloud due to long queue time.","In fact, as the scale grows, the qubit utilization rate of the serial execution mode will further diminish, causing the waste of quantum resources.","In this paper, to our best knowledge for the first time, the Quantum Program Scheduling Problem (QPSP) is formulated and introduced to improve the utility efficiency of quantum resources.","Specifically, a quantum program scheduling method concerning the circuit width, number of measurement shots, and submission time of quantum programs is proposed to reduce the execution latency.","We conduct extensive experiments on a simulated Qiskit noise model, as well as on the Xiaohong (from QuantumCTek) superconducting quantum processor.","Numerical results show the effectiveness in both QPU time and turnaround time."],"url":"http://arxiv.org/abs/2404.07882v1"}
{"created":"2024-04-11 16:10:52","title":"Multi-Robot Target Tracking with Sensing and Communication Danger Zones","abstract":"Multi-robot target tracking finds extensive applications in different scenarios, such as environmental surveillance and wildfire management, which require the robustness of the practical deployment of multi-robot systems in uncertain and dangerous environments. Traditional approaches often focus on the performance of tracking accuracy with no modeling and assumption of the environments, neglecting potential environmental hazards which result in system failures in real-world deployments. To address this challenge, we investigate multi-robot target tracking in the adversarial environment considering sensing and communication attacks with uncertainty. We design specific strategies to avoid different danger zones and proposed a multi-agent tracking framework under the perilous environment. We approximate the probabilistic constraints and formulate practical optimization strategies to address computational challenges efficiently. We evaluate the performance of our proposed methods in simulations to demonstrate the ability of robots to adjust their risk-aware behaviors under different levels of environmental uncertainty and risk confidence. The proposed method is further validated via real-world robot experiments where a team of drones successfully track dynamic ground robots while being risk-aware of the sensing and/or communication danger zones.","sentences":["Multi-robot target tracking finds extensive applications in different scenarios, such as environmental surveillance and wildfire management, which require the robustness of the practical deployment of multi-robot systems in uncertain and dangerous environments.","Traditional approaches often focus on the performance of tracking accuracy with no modeling and assumption of the environments, neglecting potential environmental hazards which result in system failures in real-world deployments.","To address this challenge, we investigate multi-robot target tracking in the adversarial environment considering sensing and communication attacks with uncertainty.","We design specific strategies to avoid different danger zones and proposed a multi-agent tracking framework under the perilous environment.","We approximate the probabilistic constraints and formulate practical optimization strategies to address computational challenges efficiently.","We evaluate the performance of our proposed methods in simulations to demonstrate the ability of robots to adjust their risk-aware behaviors under different levels of environmental uncertainty and risk confidence.","The proposed method is further validated via real-world robot experiments where a team of drones successfully track dynamic ground robots while being risk-aware of the sensing and/or communication danger zones."],"url":"http://arxiv.org/abs/2404.07880v1"}
{"created":"2024-04-11 16:10:52","title":"Diagram Analysis of Iterative Algorithms","abstract":"We study a general class of first-order iterative algorithms which includes power iteration, belief propagation and Approximate Message Passing (AMP), and many forms of gradient descent. When the input is a random matrix with i.i.d. entries, we present a new way to analyze these algorithms using combinatorial diagrams. Each diagram is a small graph, and the operations of the algorithm correspond to simple combinatorial operations on these graphs.   We prove a fundamental property of the diagrams: asymptotically, we can discard all of the diagrams except for the trees. The mechanics of first-order algorithms simplify dramatically as the algorithmic operations have particularly simple and interpretable effects on the trees. We further show that the tree-shaped diagrams are essentially a basis of asymptotically independent Gaussian vectors.   The tree approximation mirrors the assumption of the cavity method, a 40-year-old non-rigorous technique in statistical physics which has served as one of the most fundamental techniques in the field. We demonstrate the connection with the replica symmetric cavity method by \"implementing\" heuristic physics derivations into rigorous proofs. We rigorously establish that belief propagation is asymptotically equal to its associated AMP algorithm and we give a new simple proof of the state evolution formula for AMP.   These results apply when the iterative algorithm runs for constantly many iterations. We then push the diagram analysis to a number of iterations that scales with the dimension $n$ of the input matrix. We prove that for debiased power iteration, the tree diagram representation accurately describes the dynamic all the way up to $n^{\\Omega(1)}$ iterations. We conjecture that this can be extended up to $n^{1/2}$ iterations but no further. Our proofs use straightforward combinatorial arguments akin to the trace method from random matrix theory.","sentences":["We study a general class of first-order iterative algorithms which includes power iteration, belief propagation and Approximate Message Passing (AMP), and many forms of gradient descent.","When the input is a random matrix with i.i.d. entries, we present a new way to analyze these algorithms using combinatorial diagrams.","Each diagram is a small graph, and the operations of the algorithm correspond to simple combinatorial operations on these graphs.   ","We prove a fundamental property of the diagrams: asymptotically, we can discard all of the diagrams except for the trees.","The mechanics of first-order algorithms simplify dramatically as the algorithmic operations have particularly simple and interpretable effects on the trees.","We further show that the tree-shaped diagrams are essentially a basis of asymptotically independent Gaussian vectors.   ","The tree approximation mirrors the assumption of the cavity method, a 40-year-old non-rigorous technique in statistical physics which has served as one of the most fundamental techniques in the field.","We demonstrate the connection with the replica symmetric cavity method by \"implementing\" heuristic physics derivations into rigorous proofs.","We rigorously establish that belief propagation is asymptotically equal to its associated AMP algorithm and we give a new simple proof of the state evolution formula for AMP.   ","These results apply when the iterative algorithm runs for constantly many iterations.","We then push the diagram analysis to a number of iterations that scales with the dimension $n$ of the input matrix.","We prove that for debiased power iteration, the tree diagram representation accurately describes the dynamic all the way up to $n^{\\Omega(1)}$ iterations.","We conjecture that this can be extended up to $n^{1/2}$ iterations but no further.","Our proofs use straightforward combinatorial arguments akin to the trace method from random matrix theory."],"url":"http://arxiv.org/abs/2404.07881v1"}
{"created":"2024-04-11 16:10:44","title":"Analyzing Toxicity in Deep Conversations: A Reddit Case Study","abstract":"Online social media has become increasingly popular in recent years due to its ease of access and ability to connect with others. One of social media's main draws is its anonymity, allowing users to share their thoughts and opinions without fear of judgment or retribution. This anonymity has also made social media prone to harmful content, which requires moderation to ensure responsible and productive use. Several methods using artificial intelligence have been employed to detect harmful content. However, conversation and contextual analysis of hate speech are still understudied. Most promising works only analyze a single text at a time rather than the conversation supporting it. In this work, we employ a tree-based approach to understand how users behave concerning toxicity in public conversation settings. To this end, we collect both the posts and the comment sections of the top 100 posts from 8 Reddit communities that allow profanity, totaling over 1 million responses. We find that toxic comments increase the likelihood of subsequent toxic comments being produced in online conversations. Our analysis also shows that immediate context plays a vital role in shaping a response rather than the original post. We also study the effect of consensual profanity and observe overlapping similarities with non-consensual profanity in terms of user behavior and patterns.","sentences":["Online social media has become increasingly popular in recent years due to its ease of access and ability to connect with others.","One of social media's main draws is its anonymity, allowing users to share their thoughts and opinions without fear of judgment or retribution.","This anonymity has also made social media prone to harmful content, which requires moderation to ensure responsible and productive use.","Several methods using artificial intelligence have been employed to detect harmful content.","However, conversation and contextual analysis of hate speech are still understudied.","Most promising works only analyze a single text at a time rather than the conversation supporting it.","In this work, we employ a tree-based approach to understand how users behave concerning toxicity in public conversation settings.","To this end, we collect both the posts and the comment sections of the top 100 posts from 8 Reddit communities that allow profanity, totaling over 1 million responses.","We find that toxic comments increase the likelihood of subsequent toxic comments being produced in online conversations.","Our analysis also shows that immediate context plays a vital role in shaping a response rather than the original post.","We also study the effect of consensual profanity and observe overlapping similarities with non-consensual profanity in terms of user behavior and patterns."],"url":"http://arxiv.org/abs/2404.07879v1"}
{"created":"2024-04-11 16:10:16","title":"LeapFrog: The Rowhammer Instruction Skip Attack","abstract":"Since its inception, Rowhammer exploits have rapidly evolved into increasingly sophisticated threats not only compromising data integrity but also the control flow integrity of victim processes. Nevertheless, it remains a challenge for an attacker to identify vulnerable targets (i.e., Rowhammer gadgets), understand the outcome of the attempted fault, and formulate an attack that yields useful results.   In this paper, we present a new type of Rowhammer gadget, called a LeapFrog gadget, which, when present in the victim code, allows an adversary to subvert code execution to bypass a critical piece of code (e.g., authentication check logic, encryption rounds, padding in security protocols). The Leapfrog gadget manifests when the victim code stores the Program Counter (PC) value in the user or kernel stack (e.g., a return address during a function call) which, when tampered with, re-positions the return address to a location that bypasses a security-critical code pattern.   This research also presents a systematic process to identify Leapfrog gadgets. This methodology enables the automated detection of susceptible targets and the determination of optimal attack parameters. We first showcase this new attack vector through a practical demonstration on a TLS handshake client/server scenario, successfully inducing an instruction skip in a client application. We then demonstrate the attack on real-world code found in the wild, implementing an attack on OpenSSL.   Our findings extend the impact of Rowhammer attacks on control flow and contribute to the development of more robust defenses against these increasingly sophisticated threats.","sentences":["Since its inception, Rowhammer exploits have rapidly evolved into increasingly sophisticated threats not only compromising data integrity but also the control flow integrity of victim processes.","Nevertheless, it remains a challenge for an attacker to identify vulnerable targets (i.e., Rowhammer gadgets), understand the outcome of the attempted fault, and formulate an attack that yields useful results.   ","In this paper, we present a new type of Rowhammer gadget, called a LeapFrog gadget, which, when present in the victim code, allows an adversary to subvert code execution to bypass a critical piece of code (e.g., authentication check logic, encryption rounds, padding in security protocols).","The Leapfrog gadget manifests when the victim code stores the Program Counter (PC) value in the user or kernel stack (e.g., a return address during a function call) which, when tampered with, re-positions the return address to a location that bypasses a security-critical code pattern.   ","This research also presents a systematic process to identify Leapfrog gadgets.","This methodology enables the automated detection of susceptible targets and the determination of optimal attack parameters.","We first showcase this new attack vector through a practical demonstration on a TLS handshake client/server scenario, successfully inducing an instruction skip in a client application.","We then demonstrate the attack on real-world code found in the wild, implementing an attack on OpenSSL.   ","Our findings extend the impact of Rowhammer attacks on control flow and contribute to the development of more robust defenses against these increasingly sophisticated threats."],"url":"http://arxiv.org/abs/2404.07878v1"}
{"created":"2024-04-11 16:07:11","title":"Video Compression Beyond VVC: Quantitative Analysis of Intra Coding Tools in Enhanced Compression Model (ECM)","abstract":"A quantitative analysis of post-VVC luma and chroma intra tools is presented, focusing on their statistical behaviors, in terms of block selection rate under different conditions. The aim is to provide insights to the standardization community, offering a clearer understanding of interactions between tools and assisting in the design of an optimal combination of these novel tools when the JVET enters the standardization phase. Specifically, this paper examines the selection rate of intra tools as function of 1) the version of the ECM, 2) video resolution, and 3) video bitrate. Additionally, tests have been conducted on sequences beyond the JVET CTC database. The statistics show several trends and interactions, with various strength, between coding tools of both luma and chroma.","sentences":["A quantitative analysis of post-VVC luma and chroma intra tools is presented, focusing on their statistical behaviors, in terms of block selection rate under different conditions.","The aim is to provide insights to the standardization community, offering a clearer understanding of interactions between tools and assisting in the design of an optimal combination of these novel tools when the JVET enters the standardization phase.","Specifically, this paper examines the selection rate of intra tools as function of 1) the version of the ECM, 2) video resolution, and 3) video bitrate.","Additionally, tests have been conducted on sequences beyond the JVET CTC database.","The statistics show several trends and interactions, with various strength, between coding tools of both luma and chroma."],"url":"http://arxiv.org/abs/2404.07872v1"}
{"created":"2024-04-11 16:01:00","title":"The Power of Properties: Uncovering the Influential Factors in Emotion Classification","abstract":"Facial expression-based human emotion recognition is a critical research area in psychology and medicine. State-of-the-art classification performance is only reached by end-to-end trained neural networks. Nevertheless, such black-box models lack transparency in their decision-making processes, prompting efforts to ascertain the rules that underlie classifiers' decisions. Analyzing single inputs alone fails to expose systematic learned biases. These biases can be characterized as facial properties summarizing abstract information like age or medical conditions. Therefore, understanding a model's prediction behavior requires an analysis rooted in causality along such selected properties. We demonstrate that up to 91.25% of classifier output behavior changes are statistically significant concerning basic properties. Among those are age, gender, and facial symmetry. Furthermore, the medical usage of surface electromyography significantly influences emotion prediction. We introduce a workflow to evaluate explicit properties and their impact. These insights might help medical professionals select and apply classifiers regarding their specialized data and properties.","sentences":["Facial expression-based human emotion recognition is a critical research area in psychology and medicine.","State-of-the-art classification performance is only reached by end-to-end trained neural networks.","Nevertheless, such black-box models lack transparency in their decision-making processes, prompting efforts to ascertain the rules that underlie classifiers' decisions.","Analyzing single inputs alone fails to expose systematic learned biases.","These biases can be characterized as facial properties summarizing abstract information like age or medical conditions.","Therefore, understanding a model's prediction behavior requires an analysis rooted in causality along such selected properties.","We demonstrate that up to 91.25% of classifier output behavior changes are statistically significant concerning basic properties.","Among those are age, gender, and facial symmetry.","Furthermore, the medical usage of surface electromyography significantly influences emotion prediction.","We introduce a workflow to evaluate explicit properties and their impact.","These insights might help medical professionals select and apply classifiers regarding their specialized data and properties."],"url":"http://arxiv.org/abs/2404.07867v1"}
{"created":"2024-04-11 15:57:18","title":"The Dance of Logic and Unpredictability: Examining the Predictability of User Behavior on Visual Analytics Tasks","abstract":"The quest to develop intelligent visual analytics (VA) systems capable of collaborating and naturally interacting with humans presents a multifaceted and intriguing challenge. VA systems designed for collaboration must adeptly navigate a complex landscape filled with the subtleties and unpredictabilities that characterize human behavior. However, it is noteworthy that scenarios exist where human behavior manifests predictably. These scenarios typically involve routine actions or present a limited range of choices. This paper delves into the predictability of user behavior in the context of visual analytics tasks. It offers an evidence-based discussion on the circumstances under which predicting user behavior is feasible and those where it proves challenging. We conclude with a forward-looking discussion of the future work necessary to cultivate more synergistic and efficient partnerships between humans and the VA system. This exploration is not just about understanding our current capabilities and limitations in mirroring human behavior but also about envisioning and paving the way for a future where human-machine interaction is more intuitive and productive.","sentences":["The quest to develop intelligent visual analytics (VA) systems capable of collaborating and naturally interacting with humans presents a multifaceted and intriguing challenge.","VA systems designed for collaboration must adeptly navigate a complex landscape filled with the subtleties and unpredictabilities that characterize human behavior.","However, it is noteworthy that scenarios exist where human behavior manifests predictably.","These scenarios typically involve routine actions or present a limited range of choices.","This paper delves into the predictability of user behavior in the context of visual analytics tasks.","It offers an evidence-based discussion on the circumstances under which predicting user behavior is feasible and those where it proves challenging.","We conclude with a forward-looking discussion of the future work necessary to cultivate more synergistic and efficient partnerships between humans and the VA system.","This exploration is not just about understanding our current capabilities and limitations in mirroring human behavior but also about envisioning and paving the way for a future where human-machine interaction is more intuitive and productive."],"url":"http://arxiv.org/abs/2404.07865v1"}
{"created":"2024-04-11 15:55:53","title":"Backdoor Contrastive Learning via Bi-level Trigger Optimization","abstract":"Contrastive Learning (CL) has attracted enormous attention due to its remarkable capability in unsupervised representation learning. However, recent works have revealed the vulnerability of CL to backdoor attacks: the feature extractor could be misled to embed backdoored data close to an attack target class, thus fooling the downstream predictor to misclassify it as the target. Existing attacks usually adopt a fixed trigger pattern and poison the training set with trigger-injected data, hoping for the feature extractor to learn the association between trigger and target class. However, we find that such fixed trigger design fails to effectively associate trigger-injected data with target class in the embedding space due to special CL mechanisms, leading to a limited attack success rate (ASR). This phenomenon motivates us to find a better backdoor trigger design tailored for CL framework. In this paper, we propose a bi-level optimization approach to achieve this goal, where the inner optimization simulates the CL dynamics of a surrogate victim, and the outer optimization enforces the backdoor trigger to stay close to the target throughout the surrogate CL procedure. Extensive experiments show that our attack can achieve a higher attack success rate (e.g., $99\\%$ ASR on ImageNet-100) with a very low poisoning rate ($1\\%$). Besides, our attack can effectively evade existing state-of-the-art defenses. Code is available at: https://github.com/SWY666/SSL-backdoor-BLTO.","sentences":["Contrastive Learning (CL) has attracted enormous attention due to its remarkable capability in unsupervised representation learning.","However, recent works have revealed the vulnerability of CL to backdoor attacks: the feature extractor could be misled to embed backdoored data close to an attack target class, thus fooling the downstream predictor to misclassify it as the target.","Existing attacks usually adopt a fixed trigger pattern and poison the training set with trigger-injected data, hoping for the feature extractor to learn the association between trigger and target class.","However, we find that such fixed trigger design fails to effectively associate trigger-injected data with target class in the embedding space due to special CL mechanisms, leading to a limited attack success rate (ASR).","This phenomenon motivates us to find a better backdoor trigger design tailored for CL framework.","In this paper, we propose a bi-level optimization approach to achieve this goal, where the inner optimization simulates the CL dynamics of a surrogate victim, and the outer optimization enforces the backdoor trigger to stay close to the target throughout the surrogate CL procedure.","Extensive experiments show that our attack can achieve a higher attack success rate (e.g., $99\\%$ ASR on ImageNet-100) with a very low poisoning rate ($1\\%$).","Besides, our attack can effectively evade existing state-of-the-art defenses.","Code is available at: https://github.com/SWY666/SSL-backdoor-BLTO."],"url":"http://arxiv.org/abs/2404.07863v1"}
{"created":"2024-04-11 15:54:41","title":"Konnektor: Connection Protocol for Ensuring Peer Uniqueness in Decentralized P2P Networks","abstract":"Konnektor is a connection protocol designed to solve the challenge of managing unique peers within distributed peer-to-peer networks. By prioritizing network integrity and efficiency, Konnektor offers a comprehensive solution that safeguards against the spread of duplicate peers while optimizing resource utilization. This paper provides a detailed explanation of the protocol's key components, including peer addressing, connection initialization, detecting peer duplications and mitigation strategies against potential security threats.","sentences":["Konnektor is a connection protocol designed to solve the challenge of managing unique peers within distributed peer-to-peer networks.","By prioritizing network integrity and efficiency, Konnektor offers a comprehensive solution that safeguards against the spread of duplicate peers while optimizing resource utilization.","This paper provides a detailed explanation of the protocol's key components, including peer addressing, connection initialization, detecting peer duplications and mitigation strategies against potential security threats."],"url":"http://arxiv.org/abs/2404.07861v1"}
{"created":"2024-04-11 15:54:20","title":"Streaming detection of significant delay changes in public transport systems","abstract":"Public transport systems are expected to reduce pollution and contribute to sustainable development. However, disruptions in public transport such as delays may negatively affect mobility choices. To quantify delays, aggregated data from vehicle locations systems are frequently used. However, delays observed at individual stops are caused inter alia by fluctuations in running times and propagation of delays occurring in other locations. Hence, in this work, we propose both the method detecting significant delays and reference architecture, relying on stream processing engines, in which the method is implemented. The method can complement the calculation of delays defined as deviation from schedules. This provides both online rather than batch identification of significant and repetitive delays, and resilience to the limited quality of location data. The method we propose can be used with different change detectors, such as ADWIN, applied to location data stream shuffled to individual edges of a transport graph. It can detect in an online manner at which edges statistically significant delays are observed and at which edges delays arise and are reduced. Detections can be used to model mobility choices and quantify the impact of repetitive rather than random disruptions on feasible trips with multimodal trip modelling engines. The evaluation performed with the public transport data of over 2000 vehicles confirms the merits of the method and reveals that a limited-size subgraph of a transport system graph causes statistically significant delays","sentences":["Public transport systems are expected to reduce pollution and contribute to sustainable development.","However, disruptions in public transport such as delays may negatively affect mobility choices.","To quantify delays, aggregated data from vehicle locations systems are frequently used.","However, delays observed at individual stops are caused inter alia by fluctuations in running times and propagation of delays occurring in other locations.","Hence, in this work, we propose both the method detecting significant delays and reference architecture, relying on stream processing engines, in which the method is implemented.","The method can complement the calculation of delays defined as deviation from schedules.","This provides both online rather than batch identification of significant and repetitive delays, and resilience to the limited quality of location data.","The method we propose can be used with different change detectors, such as ADWIN, applied to location data stream shuffled to individual edges of a transport graph.","It can detect in an online manner at which edges statistically significant delays are observed and at which edges delays arise and are reduced.","Detections can be used to model mobility choices and quantify the impact of repetitive rather than random disruptions on feasible trips with multimodal trip modelling engines.","The evaluation performed with the public transport data of over 2000 vehicles confirms the merits of the method and reveals that a limited-size subgraph of a transport system graph causes statistically significant delays"],"url":"http://arxiv.org/abs/2404.07860v1"}
{"created":"2024-04-11 15:51:52","title":"Resolve Domain Conflicts for Generalizable Remote Physiological Measurement","abstract":"Remote photoplethysmography (rPPG) technology has become increasingly popular due to its non-invasive monitoring of various physiological indicators, making it widely applicable in multimedia interaction, healthcare, and emotion analysis. Existing rPPG methods utilize multiple datasets for training to enhance the generalizability of models. However, they often overlook the underlying conflict issues across different datasets, such as (1) label conflict resulting from different phase delays between physiological signal labels and face videos at the instance level, and (2) attribute conflict stemming from distribution shifts caused by head movements, illumination changes, skin types, etc. To address this, we introduce the DOmain-HArmonious framework (DOHA). Specifically, we first propose a harmonious phase strategy to eliminate uncertain phase delays and preserve the temporal variation of physiological signals. Next, we design a harmonious hyperplane optimization that reduces irrelevant attribute shifts and encourages the model's optimization towards a global solution that fits more valid scenarios. Our experiments demonstrate that DOHA significantly improves the performance of existing methods under multiple protocols. Our code is available at https://github.com/SWY666/rPPG-DOHA.","sentences":["Remote photoplethysmography (rPPG) technology has become increasingly popular due to its non-invasive monitoring of various physiological indicators, making it widely applicable in multimedia interaction, healthcare, and emotion analysis.","Existing rPPG methods utilize multiple datasets for training to enhance the generalizability of models.","However, they often overlook the underlying conflict issues across different datasets, such as (1) label conflict resulting from different phase delays between physiological signal labels and face videos at the instance level, and (2) attribute conflict stemming from distribution shifts caused by head movements, illumination changes, skin types, etc.","To address this, we introduce the DOmain-HArmonious framework (DOHA).","Specifically, we first propose a harmonious phase strategy to eliminate uncertain phase delays and preserve the temporal variation of physiological signals.","Next, we design a harmonious hyperplane optimization that reduces irrelevant attribute shifts and encourages the model's optimization towards a global solution that fits more valid scenarios.","Our experiments demonstrate that DOHA significantly improves the performance of existing methods under multiple protocols.","Our code is available at https://github.com/SWY666/rPPG-DOHA."],"url":"http://arxiv.org/abs/2404.07855v1"}
{"created":"2024-04-11 15:51:00","title":"Reflexive graph lenses in univalent foundations","abstract":"Martin-L\\\"of's identity types provide a generic (albeit opaque) notion of identification or \"equality\" between any two elements of the same type, embodied in a canonical reflexive graph structure $(=_A, \\mathbf{refl})$ on any type $A$. The miracle of Voevodsky's univalence principle is that it ensures, for essentially any naturally occurring structure in mathematics, that this the resultant notion of identification is equivalent to the type of isomorphisms in the category of such structures. Characterisations of this kind are not automatic and must be established one-by-one; to this end, several authors have employed reflexive graphs and displayed reflexive graphs to organise the characterisation of identity types.   We contribute reflexive graph lenses, a new family of intermediate abstractions lying between families of reflexive graphs and displayed reflexive graphs that simplifies the characterisation of identity types for complex structures. Every reflexive graph lens gives rise to a (more complicated) displayed reflexive graph, and our experience suggests that many naturally occurring displayed reflexive graphs arise in this way. Evidence for the utility of reflexive graph lenses is given by means of several case studies, including the theory of reflexive graphs itself as well as that of polynomial type operators. Finally, we exhibit an equivalence between the type of reflexive graph fibrations and the type of univalent reflexive graph lenses.","sentences":["Martin-L\\\"of's identity types provide a generic (albeit opaque) notion of identification or \"equality\" between any two elements of the same type, embodied in a canonical reflexive graph structure $(=_","A, \\mathbf{refl})$ on any type $A$.","The miracle of Voevodsky's univalence principle is that it ensures, for essentially any naturally occurring structure in mathematics, that this the resultant notion of identification is equivalent to the type of isomorphisms in the category of such structures.","Characterisations of this kind are not automatic and must be established one-by-one; to this end, several authors have employed reflexive graphs and displayed reflexive graphs to organise the characterisation of identity types.   ","We contribute reflexive graph lenses, a new family of intermediate abstractions lying between families of reflexive graphs and displayed reflexive graphs that simplifies the characterisation of identity types for complex structures.","Every reflexive graph lens gives rise to a (more complicated) displayed reflexive graph, and our experience suggests that many naturally occurring displayed reflexive graphs arise in this way.","Evidence for the utility of reflexive graph lenses is given by means of several case studies, including the theory of reflexive graphs itself as well as that of polynomial type operators.","Finally, we exhibit an equivalence between the type of reflexive graph fibrations and the type of univalent reflexive graph lenses."],"url":"http://arxiv.org/abs/2404.07854v1"}
{"created":"2024-04-11 15:47:10","title":"Guiding Large Language Models to Post-Edit Machine Translation with Error Annotations","abstract":"Machine Translation (MT) remains one of the last NLP tasks where large language models (LLMs) have not yet replaced dedicated supervised systems. This work exploits the complementary strengths of LLMs and supervised MT by guiding LLMs to automatically post-edit MT with external feedback on its quality, derived from Multidimensional Quality Metric (MQM) annotations. Working with LLaMA-2 models, we consider prompting strategies varying the nature of feedback provided and then fine-tune the LLM to improve its ability to exploit the provided guidance. Through experiments on Chinese-English, English-German, and English-Russian MQM data, we demonstrate that prompting LLMs to post-edit MT improves TER, BLEU and COMET scores, although the benefits of fine-grained feedback are not clear. Fine-tuning helps integrate fine-grained feedback more effectively and further improves translation quality based on both automatic and human evaluation.","sentences":["Machine Translation (MT) remains one of the last NLP tasks where large language models (LLMs) have not yet replaced dedicated supervised systems.","This work exploits the complementary strengths of LLMs and supervised MT by guiding LLMs to automatically post-edit MT with external feedback on its quality, derived from Multidimensional Quality Metric (MQM) annotations.","Working with LLaMA-2 models, we consider prompting strategies varying the nature of feedback provided and then fine-tune the LLM to improve its ability to exploit the provided guidance.","Through experiments on Chinese-English, English-German, and English-Russian MQM data, we demonstrate that prompting LLMs to post-edit MT improves TER, BLEU and COMET scores, although the benefits of fine-grained feedback are not clear.","Fine-tuning helps integrate fine-grained feedback more effectively and further improves translation quality based on both automatic and human evaluation."],"url":"http://arxiv.org/abs/2404.07851v1"}
{"created":"2024-04-11 15:46:42","title":"MindBridge: A Cross-Subject Brain Decoding Framework","abstract":"Brain decoding, a pivotal field in neuroscience, aims to reconstruct stimuli from acquired brain signals, primarily utilizing functional magnetic resonance imaging (fMRI). Currently, brain decoding is confined to a per-subject-per-model paradigm, limiting its applicability to the same individual for whom the decoding model is trained. This constraint stems from three key challenges: 1) the inherent variability in input dimensions across subjects due to differences in brain size; 2) the unique intrinsic neural patterns, influencing how different individuals perceive and process sensory information; 3) limited data availability for new subjects in real-world scenarios hampers the performance of decoding models. In this paper, we present a novel approach, MindBridge, that achieves cross-subject brain decoding by employing only one model. Our proposed framework establishes a generic paradigm capable of addressing these challenges by introducing biological-inspired aggregation function and novel cyclic fMRI reconstruction mechanism for subject-invariant representation learning. Notably, by cycle reconstruction of fMRI, MindBridge can enable novel fMRI synthesis, which also can serve as pseudo data augmentation. Within the framework, we also devise a novel reset-tuning method for adapting a pretrained model to a new subject. Experimental results demonstrate MindBridge's ability to reconstruct images for multiple subjects, which is competitive with dedicated subject-specific models. Furthermore, with limited data for a new subject, we achieve a high level of decoding accuracy, surpassing that of subject-specific models. This advancement in cross-subject brain decoding suggests promising directions for wider applications in neuroscience and indicates potential for more efficient utilization of limited fMRI data in real-world scenarios. Project page: https://littlepure2333.github.io/MindBridge","sentences":["Brain decoding, a pivotal field in neuroscience, aims to reconstruct stimuli from acquired brain signals, primarily utilizing functional magnetic resonance imaging (fMRI).","Currently, brain decoding is confined to a per-subject-per-model paradigm, limiting its applicability to the same individual for whom the decoding model is trained.","This constraint stems from three key challenges: 1) the inherent variability in input dimensions across subjects due to differences in brain size; 2) the unique intrinsic neural patterns, influencing how different individuals perceive and process sensory information; 3) limited data availability for new subjects in real-world scenarios hampers the performance of decoding models.","In this paper, we present a novel approach, MindBridge, that achieves cross-subject brain decoding by employing only one model.","Our proposed framework establishes a generic paradigm capable of addressing these challenges by introducing biological-inspired aggregation function and novel cyclic fMRI reconstruction mechanism for subject-invariant representation learning.","Notably, by cycle reconstruction of fMRI, MindBridge can enable novel fMRI synthesis, which also can serve as pseudo data augmentation.","Within the framework, we also devise a novel reset-tuning method for adapting a pretrained model to a new subject.","Experimental results demonstrate MindBridge's ability to reconstruct images for multiple subjects, which is competitive with dedicated subject-specific models.","Furthermore, with limited data for a new subject, we achieve a high level of decoding accuracy, surpassing that of subject-specific models.","This advancement in cross-subject brain decoding suggests promising directions for wider applications in neuroscience and indicates potential for more efficient utilization of limited fMRI data in real-world scenarios.","Project page: https://littlepure2333.github.io/MindBridge"],"url":"http://arxiv.org/abs/2404.07850v1"}
{"created":"2024-04-11 15:42:53","title":"Fuss-Free Network: A Simplified and Efficient Neural Network for Crowd Counting","abstract":"In the field of crowd-counting research, many recent deep learning based methods have demonstrated robust capabilities for accurately estimating crowd sizes. However, the enhancement in their performance often arises from an increase in the complexity of the model structure. This paper introduces the Fuss-Free Network (FFNet), a crowd counting deep learning model that is characterized by its simplicity and efficiency in terms of its structure. The model comprises only a backbone of a neural network and a multi-scale feature fusion structure.The multi-scale feature fusion structure is a simple architecture consisting of three branches, each only equipped with a focus transition module, and combines the features from these branches through the concatenation operation.Our proposed crowd counting model is trained and evaluated on four widely used public datasets, and it achieves accuracy that is comparable to that of existing complex models.The experimental results further indicate that excellent performance in crowd counting tasks can also be achieved by utilizing a simple, low-parameter, and computationally efficient neural network structure.","sentences":["In the field of crowd-counting research, many recent deep learning based methods have demonstrated robust capabilities for accurately estimating crowd sizes.","However, the enhancement in their performance often arises from an increase in the complexity of the model structure.","This paper introduces the Fuss-Free Network (FFNet), a crowd counting deep learning model that is characterized by its simplicity and efficiency in terms of its structure.","The model comprises only a backbone of a neural network and a multi-scale feature fusion structure.","The multi-scale feature fusion structure is a simple architecture consisting of three branches, each only equipped with a focus transition module, and combines the features from these branches through the concatenation operation.","Our proposed crowd counting model is trained and evaluated on four widely used public datasets, and it achieves accuracy that is comparable to that of existing complex models.","The experimental results further indicate that excellent performance in crowd counting tasks can also be achieved by utilizing a simple, low-parameter, and computationally efficient neural network structure."],"url":"http://arxiv.org/abs/2404.07847v1"}
{"created":"2024-04-11 15:39:10","title":"TBSN: Transformer-Based Blind-Spot Network for Self-Supervised Image Denoising","abstract":"Blind-spot networks (BSN) have been prevalent network architectures in self-supervised image denoising (SSID). Existing BSNs are mostly conducted with convolution layers. Although transformers offer potential solutions to the limitations of convolutions and have demonstrated success in various image restoration tasks, their attention mechanisms may violate the blind-spot requirement, thus restricting their applicability in SSID. In this paper, we present a transformer-based blind-spot network (TBSN) by analyzing and redesigning the transformer operators that meet the blind-spot requirement. Specifically, TBSN follows the architectural principles of dilated BSNs, and incorporates spatial as well as channel self-attention layers to enhance the network capability. For spatial self-attention, an elaborate mask is applied to the attention matrix to restrict its receptive field, thus mimicking the dilated convolution. For channel self-attention, we observe that it may leak the blind-spot information when the channel number is greater than spatial size in the deep layers of multi-scale architectures. To eliminate this effect, we divide the channel into several groups and perform channel attention separately. Furthermore, we introduce a knowledge distillation strategy that distills TBSN into smaller denoisers to improve computational efficiency while maintaining performance. Extensive experiments on real-world image denoising datasets show that TBSN largely extends the receptive field and exhibits favorable performance against state-of-the-art SSID methods. The code and pre-trained models will be publicly available at https://github.com/nagejacob/TBSN.","sentences":["Blind-spot networks (BSN) have been prevalent network architectures in self-supervised image denoising (SSID).","Existing BSNs are mostly conducted with convolution layers.","Although transformers offer potential solutions to the limitations of convolutions and have demonstrated success in various image restoration tasks, their attention mechanisms may violate the blind-spot requirement, thus restricting their applicability in SSID.","In this paper, we present a transformer-based blind-spot network (TBSN) by analyzing and redesigning the transformer operators that meet the blind-spot requirement.","Specifically, TBSN follows the architectural principles of dilated BSNs, and incorporates spatial as well as channel self-attention layers to enhance the network capability.","For spatial self-attention, an elaborate mask is applied to the attention matrix to restrict its receptive field, thus mimicking the dilated convolution.","For channel self-attention, we observe that it may leak the blind-spot information when the channel number is greater than spatial size in the deep layers of multi-scale architectures.","To eliminate this effect, we divide the channel into several groups and perform channel attention separately.","Furthermore, we introduce a knowledge distillation strategy that distills TBSN into smaller denoisers to improve computational efficiency while maintaining performance.","Extensive experiments on real-world image denoising datasets show that TBSN largely extends the receptive field and exhibits favorable performance against state-of-the-art SSID methods.","The code and pre-trained models will be publicly available at https://github.com/nagejacob/TBSN."],"url":"http://arxiv.org/abs/2404.07846v1"}
{"created":"2024-04-11 15:27:56","title":"On Training Data Influence of GPT Models","abstract":"Amidst the rapid advancements in generative language models, the investigation of how training data shapes the performance of GPT models is still emerging. This paper presents GPTfluence, a novel approach that leverages a featurized simulation to assess the impact of training examples on the training dynamics of GPT models. Our approach not only traces the influence of individual training instances on performance trajectories, such as loss and other key metrics, on targeted test points but also enables a comprehensive comparison with existing methods across various training scenarios in GPT models, ranging from 14 million to 2.8 billion parameters, across a range of downstream tasks. Contrary to earlier methods that struggle with generalization to new data, GPTfluence introduces a parameterized simulation of training dynamics, demonstrating robust generalization capabilities to unseen training data. This adaptability is evident across both fine-tuning and instruction-tuning scenarios, spanning tasks in natural language understanding and generation. We will make our code and data publicly available.","sentences":["Amidst the rapid advancements in generative language models, the investigation of how training data shapes the performance of GPT models is still emerging.","This paper presents GPTfluence, a novel approach that leverages a featurized simulation to assess the impact of training examples on the training dynamics of GPT models.","Our approach not only traces the influence of individual training instances on performance trajectories, such as loss and other key metrics, on targeted test points but also enables a comprehensive comparison with existing methods across various training scenarios in GPT models, ranging from 14 million to 2.8 billion parameters, across a range of downstream tasks.","Contrary to earlier methods that struggle with generalization to new data, GPTfluence introduces a parameterized simulation of training dynamics, demonstrating robust generalization capabilities to unseen training data.","This adaptability is evident across both fine-tuning and instruction-tuning scenarios, spanning tasks in natural language understanding and generation.","We will make our code and data publicly available."],"url":"http://arxiv.org/abs/2404.07840v1"}
{"created":"2024-04-11 15:27:22","title":"RecurrentGemma: Moving Past Transformers for Efficient Open Language Models","abstract":"We introduce RecurrentGemma, an open language model which uses Google's novel Griffin architecture. Griffin combines linear recurrences with local attention to achieve excellent performance on language. It has a fixed-sized state, which reduces memory use and enables efficient inference on long sequences. We provide a pre-trained model with 2B non-embedding parameters, and an instruction tuned variant. Both models achieve comparable performance to Gemma-2B despite being trained on fewer tokens.","sentences":["We introduce RecurrentGemma, an open language model which uses Google's novel Griffin architecture.","Griffin combines linear recurrences with local attention to achieve excellent performance on language.","It has a fixed-sized state, which reduces memory use and enables efficient inference on long sequences.","We provide a pre-trained model with 2B non-embedding parameters, and an instruction tuned variant.","Both models achieve comparable performance to Gemma-2B despite being trained on fewer tokens."],"url":"http://arxiv.org/abs/2404.07839v1"}
{"created":"2024-04-11 15:27:14","title":"The Role of Confidence for Trust-based Resilient Consensus (Extended Version)","abstract":"We consider a multi-agent system where agents aim to achieve a consensus despite interactions with malicious agents that communicate misleading information. Physical channels supporting communication in cyberphysical systems offer attractive opportunities to detect malicious agents, nevertheless, trustworthiness indications coming from the channel are subject to uncertainty and need to be treated with this in mind. We propose a resilient consensus protocol that incorporates trust observations from the channel and weighs them with a parameter that accounts for how confident an agent is regarding its understanding of the legitimacy of other agents in the network, with no need for the initial observation window $T_0$ that has been utilized in previous works. Analytical and numerical results show that (i) our protocol achieves a resilient consensus in the presence of malicious agents and (ii) the steady-state deviation from nominal consensus can be minimized by a suitable choice of the confidence parameter that depends on the statistics of trust observations.","sentences":["We consider a multi-agent system where agents aim to achieve a consensus despite interactions with malicious agents that communicate misleading information.","Physical channels supporting communication in cyberphysical systems offer attractive opportunities to detect malicious agents, nevertheless, trustworthiness indications coming from the channel are subject to uncertainty and need to be treated with this in mind.","We propose a resilient consensus protocol that incorporates trust observations from the channel and weighs them with a parameter that accounts for how confident an agent is regarding its understanding of the legitimacy of other agents in the network, with no need for the initial observation window $T_0$ that has been utilized in previous works.","Analytical and numerical results show that (i) our protocol achieves a resilient consensus in the presence of malicious agents and (ii) the steady-state deviation from nominal consensus can be minimized by a suitable choice of the confidence parameter that depends on the statistics of trust observations."],"url":"http://arxiv.org/abs/2404.07838v1"}
{"created":"2024-04-11 15:25:13","title":"Data-Driven System Identification of Quadrotors Subject to Motor Delays","abstract":"Recently non-linear control methods like Model Predictive Control (MPC) and Reinforcement Learning (RL) have attracted increased interest in the quadrotor control community. In contrast to classic control methods like cascaded PID controllers, MPC and RL heavily rely on an accurate model of the system dynamics. The process of quadrotor system identification is notoriously tedious and is often pursued with additional equipment like a thrust stand. Furthermore, low-level details like motor delays which are crucial for accurate end-to-end control are often neglected. In this work, we introduce a data-driven method to identify a quadrotor's inertia parameters, thrust curves, torque coefficients, and first-order motor delay purely based on proprioceptive data. The estimation of the motor delay is particularly challenging as usually, the RPMs can not be measured. We derive a Maximum A Posteriori (MAP)-based method to estimate the latent time constant. Our approach only requires about a minute of flying data that can be collected without any additional equipment and usually consists of three simple maneuvers. Experimental results demonstrate the ability of our method to accurately recover the parameters of multiple quadrotors. It also facilitates the deployment of RL-based, end-to-end quadrotor control of a large quadrotor under harsh, outdoor conditions.","sentences":["Recently non-linear control methods like Model Predictive Control (MPC) and Reinforcement Learning (RL) have attracted increased interest in the quadrotor control community.","In contrast to classic control methods like cascaded PID controllers, MPC and RL heavily rely on an accurate model of the system dynamics.","The process of quadrotor system identification is notoriously tedious and is often pursued with additional equipment like a thrust stand.","Furthermore, low-level details like motor delays which are crucial for accurate end-to-end control are often neglected.","In this work, we introduce a data-driven method to identify a quadrotor's inertia parameters, thrust curves, torque coefficients, and first-order motor delay purely based on proprioceptive data.","The estimation of the motor delay is particularly challenging as usually, the RPMs can not be measured.","We derive a Maximum A Posteriori (MAP)-based method to estimate the latent time constant.","Our approach only requires about a minute of flying data that can be collected without any additional equipment and usually consists of three simple maneuvers.","Experimental results demonstrate the ability of our method to accurately recover the parameters of multiple quadrotors.","It also facilitates the deployment of RL-based, end-to-end quadrotor control of a large quadrotor under harsh, outdoor conditions."],"url":"http://arxiv.org/abs/2404.07837v1"}
{"created":"2024-04-11 15:24:50","title":"Question Generation in Knowledge-Driven Dialog: Explainability and Evaluation","abstract":"We explore question generation in the context of knowledge-grounded dialogs focusing on explainability and evaluation. Inspired by previous work on planning-based summarisation, we present a model which instead of directly generating a question, sequentially predicts first a fact then a question. We evaluate our approach on 37k test dialogs adapted from the KGConv dataset and we show that, although more demanding in terms of inference, our approach performs on par with a standard model which solely generates a question while allowing for a detailed referenceless evaluation of the model behaviour in terms of relevance, factuality and pronominalisation.","sentences":["We explore question generation in the context of knowledge-grounded dialogs focusing on explainability and evaluation.","Inspired by previous work on planning-based summarisation, we present a model which instead of directly generating a question, sequentially predicts first a fact then a question.","We evaluate our approach on 37k test dialogs adapted from the KGConv dataset and we show that, although more demanding in terms of inference, our approach performs on par with a standard model which solely generates a question while allowing for a detailed referenceless evaluation of the model behaviour in terms of relevance, factuality and pronominalisation."],"url":"http://arxiv.org/abs/2404.07836v1"}
{"created":"2024-04-11 15:18:34","title":"Streamlined Photoacoustic Image Processing with Foundation Models: A Training-Free Solution","abstract":"Foundation models have rapidly evolved and have achieved significant accomplishments in computer vision tasks. Specifically, the prompt mechanism conveniently allows users to integrate image prior information into the model, making it possible to apply models without any training. Therefore, we propose a method based on foundation models and zero training to solve the tasks of photoacoustic (PA) image segmentation. We employed the segment anything model (SAM) by setting simple prompts and integrating the model's outputs with prior knowledge of the imaged objects to accomplish various tasks, including: (1) removing the skin signal in three-dimensional PA image rendering; (2) dual speed-of-sound reconstruction, and (3) segmentation of finger blood vessels. Through these demonstrations, we have concluded that deep learning can be directly applied in PA imaging without the requirement for network design and training. This potentially allows for a hands-on, convenient approach to achieving efficient and accurate segmentation of PA images. This letter serves as a comprehensive tutorial, facilitating the mastery of the technique through the provision of code and sample datasets.","sentences":["Foundation models have rapidly evolved and have achieved significant accomplishments in computer vision tasks.","Specifically, the prompt mechanism conveniently allows users to integrate image prior information into the model, making it possible to apply models without any training.","Therefore, we propose a method based on foundation models and zero training to solve the tasks of photoacoustic (PA) image segmentation.","We employed the segment anything model (SAM) by setting simple prompts and integrating the model's outputs with prior knowledge of the imaged objects to accomplish various tasks, including: (1) removing the skin signal in three-dimensional PA image rendering; (2) dual speed-of-sound reconstruction, and (3) segmentation of finger blood vessels.","Through these demonstrations, we have concluded that deep learning can be directly applied in PA imaging without the requirement for network design and training.","This potentially allows for a hands-on, convenient approach to achieving efficient and accurate segmentation of PA images.","This letter serves as a comprehensive tutorial, facilitating the mastery of the technique through the provision of code and sample datasets."],"url":"http://arxiv.org/abs/2404.07833v1"}
{"created":"2024-04-11 15:16:26","title":"Protected QR Code-based Anti-counterfeit System for Pharmaceutical Manufacturing","abstract":"The pharmaceutical manufacturing faces critical challenges due to the global threat of counterfeit drugs. This paper proposes a new approach of protected QR codes to secure unique product information for safeguarding the pharmaceutical supply chain. The proposed solution integrates secure QR code generation and encrypted data transmission to establish a comprehensive anti-counterfeit ecosystem. The protected QR codes encapsulate product information that cannot be identified using traditional QR code scanners which protect the information against replication and tampering. The system is developed with scalability in mind, which can be easily implemented without introducing any additional modification in the traditional supply chain.","sentences":["The pharmaceutical manufacturing faces critical challenges due to the global threat of counterfeit drugs.","This paper proposes a new approach of protected QR codes to secure unique product information for safeguarding the pharmaceutical supply chain.","The proposed solution integrates secure QR code generation and encrypted data transmission to establish a comprehensive anti-counterfeit ecosystem.","The protected QR codes encapsulate product information that cannot be identified using traditional QR code scanners which protect the information against replication and tampering.","The system is developed with scalability in mind, which can be easily implemented without introducing any additional modification in the traditional supply chain."],"url":"http://arxiv.org/abs/2404.07831v1"}
{"created":"2024-04-11 15:09:49","title":"On the Sample Efficiency of Abstractions and Potential-Based Reward Shaping in Reinforcement Learning","abstract":"The use of Potential Based Reward Shaping (PBRS) has shown great promise in the ongoing research effort to tackle sample inefficiency in Reinforcement Learning (RL). However, the choice of the potential function is critical for this technique to be effective. Additionally, RL techniques are usually constrained to use a finite horizon for computational limitations. This introduces a bias when using PBRS, thus adding an additional layer of complexity. In this paper, we leverage abstractions to automatically produce a \"good\" potential function. We analyse the bias induced by finite horizons in the context of PBRS producing novel insights. Finally, to asses sample efficiency and performance impact, we evaluate our approach on four environments including a goal-oriented navigation task and three Arcade Learning Environments (ALE) games demonstrating that we can reach the same level of performance as CNN-based solutions with a simple fully-connected network.","sentences":["The use of Potential Based Reward Shaping (PBRS) has shown great promise in the ongoing research effort to tackle sample inefficiency in Reinforcement Learning (RL).","However, the choice of the potential function is critical for this technique to be effective.","Additionally, RL techniques are usually constrained to use a finite horizon for computational limitations.","This introduces a bias when using PBRS, thus adding an additional layer of complexity.","In this paper, we leverage abstractions to automatically produce a \"good\" potential function.","We analyse the bias induced by finite horizons in the context of PBRS producing novel insights.","Finally, to asses sample efficiency and performance impact, we evaluate our approach on four environments including a goal-oriented navigation task and three Arcade Learning Environments (ALE) games demonstrating that we can reach the same level of performance as CNN-based solutions with a simple fully-connected network."],"url":"http://arxiv.org/abs/2404.07826v1"}
{"created":"2024-04-11 15:09:22","title":"Heron-Bench: A Benchmark for Evaluating Vision Language Models in Japanese","abstract":"Vision Language Models (VLMs) have undergone a rapid evolution, giving rise to significant advancements in the realm of multimodal understanding tasks. However, the majority of these models are trained and evaluated on English-centric datasets, leaving a gap in the development and evaluation of VLMs for other languages, such as Japanese. This gap can be attributed to the lack of methodologies for constructing VLMs and the absence of benchmarks to accurately measure their performance. To address this issue, we introduce a novel benchmark, Japanese Heron-Bench, for evaluating Japanese capabilities of VLMs. The Japanese Heron-Bench consists of a variety of imagequestion answer pairs tailored to the Japanese context. Additionally, we present a baseline Japanese VLM that has been trained with Japanese visual instruction tuning datasets. Our Heron-Bench reveals the strengths and limitations of the proposed VLM across various ability dimensions. Furthermore, we clarify the capability gap between strong closed models like GPT-4V and the baseline model, providing valuable insights for future research in this domain. We release the benchmark dataset and training code to facilitate further developments in Japanese VLM research.","sentences":["Vision Language Models (VLMs) have undergone a rapid evolution, giving rise to significant advancements in the realm of multimodal understanding tasks.","However, the majority of these models are trained and evaluated on English-centric datasets, leaving a gap in the development and evaluation of VLMs for other languages, such as Japanese.","This gap can be attributed to the lack of methodologies for constructing VLMs and the absence of benchmarks to accurately measure their performance.","To address this issue, we introduce a novel benchmark, Japanese Heron-Bench, for evaluating Japanese capabilities of VLMs.","The Japanese Heron-Bench consists of a variety of imagequestion answer pairs tailored to the Japanese context.","Additionally, we present a baseline Japanese VLM that has been trained with Japanese visual instruction tuning datasets.","Our Heron-Bench reveals the strengths and limitations of the proposed VLM across various ability dimensions.","Furthermore, we clarify the capability gap between strong closed models like GPT-4V and the baseline model, providing valuable insights for future research in this domain.","We release the benchmark dataset and training code to facilitate further developments in Japanese VLM research."],"url":"http://arxiv.org/abs/2404.07824v1"}
{"created":"2024-04-11 15:08:11","title":"Learning Deterministic Multi-Clock Timed Automata","abstract":"We present an algorithm for active learning of deterministic timed automata with multiple clocks. The algorithm is within the querying framework of Angluin's $L^*$ algorithm and follows the idea proposed in existing work on the active learning of deterministic one-clock timed automata. We introduce an equivalence relation over the reset-clocked language of a timed automaton and then transform the learning problem into learning the corresponding reset-clocked language of the target automaton. Since a reset-clocked language includes the clock reset information which is not observable, we first present the approach of learning from a powerful teacher who can provide reset information by answering reset information queries from the learner. Then we extend the algorithm in a normal teacher situation in which the learner can only ask standard membership query and equivalence query while the learner guesses the reset information. We prove that the learning algorithm terminates and returns a correct deterministic timed automaton. Due to the need of guessing whether the clocks reset at the transitions, the algorithm is of exponential complexity in the size of the target automaton.","sentences":["We present an algorithm for active learning of deterministic timed automata with multiple clocks.","The algorithm is within the querying framework of Angluin's $L^*$ algorithm and follows the idea proposed in existing work on the active learning of deterministic one-clock timed automata.","We introduce an equivalence relation over the reset-clocked language of a timed automaton and then transform the learning problem into learning the corresponding reset-clocked language of the target automaton.","Since a reset-clocked language includes the clock reset information which is not observable, we first present the approach of learning from a powerful teacher who can provide reset information by answering reset information queries from the learner.","Then we extend the algorithm in a normal teacher situation in which the learner can only ask standard membership query and equivalence query while the learner guesses the reset information.","We prove that the learning algorithm terminates and returns a correct deterministic timed automaton.","Due to the need of guessing whether the clocks reset at the transitions, the algorithm is of exponential complexity in the size of the target automaton."],"url":"http://arxiv.org/abs/2404.07823v1"}
{"created":"2024-04-11 15:00:55","title":"Sparse Laneformer","abstract":"Lane detection is a fundamental task in autonomous driving, and has achieved great progress as deep learning emerges. Previous anchor-based methods often design dense anchors, which highly depend on the training dataset and remain fixed during inference. We analyze that dense anchors are not necessary for lane detection, and propose a transformer-based lane detection framework based on a sparse anchor mechanism. To this end, we generate sparse anchors with position-aware lane queries and angle queries instead of traditional explicit anchors. We adopt Horizontal Perceptual Attention (HPA) to aggregate the lane features along the horizontal direction, and adopt Lane-Angle Cross Attention (LACA) to perform interactions between lane queries and angle queries. We also propose Lane Perceptual Attention (LPA) based on deformable cross attention to further refine the lane predictions. Our method, named Sparse Laneformer, is easy-to-implement and end-to-end trainable. Extensive experiments demonstrate that Sparse Laneformer performs favorably against the state-of-the-art methods, e.g., surpassing Laneformer by 3.0% F1 score and O2SFormer by 0.7% F1 score with fewer MACs on CULane with the same ResNet-34 backbone.","sentences":["Lane detection is a fundamental task in autonomous driving, and has achieved great progress as deep learning emerges.","Previous anchor-based methods often design dense anchors, which highly depend on the training dataset and remain fixed during inference.","We analyze that dense anchors are not necessary for lane detection, and propose a transformer-based lane detection framework based on a sparse anchor mechanism.","To this end, we generate sparse anchors with position-aware lane queries and angle queries instead of traditional explicit anchors.","We adopt Horizontal Perceptual Attention (HPA) to aggregate the lane features along the horizontal direction, and adopt Lane-Angle Cross Attention (LACA) to perform interactions between lane queries and angle queries.","We also propose Lane Perceptual Attention (LPA) based on deformable cross attention to further refine the lane predictions.","Our method, named Sparse Laneformer, is easy-to-implement and end-to-end trainable.","Extensive experiments demonstrate that Sparse Laneformer performs favorably against the state-of-the-art methods, e.g., surpassing Laneformer by 3.0% F1 score and O2SFormer by 0.7% F1 score with fewer MACs on CULane with the same ResNet-34 backbone."],"url":"http://arxiv.org/abs/2404.07821v1"}
{"created":"2024-04-11 14:59:49","title":"Calibration of Continual Learning Models","abstract":"Continual Learning (CL) focuses on maximizing the predictive performance of a model across a non-stationary stream of data. Unfortunately, CL models tend to forget previous knowledge, thus often underperforming when compared with an offline model trained jointly on the entire data stream. Given that any CL model will eventually make mistakes, it is of crucial importance to build calibrated CL models: models that can reliably tell their confidence when making a prediction. Model calibration is an active research topic in machine learning, yet to be properly investigated in CL. We provide the first empirical study of the behavior of calibration approaches in CL, showing that CL strategies do not inherently learn calibrated models. To mitigate this issue, we design a continual calibration approach that improves the performance of post-processing calibration methods over a wide range of different benchmarks and CL strategies. CL does not necessarily need perfect predictive models, but rather it can benefit from reliable predictive models. We believe our study on continual calibration represents a first step towards this direction.","sentences":["Continual Learning (CL) focuses on maximizing the predictive performance of a model across a non-stationary stream of data.","Unfortunately, CL models tend to forget previous knowledge, thus often underperforming when compared with an offline model trained jointly on the entire data stream.","Given that any CL model will eventually make mistakes, it is of crucial importance to build calibrated CL models: models that can reliably tell their confidence when making a prediction.","Model calibration is an active research topic in machine learning, yet to be properly investigated in CL.","We provide the first empirical study of the behavior of calibration approaches in CL, showing that CL strategies do not inherently learn calibrated models.","To mitigate this issue, we design a continual calibration approach that improves the performance of post-processing calibration methods over a wide range of different benchmarks and CL strategies.","CL does not necessarily need perfect predictive models, but rather it can benefit from reliable predictive models.","We believe our study on continual calibration represents a first step towards this direction."],"url":"http://arxiv.org/abs/2404.07817v1"}
{"created":"2024-04-11 14:59:49","title":"Robustness of voting mechanisms to external information in expectation","abstract":"Analyses of voting algorithms often overlook informational externalities shaping individual votes. For example, pre-polling information often skews voters towards candidates who may not be their top choice, but who they believe would be a worthwhile recipient of their vote. In this work, we aim to understand the role of external information in voting outcomes. We study this by analyzing (1) the probability that voting outcomes align with external information, and (2) the effect of external information on the total utility across voters, or social welfare. In practice, voting mechanisms elicit coarse information about voter utilities, such as ordinal preferences, which initially prevents us from directly analyzing the effect of informational externalities with standard voting mechanisms. To overcome this, we present an intermediary mechanism for learning how preferences change with external information which does not require eliciting full cardinal preferences. With this tool in hand, we find that voting mechanisms are generally more likely to select the alternative most favored by the external information, and when external information reflects the population's true preferences, social welfare increases in expectation.","sentences":["Analyses of voting algorithms often overlook informational externalities shaping individual votes.","For example, pre-polling information often skews voters towards candidates who may not be their top choice, but who they believe would be a worthwhile recipient of their vote.","In this work, we aim to understand the role of external information in voting outcomes.","We study this by analyzing (1) the probability that voting outcomes align with external information, and (2) the effect of external information on the total utility across voters, or social welfare.","In practice, voting mechanisms elicit coarse information about voter utilities, such as ordinal preferences, which initially prevents us from directly analyzing the effect of informational externalities with standard voting mechanisms.","To overcome this, we present an intermediary mechanism for learning how preferences change with external information which does not require eliciting full cardinal preferences.","With this tool in hand, we find that voting mechanisms are generally more likely to select the alternative most favored by the external information, and when external information reflects the population's true preferences, social welfare increases in expectation."],"url":"http://arxiv.org/abs/2404.07818v1"}
{"created":"2024-04-11 14:58:19","title":"Post-Hoc Reversal: Are We Selecting Models Prematurely?","abstract":"Trained models are often composed with post-hoc transforms such as temperature scaling (TS), ensembling and stochastic weight averaging (SWA) to improve performance, robustness, uncertainty estimation, etc. However, such transforms are typically applied only after the base models have already been finalized by standard means. In this paper, we challenge this practice with an extensive empirical study. In particular, we demonstrate a phenomenon that we call post-hoc reversal, where performance trends are reversed after applying these post-hoc transforms. This phenomenon is especially prominent in high-noise settings. For example, while base models overfit badly early in training, both conventional ensembling and SWA favor base models trained for more epochs. Post-hoc reversal can also suppress the appearance of double descent and mitigate mismatches between test loss and test error seen in base models. Based on our findings, we propose post-hoc selection, a simple technique whereby post-hoc metrics inform model development decisions such as early stopping, checkpointing, and broader hyperparameter choices. Our experimental analyses span real-world vision, language, tabular and graph datasets from domains like satellite imaging, language modeling, census prediction and social network analysis. On an LLM instruction tuning dataset, post-hoc selection results in > 1.5x MMLU improvement compared to naive selection. Code is available at https://github.com/rishabh-ranjan/post-hoc-reversal.","sentences":["Trained models are often composed with post-hoc transforms such as temperature scaling (TS), ensembling and stochastic weight averaging (SWA) to improve performance, robustness, uncertainty estimation, etc.","However, such transforms are typically applied only after the base models have already been finalized by standard means.","In this paper, we challenge this practice with an extensive empirical study.","In particular, we demonstrate a phenomenon that we call post-hoc reversal, where performance trends are reversed after applying these post-hoc transforms.","This phenomenon is especially prominent in high-noise settings.","For example, while base models overfit badly early in training, both conventional ensembling and SWA favor base models trained for more epochs.","Post-hoc reversal can also suppress the appearance of double descent and mitigate mismatches between test loss and test error seen in base models.","Based on our findings, we propose post-hoc selection, a simple technique whereby post-hoc metrics inform model development decisions such as early stopping, checkpointing, and broader hyperparameter choices.","Our experimental analyses span real-world vision, language, tabular and graph datasets from domains like satellite imaging, language modeling, census prediction and social network analysis.","On an LLM instruction tuning dataset, post-hoc selection results in > 1.5x MMLU improvement compared to naive selection.","Code is available at https://github.com/rishabh-ranjan/post-hoc-reversal."],"url":"http://arxiv.org/abs/2404.07815v1"}
{"created":"2024-04-11 14:57:19","title":"MultiLS-SP/CA: Lexical Complexity Prediction and Lexical Simplification Resources for Catalan and Spanish","abstract":"Automatic lexical simplification is a task to substitute lexical items that may be unfamiliar and difficult to understand with easier and more common words. This paper presents MultiLS-SP/CA, a novel dataset for lexical simplification in Spanish and Catalan. This dataset represents the first of its kind in Catalan and a substantial addition to the sparse data on automatic lexical simplification which is available for Spanish. Specifically, MultiLS-SP is the first dataset for Spanish which includes scalar ratings of the understanding difficulty of lexical items. In addition, we describe experiments with this dataset, which can serve as a baseline for future work on the same data.","sentences":["Automatic lexical simplification is a task to substitute lexical items that may be unfamiliar and difficult to understand with easier and more common words.","This paper presents MultiLS-SP/CA, a novel dataset for lexical simplification in Spanish and Catalan.","This dataset represents the first of its kind in Catalan and a substantial addition to the sparse data on automatic lexical simplification which is available for Spanish.","Specifically, MultiLS-SP is the first dataset for Spanish which includes scalar ratings of the understanding difficulty of lexical items.","In addition, we describe experiments with this dataset, which can serve as a baseline for future work on the same data."],"url":"http://arxiv.org/abs/2404.07814v1"}
{"created":"2024-04-11 14:51:12","title":"Voice-Assisted Real-Time Traffic Sign Recognition System Using Convolutional Neural Network","abstract":"Traffic signs are important in communicating information to drivers. Thus, comprehension of traffic signs is essential for road safety and ignorance may result in road accidents. Traffic sign detection has been a research spotlight over the past few decades. Real-time and accurate detections are the preliminaries of robust traffic sign detection system which is yet to be achieved. This study presents a voice-assisted real-time traffic sign recognition system which is capable of assisting drivers. This system functions under two subsystems. Initially, the detection and recognition of the traffic signs are carried out using a trained Convolutional Neural Network (CNN). After recognizing the specific traffic sign, it is narrated to the driver as a voice message using a text-to-speech engine. An efficient CNN model for a benchmark dataset is developed for real-time detection and recognition using Deep Learning techniques. The advantage of this system is that even if the driver misses a traffic sign, or does not look at the traffic sign, or is unable to comprehend the sign, the system detects it and narrates it to the driver. A system of this type is also important in the development of autonomous vehicles.","sentences":["Traffic signs are important in communicating information to drivers.","Thus, comprehension of traffic signs is essential for road safety and ignorance may result in road accidents.","Traffic sign detection has been a research spotlight over the past few decades.","Real-time and accurate detections are the preliminaries of robust traffic sign detection system which is yet to be achieved.","This study presents a voice-assisted real-time traffic sign recognition system which is capable of assisting drivers.","This system functions under two subsystems.","Initially, the detection and recognition of the traffic signs are carried out using a trained Convolutional Neural Network (CNN).","After recognizing the specific traffic sign, it is narrated to the driver as a voice message using a text-to-speech engine.","An efficient CNN model for a benchmark dataset is developed for real-time detection and recognition using Deep Learning techniques.","The advantage of this system is that even if the driver misses a traffic sign, or does not look at the traffic sign, or is unable to comprehend the sign, the system detects it and narrates it to the driver.","A system of this type is also important in the development of autonomous vehicles."],"url":"http://arxiv.org/abs/2404.07807v1"}
{"created":"2024-04-11 14:45:08","title":"An efficient uniqueness theorem for overcomplete tensor decomposition","abstract":"We give a new, constructive uniqueness theorem for tensor decomposition. It applies to order 3 tensors of format $n \\times n \\times p$ and can prove uniqueness of decomposition for generic tensors up to rank $r=4n/3$ as soon as $p \\geq 4$. One major advantage over Kruskal's uniqueness theorem is that our theorem has an algorithmic proof, and the resulting algorithm is efficient. Like the uniqueness theorem, it applies in the range $n \\leq r \\leq 4n/3$. As a result, we obtain the first efficient algorithm for overcomplete decomposition of generic tensors of order 3.   For instance, prior to this work it was not known how to efficiently decompose generic tensors of format $n \\times n \\times n$ and rank $r=1.01n$ (or rank $r \\leq (1+\\epsilon) n$, for some constant $\\epsilon >0$). Efficient overcomplete decomposition of generic tensors of format $n \\times n \\times 3$ remains an open problem.   Our results are based on the method of commuting extensions pioneered by Strassen for the proof of his $3n/2$ lower bound on tensor rank and border rank. In particular, we rely on an algorithm for the computation of commuting extensions recently proposed in a companion paper, and on the classical diagonalization-based \"Jennrich algorithm\" for undercomplete tensor decomposition.","sentences":["We give a new, constructive uniqueness theorem for tensor decomposition.","It applies to order 3 tensors of format $n \\times n \\times p$ and can prove uniqueness of decomposition for generic tensors up to rank $r=4n/3$ as soon as $p \\geq","4$. One major advantage over Kruskal's uniqueness theorem is that our theorem has an algorithmic proof, and the resulting algorithm is efficient.","Like the uniqueness theorem, it applies in the range $n \\leq r \\leq 4n/3$. As a result, we obtain the first efficient algorithm for overcomplete decomposition of generic tensors of order 3.   ","For instance, prior to this work it was not known how to efficiently decompose generic tensors of format $n \\times n \\times n$ and rank $r=1.01n$ (or rank $r \\leq (1+\\epsilon) n$, for some constant $\\epsilon >0$).","Efficient overcomplete decomposition of generic tensors of format $n \\times n \\times 3$ remains an open problem.   ","Our results are based on the method of commuting extensions pioneered by Strassen for the proof of his $3n/2$ lower bound on tensor rank and border rank.","In particular, we rely on an algorithm for the computation of commuting extensions recently proposed in a companion paper, and on the classical diagonalization-based \"Jennrich algorithm\" for undercomplete tensor decomposition."],"url":"http://arxiv.org/abs/2404.07801v1"}
{"created":"2024-04-11 14:38:51","title":"Illicit Promotion on Twitter","abstract":"In this paper, we present an extensive study of the promotion of illicit goods and services on Twitter, a popular online social network(OSN). This study is made possible through the design and implementation of multiple novel tools for detecting and analyzing illicit promotion activities as well as their underlying campaigns. As the results, we observe that illicit promotion is prevalent on Twitter, along with noticeable existence on other three popular OSNs including Youtube, Facebook, and TikTok. Particularly, 12 million distinct posts of illicit promotion (PIPs) have been observed on the Twitter platform, which are widely distributed in 5 major natural languages and 10 categories of illicit goods and services, e.g., drugs, data leakage, gambling, and weapon sales. What are also observed are 580K Twitter accounts publishing PIPs as well as 37K distinct instant messaging (IM) accounts that are embedded in PIPs and serve as next hops of communication, which strongly indicates that the campaigns underpinning PIPs are also of a large scale. Also, an arms race between Twitter and illicit promotion operators is also observed. On one hand, Twitter is observed to conduct content moderation in a continuous manner and almost 80% PIPs will get gradually unpublished within six months since posted. However, in the meantime, miscreants adopt various evasion tactics to masquerade their PIPs, which renders more than 90% PIPs keeping hidden from the detection radar for two months or longer.","sentences":["In this paper, we present an extensive study of the promotion of illicit goods and services on Twitter, a popular online social network(OSN).","This study is made possible through the design and implementation of multiple novel tools for detecting and analyzing illicit promotion activities as well as their underlying campaigns.","As the results, we observe that illicit promotion is prevalent on Twitter, along with noticeable existence on other three popular OSNs including Youtube, Facebook, and TikTok.","Particularly, 12 million distinct posts of illicit promotion (PIPs) have been observed on the Twitter platform, which are widely distributed in 5 major natural languages and 10 categories of illicit goods and services, e.g., drugs, data leakage, gambling, and weapon sales.","What are also observed are 580K Twitter accounts publishing PIPs as well as 37K distinct instant messaging (IM) accounts that are embedded in PIPs and serve as next hops of communication, which strongly indicates that the campaigns underpinning PIPs are also of a large scale.","Also, an arms race between Twitter and illicit promotion operators is also observed.","On one hand, Twitter is observed to conduct content moderation in a continuous manner and almost 80% PIPs will get gradually unpublished within six months since posted.","However, in the meantime, miscreants adopt various evasion tactics to masquerade their PIPs, which renders more than 90% PIPs keeping hidden from the detection radar for two months or longer."],"url":"http://arxiv.org/abs/2404.07797v1"}
{"created":"2024-04-11 14:36:13","title":"From the Lab to the Theater: An Unconventional Field Robotics Journey","abstract":"Artistic performances involving robotic systems present unique technical challenges akin to those encountered in other field deployments. In this paper, we delve into the orchestration of robotic artistic performances, focusing on the complexities inherent in communication protocols and localization methods. Through our case studies and experimental insights, we demonstrate the breadth of technical requirements for this type of deployment, and, most importantly, the significant contributions of working closely with non-experts.","sentences":["Artistic performances involving robotic systems present unique technical challenges akin to those encountered in other field deployments.","In this paper, we delve into the orchestration of robotic artistic performances, focusing on the complexities inherent in communication protocols and localization methods.","Through our case studies and experimental insights, we demonstrate the breadth of technical requirements for this type of deployment, and, most importantly, the significant contributions of working closely with non-experts."],"url":"http://arxiv.org/abs/2404.07795v1"}
{"created":"2024-04-11 14:35:59","title":"DGMamba: Domain Generalization via Generalized State Space Model","abstract":"Domain generalization~(DG) aims at solving distribution shift problems in various scenes. Existing approaches are based on Convolution Neural Networks (CNNs) or Vision Transformers (ViTs), which suffer from limited receptive fields or quadratic complexities issues. Mamba, as an emerging state space model (SSM), possesses superior linear complexity and global receptive fields. Despite this, it can hardly be applied to DG to address distribution shifts, due to the hidden state issues and inappropriate scan mechanisms. In this paper, we propose a novel framework for DG, named DGMamba, that excels in strong generalizability toward unseen domains and meanwhile has the advantages of global receptive fields, and efficient linear complexity. Our DGMamba compromises two core components: Hidden State Suppressing~(HSS) and Semantic-aware Patch refining~(SPR). In particular, HSS is introduced to mitigate the influence of hidden states associated with domain-specific features during output prediction. SPR strives to encourage the model to concentrate more on objects rather than context, consisting of two designs: Prior-Free Scanning~(PFS), and Domain Context Interchange~(DCI). Concretely, PFS aims to shuffle the non-semantic patches within images, creating more flexible and effective sequences from images, and DCI is designed to regularize Mamba with the combination of mismatched non-semantic and semantic information by fusing patches among domains. Extensive experiments on four commonly used DG benchmarks demonstrate that the proposed DGMamba achieves remarkably superior results to state-of-the-art models. The code will be made publicly available.","sentences":["Domain generalization~(DG) aims at solving distribution shift problems in various scenes.","Existing approaches are based on Convolution Neural Networks (CNNs) or Vision Transformers (ViTs), which suffer from limited receptive fields or quadratic complexities issues.","Mamba, as an emerging state space model (SSM), possesses superior linear complexity and global receptive fields.","Despite this, it can hardly be applied to DG to address distribution shifts, due to the hidden state issues and inappropriate scan mechanisms.","In this paper, we propose a novel framework for DG, named DGMamba, that excels in strong generalizability toward unseen domains and meanwhile has the advantages of global receptive fields, and efficient linear complexity.","Our DGMamba compromises two core components: Hidden State Suppressing~(HSS) and Semantic-aware Patch refining~(SPR).","In particular, HSS is introduced to mitigate the influence of hidden states associated with domain-specific features during output prediction.","SPR strives to encourage the model to concentrate more on objects rather than context, consisting of two designs: Prior-Free Scanning~(PFS), and Domain Context Interchange~(DCI).","Concretely, PFS aims to shuffle the non-semantic patches within images, creating more flexible and effective sequences from images, and DCI is designed to regularize Mamba with the combination of mismatched non-semantic and semantic information by fusing patches among domains.","Extensive experiments on four commonly used DG benchmarks demonstrate that the proposed DGMamba achieves remarkably superior results to state-of-the-art models.","The code will be made publicly available."],"url":"http://arxiv.org/abs/2404.07794v1"}
{"created":"2024-04-11 14:35:23","title":"Nostra Domina at EvaLatin 2024: Improving Latin Polarity Detection through Data Augmentation","abstract":"This paper describes submissions from the team Nostra Domina to the EvaLatin 2024 shared task of emotion polarity detection. Given the low-resource environment of Latin and the complexity of sentiment in rhetorical genres like poetry, we augmented the available data through automatic polarity annotation. We present two methods for doing so on the basis of the $k$-means algorithm, and we employ a variety of Latin large language models (LLMs) in a neural architecture to better capture the underlying contextual sentiment representations. Our best approach achieved the second highest macro-averaged Macro-$F_1$ score on the shared task's test set.","sentences":["This paper describes submissions from the team Nostra Domina to the EvaLatin 2024 shared task of emotion polarity detection.","Given the low-resource environment of Latin and the complexity of sentiment in rhetorical genres like poetry, we augmented the available data through automatic polarity annotation.","We present two methods for doing so on the basis of the $k$-means algorithm, and we employ a variety of Latin large language models (LLMs) in a neural architecture to better capture the underlying contextual sentiment representations.","Our best approach achieved the second highest macro-averaged Macro-$F_1$ score on the shared task's test set."],"url":"http://arxiv.org/abs/2404.07792v1"}
{"created":"2024-04-11 14:31:11","title":"VIFNet: An End-to-end Visible-Infrared Fusion Network for Image Dehazing","abstract":"Image dehazing poses significant challenges in environmental perception. Recent research mainly focus on deep learning-based methods with single modality, while they may result in severe information loss especially in dense-haze scenarios. The infrared image exhibits robustness to the haze, however, existing methods have primarily treated the infrared modality as auxiliary information, failing to fully explore its rich information in dehazing. To address this challenge, the key insight of this study is to design a visible-infrared fusion network for image dehazing. In particular, we propose a multi-scale Deep Structure Feature Extraction (DSFE) module, which incorporates the Channel-Pixel Attention Block (CPAB) to restore more spatial and marginal information within the deep structural features. Additionally, we introduce an inconsistency weighted fusion strategy to merge the two modalities by leveraging the more reliable information. To validate this, we construct a visible-infrared multimodal dataset called AirSim-VID based on the AirSim simulation platform. Extensive experiments performed on challenging real and simulated image datasets demonstrate that VIFNet can outperform many state-of-the-art competing methods. The code and dataset are available at https://github.com/mengyu212/VIFNet_dehazing.","sentences":["Image dehazing poses significant challenges in environmental perception.","Recent research mainly focus on deep learning-based methods with single modality, while they may result in severe information loss especially in dense-haze scenarios.","The infrared image exhibits robustness to the haze, however, existing methods have primarily treated the infrared modality as auxiliary information, failing to fully explore its rich information in dehazing.","To address this challenge, the key insight of this study is to design a visible-infrared fusion network for image dehazing.","In particular, we propose a multi-scale Deep Structure Feature Extraction (DSFE) module, which incorporates the Channel-Pixel Attention Block (CPAB) to restore more spatial and marginal information within the deep structural features.","Additionally, we introduce an inconsistency weighted fusion strategy to merge the two modalities by leveraging the more reliable information.","To validate this, we construct a visible-infrared multimodal dataset called AirSim-VID based on the AirSim simulation platform.","Extensive experiments performed on challenging real and simulated image datasets demonstrate that VIFNet can outperform many state-of-the-art competing methods.","The code and dataset are available at https://github.com/mengyu212/VIFNet_dehazing."],"url":"http://arxiv.org/abs/2404.07790v1"}
{"created":"2024-04-11 14:29:35","title":"An equilibrium-seeking search algorithm for integrating large-scale activity-based and dynamic traffic assignment models","abstract":"This paper proposes an iterative methodology to integrate large-scale behavioral activity-based models with dynamic traffic assignment models. The main novelty of the proposed approach is the decoupling of the two parts, allowing the ex-post integration of any existing model as long as certain assumptions are satisfied. A measure of error is defined to characterize a search space easily explorable within its boundaries. Within it, a joint distribution of the number of trips and travel times is identified as the equilibrium distribution, i.e., the distribution for which trip numbers and travel times are bound in the neighborhood of the equilibrium between supply and demand. The approach is tested on a medium-sized city of 400,000 inhabitants and the results suggest that the proposed iterative approach does perform well, reaching equilibrium between demand and supply in a limited number of iterations thanks to its perturbation techniques. Overall, 15 iterations are needed to reach values of the measure of error lower than 10%. The equilibrium identified this way is then validated against baseline distributions to demonstrate the goodness of the results.","sentences":["This paper proposes an iterative methodology to integrate large-scale behavioral activity-based models with dynamic traffic assignment models.","The main novelty of the proposed approach is the decoupling of the two parts, allowing the ex-post integration of any existing model as long as certain assumptions are satisfied.","A measure of error is defined to characterize a search space easily explorable within its boundaries.","Within it, a joint distribution of the number of trips and travel times is identified as the equilibrium distribution, i.e., the distribution for which trip numbers and travel times are bound in the neighborhood of the equilibrium between supply and demand.","The approach is tested on a medium-sized city of 400,000 inhabitants and the results suggest that the proposed iterative approach does perform well, reaching equilibrium between demand and supply in a limited number of iterations thanks to its perturbation techniques.","Overall, 15 iterations are needed to reach values of the measure of error lower than 10%.","The equilibrium identified this way is then validated against baseline distributions to demonstrate the goodness of the results."],"url":"http://arxiv.org/abs/2404.07789v1"}
{"created":"2024-04-11 14:29:30","title":"AUG: A New Dataset and An Efficient Model for Aerial Image Urban Scene Graph Generation","abstract":"Scene graph generation (SGG) aims to understand the visual objects and their semantic relationships from one given image. Until now, lots of SGG datasets with the eyelevel view are released but the SGG dataset with the overhead view is scarcely studied. By contrast to the object occlusion problem in the eyelevel view, which impedes the SGG, the overhead view provides a new perspective that helps to promote the SGG by providing a clear perception of the spatial relationships of objects in the ground scene. To fill in the gap of the overhead view dataset, this paper constructs and releases an aerial image urban scene graph generation (AUG) dataset. Images from the AUG dataset are captured with the low-attitude overhead view. In the AUG dataset, 25,594 objects, 16,970 relationships, and 27,175 attributes are manually annotated. To avoid the local context being overwhelmed in the complex aerial urban scene, this paper proposes one new locality-preserving graph convolutional network (LPG). Different from the traditional graph convolutional network, which has the natural advantage of capturing the global context for SGG, the convolutional layer in the LPG integrates the non-destructive initial features of the objects with dynamically updated neighborhood information to preserve the local context under the premise of mining the global context. To address the problem that there exists an extra-large number of potential object relationship pairs but only a small part of them is meaningful in AUG, we propose the adaptive bounding box scaling factor for potential relationship detection (ABS-PRD) to intelligently prune the meaningless relationship pairs. Extensive experiments on the AUG dataset show that our LPG can significantly outperform the state-of-the-art methods and the effectiveness of the proposed locality-preserving strategy.","sentences":["Scene graph generation (SGG) aims to understand the visual objects and their semantic relationships from one given image.","Until now, lots of SGG datasets with the eyelevel view are released but the SGG dataset with the overhead view is scarcely studied.","By contrast to the object occlusion problem in the eyelevel view, which impedes the SGG, the overhead view provides a new perspective that helps to promote the SGG by providing a clear perception of the spatial relationships of objects in the ground scene.","To fill in the gap of the overhead view dataset, this paper constructs and releases an aerial image urban scene graph generation (AUG) dataset.","Images from the AUG dataset are captured with the low-attitude overhead view.","In the AUG dataset, 25,594 objects, 16,970 relationships, and 27,175 attributes are manually annotated.","To avoid the local context being overwhelmed in the complex aerial urban scene, this paper proposes one new locality-preserving graph convolutional network (LPG).","Different from the traditional graph convolutional network, which has the natural advantage of capturing the global context for SGG, the convolutional layer in the LPG integrates the non-destructive initial features of the objects with dynamically updated neighborhood information to preserve the local context under the premise of mining the global context.","To address the problem that there exists an extra-large number of potential object relationship pairs but only a small part of them is meaningful in AUG, we propose the adaptive bounding box scaling factor for potential relationship detection (ABS-PRD) to intelligently prune the meaningless relationship pairs.","Extensive experiments on the AUG dataset show that our LPG can significantly outperform the state-of-the-art methods and the effectiveness of the proposed locality-preserving strategy."],"url":"http://arxiv.org/abs/2404.07788v1"}
{"created":"2024-04-11 14:28:04","title":"PRAM: Place Recognition Anywhere Model for Efficient Visual Localization","abstract":"Humans localize themselves efficiently in known environments by first recognizing landmarks defined on certain objects and their spatial relationships, and then verifying the location by aligning detailed structures of recognized objects with those in the memory. Inspired by this, we propose the place recognition anywhere model (PRAM) to perform visual localization as efficiently as humans do. PRAM consists of two main components - recognition and registration. In detail, first of all, a self-supervised map-centric landmark definition strategy is adopted, making places in either indoor or outdoor scenes act as unique landmarks. Then, sparse keypoints extracted from images, are utilized as the input to a transformer-based deep neural network for landmark recognition; these keypoints enable PRAM to recognize hundreds of landmarks with high time and memory efficiency. Keypoints along with recognized landmark labels are further used for registration between query images and the 3D landmark map. Different from previous hierarchical methods, PRAM discards global and local descriptors, and reduces over 90% storage. Since PRAM utilizes recognition and landmark-wise verification to replace global reference search and exhaustive matching respectively, it runs 2.4 times faster than prior state-of-the-art approaches. Moreover, PRAM opens new directions for visual localization including multi-modality localization, map-centric feature learning, and hierarchical scene coordinate regression.","sentences":["Humans localize themselves efficiently in known environments by first recognizing landmarks defined on certain objects and their spatial relationships, and then verifying the location by aligning detailed structures of recognized objects with those in the memory.","Inspired by this, we propose the place recognition anywhere model (PRAM) to perform visual localization as efficiently as humans do.","PRAM consists of two main components - recognition and registration.","In detail, first of all, a self-supervised map-centric landmark definition strategy is adopted, making places in either indoor or outdoor scenes act as unique landmarks.","Then, sparse keypoints extracted from images, are utilized as the input to a transformer-based deep neural network for landmark recognition; these keypoints enable PRAM to recognize hundreds of landmarks with high time and memory efficiency.","Keypoints along with recognized landmark labels are further used for registration between query images and the 3D landmark map.","Different from previous hierarchical methods, PRAM discards global and local descriptors, and reduces over 90% storage.","Since PRAM utilizes recognition and landmark-wise verification to replace global reference search and exhaustive matching respectively, it runs 2.4 times faster than prior state-of-the-art approaches.","Moreover, PRAM opens new directions for visual localization including multi-modality localization, map-centric feature learning, and hierarchical scene coordinate regression."],"url":"http://arxiv.org/abs/2404.07785v1"}
{"created":"2024-04-11 14:20:38","title":"Estimating Visibility from Alternate Perspectives for Motion Planning with Occlusions","abstract":"Visibility is a crucial aspect of planning and control of autonomous vehicles (AV), particularly when navigating environments with occlusions. However, when an AV follows a trajectory with multiple occlusions, existing methods evaluate each occlusion individually, calculate a visibility cost for each, and rely on the planner to minimize the overall cost. This can result in conflicting priorities for the planner, as individual occlusion costs may appear to be in opposition. We solve this problem by creating an alternate perspective cost map that allows for an aggregate view of the occlusions in the environment. The value of each cell on the cost map is a measure of the amount of visual information that the vehicle can gain about the environment by visiting that location. Our proposed method identifies observation locations and occlusion targets drawn from both map data and sensor data. We show how to estimate an alternate perspective for each observation location and then combine all estimates into a single alternate perspective cost map for motion planning.","sentences":["Visibility is a crucial aspect of planning and control of autonomous vehicles (AV), particularly when navigating environments with occlusions.","However, when an AV follows a trajectory with multiple occlusions, existing methods evaluate each occlusion individually, calculate a visibility cost for each, and rely on the planner to minimize the overall cost.","This can result in conflicting priorities for the planner, as individual occlusion costs may appear to be in opposition.","We solve this problem by creating an alternate perspective cost map that allows for an aggregate view of the occlusions in the environment.","The value of each cell on the cost map is a measure of the amount of visual information that the vehicle can gain about the environment by visiting that location.","Our proposed method identifies observation locations and occlusion targets drawn from both map data and sensor data.","We show how to estimate an alternate perspective for each observation location and then combine all estimates into a single alternate perspective cost map for motion planning."],"url":"http://arxiv.org/abs/2404.07781v1"}
{"created":"2024-04-11 14:15:29","title":"Improving Network Degree Correlation by Degree-preserving Rewiring","abstract":"Degree correlation is a crucial measure in networks, significantly impacting network topology and dynamical behavior. The degree sequence of a network is a significant characteristic, and altering network degree correlation through degree-preserving rewiring poses an interesting problem. In this paper, we define the problem of maximizing network degree correlation through a finite number of rewirings and use the assortativity coefficient to measure it. We analyze the changes in assortativity coefficient under degree-preserving rewiring and establish its relationship with the s-metric. Under our assumptions, we prove the problem to be monotonic and submodular, leading to the proposal of the GA method to enhance network degree correlation. By formulating an integer programming model, we demonstrate that the GA method can effectively approximate the optimal solution and validate its superiority over other baseline methods through experiments on three types of real-world networks. Additionally, we introduce three heuristic rewiring strategies, EDA, TA and PEA, and demonstrate their applicability to different types of networks. Furthermore, we extend our investigation to explore the impact of these rewiring strategies on several spectral robustness metrics based on the adjacency matrix. Finally, we examine the robustness of various centrality metrics in the network while enhancing network degree correlation using the GA method.","sentences":["Degree correlation is a crucial measure in networks, significantly impacting network topology and dynamical behavior.","The degree sequence of a network is a significant characteristic, and altering network degree correlation through degree-preserving rewiring poses an interesting problem.","In this paper, we define the problem of maximizing network degree correlation through a finite number of rewirings and use the assortativity coefficient to measure it.","We analyze the changes in assortativity coefficient under degree-preserving rewiring and establish its relationship with the s-metric.","Under our assumptions, we prove the problem to be monotonic and submodular, leading to the proposal of the GA method to enhance network degree correlation.","By formulating an integer programming model, we demonstrate that the GA method can effectively approximate the optimal solution and validate its superiority over other baseline methods through experiments on three types of real-world networks.","Additionally, we introduce three heuristic rewiring strategies, EDA, TA and PEA, and demonstrate their applicability to different types of networks.","Furthermore, we extend our investigation to explore the impact of these rewiring strategies on several spectral robustness metrics based on the adjacency matrix.","Finally, we examine the robustness of various centrality metrics in the network while enhancing network degree correlation using the GA method."],"url":"http://arxiv.org/abs/2404.07779v1"}
{"created":"2024-04-11 14:13:53","title":"Unsupervised Concept Drift Detection based on Parallel Activations of Neural Network","abstract":"Practical applications of artificial intelligence increasingly often have to deal with the streaming properties of real data, which, considering the time factor, are subject to phenomena such as periodicity and more or less chaotic degeneration - resulting directly in the concept drifts. The modern concept drift detectors almost always assume immediate access to labels, which due to their cost, limited availability and possible delay has been shown to be unrealistic. This work proposes an unsupervised Parallel Activations Drift Detector, utilizing the outputs of an untrained neural network, presenting its key design elements, intuitions about processing properties, and a pool of computer experiments demonstrating its competitiveness with state-of-the-art methods.","sentences":["Practical applications of artificial intelligence increasingly often have to deal with the streaming properties of real data, which, considering the time factor, are subject to phenomena such as periodicity and more or less chaotic degeneration - resulting directly in the concept drifts.","The modern concept drift detectors almost always assume immediate access to labels, which due to their cost, limited availability and possible delay has been shown to be unrealistic.","This work proposes an unsupervised Parallel Activations Drift Detector, utilizing the outputs of an untrained neural network, presenting its key design elements, intuitions about processing properties, and a pool of computer experiments demonstrating its competitiveness with state-of-the-art methods."],"url":"http://arxiv.org/abs/2404.07776v1"}
{"created":"2024-04-11 14:13:44","title":"Discourse-Aware In-Context Learning for Temporal Expression Normalization","abstract":"Temporal expression (TE) normalization is a well-studied problem. However, the predominately used rule-based systems are highly restricted to specific settings, and upcoming machine learning approaches suffer from a lack of labeled data. In this work, we explore the feasibility of proprietary and open-source large language models (LLMs) for TE normalization using in-context learning to inject task, document, and example information into the model. We explore various sample selection strategies to retrieve the most relevant set of examples. By using a window-based prompt design approach, we can perform TE normalization across sentences, while leveraging the LLM knowledge without training the model. Our experiments show competitive results to models designed for this task. In particular, our method achieves large performance improvements for non-standard settings by dynamically including relevant examples during inference.","sentences":["Temporal expression (TE) normalization is a well-studied problem.","However, the predominately used rule-based systems are highly restricted to specific settings, and upcoming machine learning approaches suffer from a lack of labeled data.","In this work, we explore the feasibility of proprietary and open-source large language models (LLMs) for TE normalization using in-context learning to inject task, document, and example information into the model.","We explore various sample selection strategies to retrieve the most relevant set of examples.","By using a window-based prompt design approach, we can perform TE normalization across sentences, while leveraging the LLM knowledge without training the model.","Our experiments show competitive results to models designed for this task.","In particular, our method achieves large performance improvements for non-standard settings by dynamically including relevant examples during inference."],"url":"http://arxiv.org/abs/2404.07775v1"}
{"created":"2024-04-11 14:09:41","title":"Sketch-Plan-Generalize: Continual Few-Shot Learning of Inductively Generalizable Spatial Concepts for Language-Guided Robot Manipulation","abstract":"Our goal is to build embodied agents that can learn inductively generalizable spatial concepts in a continual manner, e.g, constructing a tower of a given height. Existing work suffers from certain limitations (a) (Liang et al., 2023) and their multi-modal extensions, rely heavily on prior knowledge and are not grounded in the demonstrations (b) (Liu et al., 2023) lack the ability to generalize due to their purely neural approach. A key challenge is to achieve a fine balance between symbolic representations which have the capability to generalize, and neural representations that are physically grounded. In response, we propose a neuro-symbolic approach by expressing inductive concepts as symbolic compositions over grounded neural concepts. Our key insight is to decompose the concept learning problem into the following steps 1) Sketch: Getting a programmatic representation for the given instruction 2) Plan: Perform Model-Based RL over the sequence of grounded neural action concepts to learn a grounded plan 3) Generalize: Abstract out a generic (lifted) Python program to facilitate generalizability. Continual learning is achieved by interspersing learning of grounded neural concepts with higher level symbolic constructs. Our experiments demonstrate that our approach significantly outperforms existing baselines in terms of its ability to learn novel concepts and generalize inductively.","sentences":["Our goal is to build embodied agents that can learn inductively generalizable spatial concepts in a continual manner, e.g, constructing a tower of a given height.","Existing work suffers from certain limitations (a) (Liang et al., 2023) and their multi-modal extensions, rely heavily on prior knowledge and are not grounded in the demonstrations (b) (Liu et al., 2023) lack the ability to generalize due to their purely neural approach.","A key challenge is to achieve a fine balance between symbolic representations which have the capability to generalize, and neural representations that are physically grounded.","In response, we propose a neuro-symbolic approach by expressing inductive concepts as symbolic compositions over grounded neural concepts.","Our key insight is to decompose the concept learning problem into the following steps 1) Sketch: Getting a programmatic representation for the given instruction 2) Plan: Perform Model-Based RL over the sequence of grounded neural action concepts to learn a grounded plan 3) Generalize:","Abstract out a generic (lifted) Python program to facilitate generalizability.","Continual learning is achieved by interspersing learning of grounded neural concepts with higher level symbolic constructs.","Our experiments demonstrate that our approach significantly outperforms existing baselines in terms of its ability to learn novel concepts and generalize inductively."],"url":"http://arxiv.org/abs/2404.07774v1"}
{"created":"2024-04-11 14:08:45","title":"ConsistencyDet: Robust Object Detector with Denoising Paradigm of Consistency Model","abstract":"Object detection, a quintessential task in the realm of perceptual computing, can be tackled using a generative methodology. In the present study, we introduce a novel framework designed to articulate object detection as a denoising diffusion process, which operates on perturbed bounding boxes of annotated entities. This framework, termed ConsistencyDet, leverages an innovative denoising concept known as the Consistency Model. The hallmark of this model is its self-consistency feature, which empowers the model to map distorted information from any temporal stage back to its pristine state, thereby realizing a ``one-step denoising'' mechanism. Such an attribute markedly elevates the operational efficiency of the model, setting it apart from the conventional Diffusion Model. Throughout the training phase, ConsistencyDet initiates the diffusion sequence with noise-infused boxes derived from the ground-truth annotations and conditions the model to perform the denoising task. Subsequently, in the inference stage, the model employs a denoising sampling strategy that commences with bounding boxes randomly sampled from a normal distribution. Through iterative refinement, the model transforms an assortment of arbitrarily generated boxes into the definitive detections. Comprehensive evaluations employing standard benchmarks, such as MS-COCO and LVIS, corroborate that ConsistencyDet surpasses other leading-edge detectors in performance metrics.","sentences":["Object detection, a quintessential task in the realm of perceptual computing, can be tackled using a generative methodology.","In the present study, we introduce a novel framework designed to articulate object detection as a denoising diffusion process, which operates on perturbed bounding boxes of annotated entities.","This framework, termed ConsistencyDet, leverages an innovative denoising concept known as the Consistency Model.","The hallmark of this model is its self-consistency feature, which empowers the model to map distorted information from any temporal stage back to its pristine state, thereby realizing a ``one-step denoising'' mechanism.","Such an attribute markedly elevates the operational efficiency of the model, setting it apart from the conventional Diffusion Model.","Throughout the training phase, ConsistencyDet initiates the diffusion sequence with noise-infused boxes derived from the ground-truth annotations and conditions the model to perform the denoising task.","Subsequently, in the inference stage, the model employs a denoising sampling strategy that commences with bounding boxes randomly sampled from a normal distribution.","Through iterative refinement, the model transforms an assortment of arbitrarily generated boxes into the definitive detections.","Comprehensive evaluations employing standard benchmarks, such as MS-COCO and LVIS, corroborate that ConsistencyDet surpasses other leading-edge detectors in performance metrics."],"url":"http://arxiv.org/abs/2404.07773v1"}
{"created":"2024-04-11 14:07:25","title":"An Overview of Diffusion Models: Applications, Guided Generation, Statistical Rates and Optimization","abstract":"Diffusion models, a powerful and universal generative AI technology, have achieved tremendous success in computer vision, audio, reinforcement learning, and computational biology. In these applications, diffusion models provide flexible high-dimensional data modeling, and act as a sampler for generating new samples under active guidance towards task-desired properties. Despite the significant empirical success, theory of diffusion models is very limited, potentially slowing down principled methodological innovations for further harnessing and improving diffusion models. In this paper, we review emerging applications of diffusion models, understanding their sample generation under various controls. Next, we overview the existing theories of diffusion models, covering their statistical properties and sampling capabilities. We adopt a progressive routine, beginning with unconditional diffusion models and connecting to conditional counterparts. Further, we review a new avenue in high-dimensional structured optimization through conditional diffusion models, where searching for solutions is reformulated as a conditional sampling problem and solved by diffusion models. Lastly, we discuss future directions about diffusion models. The purpose of this paper is to provide a well-rounded theoretical exposure for stimulating forward-looking theories and methods of diffusion models.","sentences":["Diffusion models, a powerful and universal generative AI technology, have achieved tremendous success in computer vision, audio, reinforcement learning, and computational biology.","In these applications, diffusion models provide flexible high-dimensional data modeling, and act as a sampler for generating new samples under active guidance towards task-desired properties.","Despite the significant empirical success, theory of diffusion models is very limited, potentially slowing down principled methodological innovations for further harnessing and improving diffusion models.","In this paper, we review emerging applications of diffusion models, understanding their sample generation under various controls.","Next, we overview the existing theories of diffusion models, covering their statistical properties and sampling capabilities.","We adopt a progressive routine, beginning with unconditional diffusion models and connecting to conditional counterparts.","Further, we review a new avenue in high-dimensional structured optimization through conditional diffusion models, where searching for solutions is reformulated as a conditional sampling problem and solved by diffusion models.","Lastly, we discuss future directions about diffusion models.","The purpose of this paper is to provide a well-rounded theoretical exposure for stimulating forward-looking theories and methods of diffusion models."],"url":"http://arxiv.org/abs/2404.07771v1"}
