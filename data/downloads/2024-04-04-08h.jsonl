{"created":"2024-04-03 17:59:53","title":"Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction","abstract":"We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine \"next-scale prediction\" or \"next-resolution prediction\", diverging from the standard raster-scan \"next-token prediction\". This simple, intuitive methodology allows autoregressive (AR) transformers to learn visual distributions fast and generalize well: VAR, for the first time, makes AR models surpass diffusion transformers in image generation. On ImageNet 256x256 benchmark, VAR significantly improve AR baseline by improving Frechet inception distance (FID) from 18.65 to 1.80, inception score (IS) from 80.4 to 356.4, with around 20x faster inference speed. It is also empirically verified that VAR outperforms the Diffusion Transformer (DiT) in multiple dimensions including image quality, inference speed, data efficiency, and scalability. Scaling up VAR models exhibits clear power-law scaling laws similar to those observed in LLMs, with linear correlation coefficients near -0.998 as solid evidence. VAR further showcases zero-shot generalization ability in downstream tasks including image in-painting, out-painting, and editing. These results suggest VAR has initially emulated the two important properties of LLMs: Scaling Laws and zero-shot task generalization. We have released all models and codes to promote the exploration of AR/VAR models for visual generation and unified learning.","sentences":["We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine \"next-scale prediction\" or \"next-resolution prediction\", diverging from the standard raster-scan \"next-token prediction\".","This simple, intuitive methodology allows autoregressive (AR) transformers to learn visual distributions fast and generalize well: VAR, for the first time, makes AR models surpass diffusion transformers in image generation.","On ImageNet 256x256 benchmark, VAR significantly improve AR baseline by improving Frechet inception distance (FID) from 18.65 to 1.80, inception score (IS) from 80.4 to 356.4, with around 20x faster inference speed.","It is also empirically verified that VAR outperforms the Diffusion Transformer (DiT) in multiple dimensions including image quality, inference speed, data efficiency, and scalability.","Scaling up VAR models exhibits clear power-law scaling laws similar to those observed in LLMs, with linear correlation coefficients near -0.998 as solid evidence.","VAR further showcases zero-shot generalization ability in downstream tasks including image in-painting, out-painting, and editing.","These results suggest VAR has initially emulated the two important properties of LLMs: Scaling Laws and zero-shot task generalization.","We have released all models and codes to promote the exploration of AR/VAR models for visual generation and unified learning."],"url":"http://arxiv.org/abs/2404.02905v1"}
{"created":"2024-04-03 17:59:36","title":"ALOHa: A New Measure for Hallucination in Captioning Models","abstract":"Despite recent advances in multimodal pre-training for visual description, state-of-the-art models still produce captions containing errors, such as hallucinating objects not present in a scene. The existing prominent metric for object hallucination, CHAIR, is limited to a fixed set of MS COCO objects and synonyms. In this work, we propose a modernized open-vocabulary metric, ALOHa, which leverages large language models (LLMs) to measure object hallucinations. Specifically, we use an LLM to extract groundable objects from a candidate caption, measure their semantic similarity to reference objects from captions and object detections, and use Hungarian matching to produce a final hallucination score. We show that ALOHa correctly identifies 13.6% more hallucinated objects than CHAIR on HAT, a new gold-standard subset of MS COCO Captions annotated for hallucinations, and 30.8% more on nocaps, where objects extend beyond MS COCO categories. Our code is available at https://davidmchan.github.io/aloha/.","sentences":["Despite recent advances in multimodal pre-training for visual description, state-of-the-art models still produce captions containing errors, such as hallucinating objects not present in a scene.","The existing prominent metric for object hallucination, CHAIR, is limited to a fixed set of MS COCO objects and synonyms.","In this work, we propose a modernized open-vocabulary metric, ALOHa, which leverages large language models (LLMs) to measure object hallucinations.","Specifically, we use an LLM to extract groundable objects from a candidate caption, measure their semantic similarity to reference objects from captions and object detections, and use Hungarian matching to produce a final hallucination score.","We show that ALOHa correctly identifies 13.6% more hallucinated objects than CHAIR on HAT, a new gold-standard subset of MS COCO Captions annotated for hallucinations, and 30.8% more on nocaps, where objects extend beyond MS COCO categories.","Our code is available at https://davidmchan.github.io/aloha/."],"url":"http://arxiv.org/abs/2404.02904v1"}
{"created":"2024-04-03 17:59:28","title":"LidarDM: Generative LiDAR Simulation in a Generated World","abstract":"We present LidarDM, a novel LiDAR generative model capable of producing realistic, layout-aware, physically plausible, and temporally coherent LiDAR videos. LidarDM stands out with two unprecedented capabilities in LiDAR generative modeling: (i) LiDAR generation guided by driving scenarios, offering significant potential for autonomous driving simulations, and (ii) 4D LiDAR point cloud generation, enabling the creation of realistic and temporally coherent sequences. At the heart of our model is a novel integrated 4D world generation framework. Specifically, we employ latent diffusion models to generate the 3D scene, combine it with dynamic actors to form the underlying 4D world, and subsequently produce realistic sensory observations within this virtual environment. Our experiments indicate that our approach outperforms competing algorithms in realism, temporal coherency, and layout consistency. We additionally show that LidarDM can be used as a generative world model simulator for training and testing perception models.","sentences":["We present LidarDM, a novel LiDAR generative model capable of producing realistic, layout-aware, physically plausible, and temporally coherent LiDAR videos.","LidarDM stands out with two unprecedented capabilities in LiDAR generative modeling: (i) LiDAR generation guided by driving scenarios, offering significant potential for autonomous driving simulations, and (ii) 4D LiDAR point cloud generation, enabling the creation of realistic and temporally coherent sequences.","At the heart of our model is a novel integrated 4D world generation framework.","Specifically, we employ latent diffusion models to generate the 3D scene, combine it with dynamic actors to form the underlying 4D world, and subsequently produce realistic sensory observations within this virtual environment.","Our experiments indicate that our approach outperforms competing algorithms in realism, temporal coherency, and layout consistency.","We additionally show that LidarDM can be used as a generative world model simulator for training and testing perception models."],"url":"http://arxiv.org/abs/2404.02903v1"}
{"created":"2024-04-03 17:58:21","title":"DeiT-LT Distillation Strikes Back for Vision Transformer Training on Long-Tailed Datasets","abstract":"Vision Transformer (ViT) has emerged as a prominent architecture for various computer vision tasks. In ViT, we divide the input image into patch tokens and process them through a stack of self attention blocks. However, unlike Convolutional Neural Networks (CNN), ViTs simple architecture has no informative inductive bias (e.g., locality,etc. ). Due to this, ViT requires a large amount of data for pre-training. Various data efficient approaches (DeiT) have been proposed to train ViT on balanced datasets effectively. However, limited literature discusses the use of ViT for datasets with long-tailed imbalances. In this work, we introduce DeiT-LT to tackle the problem of training ViTs from scratch on long-tailed datasets. In DeiT-LT, we introduce an efficient and effective way of distillation from CNN via distillation DIST token by using out-of-distribution images and re-weighting the distillation loss to enhance focus on tail classes. This leads to the learning of local CNN-like features in early ViT blocks, improving generalization for tail classes. Further, to mitigate overfitting, we propose distilling from a flat CNN teacher, which leads to learning low-rank generalizable features for DIST tokens across all ViT blocks. With the proposed DeiT-LT scheme, the distillation DIST token becomes an expert on the tail classes, and the classifier CLS token becomes an expert on the head classes. The experts help to effectively learn features corresponding to both the majority and minority classes using a distinct set of tokens within the same ViT architecture. We show the effectiveness of DeiT-LT for training ViT from scratch on datasets ranging from small-scale CIFAR-10 LT to large-scale iNaturalist-2018.","sentences":["Vision Transformer (ViT) has emerged as a prominent architecture for various computer vision tasks.","In ViT, we divide the input image into patch tokens and process them through a stack of self attention blocks.","However, unlike Convolutional Neural Networks (CNN), ViTs simple architecture has no informative inductive bias (e.g., locality,etc. ).","Due to this, ViT requires a large amount of data for pre-training.","Various data efficient approaches (DeiT) have been proposed to train ViT on balanced datasets effectively.","However, limited literature discusses the use of ViT for datasets with long-tailed imbalances.","In this work, we introduce DeiT-LT to tackle the problem of training ViTs from scratch on long-tailed datasets.","In DeiT-LT, we introduce an efficient and effective way of distillation from CNN via distillation DIST token by using out-of-distribution images and re-weighting the distillation loss to enhance focus on tail classes.","This leads to the learning of local CNN-like features in early ViT blocks, improving generalization for tail classes.","Further, to mitigate overfitting, we propose distilling from a flat CNN teacher, which leads to learning low-rank generalizable features for DIST tokens across all ViT blocks.","With the proposed DeiT-LT scheme, the distillation DIST token becomes an expert on the tail classes, and the classifier CLS token becomes an expert on the head classes.","The experts help to effectively learn features corresponding to both the majority and minority classes using a distinct set of tokens within the same ViT architecture.","We show the effectiveness of DeiT-LT for training ViT from scratch on datasets ranging from small-scale CIFAR-10 LT to large-scale iNaturalist-2018."],"url":"http://arxiv.org/abs/2404.02900v1"}
{"created":"2024-04-03 17:57:15","title":"MatAtlas: Text-driven Consistent Geometry Texturing and Material Assignment","abstract":"We present MatAtlas, a method for consistent text-guided 3D model texturing. Following recent progress we leverage a large scale text-to-image generation model (e.g., Stable Diffusion) as a prior to texture a 3D model. We carefully design an RGB texturing pipeline that leverages a grid pattern diffusion, driven by depth and edges. By proposing a multi-step texture refinement process, we significantly improve the quality and 3D consistency of the texturing output. To further address the problem of baked-in lighting, we move beyond RGB colors and pursue assigning parametric materials to the assets. Given the high-quality initial RGB texture, we propose a novel material retrieval method capitalized on Large Language Models (LLM), enabling editabiliy and relightability. We evaluate our method on a wide variety of geometries and show that our method significantly outperform prior arts. We also analyze the role of each component through a detailed ablation study.","sentences":["We present MatAtlas, a method for consistent text-guided 3D model texturing.","Following recent progress we leverage a large scale text-to-image generation model (e.g., Stable Diffusion) as a prior to texture a 3D model.","We carefully design an RGB texturing pipeline that leverages a grid pattern diffusion, driven by depth and edges.","By proposing a multi-step texture refinement process, we significantly improve the quality and 3D consistency of the texturing output.","To further address the problem of baked-in lighting, we move beyond RGB colors and pursue assigning parametric materials to the assets.","Given the high-quality initial RGB texture, we propose a novel material retrieval method capitalized on Large Language Models (LLM), enabling editabiliy and relightability.","We evaluate our method on a wide variety of geometries and show that our method significantly outperform prior arts.","We also analyze the role of each component through a detailed ablation study."],"url":"http://arxiv.org/abs/2404.02899v1"}
{"created":"2024-04-03 17:55:20","title":"A Mean Field Game Model for Timely Computation in Edge Computing Systems","abstract":"We consider the problem of task offloading in multi-access edge computing (MEC) systems constituting $N$ devices assisted by an edge server (ES), where the devices can split task execution between a local processor and the ES. Since the local task execution and communication with the ES both consume power, each device must judiciously choose between the two. We model the problem as a large population non-cooperative game among the $N$ devices. Since computation of an equilibrium in this scenario is difficult due to the presence of a large number of devices, we employ the mean-field game framework to reduce the finite-agent game problem to a generic user's multi-objective optimization problem, with a coupled consistency condition. By leveraging the novel age of information (AoI) metric, we invoke techniques from stochastic hybrid systems (SHS) theory and study the tradeoffs between increasing information freshness and reducing power consumption. In numerical simulations, we validate that a higher load at the ES may lead devices to upload their task to the ES less often.","sentences":["We consider the problem of task offloading in multi-access edge computing (MEC) systems constituting $N$ devices assisted by an edge server (ES), where the devices can split task execution between a local processor and the ES.","Since the local task execution and communication with the ES both consume power, each device must judiciously choose between the two.","We model the problem as a large population non-cooperative game among the $N$ devices.","Since computation of an equilibrium in this scenario is difficult due to the presence of a large number of devices, we employ the mean-field game framework to reduce the finite-agent game problem to a generic user's multi-objective optimization problem, with a coupled consistency condition.","By leveraging the novel age of information (AoI) metric, we invoke techniques from stochastic hybrid systems (SHS) theory and study the tradeoffs between increasing information freshness and reducing power consumption.","In numerical simulations, we validate that a higher load at the ES may lead devices to upload their task to the ES less often."],"url":"http://arxiv.org/abs/2404.02898v1"}
{"created":"2024-04-03 17:54:37","title":"Deep Image Composition Meets Image Forgery","abstract":"Image forgery is a topic that has been studied for many years. Before the breakthrough of deep learning, forged images were detected using handcrafted features that did not require training. These traditional methods failed to perform satisfactorily even on datasets much worse in quality than real-life image manipulations. Advances in deep learning have impacted image forgery detection as much as they have impacted other areas of computer vision and have improved the state of the art. Deep learning models require large amounts of labeled data for training. In the case of image forgery, labeled data at the pixel level is a very important factor for the models to learn. None of the existing datasets have sufficient size, realism and pixel-level labeling at the same time. This is due to the high cost of producing and labeling quality images. It can take hours for an image editing expert to manipulate just one image. To bridge this gap, we automate data generation using image composition techniques that are very related to image forgery. Unlike other automated data generation frameworks, we use state of the art image composition deep learning models to generate spliced images close to the quality of real-life manipulations. Finally, we test the generated dataset on the SOTA image manipulation detection model and show that its prediction performance is lower compared to existing datasets, i.e. we produce realistic images that are more difficult to detect. Dataset will be available at https://github.com/99eren99/DIS25k .","sentences":["Image forgery is a topic that has been studied for many years.","Before the breakthrough of deep learning, forged images were detected using handcrafted features that did not require training.","These traditional methods failed to perform satisfactorily even on datasets much worse in quality than real-life image manipulations.","Advances in deep learning have impacted image forgery detection as much as they have impacted other areas of computer vision and have improved the state of the art.","Deep learning models require large amounts of labeled data for training.","In the case of image forgery, labeled data at the pixel level is a very important factor for the models to learn.","None of the existing datasets have sufficient size, realism and pixel-level labeling at the same time.","This is due to the high cost of producing and labeling quality images.","It can take hours for an image editing expert to manipulate just one image.","To bridge this gap, we automate data generation using image composition techniques that are very related to image forgery.","Unlike other automated data generation frameworks, we use state of the art image composition deep learning models to generate spliced images close to the quality of real-life manipulations.","Finally, we test the generated dataset on the SOTA image manipulation detection model and show that its prediction performance is lower compared to existing datasets, i.e. we produce realistic images that are more difficult to detect.","Dataset will be available at https://github.com/99eren99/DIS25k ."],"url":"http://arxiv.org/abs/2404.02897v1"}
{"created":"2024-04-03 17:53:32","title":"Comment on \"Machine learning conservation laws from differential equations\"","abstract":"In lieu of abstract, first paragraph reads: Six months after the author derived a constant of motion for a 1D damped harmonic oscillator [1], a similar result appeared by Liu, Madhavan, and Tegmark [2, 3], without citing the author. However, their derivation contained six serious errors, causing both their method and result to be incorrect. In this Comment, those errors are reviewed.","sentences":["In lieu of abstract, first paragraph reads: Six months after the author derived a constant of motion for a 1D damped harmonic oscillator [1], a similar result appeared by Liu, Madhavan, and Tegmark","[2, 3], without citing the author.","However, their derivation contained six serious errors, causing both their method and result to be incorrect.","In this Comment, those errors are reviewed."],"url":"http://arxiv.org/abs/2404.02896v1"}
{"created":"2024-04-03 17:51:20","title":"Automated Transparency: A Legal and Empirical Analysis of the Digital Services Act Transparency Database","abstract":"The Digital Services Act (DSA) is a much awaited platforms liability reform in the European Union that was adopted on 1 November 2022 with the ambition to set a global example in terms of accountability and transparency. Among other obligations, the DSA emphasizes the need for online platforms to report on their content moderation decisions (`statements of reasons' - SoRs), which is a novel transparency mechanism we refer to as automated transparency in this study. SoRs are currently made available in the DSA Transparency Database, launched by the European Commission in September 2023. The DSA Transparency Database marks a historical achievement in platform governance, and allows investigations about the actual transparency gains, both at structure level as well as at the level of platform compliance. This study aims to understand whether the Transparency Database helps the DSA to live up to its transparency promises. We use legal and empirical arguments to show that while there are some transparency gains, compliance remains problematic, as the current database structure allows for a lot of discretion from platforms in terms of transparency practices. In our empirical study, we analyze a representative sample of the Transparency Database (131m SoRs) submitted in November 2023, to characterise and evaluate platform content moderation practices.","sentences":["The Digital Services Act (DSA) is a much awaited platforms liability reform in the European Union that was adopted on 1 November 2022 with the ambition to set a global example in terms of accountability and transparency.","Among other obligations, the DSA emphasizes the need for online platforms to report on their content moderation decisions (`statements of reasons' - SoRs), which is a novel transparency mechanism we refer to as automated transparency in this study.","SoRs are currently made available in the DSA Transparency Database, launched by the European Commission in September 2023.","The DSA Transparency Database marks a historical achievement in platform governance, and allows investigations about the actual transparency gains, both at structure level as well as at the level of platform compliance.","This study aims to understand whether the Transparency Database helps the DSA to live up to its transparency promises.","We use legal and empirical arguments to show that while there are some transparency gains, compliance remains problematic, as the current database structure allows for a lot of discretion from platforms in terms of transparency practices.","In our empirical study, we analyze a representative sample of the Transparency Database (131m SoRs) submitted in November 2023, to characterise and evaluate platform content moderation practices."],"url":"http://arxiv.org/abs/2404.02894v1"}
{"created":"2024-04-03 17:51:18","title":"ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline","abstract":"Large language models (LLMs) have shown excellent mastering of human language, but still struggle in real-world applications that require mathematical problem-solving. While many strategies and datasets to enhance LLMs' mathematics are developed, it remains a challenge to simultaneously maintain and improve both language and mathematical capabilities in deployed LLM systems.In this work, we tailor the Self-Critique pipeline, which addresses the challenge in the feedback learning stage of LLM alignment. We first train a general Math-Critique model from the LLM itself to provide feedback signals. Then, we sequentially employ rejective fine-tuning and direct preference optimization over the LLM's own generations for data collection. Based on ChatGLM3-32B, we conduct a series of experiments on both academic and our newly created challenging dataset, MathUserEval. Results show that our pipeline significantly enhances the LLM's mathematical problem-solving while still improving its language ability, outperforming LLMs that could be two times larger. Related techniques have been deployed to ChatGLM\\footnote{\\url{https://chatglm.cn}}, an online serving LLM. Related evaluation dataset and scripts are released at \\url{https://github.com/THUDM/ChatGLM-Math}.","sentences":["Large language models (LLMs) have shown excellent mastering of human language, but still struggle in real-world applications that require mathematical problem-solving.","While many strategies and datasets to enhance LLMs' mathematics are developed, it remains a challenge to simultaneously maintain and improve both language and mathematical capabilities in deployed LLM systems.","In this work, we tailor the Self-Critique pipeline, which addresses the challenge in the feedback learning stage of LLM alignment.","We first train a general Math-Critique model from the LLM itself to provide feedback signals.","Then, we sequentially employ rejective fine-tuning and direct preference optimization over the LLM's own generations for data collection.","Based on ChatGLM3-32B, we conduct a series of experiments on both academic and our newly created challenging dataset, MathUserEval.","Results show that our pipeline significantly enhances the LLM's mathematical problem-solving while still improving its language ability, outperforming LLMs that could be two times larger.","Related techniques have been deployed to ChatGLM\\footnote{\\url{https://chatglm.cn}}, an online serving LLM.","Related evaluation dataset and scripts are released at \\url{https://github.com/THUDM/ChatGLM-Math}."],"url":"http://arxiv.org/abs/2404.02893v1"}
{"created":"2024-04-03 17:49:41","title":"MODNO: Multi Operator Learning With Distributed Neural Operators","abstract":"The study of operator learning involves the utilization of neural networks to approximate operators. Traditionally, the focus has been on single-operator learning (SOL). However, recent advances have rapidly expanded this to include the approximation of multiple operators using foundation models equipped with millions or billions of trainable parameters, leading to the research of multi-operator learning (MOL). In this paper, we present a novel distributed training approach aimed at enabling a single neural operator with significantly fewer parameters to effectively tackle multi-operator learning challenges, all without incurring additional average costs. Our method is applicable to various Chen-Chen-type neural operators, such as Deep Operator Neural Networks (DON). The core idea is to independently learn the output basis functions for each operator using its dedicated data, while simultaneously centralizing the learning of the input function encoding shared by all operators using the entire dataset. Through a systematic study of five numerical examples, we compare the accuracy and cost of training a single neural operator for each operator independently versus training a MOL model using our proposed method. Our results demonstrate enhanced efficiency and satisfactory accuracy. Moreover, our approach illustrates that some operators with limited data can be more effectively constructed with the aid of data from analogous operators through MOL learning. This highlights another MOL's potential to bolster operator learning.","sentences":["The study of operator learning involves the utilization of neural networks to approximate operators.","Traditionally, the focus has been on single-operator learning (SOL).","However, recent advances have rapidly expanded this to include the approximation of multiple operators using foundation models equipped with millions or billions of trainable parameters, leading to the research of multi-operator learning (MOL).","In this paper, we present a novel distributed training approach aimed at enabling a single neural operator with significantly fewer parameters to effectively tackle multi-operator learning challenges, all without incurring additional average costs.","Our method is applicable to various Chen-Chen-type neural operators, such as Deep Operator Neural Networks (DON).","The core idea is to independently learn the output basis functions for each operator using its dedicated data, while simultaneously centralizing the learning of the input function encoding shared by all operators using the entire dataset.","Through a systematic study of five numerical examples, we compare the accuracy and cost of training a single neural operator for each operator independently versus training a MOL model using our proposed method.","Our results demonstrate enhanced efficiency and satisfactory accuracy.","Moreover, our approach illustrates that some operators with limited data can be more effectively constructed with the aid of data from analogous operators through MOL learning.","This highlights another MOL's potential to bolster operator learning."],"url":"http://arxiv.org/abs/2404.02892v1"}
{"created":"2024-04-03 17:44:02","title":"Steganographic Passport: An Owner and User Verifiable Credential for Deep Model IP Protection Without Retraining","abstract":"Ensuring the legal usage of deep models is crucial to promoting trustable, accountable, and responsible artificial intelligence innovation. Current passport-based methods that obfuscate model functionality for license-to-use and ownership verifications suffer from capacity and quality constraints, as they require retraining the owner model for new users. They are also vulnerable to advanced Expanded Residual Block ambiguity attacks. We propose Steganographic Passport, which uses an invertible steganographic network to decouple license-to-use from ownership verification by hiding the user's identity images into the owner-side passport and recovering them from their respective user-side passports. An irreversible and collision-resistant hash function is used to avoid exposing the owner-side passport from the derived user-side passports and increase the uniqueness of the model signature. To safeguard both the passport and model's weights against advanced ambiguity attacks, an activation-level obfuscation is proposed for the verification branch of the owner's model. By jointly training the verification and deployment branches, their weights become tightly coupled. The proposed method supports agile licensing of deep models by providing a strong ownership proof and license accountability without requiring a separate model retraining for the admission of every new user. Experiment results show that our Steganographic Passport outperforms other passport-based deep model protection methods in robustness against various known attacks.","sentences":["Ensuring the legal usage of deep models is crucial to promoting trustable, accountable, and responsible artificial intelligence innovation.","Current passport-based methods that obfuscate model functionality for license-to-use and ownership verifications suffer from capacity and quality constraints, as they require retraining the owner model for new users.","They are also vulnerable to advanced Expanded Residual Block ambiguity attacks.","We propose Steganographic Passport, which uses an invertible steganographic network to decouple license-to-use from ownership verification by hiding the user's identity images into the owner-side passport and recovering them from their respective user-side passports.","An irreversible and collision-resistant hash function is used to avoid exposing the owner-side passport from the derived user-side passports and increase the uniqueness of the model signature.","To safeguard both the passport and model's weights against advanced ambiguity attacks, an activation-level obfuscation is proposed for the verification branch of the owner's model.","By jointly training the verification and deployment branches, their weights become tightly coupled.","The proposed method supports agile licensing of deep models by providing a strong ownership proof and license accountability without requiring a separate model retraining for the admission of every new user.","Experiment results show that our Steganographic Passport outperforms other passport-based deep model protection methods in robustness against various known attacks."],"url":"http://arxiv.org/abs/2404.02889v1"}
{"created":"2024-04-03 17:42:22","title":"Learning Quadrupedal Locomotion via Differentiable Simulation","abstract":"The emergence of differentiable simulators enabling analytic gradient computation has motivated a new wave of learning algorithms that hold the potential to significantly increase sample efficiency over traditional Reinforcement Learning (RL) methods. While recent research has demonstrated performance gains in scenarios with comparatively smooth dynamics and, thus, smooth optimization landscapes, research on leveraging differentiable simulators for contact-rich scenarios, such as legged locomotion, is scarce. This may be attributed to the discontinuous nature of contact, which introduces several challenges to optimizing with analytic gradients. The purpose of this paper is to determine if analytic gradients can be beneficial even in the face of contact. Our investigation focuses on the effects of different soft and hard contact models on the learning process, examining optimization challenges through the lens of contact simulation. We demonstrate the viability of employing analytic gradients to learn physically plausible locomotion skills with a quadrupedal robot using Short-Horizon Actor-Critic (SHAC), a learning algorithm leveraging analytic gradients, and draw a comparison to a state-of-the-art RL algorithm, Proximal Policy Optimization (PPO), to understand the benefits of analytic gradients.","sentences":["The emergence of differentiable simulators enabling analytic gradient computation has motivated a new wave of learning algorithms that hold the potential to significantly increase sample efficiency over traditional Reinforcement Learning (RL) methods.","While recent research has demonstrated performance gains in scenarios with comparatively smooth dynamics and, thus, smooth optimization landscapes, research on leveraging differentiable simulators for contact-rich scenarios, such as legged locomotion, is scarce.","This may be attributed to the discontinuous nature of contact, which introduces several challenges to optimizing with analytic gradients.","The purpose of this paper is to determine if analytic gradients can be beneficial even in the face of contact.","Our investigation focuses on the effects of different soft and hard contact models on the learning process, examining optimization challenges through the lens of contact simulation.","We demonstrate the viability of employing analytic gradients to learn physically plausible locomotion skills with a quadrupedal robot using Short-Horizon Actor-Critic (SHAC), a learning algorithm leveraging analytic gradients, and draw a comparison to a state-of-the-art RL algorithm, Proximal Policy Optimization (PPO), to understand the benefits of analytic gradients."],"url":"http://arxiv.org/abs/2404.02887v1"}
{"created":"2024-04-03 17:38:15","title":"PoCo: Point Context Cluster for RGBD Indoor Place Recognition","abstract":"We present a novel end-to-end algorithm (PoCo) for the indoor RGB-D place recognition task, aimed at identifying the most likely match for a given query frame within a reference database. The task presents inherent challenges attributed to the constrained field of view and limited range of perception sensors. We propose a new network architecture, which generalizes the recent Context of Clusters (CoCs) to extract global descriptors directly from the noisy point clouds through end-to-end learning. Moreover, we develop the architecture by integrating both color and geometric modalities into the point features to enhance the global descriptor representation. We conducted evaluations on public datasets ScanNet-PR and ARKit with 807 and 5047 scenarios, respectively. PoCo achieves SOTA performance: on ScanNet-PR, we achieve R@1 of 64.63%, a 5.7% improvement from the best-published result CGis (61.12%); on Arkit, we achieve R@1 of 45.12%, a 13.3% improvement from the best-published result CGis (39.82%). In addition, PoCo shows higher efficiency than CGis in inference time (1.75X-faster), and we demonstrate the effectiveness of PoCo in recognizing places within a real-world laboratory environment.","sentences":["We present a novel end-to-end algorithm (PoCo) for the indoor RGB-D place recognition task, aimed at identifying the most likely match for a given query frame within a reference database.","The task presents inherent challenges attributed to the constrained field of view and limited range of perception sensors.","We propose a new network architecture, which generalizes the recent Context of Clusters (CoCs) to extract global descriptors directly from the noisy point clouds through end-to-end learning.","Moreover, we develop the architecture by integrating both color and geometric modalities into the point features to enhance the global descriptor representation.","We conducted evaluations on public datasets ScanNet-PR and ARKit with 807 and 5047 scenarios, respectively.","PoCo achieves SOTA performance: on ScanNet-PR, we achieve R@1 of 64.63%, a 5.7% improvement from the best-published result CGis (61.12%); on Arkit, we achieve R@1 of 45.12%, a 13.3% improvement from the best-published result CGis (39.82%).","In addition, PoCo shows higher efficiency than CGis in inference time (1.75X-faster), and we demonstrate the effectiveness of PoCo in recognizing places within a real-world laboratory environment."],"url":"http://arxiv.org/abs/2404.02885v1"}
{"created":"2024-04-03 17:34:28","title":"On the Scalability of Diffusion-based Text-to-Image Generation","abstract":"Scaling up model and data size has been quite successful for the evolution of LLMs. However, the scaling law for the diffusion based text-to-image (T2I) models is not fully explored. It is also unclear how to efficiently scale the model for better performance at reduced cost. The different training settings and expensive training cost make a fair model comparison extremely difficult. In this work, we empirically study the scaling properties of diffusion based T2I models by performing extensive and rigours ablations on scaling both denoising backbones and training set, including training scaled UNet and Transformer variants ranging from 0.4B to 4B parameters on datasets upto 600M images. For model scaling, we find the location and amount of cross attention distinguishes the performance of existing UNet designs. And increasing the transformer blocks is more parameter-efficient for improving text-image alignment than increasing channel numbers. We then identify an efficient UNet variant, which is 45% smaller and 28% faster than SDXL's UNet. On the data scaling side, we show the quality and diversity of the training set matters more than simply dataset size. Increasing caption density and diversity improves text-image alignment performance and the learning efficiency. Finally, we provide scaling functions to predict the text-image alignment performance as functions of the scale of model size, compute and dataset size.","sentences":["Scaling up model and data size has been quite successful for the evolution of LLMs.","However, the scaling law for the diffusion based text-to-image (T2I) models is not fully explored.","It is also unclear how to efficiently scale the model for better performance at reduced cost.","The different training settings and expensive training cost make a fair model comparison extremely difficult.","In this work, we empirically study the scaling properties of diffusion based T2I models by performing extensive and rigours ablations on scaling both denoising backbones and training set, including training scaled UNet and Transformer variants ranging from 0.4B to 4B parameters on datasets upto 600M images.","For model scaling, we find the location and amount of cross attention distinguishes the performance of existing UNet designs.","And increasing the transformer blocks is more parameter-efficient for improving text-image alignment than increasing channel numbers.","We then identify an efficient UNet variant, which is 45% smaller and 28% faster than SDXL's UNet.","On the data scaling side, we show the quality and diversity of the training set matters more than simply dataset size.","Increasing caption density and diversity improves text-image alignment performance and the learning efficiency.","Finally, we provide scaling functions to predict the text-image alignment performance as functions of the scale of model size, compute and dataset size."],"url":"http://arxiv.org/abs/2404.02883v1"}
{"created":"2024-04-03 17:33:21","title":"Linear Attention Sequence Parallelism","abstract":"Sequence Parallel (SP) serves as a prevalent strategy to handle long sequences that exceed the memory limit of a single GPU. However, existing SP methods do not take advantage of linear attention features, resulting in sub-optimal parallelism efficiency and usability for linear attention-based language models. In this paper, we introduce Linear Attention Sequence Parallel (LASP), an efficient SP method tailored to linear attention-based language models. Specifically, we design an efficient point-to-point communication mechanism to leverage the right-product kernel trick of linear attention, which sharply decreases the communication overhead of SP. We also enhance the practical efficiency of LASP by performing kernel fusion and intermediate state caching, making the implementation of LASP hardware-friendly on GPU clusters. Furthermore, we meticulously ensure the compatibility of sequence-level LASP with all types of batch-level data parallel methods, which is vital for distributed training on large clusters with long sequences and large batches. We conduct extensive experiments on two linear attention-based models with varying sequence lengths and GPU cluster sizes. LASP scales sequence length up to 4096K using 128 A100 80G GPUs on 1B models, which is 8 times longer than existing SP methods while being significantly faster. The code is available at https://github.com/OpenNLPLab/LASP.","sentences":["Sequence Parallel (SP) serves as a prevalent strategy to handle long sequences that exceed the memory limit of a single GPU.","However, existing SP methods do not take advantage of linear attention features, resulting in sub-optimal parallelism efficiency and usability for linear attention-based language models.","In this paper, we introduce Linear Attention Sequence Parallel (LASP), an efficient SP method tailored to linear attention-based language models.","Specifically, we design an efficient point-to-point communication mechanism to leverage the right-product kernel trick of linear attention, which sharply decreases the communication overhead of SP.","We also enhance the practical efficiency of LASP by performing kernel fusion and intermediate state caching, making the implementation of LASP hardware-friendly on GPU clusters.","Furthermore, we meticulously ensure the compatibility of sequence-level LASP with all types of batch-level data parallel methods, which is vital for distributed training on large clusters with long sequences and large batches.","We conduct extensive experiments on two linear attention-based models with varying sequence lengths and GPU cluster sizes.","LASP scales sequence length up to 4096K using 128 A100 80G GPUs on 1B models, which is 8 times longer than existing SP methods while being significantly faster.","The code is available at https://github.com/OpenNLPLab/LASP."],"url":"http://arxiv.org/abs/2404.02882v1"}
{"created":"2024-04-03 17:32:52","title":"On computing approximate Lewis weights","abstract":"In this note we provide and analyze a simple method that given an $n \\times d$ matrix, outputs approximate $\\ell_p$-Lewis weights, a natural measure of the importance of the rows with respect to the $\\ell_p$ norm, for $p \\geq 2$. More precisely, we provide a simple post-processing procedure that turns natural one-sided approximate $\\ell_p$-Lewis weights into two-sided approximations. When combined with a simple one-sided approximation algorithm presented by Lee (PhD thesis, `16) this yields an algorithm for computing two-sided approximations of the $\\ell_p$-Lewis weights of an $n \\times d$-matrix using $\\mathrm{poly}(d,p)$ approximate leverage score computations. While efficient high-accuracy algorithms for approximating $\\ell_p$-Lewis had been established previously by Fazel, Lee, Padmanabhan and Sidford (SODA `22), the simple structure and approximation tolerance of our algorithm may make it of use for different applications.","sentences":["In this note we provide and analyze a simple method that given an $n \\times d$ matrix, outputs approximate $\\ell_p$-Lewis weights, a natural measure of the importance of the rows with respect to the $\\ell_p$ norm, for $p \\geq 2$.","More precisely, we provide a simple post-processing procedure that turns natural one-sided approximate $\\ell_p$-Lewis weights into two-sided approximations.","When combined with a simple one-sided approximation algorithm presented by Lee (PhD thesis, `16) this yields an algorithm for computing two-sided approximations of the $\\ell_p$-Lewis weights of an $n \\times d$-matrix using $\\mathrm{poly}(d,p)$ approximate leverage score computations.","While efficient high-accuracy algorithms for approximating $\\ell_p$-Lewis had been established previously by Fazel, Lee, Padmanabhan and Sidford (SODA `22), the simple structure and approximation tolerance of our algorithm may make it of use for different applications."],"url":"http://arxiv.org/abs/2404.02881v1"}
{"created":"2024-04-03 17:32:50","title":"Fragmented Moments, Balanced Choices: How Do People Make Use of Their Waiting Time?","abstract":"Everyone spends some time waiting every day. HCI research has developed tools for boosting productivity while waiting. However, little is known about how people naturally spend their waiting time. We conducted an experience sampling study with 21 working adults who used a mobile app to report their daily waiting time activities over two weeks. The aim of this study is to understand the activities people do while waiting and the effect of situational factors. We found that participants spent about 60% of their waiting time on leisure activities, 20% on productive activities, and 20% on maintenance activities. These choices are sensitive to situational factors, including accessible device, location, and certain routines of the day. Our study complements previous ones by demonstrating that people purpose waiting time for various goals beyond productivity and to maintain work-life balance. Our findings shed light on future empirical research and system design for time management.","sentences":["Everyone spends some time waiting every day.","HCI research has developed tools for boosting productivity while waiting.","However, little is known about how people naturally spend their waiting time.","We conducted an experience sampling study with 21 working adults who used a mobile app to report their daily waiting time activities over two weeks.","The aim of this study is to understand the activities people do while waiting and the effect of situational factors.","We found that participants spent about 60% of their waiting time on leisure activities, 20% on productive activities, and 20% on maintenance activities.","These choices are sensitive to situational factors, including accessible device, location, and certain routines of the day.","Our study complements previous ones by demonstrating that people purpose waiting time for various goals beyond productivity and to maintain work-life balance.","Our findings shed light on future empirical research and system design for time management."],"url":"http://arxiv.org/abs/2404.02880v1"}
{"created":"2024-04-03 17:24:27","title":"FlightScope: A Deep Comprehensive Assessment of Aircraft Detection Algorithms in Satellite Imagery","abstract":"Object detection in remotely sensed satellite pictures is fundamental in many fields such as biophysical, and environmental monitoring. While deep learning algorithms are constantly evolving, they have been mostly implemented and tested on popular ground-based taken photos. This paper critically evaluates and compares a suite of advanced object detection algorithms customized for the task of identifying aircraft within satellite imagery. Using the large HRPlanesV2 dataset, together with a rigorous validation with the GDIT dataset, this research encompasses an array of methodologies including YOLO versions 5 and 8, Faster RCNN, CenterNet, RetinaNet, RTMDet, and DETR, all trained from scratch. This exhaustive training and validation study reveal YOLOv5 as the preeminent model for the specific case of identifying airplanes from remote sensing data, showcasing high precision and adaptability across diverse imaging conditions. This research highlight the nuanced performance landscapes of these algorithms, with YOLOv5 emerging as a robust solution for aerial object detection, underlining its importance through superior mean average precision, Recall, and Intersection over Union scores. The findings described here underscore the fundamental role of algorithm selection aligned with the specific demands of satellite imagery analysis and extend a comprehensive framework to evaluate model efficacy. The benchmark toolkit and codes, available via https://github.com/toelt-llc/FlightScope_Bench, aims to further exploration and innovation in the realm of remote sensing object detection, paving the way for improved analytical methodologies in satellite imagery applications.","sentences":["Object detection in remotely sensed satellite pictures is fundamental in many fields such as biophysical, and environmental monitoring.","While deep learning algorithms are constantly evolving, they have been mostly implemented and tested on popular ground-based taken photos.","This paper critically evaluates and compares a suite of advanced object detection algorithms customized for the task of identifying aircraft within satellite imagery.","Using the large HRPlanesV2 dataset, together with a rigorous validation with the GDIT dataset, this research encompasses an array of methodologies including YOLO versions 5 and 8, Faster RCNN, CenterNet, RetinaNet, RTMDet, and DETR, all trained from scratch.","This exhaustive training and validation study reveal YOLOv5 as the preeminent model for the specific case of identifying airplanes from remote sensing data, showcasing high precision and adaptability across diverse imaging conditions.","This research highlight the nuanced performance landscapes of these algorithms, with YOLOv5 emerging as a robust solution for aerial object detection, underlining its importance through superior mean average precision, Recall, and Intersection over Union scores.","The findings described here underscore the fundamental role of algorithm selection aligned with the specific demands of satellite imagery analysis and extend a comprehensive framework to evaluate model efficacy.","The benchmark toolkit and codes, available via https://github.com/toelt-llc/FlightScope_Bench, aims to further exploration and innovation in the realm of remote sensing object detection, paving the way for improved analytical methodologies in satellite imagery applications."],"url":"http://arxiv.org/abs/2404.02877v1"}
{"created":"2024-04-03 17:09:00","title":"Integrating Explanations in Learning LTL Specifications from Demonstrations","abstract":"This paper investigates whether recent advances in Large Language Models (LLMs) can assist in translating human explanations into a format that can robustly support learning Linear Temporal Logic (LTL) from demonstrations. Both LLMs and optimization-based methods can extract LTL specifications from demonstrations; however, they have distinct limitations. LLMs can quickly generate solutions and incorporate human explanations, but their lack of consistency and reliability hampers their applicability in safety-critical domains. On the other hand, optimization-based methods do provide formal guarantees but cannot process natural language explanations and face scalability challenges. We present a principled approach to combining LLMs and optimization-based methods to faithfully translate human explanations and demonstrations into LTL specifications. We have implemented a tool called Janaka based on our approach. Our experiments demonstrate the effectiveness of combining explanations with demonstrations in learning LTL specifications through several case studies.","sentences":["This paper investigates whether recent advances in Large Language Models (LLMs) can assist in translating human explanations into a format that can robustly support learning Linear Temporal Logic (LTL) from demonstrations.","Both LLMs and optimization-based methods can extract LTL specifications from demonstrations; however, they have distinct limitations.","LLMs can quickly generate solutions and incorporate human explanations, but their lack of consistency and reliability hampers their applicability in safety-critical domains.","On the other hand, optimization-based methods do provide formal guarantees but cannot process natural language explanations and face scalability challenges.","We present a principled approach to combining LLMs and optimization-based methods to faithfully translate human explanations and demonstrations into LTL specifications.","We have implemented a tool called Janaka based on our approach.","Our experiments demonstrate the effectiveness of combining explanations with demonstrations in learning LTL specifications through several case studies."],"url":"http://arxiv.org/abs/2404.02872v1"}
{"created":"2024-04-03 17:05:41","title":"Human Activity Recognition using Smartphones","abstract":"Human Activity Recognition is a subject of great research today and has its applications in remote healthcare, activity tracking of the elderly or the disables, calories burnt tracking etc. In our project, we have created an Android application that recognizes the daily human activities and calculate the calories burnt in real time. We first captured labeled triaxial acceleration readings for different daily human activities from the smartphone's embedded accelerometer. These readings were preprocessed using a median filter. 42 features were extracted using various methods. We then tested various machine learning algorithms along with dimensionality reduction. Finally, in our Android application, we used the machine learning algorithm and a subset of features that provided maximum accuracy and minimum model building time. This is used for real-time activity recognition and calculation of calories burnt using a formula based on Metabolic Equivalent.","sentences":["Human Activity Recognition is a subject of great research today and has its applications in remote healthcare, activity tracking of the elderly or the disables, calories burnt tracking etc.","In our project, we have created an Android application that recognizes the daily human activities and calculate the calories burnt in real time.","We first captured labeled triaxial acceleration readings for different daily human activities from the smartphone's embedded accelerometer.","These readings were preprocessed using a median filter.","42 features were extracted using various methods.","We then tested various machine learning algorithms along with dimensionality reduction.","Finally, in our Android application, we used the machine learning algorithm and a subset of features that provided maximum accuracy and minimum model building time.","This is used for real-time activity recognition and calculation of calories burnt using a formula based on Metabolic Equivalent."],"url":"http://arxiv.org/abs/2404.02869v1"}
{"created":"2024-04-03 17:03:18","title":"UDON: A case for offloading to general purpose compute on CXL memory","abstract":"Upcoming CXL-based disaggregated memory devices feature special purpose units to offload compute to near-memory. In this paper, we explore opportunities for offloading compute to general purpose cores on CXL memory devices, thereby enabling a greater utility and diversity of offload.   We study two classes of popular memory intensive applications: ML inference and vector database as candidates for computational offload. The study uses Arm AArch64-based dual-socket NUMA systems to emulate CXL type-2 devices.   Our study shows promising results. With our ML inference model partitioning strategy for compute offload, we can place up to 90% data in remote memory with just 20% performance trade-off. Offloading Hierarchical Navigable Small World (HNSW) kernels in vector databases can provide upto 6.87$\\times$ performance improvement with under 10% offload overhead.","sentences":["Upcoming CXL-based disaggregated memory devices feature special purpose units to offload compute to near-memory.","In this paper, we explore opportunities for offloading compute to general purpose cores on CXL memory devices, thereby enabling a greater utility and diversity of offload.   ","We study two classes of popular memory intensive applications: ML inference and vector database as candidates for computational offload.","The study uses Arm AArch64-based dual-socket NUMA systems to emulate CXL type-2 devices.   ","Our study shows promising results.","With our ML inference model partitioning strategy for compute offload, we can place up to 90% data in remote memory with just 20% performance trade-off.","Offloading Hierarchical Navigable Small World (HNSW) kernels in vector databases can provide upto 6.87$\\times$ performance improvement with under 10% offload overhead."],"url":"http://arxiv.org/abs/2404.02868v1"}
{"created":"2024-04-03 16:58:03","title":"Guarantees of confidentiality via Hammersley-Chapman-Robbins bounds","abstract":"Protecting privacy during inference with deep neural networks is possible by adding noise to the activations in the last layers prior to the final classifiers or other task-specific layers. The activations in such layers are known as \"features\" (or, less commonly, as \"embeddings\" or \"feature embeddings\"). The added noise helps prevent reconstruction of the inputs from the noisy features. Lower bounding the variance of every possible unbiased estimator of the inputs quantifies the confidentiality arising from such added noise. Convenient, computationally tractable bounds are available from classic inequalities of Hammersley and of Chapman and Robbins -- the HCR bounds. Numerical experiments indicate that the HCR bounds are on the precipice of being effectual for small neural nets with the data sets, \"MNIST\" and \"CIFAR-10,\" which contain 10 classes each for image classification. The HCR bounds appear to be insufficient on their own to guarantee confidentiality of the inputs to inference with standard deep neural nets, \"ResNet-18\" and \"Swin-T,\" pre-trained on the data set, \"ImageNet-1000,\" which contains 1000 classes. Supplementing the addition of noise to features with other methods for providing confidentiality may be warranted in the case of ImageNet. In all cases, the results reported here limit consideration to amounts of added noise that incur little degradation in the accuracy of classification from the noisy features. Thus, the added noise enhances confidentiality without much reduction in the accuracy on the task of image classification.","sentences":["Protecting privacy during inference with deep neural networks is possible by adding noise to the activations in the last layers prior to the final classifiers or other task-specific layers.","The activations in such layers are known as \"features\" (or, less commonly, as \"embeddings\" or \"feature embeddings\").","The added noise helps prevent reconstruction of the inputs from the noisy features.","Lower bounding the variance of every possible unbiased estimator of the inputs quantifies the confidentiality arising from such added noise.","Convenient, computationally tractable bounds are available from classic inequalities of Hammersley and of Chapman and Robbins -- the HCR bounds.","Numerical experiments indicate that the HCR bounds are on the precipice of being effectual for small neural nets with the data sets, \"MNIST\" and \"CIFAR-10,\" which contain 10 classes each for image classification.","The HCR bounds appear to be insufficient on their own to guarantee confidentiality of the inputs to inference with standard deep neural nets, \"ResNet-18\" and \"Swin-T,\" pre-trained on the data set, \"ImageNet-1000,\" which contains 1000 classes.","Supplementing the addition of noise to features with other methods for providing confidentiality may be warranted in the case of ImageNet.","In all cases, the results reported here limit consideration to amounts of added noise that incur little degradation in the accuracy of classification from the noisy features.","Thus, the added noise enhances confidentiality without much reduction in the accuracy on the task of image classification."],"url":"http://arxiv.org/abs/2404.02866v1"}
{"created":"2024-04-03 16:57:26","title":"End-To-End Self-tuning Self-supervised Time Series Anomaly Detection","abstract":"Time series anomaly detection (TSAD) finds many applications such as monitoring environmental sensors, industry KPIs, patient biomarkers, etc. A two-fold challenge for TSAD is a versatile and unsupervised model that can detect various different types of time series anomalies (spikes, discontinuities, trend shifts, etc.) without any labeled data. Modern neural networks have outstanding ability in modeling complex time series. Self-supervised models in particular tackle unsupervised TSAD by transforming the input via various augmentations to create pseudo anomalies for training. However, their performance is sensitive to the choice of augmentation, which is hard to choose in practice, while there exists no effort in the literature on data augmentation tuning for TSAD without labels. Our work aims to fill this gap. We introduce TSAP for TSA \"on autoPilot\", which can (self-)tune augmentation hyperparameters end-to-end. It stands on two key components: a differentiable augmentation architecture and an unsupervised validation loss to effectively assess the alignment between augmentation type and anomaly type. Case studies show TSAP's ability to effectively select the (discrete) augmentation type and associated (continuous) hyperparameters. In turn, it outperforms established baselines, including SOTA self-supervised models, on diverse TSAD tasks exhibiting different anomaly types.","sentences":["Time series anomaly detection (TSAD) finds many applications such as monitoring environmental sensors, industry KPIs, patient biomarkers, etc.","A two-fold challenge for TSAD is a versatile and unsupervised model that can detect various different types of time series anomalies (spikes, discontinuities, trend shifts, etc.) without any labeled data.","Modern neural networks have outstanding ability in modeling complex time series.","Self-supervised models in particular tackle unsupervised TSAD by transforming the input via various augmentations to create pseudo anomalies for training.","However, their performance is sensitive to the choice of augmentation, which is hard to choose in practice, while there exists no effort in the literature on data augmentation tuning for TSAD without labels.","Our work aims to fill this gap.","We introduce TSAP for TSA \"on autoPilot\", which can (self-)tune augmentation hyperparameters end-to-end.","It stands on two key components: a differentiable augmentation architecture and an unsupervised validation loss to effectively assess the alignment between augmentation type and anomaly type.","Case studies show TSAP's ability to effectively select the (discrete) augmentation type and associated (continuous) hyperparameters.","In turn, it outperforms established baselines, including SOTA self-supervised models, on diverse TSAD tasks exhibiting different anomaly types."],"url":"http://arxiv.org/abs/2404.02865v1"}
{"created":"2024-04-03 16:33:42","title":"Toward Inference-optimal Mixture-of-Expert Large Language Models","abstract":"Mixture-of-Expert (MoE) based large language models (LLMs), such as the recent Mixtral and DeepSeek-MoE, have shown great promise in scaling model size without suffering from the quadratic growth of training cost of dense transformers. Like dense models, training MoEs requires answering the same question: given a training budget, what is the optimal allocation on the model size and number of tokens? We study the scaling law of MoE-based LLMs regarding the relations between the model performance, model size, dataset size, and the expert degree. Echoing previous research studying MoE in different contexts, we observe the diminishing return of increasing the number of experts, but this seems to suggest we should scale the number of experts until saturation, as the training cost would remain constant, which is problematic during inference time. We propose to amend the scaling law of MoE by introducing inference efficiency as another metric besides the validation loss. We find that MoEs with a few (4/8) experts are the most serving efficient solution under the same performance, but costs 2.5-3.5x more in training. On the other hand, training a (16/32) expert MoE much smaller (70-85%) than the loss-optimal solution, but with a larger training dataset is a promising setup under a training budget.","sentences":["Mixture-of-Expert (MoE) based large language models (LLMs), such as the recent Mixtral and DeepSeek-MoE, have shown great promise in scaling model size without suffering from the quadratic growth of training cost of dense transformers.","Like dense models, training MoEs requires answering the same question: given a training budget, what is the optimal allocation on the model size and number of tokens?","We study the scaling law of MoE-based LLMs regarding the relations between the model performance, model size, dataset size, and the expert degree.","Echoing previous research studying MoE in different contexts, we observe the diminishing return of increasing the number of experts, but this seems to suggest we should scale the number of experts until saturation, as the training cost would remain constant, which is problematic during inference time.","We propose to amend the scaling law of MoE by introducing inference efficiency as another metric besides the validation loss.","We find that MoEs with a few (4/8) experts are the most serving efficient solution under the same performance, but costs 2.5-3.5x more in training.","On the other hand, training a (16/32) expert MoE much smaller (70-85%) than the loss-optimal solution, but with a larger training dataset is a promising setup under a training budget."],"url":"http://arxiv.org/abs/2404.02852v1"}
{"created":"2024-04-03 16:23:37","title":"Cross-Modal Conditioned Reconstruction for Language-guided Medical Image Segmentation","abstract":"Recent developments underscore the potential of textual information in enhancing learning models for a deeper understanding of medical visual semantics. However, language-guided medical image segmentation still faces a challenging issue. Previous works employ implicit and ambiguous architectures to embed textual information. This leads to segmentation results that are inconsistent with the semantics represented by the language, sometimes even diverging significantly. To this end, we propose a novel cross-modal conditioned Reconstruction for Language-guided Medical Image Segmentation (RecLMIS) to explicitly capture cross-modal interactions, which assumes that well-aligned medical visual features and medical notes can effectively reconstruct each other. We introduce conditioned interaction to adaptively predict patches and words of interest. Subsequently, they are utilized as conditioning factors for mutual reconstruction to align with regions described in the medical notes. Extensive experiments demonstrate the superiority of our RecLMIS, surpassing LViT by 3.74% mIoU on the publicly available MosMedData+ dataset and achieving an average increase of 1.89% mIoU for cross-domain tests on our QATA-CoV19 dataset. Simultaneously, we achieve a relative reduction of 20.2% in parameter count and a 55.5% decrease in computational load. The code will be available at https://github.com/ShashankHuang/RecLMIS.","sentences":["Recent developments underscore the potential of textual information in enhancing learning models for a deeper understanding of medical visual semantics.","However, language-guided medical image segmentation still faces a challenging issue.","Previous works employ implicit and ambiguous architectures to embed textual information.","This leads to segmentation results that are inconsistent with the semantics represented by the language, sometimes even diverging significantly.","To this end, we propose a novel cross-modal conditioned Reconstruction for Language-guided Medical Image Segmentation (RecLMIS) to explicitly capture cross-modal interactions, which assumes that well-aligned medical visual features and medical notes can effectively reconstruct each other.","We introduce conditioned interaction to adaptively predict patches and words of interest.","Subsequently, they are utilized as conditioning factors for mutual reconstruction to align with regions described in the medical notes.","Extensive experiments demonstrate the superiority of our RecLMIS, surpassing LViT by 3.74% mIoU on the publicly available MosMedData+ dataset and achieving an average increase of 1.89% mIoU for cross-domain tests on our QATA-CoV19 dataset.","Simultaneously, we achieve a relative reduction of 20.2% in parameter count and a 55.5% decrease in computational load.","The code will be available at https://github.com/ShashankHuang/RecLMIS."],"url":"http://arxiv.org/abs/2404.02845v1"}
{"created":"2024-04-03 16:19:47","title":"AI-augmented Automation for Real Driving Prediction: an Industrial Use Case","abstract":"The risen complexity of automotive systems requires new development strategies and methods to master the upcoming challenges. Traditional methods need thus to be changed by an increased level of automation, and a faster continuous improvement cycle. In this context, current vehicle performance tests represent a very time-consuming and expensive task due to the need to perform the tests in real driving conditions. As a consequence, agile/iterative processes like DevOps are largely hindered by the necessity of triggering frequent tests. This paper reports on a practical experience of developing an AI-augmented solution based on Machine Learning and Model-based Engineering to support continuous vehicle development and testing. In particular, historical data collected in real driving conditions is leveraged to synthesize a high-fidelity driving simulator and hence enable performance tests in virtual environments. Based on this practical experience, this paper also proposes a conceptual framework to support predictions based on real driving behavior.","sentences":["The risen complexity of automotive systems requires new development strategies and methods to master the upcoming challenges.","Traditional methods need thus to be changed by an increased level of automation, and a faster continuous improvement cycle.","In this context, current vehicle performance tests represent a very time-consuming and expensive task due to the need to perform the tests in real driving conditions.","As a consequence, agile/iterative processes like DevOps are largely hindered by the necessity of triggering frequent tests.","This paper reports on a practical experience of developing an AI-augmented solution based on Machine Learning and Model-based Engineering to support continuous vehicle development and testing.","In particular, historical data collected in real driving conditions is leveraged to synthesize a high-fidelity driving simulator and hence enable performance tests in virtual environments.","Based on this practical experience, this paper also proposes a conceptual framework to support predictions based on real driving behavior."],"url":"http://arxiv.org/abs/2404.02841v1"}
{"created":"2024-04-03 16:19:39","title":"A Survey on Error-Bounded Lossy Compression for Scientific Datasets","abstract":"Error-bounded lossy compression has been effective in significantly reducing the data storage/transfer burden while preserving the reconstructed data fidelity very well. Many error-bounded lossy compressors have been developed for a wide range of parallel and distributed use cases for years. These lossy compressors are designed with distinct compression models and design principles, such that each of them features particular pros and cons. In this paper we provide a comprehensive survey of emerging error-bounded lossy compression techniques for different use cases each involving big data to process. The key contribution is fourfold. (1) We summarize an insightful taxonomy of lossy compression into 6 classic compression models. (2) We provide a comprehensive survey of 10+ commonly used compression components/modules used in error-bounded lossy compressors. (3) We provide a comprehensive survey of 10+ state-of-the-art error-bounded lossy compressors as well as how they combine the various compression modules in their designs. (4) We provide a comprehensive survey of the lossy compression for 10+ modern scientific applications and use-cases. We believe this survey is useful to multiple communities including scientific applications, high-performance computing, lossy compression, and big data.","sentences":["Error-bounded lossy compression has been effective in significantly reducing the data storage/transfer burden while preserving the reconstructed data fidelity very well.","Many error-bounded lossy compressors have been developed for a wide range of parallel and distributed use cases for years.","These lossy compressors are designed with distinct compression models and design principles, such that each of them features particular pros and cons.","In this paper we provide a comprehensive survey of emerging error-bounded lossy compression techniques for different use cases each involving big data to process.","The key contribution is fourfold.","(1) We summarize an insightful taxonomy of lossy compression into 6 classic compression models.","(2) We provide a comprehensive survey of 10+ commonly used compression components/modules used in error-bounded lossy compressors.","(3) We provide a comprehensive survey of 10+ state-of-the-art error-bounded lossy compressors as well as how they combine the various compression modules in their designs.","(4) We provide a comprehensive survey of the lossy compression for 10+ modern scientific applications and use-cases.","We believe this survey is useful to multiple communities including scientific applications, high-performance computing, lossy compression, and big data."],"url":"http://arxiv.org/abs/2404.02840v1"}
{"created":"2024-04-03 16:17:53","title":"I-Design: Personalized LLM Interior Designer","abstract":"Interior design allows us to be who we are and live how we want - each design is as unique as our distinct personality. However, it is not trivial for non-professionals to express and materialize this since it requires aligning functional and visual expectations with the constraints of physical space; this renders interior design a luxury. To make it more accessible, we present I-Design, a personalized interior designer that allows users to generate and visualize their design goals through natural language communication. I-Design starts with a team of large language model agents that engage in dialogues and logical reasoning with one another, transforming textual user input into feasible scene graph designs with relative object relationships. Subsequently, an effective placement algorithm determines optimal locations for each object within the scene. The final design is then constructed in 3D by retrieving and integrating assets from an existing object database. Additionally, we propose a new evaluation protocol that utilizes a vision-language model and complements the design pipeline. Extensive quantitative and qualitative experiments show that I-Design outperforms existing methods in delivering high-quality 3D design solutions and aligning with abstract concepts that match user input, showcasing its advantages across detailed 3D arrangement and conceptual fidelity.","sentences":["Interior design allows us to be who we are and live how we want - each design is as unique as our distinct personality.","However, it is not trivial for non-professionals to express and materialize this since it requires aligning functional and visual expectations with the constraints of physical space; this renders interior design a luxury.","To make it more accessible, we present I-Design, a personalized interior designer that allows users to generate and visualize their design goals through natural language communication.","I-Design starts with a team of large language model agents that engage in dialogues and logical reasoning with one another, transforming textual user input into feasible scene graph designs with relative object relationships.","Subsequently, an effective placement algorithm determines optimal locations for each object within the scene.","The final design is then constructed in 3D by retrieving and integrating assets from an existing object database.","Additionally, we propose a new evaluation protocol that utilizes a vision-language model and complements the design pipeline.","Extensive quantitative and qualitative experiments show that I-Design outperforms existing methods in delivering high-quality 3D design solutions and aligning with abstract concepts that match user input, showcasing its advantages across detailed 3D arrangement and conceptual fidelity."],"url":"http://arxiv.org/abs/2404.02838v1"}
{"created":"2024-04-03 16:16:31","title":"Cherry on Top: Parameter Heterogeneity and Quantization in Large Language Models","abstract":"This paper reveals the phenomenon of parameter heterogeneity in large language models (LLMs). We find that a small subset of ``cherry'' parameters exhibit a disproportionately large influence on model performance, while the vast majority of parameters have minimal impact. This heterogeneity is found to be prevalent across different model families, scales, and types. Motivated by this observation, we propose CherryQ, a novel quantization method that unifies the optimization of mixed-precision parameters. CherryQ identifies and preserves the critical cherry parameters in high precision while aggressively quantizing the remaining parameters to low precision. Extensive experiments demonstrate the effectiveness of CherryQ. CherryQ outperforms existing quantization approaches in terms of perplexity and downstream task performance. Notably, our 3-bit quantized Vicuna-1.5 exhibits competitive performance compared to their 16-bit counterparts. These findings highlight the potential of CherryQ for enabling efficient deployment of LLMs by taking advantage of parameter heterogeneity.","sentences":["This paper reveals the phenomenon of parameter heterogeneity in large language models (LLMs).","We find that a small subset of ``cherry'' parameters exhibit a disproportionately large influence on model performance, while the vast majority of parameters have minimal impact.","This heterogeneity is found to be prevalent across different model families, scales, and types.","Motivated by this observation, we propose CherryQ, a novel quantization method that unifies the optimization of mixed-precision parameters.","CherryQ identifies and preserves the critical cherry parameters in high precision while aggressively quantizing the remaining parameters to low precision.","Extensive experiments demonstrate the effectiveness of CherryQ. CherryQ outperforms existing quantization approaches in terms of perplexity and downstream task performance.","Notably, our 3-bit quantized Vicuna-1.5 exhibits competitive performance compared to their 16-bit counterparts.","These findings highlight the potential of CherryQ for enabling efficient deployment of LLMs by taking advantage of parameter heterogeneity."],"url":"http://arxiv.org/abs/2404.02837v1"}
{"created":"2024-04-03 16:13:29","title":"Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation: A Systematic Comparison","abstract":"Retrieval-Augmented Neural Machine Translation (RAMT) architectures retrieve examples from memory to guide the generation process. While most works in this trend explore new ways to exploit the retrieved examples, the upstream retrieval step is mostly unexplored. In this paper, we study the effect of varying retrieval methods for several translation architectures, to better understand the interplay between these two processes. We conduct experiments in two language pairs in a multi-domain setting and consider several downstream architectures based on a standard autoregressive model, an edit-based model, and a large language model with in-context learning. Our experiments show that the choice of the retrieval technique impacts the translation scores, with variance across architectures. We also discuss the effects of increasing the number and diversity of examples, which are mostly positive across the board.","sentences":["Retrieval-Augmented Neural Machine Translation (RAMT) architectures retrieve examples from memory to guide the generation process.","While most works in this trend explore new ways to exploit the retrieved examples, the upstream retrieval step is mostly unexplored.","In this paper, we study the effect of varying retrieval methods for several translation architectures, to better understand the interplay between these two processes.","We conduct experiments in two language pairs in a multi-domain setting and consider several downstream architectures based on a standard autoregressive model, an edit-based model, and a large language model with in-context learning.","Our experiments show that the choice of the retrieval technique impacts the translation scores, with variance across architectures.","We also discuss the effects of increasing the number and diversity of examples, which are mostly positive across the board."],"url":"http://arxiv.org/abs/2404.02835v1"}
{"created":"2024-04-03 16:10:17","title":"\"Are Adversarial Phishing Webpages a Threat in Reality?\" Understanding the Users' Perception of Adversarial Webpages","abstract":"Machine learning based phishing website detectors (ML-PWD) are a critical part of today's anti-phishing solutions in operation. Unfortunately, ML-PWD are prone to adversarial evasions, evidenced by both academic studies and analyses of real-world adversarial phishing webpages. However, existing works mostly focused on assessing adversarial phishing webpages against ML-PWD, while neglecting a crucial aspect: investigating whether they can deceive the actual target of phishing -- the end users. In this paper, we fill this gap by conducting two user studies (n=470) to examine how human users perceive adversarial phishing webpages, spanning both synthetically crafted ones (which we create by evading a state-of-the-art ML-PWD) as well as real adversarial webpages (taken from the wild Web) that bypassed a production-grade ML-PWD. Our findings confirm that adversarial phishing is a threat to both users and ML-PWD, since most adversarial phishing webpages have comparable effectiveness on users w.r.t. unperturbed ones. However, not all adversarial perturbations are equally effective. For example, those with added typos are significantly more noticeable to users, who tend to overlook perturbations of higher visual magnitude (such as replacing the background). We also show that users' self-reported frequency of visiting a brand's website has a statistically negative correlation with their phishing detection accuracy, which is likely caused by overconfidence. We release our resources.","sentences":["Machine learning based phishing website detectors (ML-PWD) are a critical part of today's anti-phishing solutions in operation.","Unfortunately, ML-PWD are prone to adversarial evasions, evidenced by both academic studies and analyses of real-world adversarial phishing webpages.","However, existing works mostly focused on assessing adversarial phishing webpages against ML-PWD, while neglecting a crucial aspect: investigating whether they can deceive the actual target of phishing -- the end users.","In this paper, we fill this gap by conducting two user studies (n=470) to examine how human users perceive adversarial phishing webpages, spanning both synthetically crafted ones (which we create by evading a state-of-the-art ML-PWD) as well as real adversarial webpages (taken from the wild Web) that bypassed a production-grade ML-PWD.","Our findings confirm that adversarial phishing is a threat to both users and ML-PWD, since most adversarial phishing webpages have comparable effectiveness on users w.r.t.","unperturbed ones.","However, not all adversarial perturbations are equally effective.","For example, those with added typos are significantly more noticeable to users, who tend to overlook perturbations of higher visual magnitude (such as replacing the background).","We also show that users' self-reported frequency of visiting a brand's website has a statistically negative correlation with their phishing detection accuracy, which is likely caused by overconfidence.","We release our resources."],"url":"http://arxiv.org/abs/2404.02832v1"}
{"created":"2024-04-03 16:08:01","title":"Empowering Biomedical Discovery with AI Agents","abstract":"We envision 'AI scientists' as systems capable of skeptical learning and reasoning that empower biomedical research through collaborative agents that integrate machine learning tools with experimental platforms. Rather than taking humans out of the discovery process, biomedical AI agents combine human creativity and expertise with AI's ability to analyze large datasets, navigate hypothesis spaces, and execute repetitive tasks. AI agents are proficient in a variety of tasks, including self-assessment and planning of discovery workflows. These agents use large language models and generative models to feature structured memory for continual learning and use machine learning tools to incorporate scientific knowledge, biological principles, and theories. AI agents can impact areas ranging from hybrid cell simulation, programmable control of phenotypes, and the design of cellular circuits to the development of new therapies.","sentences":["We envision 'AI scientists' as systems capable of skeptical learning and reasoning that empower biomedical research through collaborative agents that integrate machine learning tools with experimental platforms.","Rather than taking humans out of the discovery process, biomedical AI agents combine human creativity and expertise with AI's ability to analyze large datasets, navigate hypothesis spaces, and execute repetitive tasks.","AI agents are proficient in a variety of tasks, including self-assessment and planning of discovery workflows.","These agents use large language models and generative models to feature structured memory for continual learning and use machine learning tools to incorporate scientific knowledge, biological principles, and theories.","AI agents can impact areas ranging from hybrid cell simulation, programmable control of phenotypes, and the design of cellular circuits to the development of new therapies."],"url":"http://arxiv.org/abs/2404.02831v1"}
{"created":"2024-04-03 16:04:59","title":"Enhancing Interpretability of Vertebrae Fracture Grading using Human-interpretable Prototypes","abstract":"Vertebral fracture grading classifies the severity of vertebral fractures, which is a challenging task in medical imaging and has recently attracted Deep Learning (DL) models. Only a few works attempted to make such models human-interpretable despite the need for transparency and trustworthiness in critical use cases like DL-assisted medical diagnosis. Moreover, such models either rely on post-hoc methods or additional annotations. In this work, we propose a novel interpretable-by-design method, ProtoVerse, to find relevant sub-parts of vertebral fractures (prototypes) that reliably explain the model's decision in a human-understandable way. Specifically, we introduce a novel diversity-promoting loss to mitigate prototype repetitions in small datasets with intricate semantics. We have experimented with the VerSe'19 dataset and outperformed the existing prototype-based method. Further, our model provides superior interpretability against the post-hoc method. Importantly, expert radiologists validated the visual interpretability of our results, showing clinical applicability.","sentences":["Vertebral fracture grading classifies the severity of vertebral fractures, which is a challenging task in medical imaging and has recently attracted Deep Learning (DL) models.","Only a few works attempted to make such models human-interpretable despite the need for transparency and trustworthiness in critical use cases like DL-assisted medical diagnosis.","Moreover, such models either rely on post-hoc methods or additional annotations.","In this work, we propose a novel interpretable-by-design method, ProtoVerse, to find relevant sub-parts of vertebral fractures (prototypes) that reliably explain the model's decision in a human-understandable way.","Specifically, we introduce a novel diversity-promoting loss to mitigate prototype repetitions in small datasets with intricate semantics.","We have experimented with the VerSe'19 dataset and outperformed the existing prototype-based method.","Further, our model provides superior interpretability against the post-hoc method.","Importantly, expert radiologists validated the visual interpretability of our results, showing clinical applicability."],"url":"http://arxiv.org/abs/2404.02830v1"}
{"created":"2024-04-03 15:59:42","title":"BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models","abstract":"This work presents BAdam, an optimizer that leverages the block coordinate optimization framework with Adam as the inner solver. BAdam offers a memory efficient approach to the full parameter finetuning of large language models and reduces running time of the backward process thanks to the chain rule property. Experimentally, we apply BAdam to instruction-tune the Llama 2-7B model on the Alpaca-GPT4 dataset using a single RTX3090-24GB GPU. The results indicate that BAdam exhibits superior convergence behavior in comparison to LoRA and LOMO. Furthermore, our downstream performance evaluation of the instruction-tuned models using the MT-bench shows that BAdam modestly surpasses LoRA and more substantially outperforms LOMO. Finally, we compare BAdam with Adam on a medium-sized task, i.e., finetuning RoBERTa-large on the SuperGLUE benchmark. The results demonstrate that BAdam is capable of narrowing the performance gap with Adam. Our code is available at https://github.com/Ledzy/BAdam.","sentences":["This work presents BAdam, an optimizer that leverages the block coordinate optimization framework with Adam as the inner solver.","BAdam offers a memory efficient approach to the full parameter finetuning of large language models and reduces running time of the backward process thanks to the chain rule property.","Experimentally, we apply BAdam to instruction-tune the Llama 2-7B model on the Alpaca-GPT4 dataset using a single RTX3090-24GB GPU.","The results indicate that BAdam exhibits superior convergence behavior in comparison to LoRA and LOMO.","Furthermore, our downstream performance evaluation of the instruction-tuned models using the MT-bench shows that BAdam modestly surpasses LoRA and more substantially outperforms LOMO.","Finally, we compare BAdam with Adam on a medium-sized task, i.e., finetuning RoBERTa-large on the SuperGLUE benchmark.","The results demonstrate that BAdam is capable of narrowing the performance gap with Adam.","Our code is available at https://github.com/Ledzy/BAdam."],"url":"http://arxiv.org/abs/2404.02827v1"}
{"created":"2024-04-03 15:59:31","title":"An Error-Bounded Lossy Compression Method with Bit-Adaptive Quantization for Particle Data","abstract":"This paper presents error-bounded lossy compression tailored for particle datasets from diverse scientific applications in cosmology, fluid dynamics, and fusion energy sciences. As today's high-performance computing capabilities advance, these datasets often reach trillions of points, posing significant visualization, analysis, and storage challenges. While error-bounded lossy compression makes it possible to represent floating-point values with strict pointwise accuracy guarantees, the lack of correlations in particle data's storage ordering often limits the compression ratio. Inspired by quantization-encoding schemes in SZ lossy compressors, we dynamically determine the number of bits to encode particles of the dataset to increase the compression ratio. Specifically, we utilize a k-d tree to partition particles into subregions and generate ``bit boxes'' centered at particles for each subregion to encode their positions. These bit boxes ensure error control while reducing the bit count used for compression. We comprehensively evaluate our method against state-of-the-art compressors on cosmology, fluid dynamics, and fusion plasma datasets.","sentences":["This paper presents error-bounded lossy compression tailored for particle datasets from diverse scientific applications in cosmology, fluid dynamics, and fusion energy sciences.","As today's high-performance computing capabilities advance, these datasets often reach trillions of points, posing significant visualization, analysis, and storage challenges.","While error-bounded lossy compression makes it possible to represent floating-point values with strict pointwise accuracy guarantees, the lack of correlations in particle data's storage ordering often limits the compression ratio.","Inspired by quantization-encoding schemes in SZ lossy compressors, we dynamically determine the number of bits to encode particles of the dataset to increase the compression ratio.","Specifically, we utilize a k-d tree to partition particles into subregions and generate ``bit boxes'' centered at particles for each subregion to encode their positions.","These bit boxes ensure error control while reducing the bit count used for compression.","We comprehensively evaluate our method against state-of-the-art compressors on cosmology, fluid dynamics, and fusion plasma datasets."],"url":"http://arxiv.org/abs/2404.02826v1"}
{"created":"2024-04-03 15:55:39","title":"Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models","abstract":"The ability of large language models (LLMs) to follow instructions is crucial to real-world applications. Despite recent advances, several studies have highlighted that LLMs struggle when faced with challenging instructions, especially those that include complex constraints, hindering their effectiveness in various tasks. To address this challenge, we introduce Conifer, a novel instruction tuning dataset, designed to enhance LLMs to follow multi-level instructions with complex constraints. Utilizing GPT-4, we curate the dataset by a series of LLM-driven refinement processes to ensure high quality. We also propose a progressive learning scheme that emphasizes an easy-to-hard progression, and learning from process feedback. Models trained with Conifer exhibit remarkable improvements in instruction-following abilities, especially for instructions with complex constraints. On several instruction-following benchmarks, our 7B model outperforms the state-of-the-art open-source 7B models, even exceeds the performance of models 10 times larger on certain metrics. All the code and Conifer dataset are available at https://www.github.com/ConiferLM/Conifer.","sentences":["The ability of large language models (LLMs) to follow instructions is crucial to real-world applications.","Despite recent advances, several studies have highlighted that LLMs struggle when faced with challenging instructions, especially those that include complex constraints, hindering their effectiveness in various tasks.","To address this challenge, we introduce Conifer, a novel instruction tuning dataset, designed to enhance LLMs to follow multi-level instructions with complex constraints.","Utilizing GPT-4, we curate the dataset by a series of LLM-driven refinement processes to ensure high quality.","We also propose a progressive learning scheme that emphasizes an easy-to-hard progression, and learning from process feedback.","Models trained with Conifer exhibit remarkable improvements in instruction-following abilities, especially for instructions with complex constraints.","On several instruction-following benchmarks, our 7B model outperforms the state-of-the-art open-source 7B models, even exceeds the performance of models 10 times larger on certain metrics.","All the code and Conifer dataset are available at https://www.github.com/ConiferLM/Conifer."],"url":"http://arxiv.org/abs/2404.02823v1"}
{"created":"2024-04-03 15:55:27","title":"Identifying Climate Targets in National Laws and Policies using Machine Learning","abstract":"Quantified policy targets are a fundamental element of climate policy, typically characterised by domain-specific and technical language. Current methods for curating comprehensive views of global climate policy targets entail significant manual effort. At present there are few scalable methods for extracting climate targets from national laws or policies, which limits policymakers' and researchers' ability to (1) assess private and public sector alignment with global goals and (2) inform policy decisions. In this paper we present an approach for extracting mentions of climate targets from national laws and policies. We create an expert-annotated dataset identifying three categories of target ('Net Zero', 'Reduction' and 'Other' (e.g. renewable energy targets)) and train a classifier to reliably identify them in text. We investigate bias and equity impacts related to our model and identify specific years and country names as problematic features. Finally, we investigate the characteristics of the dataset produced by running this classifier on the Climate Policy Radar (CPR) dataset of global national climate laws and policies and UNFCCC submissions, highlighting the potential of automated and scalable data collection for existing climate policy databases and supporting further research. Our work represents a significant upgrade in the accessibility of these key climate policy elements for policymakers and researchers. We publish our model at \\url{https://huggingface.co/ClimatePolicyRadar/national-climate-targets} and related dataset at \\url{https://huggingface.co/datasets/ClimatePolicyRadar/national-climate-targets}.","sentences":["Quantified policy targets are a fundamental element of climate policy, typically characterised by domain-specific and technical language.","Current methods for curating comprehensive views of global climate policy targets entail significant manual effort.","At present there are few scalable methods for extracting climate targets from national laws or policies, which limits policymakers' and researchers' ability to (1) assess private and public sector alignment with global goals and (2) inform policy decisions.","In this paper we present an approach for extracting mentions of climate targets from national laws and policies.","We create an expert-annotated dataset identifying three categories of target ('Net Zero', 'Reduction' and 'Other' (e.g. renewable energy targets)) and train a classifier to reliably identify them in text.","We investigate bias and equity impacts related to our model and identify specific years and country names as problematic features.","Finally, we investigate the characteristics of the dataset produced by running this classifier on the Climate Policy Radar (CPR) dataset of global national climate laws and policies and UNFCCC submissions, highlighting the potential of automated and scalable data collection for existing climate policy databases and supporting further research.","Our work represents a significant upgrade in the accessibility of these key climate policy elements for policymakers and researchers.","We publish our model at \\url{https://huggingface.co/ClimatePolicyRadar/national-climate-targets} and related dataset at \\url{https://huggingface.co/datasets/ClimatePolicyRadar/national-climate-targets}."],"url":"http://arxiv.org/abs/2404.02822v1"}
{"created":"2024-04-03 15:38:36","title":"A Survey of Optimization-based Task and Motion Planning: From Classical To Learning Approaches","abstract":"Task and Motion Planning (TAMP) integrates high-level task planning and low-level motion planning to equip robots with the autonomy to effectively reason over long-horizon, dynamic tasks. Optimization-based TAMP focuses on hybrid optimization approaches that define goal conditions via objective functions and are capable of handling open-ended goals, robotic dynamics, and physical interaction between the robot and the environment. Therefore, optimization-based TAMP is particularly suited to solve highly complex, contact-rich locomotion and manipulation problems. This survey provides a comprehensive review on optimization-based TAMP, covering (i) planning domain representations, including action description languages and temporal logic, (ii) individual solution strategies for components of TAMP, including AI planning and trajectory optimization (TO), and (iii) the dynamic interplay between logic-based task planning and model-based TO. A particular focus of this survey is to highlight the algorithm structures to efficiently solve TAMP, especially hierarchical and distributed approaches. Additionally, the survey emphasizes the synergy between the classical methods and contemporary learning-based innovations such as large language models. Furthermore, the future research directions for TAMP is discussed in this survey, highlighting both algorithmic and application-specific challenges.","sentences":["Task and Motion Planning (TAMP) integrates high-level task planning and low-level motion planning to equip robots with the autonomy to effectively reason over long-horizon, dynamic tasks.","Optimization-based TAMP focuses on hybrid optimization approaches that define goal conditions via objective functions and are capable of handling open-ended goals, robotic dynamics, and physical interaction between the robot and the environment.","Therefore, optimization-based TAMP is particularly suited to solve highly complex, contact-rich locomotion and manipulation problems.","This survey provides a comprehensive review on optimization-based TAMP, covering (i) planning domain representations, including action description languages and temporal logic, (ii) individual solution strategies for components of TAMP, including AI planning and trajectory optimization (TO), and (iii) the dynamic interplay between logic-based task planning and model-based TO.","A particular focus of this survey is to highlight the algorithm structures to efficiently solve TAMP, especially hierarchical and distributed approaches.","Additionally, the survey emphasizes the synergy between the classical methods and contemporary learning-based innovations such as large language models.","Furthermore, the future research directions for TAMP is discussed in this survey, highlighting both algorithmic and application-specific challenges."],"url":"http://arxiv.org/abs/2404.02817v1"}
{"created":"2024-04-03 15:31:49","title":"Wideband Beamforming for Near-Field Communications with Circular Arrays","abstract":"The beamforming performance of the uniform circular array (UCA) in near-field wideband communication systems is investigated. Compared to uniform linear array (ULA), UCA exhibits uniform effective array aperture in all directions, thus enabling more users to benefit from near-field communications. In this paper, the unique beam squint effect in near-field wideband UCA systems is comprehensively analyzed in both the distance and angular domains. It is rigorously demonstrated that the beam focal point only exists at a specific frequency in wideband UCA systems, resulting in significant beamforming loss. To alleviate this unique beam squint effect, the true-time delay (TTD)-based beamforming architecture is exploited. In particular, two wideband beamforming optimization approaches leveraging TTD units are proposed. 1) Analytical approach: In this approach, the phase shifters (PSs) and the time delay of TTD units are designed based on the analytical formula for beamforming gain. Following this design, the minimum number of TTD units required to achieve a predetermined beamforming gain is quantified. 2) Joint-optimization approach: In this method, the PSs and the TTD units are jointly optimized under practical maximum delay constraints to approximate the optimal unconstrained analog beamformer. Specifically, an efficient alternating optimization algorithm is proposed, where the PSs and the TTD units are alternately updated using either the closed-form solution or the low-complexity linear search approach. Extensive numerical results demonstrate that 1) the proposed beamforming schemes effectively mitigate the beam squint effect, and 2) the joint-optimization approach outperforms the analytical approach in terms of array gain and achievable spectral efficiency.","sentences":["The beamforming performance of the uniform circular array (UCA) in near-field wideband communication systems is investigated.","Compared to uniform linear array (ULA), UCA exhibits uniform effective array aperture in all directions, thus enabling more users to benefit from near-field communications.","In this paper, the unique beam squint effect in near-field wideband UCA systems is comprehensively analyzed in both the distance and angular domains.","It is rigorously demonstrated that the beam focal point only exists at a specific frequency in wideband UCA systems, resulting in significant beamforming loss.","To alleviate this unique beam squint effect, the true-time delay (TTD)-based beamforming architecture is exploited.","In particular, two wideband beamforming optimization approaches leveraging TTD units are proposed.","1) Analytical approach: In this approach, the phase shifters (PSs) and the time delay of TTD units are designed based on the analytical formula for beamforming gain.","Following this design, the minimum number of TTD units required to achieve a predetermined beamforming gain is quantified.","2) Joint-optimization approach: In this method, the PSs and the TTD units are jointly optimized under practical maximum delay constraints to approximate the optimal unconstrained analog beamformer.","Specifically, an efficient alternating optimization algorithm is proposed, where the PSs and the TTD units are alternately updated using either the closed-form solution or the low-complexity linear search approach.","Extensive numerical results demonstrate that 1) the proposed beamforming schemes effectively mitigate the beam squint effect, and 2) the joint-optimization approach outperforms the analytical approach in terms of array gain and achievable spectral efficiency."],"url":"http://arxiv.org/abs/2404.02811v1"}
{"created":"2024-04-03 15:31:18","title":"Generative-Contrastive Heterogeneous Graph Neural Network","abstract":"Heterogeneous Graphs (HGs) can effectively model complex relationships in the real world by multi-type nodes and edges. In recent years, inspired by self-supervised learning, contrastive Heterogeneous Graphs Neural Networks (HGNNs) have shown great potential by utilizing data augmentation and discriminators for downstream tasks. However, data augmentation is still limited due to the discrete and abstract nature of graphs. To tackle the above limitations, we propose a novel \\textit{Generative-Contrastive Heterogeneous Graph Neural Network (GC-HGNN)}. Specifically, we first propose a heterogeneous graph generative learning enhanced contrastive paradigm. This paradigm includes: 1) A contrastive view augmentation strategy by using masked autoencoder. 2) Position-aware and semantics-aware positive sample sampling strategy for generate hard negative samples. 3) A hierarchical contrastive learning strategy for capturing local and global information. Furthermore, the hierarchical contrastive learning and sampling strategies aim to constitute an enhanced discriminator under the generative-contrastive perspective. Finally, we compare our model with seventeen baselines on eight real-world datasets. Our model outperforms the latest contrastive and generative baselines on node classification and link prediction tasks. To reproduce our work, we have open-sourced our code at https://github.com/xxx.","sentences":["Heterogeneous Graphs (HGs) can effectively model complex relationships in the real world by multi-type nodes and edges.","In recent years, inspired by self-supervised learning, contrastive Heterogeneous Graphs Neural Networks (HGNNs) have shown great potential by utilizing data augmentation and discriminators for downstream tasks.","However, data augmentation is still limited due to the discrete and abstract nature of graphs.","To tackle the above limitations, we propose a novel \\textit{Generative-Contrastive Heterogeneous Graph Neural Network (GC-HGNN)}.","Specifically, we first propose a heterogeneous graph generative learning enhanced contrastive paradigm.","This paradigm includes: 1) A contrastive view augmentation strategy by using masked autoencoder.","2) Position-aware and semantics-aware positive sample sampling strategy for generate hard negative samples.","3) A hierarchical contrastive learning strategy for capturing local and global information.","Furthermore, the hierarchical contrastive learning and sampling strategies aim to constitute an enhanced discriminator under the generative-contrastive perspective.","Finally, we compare our model with seventeen baselines on eight real-world datasets.","Our model outperforms the latest contrastive and generative baselines on node classification and link prediction tasks.","To reproduce our work, we have open-sourced our code at https://github.com/xxx."],"url":"http://arxiv.org/abs/2404.02810v1"}
{"created":"2024-04-03 15:20:57","title":"The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers","abstract":"Evaluation of large language models (LLMs) for code has primarily relied on static benchmarks, including HumanEval (Chen et al., 2021), which measure the ability of LLMs to generate complete code that passes unit tests. As LLMs are increasingly used as programmer assistants, we study whether gains on existing benchmarks translate to gains in programmer productivity when coding with LLMs, including time spent coding. In addition to static benchmarks, we investigate the utility of preference metrics that might be used as proxies to measure LLM helpfulness, such as code acceptance or copy rates. To do so, we introduce RealHumanEval, a web interface to measure the ability of LLMs to assist programmers, through either autocomplete or chat support. We conducted a user study (N=213) using RealHumanEval in which users interacted with six LLMs of varying base model performance. Despite static benchmarks not incorporating humans-in-the-loop, we find that improvements in benchmark performance lead to increased programmer productivity; however gaps in benchmark versus human performance are not proportional -- a trend that holds across both forms of LLM support. In contrast, we find that programmer preferences do not correlate with their actual performance, motivating the need for better, human-centric proxy signals. We also open-source RealHumanEval to enable human-centric evaluation of new models and the study data to facilitate efforts to improve code models.","sentences":["Evaluation of large language models (LLMs) for code has primarily relied on static benchmarks, including HumanEval (Chen et al., 2021), which measure the ability of LLMs to generate complete code that passes unit tests.","As LLMs are increasingly used as programmer assistants, we study whether gains on existing benchmarks translate to gains in programmer productivity when coding with LLMs, including time spent coding.","In addition to static benchmarks, we investigate the utility of preference metrics that might be used as proxies to measure LLM helpfulness, such as code acceptance or copy rates.","To do so, we introduce RealHumanEval, a web interface to measure the ability of LLMs to assist programmers, through either autocomplete or chat support.","We conducted a user study (N=213) using RealHumanEval in which users interacted with six LLMs of varying base model performance.","Despite static benchmarks not incorporating humans-in-the-loop, we find that improvements in benchmark performance lead to increased programmer productivity; however gaps in benchmark versus human performance are not proportional -- a trend that holds across both forms of LLM support.","In contrast, we find that programmer preferences do not correlate with their actual performance, motivating the need for better, human-centric proxy signals.","We also open-source RealHumanEval to enable human-centric evaluation of new models and the study data to facilitate efforts to improve code models."],"url":"http://arxiv.org/abs/2404.02806v1"}
{"created":"2024-04-03 15:20:24","title":"Efficient Multi-Vector Dense Retrieval Using Bit Vectors","abstract":"Dense retrieval techniques employ pre-trained large language models to build a high-dimensional representation of queries and passages. These representations compute the relevance of a passage w.r.t. to a query using efficient similarity measures. In this line, multi-vector representations show improved effectiveness at the expense of a one-order-of-magnitude increase in memory footprint and query latency by encoding queries and documents on a per-token level. Recently, PLAID has tackled these problems by introducing a centroid-based term representation to reduce the memory impact of multi-vector systems. By exploiting a centroid interaction mechanism, PLAID filters out non-relevant documents, thus reducing the cost of the successive ranking stages. This paper proposes ``Efficient Multi-Vector dense retrieval with Bit vectors'' (EMVB), a novel framework for efficient query processing in multi-vector dense retrieval. First, EMVB employs a highly efficient pre-filtering step of passages using optimized bit vectors. Second, the computation of the centroid interaction happens column-wise, exploiting SIMD instructions, thus reducing its latency. Third, EMVB leverages Product Quantization (PQ) to reduce the memory footprint of storing vector representations while jointly allowing for fast late interaction. Fourth, we introduce a per-document term filtering method that further improves the efficiency of the last step. Experiments on MS MARCO and LoTTE show that EMVB is up to 2.8x faster while reducing the memory footprint by 1.8x with no loss in retrieval accuracy compared to PLAID.","sentences":["Dense retrieval techniques employ pre-trained large language models to build a high-dimensional representation of queries and passages.","These representations compute the relevance of a passage w.r.t.","to a query using efficient similarity measures.","In this line, multi-vector representations show improved effectiveness at the expense of a one-order-of-magnitude increase in memory footprint and query latency by encoding queries and documents on a per-token level.","Recently, PLAID has tackled these problems by introducing a centroid-based term representation to reduce the memory impact of multi-vector systems.","By exploiting a centroid interaction mechanism, PLAID filters out non-relevant documents, thus reducing the cost of the successive ranking stages.","This paper proposes ``Efficient Multi-Vector dense retrieval with Bit vectors'' (EMVB), a novel framework for efficient query processing in multi-vector dense retrieval.","First, EMVB employs a highly efficient pre-filtering step of passages using optimized bit vectors.","Second, the computation of the centroid interaction happens column-wise, exploiting SIMD instructions, thus reducing its latency.","Third, EMVB leverages Product Quantization (PQ) to reduce the memory footprint of storing vector representations while jointly allowing for fast late interaction.","Fourth, we introduce a per-document term filtering method that further improves the efficiency of the last step.","Experiments on MS MARCO and LoTTE show that EMVB is up to 2.8x faster while reducing the memory footprint by 1.8x with no loss in retrieval accuracy compared to PLAID."],"url":"http://arxiv.org/abs/2404.02805v1"}
{"created":"2024-04-03 15:17:21","title":"On Few-Shot Prompting for Controllable Question-Answer Generation in Narrative Comprehension","abstract":"Question Generation aims to automatically generate questions based on a given input provided as context. A controllable question generation scheme focuses on generating questions with specific attributes, allowing better control. In this study, we propose a few-shot prompting strategy for controlling the generation of question-answer pairs from children's narrative texts. We aim to control two attributes: the question's explicitness and underlying narrative elements. With empirical evaluation, we show the effectiveness of controlling the generation process by employing few-shot prompting side by side with a reference model. Our experiments highlight instances where the few-shot strategy surpasses the reference model, particularly in scenarios such as semantic closeness evaluation and the diversity and coherency of question-answer pairs. However, these improvements are not always statistically significant. The code is publicly available at github.com/bernardoleite/few-shot-prompting-qg-control.","sentences":["Question Generation aims to automatically generate questions based on a given input provided as context.","A controllable question generation scheme focuses on generating questions with specific attributes, allowing better control.","In this study, we propose a few-shot prompting strategy for controlling the generation of question-answer pairs from children's narrative texts.","We aim to control two attributes: the question's explicitness and underlying narrative elements.","With empirical evaluation, we show the effectiveness of controlling the generation process by employing few-shot prompting side by side with a reference model.","Our experiments highlight instances where the few-shot strategy surpasses the reference model, particularly in scenarios such as semantic closeness evaluation and the diversity and coherency of question-answer pairs.","However, these improvements are not always statistically significant.","The code is publicly available at github.com/bernardoleite/few-shot-prompting-qg-control."],"url":"http://arxiv.org/abs/2404.02800v1"}
{"created":"2024-04-03 15:07:00","title":"AI and personalized learning: bridging the gap with modern educational goals","abstract":"Personalized learning (PL) aspires to provide an alternative to the one-size-fits-all approach in education. Technology-based PL solutions have shown notable effectiveness in enhancing learning performance. However, their alignment with the broader goals of modern education is inconsistent across technologies and research areas. In this paper, we examine the characteristics of AI-driven PL solutions in light of the OECD Learning Compass 2030 goals. Our analysis indicates a gap between the objectives of modern education and the current direction of PL. We identify areas where most present-day PL technologies could better embrace essential elements of contemporary education, such as collaboration, cognitive engagement, and the development of general competencies. While the present PL solutions are instrumental in aiding learning processes, the PL envisioned by educational experts extends beyond simple technological tools and requires a holistic change in the educational system. Finally, we explore the potential of large language models, such as ChatGPT, and propose a hybrid model that blends artificial intelligence with a collaborative, teacher-facilitated approach to personalized learning.","sentences":["Personalized learning (PL) aspires to provide an alternative to the one-size-fits-all approach in education.","Technology-based PL solutions have shown notable effectiveness in enhancing learning performance.","However, their alignment with the broader goals of modern education is inconsistent across technologies and research areas.","In this paper, we examine the characteristics of AI-driven PL solutions in light of the OECD Learning Compass 2030 goals.","Our analysis indicates a gap between the objectives of modern education and the current direction of PL.","We identify areas where most present-day PL technologies could better embrace essential elements of contemporary education, such as collaboration, cognitive engagement, and the development of general competencies.","While the present PL solutions are instrumental in aiding learning processes, the PL envisioned by educational experts extends beyond simple technological tools and requires a holistic change in the educational system.","Finally, we explore the potential of large language models, such as ChatGPT, and propose a hybrid model that blends artificial intelligence with a collaborative, teacher-facilitated approach to personalized learning."],"url":"http://arxiv.org/abs/2404.02798v1"}
{"created":"2024-04-03 15:02:03","title":"Planning for Robust Open-loop Pushing: Exploiting Quasi-static Belief Dynamics and Contact-informed Optimization","abstract":"Non-prehensile manipulation such as pushing is typically subject to uncertain, non-smooth dynamics. However, modeling the uncertainty of the dynamics typically results in intractable belief dynamics, making data-efficient planning under uncertainty difficult. This article focuses on the problem of efficiently generating robust open-loop pushing plans. First, we investigate how the belief over object configurations propagates through quasi-static contact dynamics. We exploit the simplified dynamics to predict the variance of the object configuration without sampling from a perturbation distribution. In a sampling-based trajectory optimization algorithm, the gain of the variance is constrained in order to enforce robustness of the plan. Second, we propose an informed trajectory sampling mechanism for drawing robot trajectories that are likely to make contact with the object. This sampling mechanism is shown to significantly improve chances of finding robust solutions, especially when making-and-breaking contacts is required. We demonstrate that the proposed approach is able to synthesize bi-manual pushing trajectories, resulting in successful long-horizon pushing maneuvers without exteroceptive feedback such as vision or tactile feedback.","sentences":["Non-prehensile manipulation such as pushing is typically subject to uncertain, non-smooth dynamics.","However, modeling the uncertainty of the dynamics typically results in intractable belief dynamics, making data-efficient planning under uncertainty difficult.","This article focuses on the problem of efficiently generating robust open-loop pushing plans.","First, we investigate how the belief over object configurations propagates through quasi-static contact dynamics.","We exploit the simplified dynamics to predict the variance of the object configuration without sampling from a perturbation distribution.","In a sampling-based trajectory optimization algorithm, the gain of the variance is constrained in order to enforce robustness of the plan.","Second, we propose an informed trajectory sampling mechanism for drawing robot trajectories that are likely to make contact with the object.","This sampling mechanism is shown to significantly improve chances of finding robust solutions, especially when making-and-breaking contacts is required.","We demonstrate that the proposed approach is able to synthesize bi-manual pushing trajectories, resulting in successful long-horizon pushing maneuvers without exteroceptive feedback such as vision or tactile feedback."],"url":"http://arxiv.org/abs/2404.02795v1"}
{"created":"2024-04-03 14:58:00","title":"MULAN: A Multi Layer Annotated Dataset for Controllable Text-to-Image Generation","abstract":"Text-to-image generation has achieved astonishing results, yet precise spatial controllability and prompt fidelity remain highly challenging. This limitation is typically addressed through cumbersome prompt engineering, scene layout conditioning, or image editing techniques which often require hand drawn masks. Nonetheless, pre-existing works struggle to take advantage of the natural instance-level compositionality of scenes due to the typically flat nature of rasterized RGB output images. Towards adressing this challenge, we introduce MuLAn: a novel dataset comprising over 44K MUlti-Layer ANnotations of RGB images as multilayer, instance-wise RGBA decompositions, and over 100K instance images. To build MuLAn, we developed a training free pipeline which decomposes a monocular RGB image into a stack of RGBA layers comprising of background and isolated instances. We achieve this through the use of pretrained general-purpose models, and by developing three modules: image decomposition for instance discovery and extraction, instance completion to reconstruct occluded areas, and image re-assembly. We use our pipeline to create MuLAn-COCO and MuLAn-LAION datasets, which contain a variety of image decompositions in terms of style, composition and complexity. With MuLAn, we provide the first photorealistic resource providing instance decomposition and occlusion information for high quality images, opening up new avenues for text-to-image generative AI research. With this, we aim to encourage the development of novel generation and editing technology, in particular layer-wise solutions. MuLAn data resources are available at https://MuLAn-dataset.github.io/.","sentences":["Text-to-image generation has achieved astonishing results, yet precise spatial controllability and prompt fidelity remain highly challenging.","This limitation is typically addressed through cumbersome prompt engineering, scene layout conditioning, or image editing techniques which often require hand drawn masks.","Nonetheless, pre-existing works struggle to take advantage of the natural instance-level compositionality of scenes due to the typically flat nature of rasterized RGB output images.","Towards adressing this challenge, we introduce MuLAn: a novel dataset comprising over 44K MUlti-Layer ANnotations of RGB images as multilayer, instance-wise RGBA decompositions, and over 100K instance images.","To build MuLAn, we developed a training free pipeline which decomposes a monocular RGB image into a stack of RGBA layers comprising of background and isolated instances.","We achieve this through the use of pretrained general-purpose models, and by developing three modules: image decomposition for instance discovery and extraction, instance completion to reconstruct occluded areas, and image re-assembly.","We use our pipeline to create MuLAn-COCO and MuLAn-LAION datasets, which contain a variety of image decompositions in terms of style, composition and complexity.","With MuLAn, we provide the first photorealistic resource providing instance decomposition and occlusion information for high quality images, opening up new avenues for text-to-image generative AI research.","With this, we aim to encourage the development of novel generation and editing technology, in particular layer-wise solutions.","MuLAn data resources are available at https://MuLAn-dataset.github.io/."],"url":"http://arxiv.org/abs/2404.02790v1"}
{"created":"2024-04-03 14:56:06","title":"GenN2N: Generative NeRF2NeRF Translation","abstract":"We present GenN2N, a unified NeRF-to-NeRF translation framework for various NeRF translation tasks such as text-driven NeRF editing, colorization, super-resolution, inpainting, etc. Unlike previous methods designed for individual translation tasks with task-specific schemes, GenN2N achieves all these NeRF editing tasks by employing a plug-and-play image-to-image translator to perform editing in the 2D domain and lifting 2D edits into the 3D NeRF space. Since the 3D consistency of 2D edits may not be assured, we propose to model the distribution of the underlying 3D edits through a generative model that can cover all possible edited NeRFs. To model the distribution of 3D edited NeRFs from 2D edited images, we carefully design a VAE-GAN that encodes images while decoding NeRFs. The latent space is trained to align with a Gaussian distribution and the NeRFs are supervised through an adversarial loss on its renderings. To ensure the latent code does not depend on 2D viewpoints but truly reflects the 3D edits, we also regularize the latent code through a contrastive learning scheme. Extensive experiments on various editing tasks show GenN2N, as a universal framework, performs as well or better than task-specific specialists while possessing flexible generative power. More results on our project page: https://xiangyueliu.github.io/GenN2N/","sentences":["We present GenN2N, a unified NeRF-to-NeRF translation framework for various NeRF translation tasks such as text-driven NeRF editing, colorization, super-resolution, inpainting, etc.","Unlike previous methods designed for individual translation tasks with task-specific schemes, GenN2N achieves all these NeRF editing tasks by employing a plug-and-play image-to-image translator to perform editing in the 2D domain and lifting 2D edits into the 3D NeRF space.","Since the 3D consistency of 2D edits may not be assured, we propose to model the distribution of the underlying 3D edits through a generative model that can cover all possible edited NeRFs.","To model the distribution of 3D edited NeRFs from 2D edited images, we carefully design a VAE-GAN that encodes images while decoding NeRFs.","The latent space is trained to align with a Gaussian distribution and the NeRFs are supervised through an adversarial loss on its renderings.","To ensure the latent code does not depend on 2D viewpoints but truly reflects the 3D edits, we also regularize the latent code through a contrastive learning scheme.","Extensive experiments on various editing tasks show GenN2N, as a universal framework, performs as well or better than task-specific specialists while possessing flexible generative power.","More results on our project page: https://xiangyueliu.github.io/GenN2N/"],"url":"http://arxiv.org/abs/2404.02788v1"}
{"created":"2024-04-03 14:55:17","title":"Domain Generalization through Meta-Learning: A Survey","abstract":"Deep neural networks (DNNs) have revolutionized artificial intelligence but often lack performance when faced with out-of-distribution (OOD) data, a common scenario due to the inevitable domain shifts in real-world applications. This limitation stems from the common assumption that training and testing data share the same distribution-an assumption frequently violated in practice. Despite their effectiveness with large amounts of data and computational power, DNNs struggle with distributional shifts and limited labeled data, leading to overfitting and poor generalization across various tasks and domains. Meta-learning presents a promising approach by employing algorithms that acquire transferable knowledge across various tasks for fast adaptation, eliminating the need to learn each task from scratch. This survey paper delves into the realm of meta-learning with a focus on its contribution to domain generalization. We first clarify the concept of meta-learning for domain generalization and introduce a novel taxonomy based on the feature extraction strategy and the classifier learning methodology, offering a granular view of methodologies. Through an exhaustive review of existing methods and underlying theories, we map out the fundamentals of the field. Our survey provides practical insights and an informed discussion on promising research directions, paving the way for future innovation in meta-learning for domain generalization.","sentences":["Deep neural networks (DNNs) have revolutionized artificial intelligence but often lack performance when faced with out-of-distribution (OOD) data, a common scenario due to the inevitable domain shifts in real-world applications.","This limitation stems from the common assumption that training and testing data share the same distribution-an assumption frequently violated in practice.","Despite their effectiveness with large amounts of data and computational power, DNNs struggle with distributional shifts and limited labeled data, leading to overfitting and poor generalization across various tasks and domains.","Meta-learning presents a promising approach by employing algorithms that acquire transferable knowledge across various tasks for fast adaptation, eliminating the need to learn each task from scratch.","This survey paper delves into the realm of meta-learning with a focus on its contribution to domain generalization.","We first clarify the concept of meta-learning for domain generalization and introduce a novel taxonomy based on the feature extraction strategy and the classifier learning methodology, offering a granular view of methodologies.","Through an exhaustive review of existing methods and underlying theories, we map out the fundamentals of the field.","Our survey provides practical insights and an informed discussion on promising research directions, paving the way for future innovation in meta-learning for domain generalization."],"url":"http://arxiv.org/abs/2404.02785v1"}
{"created":"2024-04-03 14:54:59","title":"Minimizing the Number of Tardy Jobs and Maximal Tardiness on a Single Machine is NP-hard","abstract":"This paper resolves a long-standing open question in bicriteria scheduling regarding the complexity of a single machine scheduling problem which combines the number of tardy jobs and the maximal tardiness criteria. We use the lexicographic approach with the maximal tardiness being the primary criterion. Accordingly, the objective is to find, among all solutions minimizing the maximal tardiness, the one which has the minimum number of tardy jobs. The complexity of this problem has been open for over thirty years, and has been known since then to be one of the most challenging open questions in multicriteria scheduling. We resolve this question by proving that the problem is strongly NP-hard. We also prove that the problem is at least weakly NP-hard when we switch roles between the two criteria (i.e., when the number of tardy jobs is the primary criterion). Finally, we provide hardness results for two other approaches (constraint and a priori approaches) to deal with these two criteria.","sentences":["This paper resolves a long-standing open question in bicriteria scheduling regarding the complexity of a single machine scheduling problem which combines the number of tardy jobs and the maximal tardiness criteria.","We use the lexicographic approach with the maximal tardiness being the primary criterion.","Accordingly, the objective is to find, among all solutions minimizing the maximal tardiness, the one which has the minimum number of tardy jobs.","The complexity of this problem has been open for over thirty years, and has been known since then to be one of the most challenging open questions in multicriteria scheduling.","We resolve this question by proving that the problem is strongly NP-hard.","We also prove that the problem is at least weakly NP-hard when we switch roles between the two criteria (i.e., when the number of tardy jobs is the primary criterion).","Finally, we provide hardness results for two other approaches (constraint and a priori approaches) to deal with these two criteria."],"url":"http://arxiv.org/abs/2404.02784v1"}
{"created":"2024-04-03 14:47:48","title":"Federated Computing -- Survey on Building Blocks, Extensions and Systems","abstract":"In response to the increasing volume and sensitivity of data, traditional centralized computing models face challenges, such as data security breaches and regulatory hurdles. Federated Computing (FC) addresses these concerns by enabling collaborative processing without compromising individual data privacy. This is achieved through a decentralized network of devices, each retaining control over its data, while participating in collective computations. The motivation behind FC extends beyond technical considerations to encompass societal implications. As the need for responsible AI and ethical data practices intensifies, FC aligns with the principles of user empowerment and data sovereignty. FC comprises of Federated Learning (FL) and Federated Analytics (FA). FC systems became more complex over time and they currently lack a clear definition and taxonomy describing its moving pieces. Current surveys capture domain-specific FL use cases, describe individual components in an FC pipeline individually or decoupled from each other, or provide a quantitative overview of the number of published papers. This work surveys more than 150 papers to distill the underlying structure of FC systems with their basic building blocks, extensions, architecture, environment, and motivation. We capture FL and FA systems individually and point out unique difference between those two.","sentences":["In response to the increasing volume and sensitivity of data, traditional centralized computing models face challenges, such as data security breaches and regulatory hurdles.","Federated Computing (FC) addresses these concerns by enabling collaborative processing without compromising individual data privacy.","This is achieved through a decentralized network of devices, each retaining control over its data, while participating in collective computations.","The motivation behind FC extends beyond technical considerations to encompass societal implications.","As the need for responsible AI and ethical data practices intensifies, FC aligns with the principles of user empowerment and data sovereignty.","FC comprises of Federated Learning (FL) and Federated Analytics (FA).","FC systems became more complex over time and they currently lack a clear definition and taxonomy describing its moving pieces.","Current surveys capture domain-specific FL use cases, describe individual components in an FC pipeline individually or decoupled from each other, or provide a quantitative overview of the number of published papers.","This work surveys more than 150 papers to distill the underlying structure of FC systems with their basic building blocks, extensions, architecture, environment, and motivation.","We capture FL and FA systems individually and point out unique difference between those two."],"url":"http://arxiv.org/abs/2404.02779v1"}
{"created":"2024-04-03 14:39:47","title":"FPT: Feature Prompt Tuning for Few-shot Readability Assessment","abstract":"Prompt-based methods have achieved promising results in most few-shot text classification tasks. However, for readability assessment tasks, traditional prompt methods lackcrucial linguistic knowledge, which has already been proven to be essential. Moreover, previous studies on utilizing linguistic features have shown non-robust performance in few-shot settings and may even impair model performance.To address these issues, we propose a novel prompt-based tuning framework that incorporates rich linguistic knowledge, called Feature Prompt Tuning (FPT). Specifically, we extract linguistic features from the text and embed them into trainable soft prompts. Further, we devise a new loss function to calibrate the similarity ranking order between categories. Experimental results demonstrate that our proposed method FTP not only exhibits a significant performance improvement over the prior best prompt-based tuning approaches, but also surpasses the previous leading methods that incorporate linguistic features. Also, our proposed model significantly outperforms the large language model gpt-3.5-turbo-16k in most cases. Our proposed method establishes a new architecture for prompt tuning that sheds light on how linguistic features can be easily adapted to linguistic-related tasks.","sentences":["Prompt-based methods have achieved promising results in most few-shot text classification tasks.","However, for readability assessment tasks, traditional prompt methods lackcrucial linguistic knowledge, which has already been proven to be essential.","Moreover, previous studies on utilizing linguistic features have shown non-robust performance in few-shot settings and may even impair model performance.","To address these issues, we propose a novel prompt-based tuning framework that incorporates rich linguistic knowledge, called Feature Prompt Tuning (FPT).","Specifically, we extract linguistic features from the text and embed them into trainable soft prompts.","Further, we devise a new loss function to calibrate the similarity ranking order between categories.","Experimental results demonstrate that our proposed method FTP not only exhibits a significant performance improvement over the prior best prompt-based tuning approaches, but also surpasses the previous leading methods that incorporate linguistic features.","Also, our proposed model significantly outperforms the large language model gpt-3.5-turbo-16k in most cases.","Our proposed method establishes a new architecture for prompt tuning that sheds light on how linguistic features can be easily adapted to linguistic-related tasks."],"url":"http://arxiv.org/abs/2404.02772v1"}
{"created":"2024-04-03 14:37:00","title":"Forming Large Patterns with Local Robots in the OBLOT Model","abstract":"In the arbitrary pattern formation problem, $n$ autonomous, mobile robots must form an arbitrary pattern $P \\subseteq \\mathbb{R}^2$. The (deterministic) robots are typically assumed to be indistinguishable, disoriented, and unable to communicate. An important distinction is whether robots have memory and/or a limited viewing range. Previous work managed to form $P$ under a natural symmetry condition if robots have no memory but an unlimited viewing range [22] or if robots have a limited viewing range but memory [25]. In the latter case, $P$ is only formed in a shrunk version that has constant diameter.   Without memory and with limited viewing range, forming arbitrary patterns remains an open problem. We provide a partial solution by showing that $P$ can be formed under the same symmetry condition if the robots' initial diameter is $\\leq 1$. Our protocol partitions $P$ into rotation-symmetric components and exploits the initial mutual visibility to form one cluster per component. Using a careful placement of the clusters and their robots, we show that a cluster can move in a coordinated way through its component while drawing $P$ by dropping one robot per pattern coordinate.","sentences":["In the arbitrary pattern formation problem, $n$ autonomous, mobile robots must form an arbitrary pattern $P \\subseteq \\mathbb{R}^2$.","The (deterministic) robots are typically assumed to be indistinguishable, disoriented, and unable to communicate.","An important distinction is whether robots have memory and/or a limited viewing range.","Previous work managed to form $P$ under a natural symmetry condition if robots have no memory but an unlimited viewing range","[22] or if robots have a limited viewing range but memory [25].","In the latter case, $P$ is only formed in a shrunk version that has constant diameter.   ","Without memory and with limited viewing range, forming arbitrary patterns remains an open problem.","We provide a partial solution by showing that $P$ can be formed under the same symmetry condition if the robots' initial diameter is $\\leq 1$.","Our protocol partitions $P$ into rotation-symmetric components and exploits the initial mutual visibility to form one cluster per component.","Using a careful placement of the clusters and their robots, we show that a cluster can move in a coordinated way through its component while drawing $P$ by dropping one robot per pattern coordinate."],"url":"http://arxiv.org/abs/2404.02771v1"}
{"created":"2024-04-03 14:19:35","title":"Closing the Implementation Gap in MC: Fully Chemical Synchronization and Detection for Cellular Receivers","abstract":"In the context of the Internet of Bio-Nano Things (IoBNT), nano-devices are envisioned to perform complex tasks collaboratively, i.e., by communicating with each other. One candidate for the implementation of such devices are engineered cells due to their inherent biocompatibility. However, because each engineered cell has only little computational capabilities, transmitter and receiver (RX) functionalities can afford only limited complexity. In this paper, we propose a simple, yet modular, architecture for a cellular RX that is capable of processing a stream of observed symbols using chemical reaction networks. Furthermore, we propose two specific detector implementations for the RX. The first detector is based on a machine learning model that is trained offline, i.e., before the cellular RX is deployed. The second detector utilizes pilot symbol-based training and is therefore able to continuously adapt to changing channel conditions online, i.e., after deployment. To coordinate the different chemical processing steps involved in symbol detection, the proposed cellular RX leverages an internal chemical timer. Furthermore, the RX is synchronized with the transmitter via external, i.e., extracellular, signals. Finally, the proposed architecture is validated using theoretical analysis and stochastic simulations. The presented results confirm the feasibility of both proposed implementations and reveal that the proposed online learning-based RX is able to perform reliable detection even in initially unknown or slowly changing channels. By its modular design and exclusively chemical implementation, the proposed RX contributes towards the realization of versatile and biocompatible nano-scale communication networks for IoBNT applications narrowing the existing implementation gap in cellular molecular communication (MC).","sentences":["In the context of the Internet of Bio-Nano Things (IoBNT), nano-devices are envisioned to perform complex tasks collaboratively, i.e., by communicating with each other.","One candidate for the implementation of such devices are engineered cells due to their inherent biocompatibility.","However, because each engineered cell has only little computational capabilities, transmitter and receiver (RX) functionalities can afford only limited complexity.","In this paper, we propose a simple, yet modular, architecture for a cellular RX that is capable of processing a stream of observed symbols using chemical reaction networks.","Furthermore, we propose two specific detector implementations for the RX.","The first detector is based on a machine learning model that is trained offline, i.e., before the cellular RX is deployed.","The second detector utilizes pilot symbol-based training and is therefore able to continuously adapt to changing channel conditions online, i.e., after deployment.","To coordinate the different chemical processing steps involved in symbol detection, the proposed cellular RX leverages an internal chemical timer.","Furthermore, the RX is synchronized with the transmitter via external, i.e., extracellular, signals.","Finally, the proposed architecture is validated using theoretical analysis and stochastic simulations.","The presented results confirm the feasibility of both proposed implementations and reveal that the proposed online learning-based RX is able to perform reliable detection even in initially unknown or slowly changing channels.","By its modular design and exclusively chemical implementation, the proposed RX contributes towards the realization of versatile and biocompatible nano-scale communication networks for IoBNT applications narrowing the existing implementation gap in cellular molecular communication (MC)."],"url":"http://arxiv.org/abs/2404.02765v1"}
{"created":"2024-04-03 14:07:02","title":"AQuA -- Combining Experts' and Non-Experts' Views To Assess Deliberation Quality in Online Discussions Using LLMs","abstract":"Measuring the quality of contributions in political online discussions is crucial in deliberation research and computer science. Research has identified various indicators to assess online discussion quality, and with deep learning advancements, automating these measures has become feasible. While some studies focus on analyzing specific quality indicators, a comprehensive quality score incorporating various deliberative aspects is often preferred. In this work, we introduce AQuA, an additive score that calculates a unified deliberative quality score from multiple indices for each discussion post. Unlike other singular scores, AQuA preserves information on the deliberative aspects present in comments, enhancing model transparency. We develop adapter models for 20 deliberative indices, and calculate correlation coefficients between experts' annotations and the perceived deliberativeness by non-experts to weigh the individual indices into a single deliberative score. We demonstrate that the AQuA score can be computed easily from pre-trained adapters and aligns well with annotations on other datasets that have not be seen during training. The analysis of experts' vs. non-experts' annotations confirms theoretical findings in the social science literature.","sentences":["Measuring the quality of contributions in political online discussions is crucial in deliberation research and computer science.","Research has identified various indicators to assess online discussion quality, and with deep learning advancements, automating these measures has become feasible.","While some studies focus on analyzing specific quality indicators, a comprehensive quality score incorporating various deliberative aspects is often preferred.","In this work, we introduce AQuA, an additive score that calculates a unified deliberative quality score from multiple indices for each discussion post.","Unlike other singular scores, AQuA preserves information on the deliberative aspects present in comments, enhancing model transparency.","We develop adapter models for 20 deliberative indices, and calculate correlation coefficients between experts' annotations and the perceived deliberativeness by non-experts to weigh the individual indices into a single deliberative score.","We demonstrate that the AQuA score can be computed easily from pre-trained adapters and aligns well with annotations on other datasets that have not be seen during training.","The analysis of experts' vs. non-experts' annotations confirms theoretical findings in the social science literature."],"url":"http://arxiv.org/abs/2404.02761v1"}
{"created":"2024-04-03 14:05:39","title":"Unsupervised Occupancy Learning from Sparse Point Cloud","abstract":"Implicit Neural Representations have gained prominence as a powerful framework for capturing complex data modalities, encompassing a wide range from 3D shapes to images and audio. Within the realm of 3D shape representation, Neural Signed Distance Functions (SDF) have demonstrated remarkable potential in faithfully encoding intricate shape geometry. However, learning SDFs from 3D point clouds in the absence of ground truth supervision remains a very challenging task. In this paper, we propose a method to infer occupancy fields instead of SDFs as they are easier to learn from sparse inputs. We leverage a margin-based uncertainty measure to differentially sample from the decision boundary of the occupancy function and supervise the sampled boundary points using the input point cloud. We further stabilize the optimization process at the early stages of the training by biasing the occupancy function towards minimal entropy fields while maximizing its entropy at the input point cloud. Through extensive experiments and evaluations, we illustrate the efficacy of our proposed method, highlighting its capacity to improve implicit shape inference with respect to baselines and the state-of-the-art using synthetic and real data.","sentences":["Implicit Neural Representations have gained prominence as a powerful framework for capturing complex data modalities, encompassing a wide range from 3D shapes to images and audio.","Within the realm of 3D shape representation, Neural Signed Distance Functions (SDF) have demonstrated remarkable potential in faithfully encoding intricate shape geometry.","However, learning SDFs from 3D point clouds in the absence of ground truth supervision remains a very challenging task.","In this paper, we propose a method to infer occupancy fields instead of SDFs as they are easier to learn from sparse inputs.","We leverage a margin-based uncertainty measure to differentially sample from the decision boundary of the occupancy function and supervise the sampled boundary points using the input point cloud.","We further stabilize the optimization process at the early stages of the training by biasing the occupancy function towards minimal entropy fields while maximizing its entropy at the input point cloud.","Through extensive experiments and evaluations, we illustrate the efficacy of our proposed method, highlighting its capacity to improve implicit shape inference with respect to baselines and the state-of-the-art using synthetic and real data."],"url":"http://arxiv.org/abs/2404.02759v1"}
{"created":"2024-04-03 13:57:08","title":"DIBS: Enhancing Dense Video Captioning with Unlabeled Videos via Pseudo Boundary Enrichment and Online Refinement","abstract":"We present Dive Into the BoundarieS (DIBS), a novel pretraining framework for dense video captioning (DVC), that elaborates on improving the quality of the generated event captions and their associated pseudo event boundaries from unlabeled videos. By leveraging the capabilities of diverse large language models (LLMs), we generate rich DVC-oriented caption candidates and optimize the corresponding pseudo boundaries under several meticulously designed objectives, considering diversity, event-centricity, temporal ordering, and coherence. Moreover, we further introduce a novel online boundary refinement strategy that iteratively improves the quality of pseudo boundaries during training. Comprehensive experiments have been conducted to examine the effectiveness of the proposed technique components. By leveraging a substantial amount of unlabeled video data, such as HowTo100M, we achieve a remarkable advancement on standard DVC datasets like YouCook2 and ActivityNet. We outperform the previous state-of-the-art Vid2Seq across a majority of metrics, achieving this with just 0.4% of the unlabeled video data used for pre-training by Vid2Seq.","sentences":["We present Dive Into the BoundarieS (DIBS), a novel pretraining framework for dense video captioning (DVC), that elaborates on improving the quality of the generated event captions and their associated pseudo event boundaries from unlabeled videos.","By leveraging the capabilities of diverse large language models (LLMs), we generate rich DVC-oriented caption candidates and optimize the corresponding pseudo boundaries under several meticulously designed objectives, considering diversity, event-centricity, temporal ordering, and coherence.","Moreover, we further introduce a novel online boundary refinement strategy that iteratively improves the quality of pseudo boundaries during training.","Comprehensive experiments have been conducted to examine the effectiveness of the proposed technique components.","By leveraging a substantial amount of unlabeled video data, such as HowTo100M, we achieve a remarkable advancement on standard DVC datasets like YouCook2 and ActivityNet.","We outperform the previous state-of-the-art Vid2Seq across a majority of metrics, achieving this with just 0.4% of the unlabeled video data used for pre-training by Vid2Seq."],"url":"http://arxiv.org/abs/2404.02755v1"}
{"created":"2024-04-03 13:56:33","title":"Continual Learning of Numerous Tasks from Long-tail Distributions","abstract":"Continual learning, an important aspect of artificial intelligence and machine learning research, focuses on developing models that learn and adapt to new tasks while retaining previously acquired knowledge. Existing continual learning algorithms usually involve a small number of tasks with uniform sizes and may not accurately represent real-world learning scenarios. In this paper, we investigate the performance of continual learning algorithms with a large number of tasks drawn from a task distribution that is long-tail in terms of task sizes. We design one synthetic dataset and two real-world continual learning datasets to evaluate the performance of existing algorithms in such a setting. Moreover, we study an overlooked factor in continual learning, the optimizer states, e.g. first and second moments in the Adam optimizer, and investigate how it can be used to improve continual learning performance. We propose a method that reuses the optimizer states in Adam by maintaining a weighted average of the second moments from previous tasks. We demonstrate that our method, compatible with most existing continual learning algorithms, effectively reduces forgetting with only a small amount of additional computational or memory costs, and provides further improvements on existing continual learning algorithms, particularly in a long-tail task sequence.","sentences":["Continual learning, an important aspect of artificial intelligence and machine learning research, focuses on developing models that learn and adapt to new tasks while retaining previously acquired knowledge.","Existing continual learning algorithms usually involve a small number of tasks with uniform sizes and may not accurately represent real-world learning scenarios.","In this paper, we investigate the performance of continual learning algorithms with a large number of tasks drawn from a task distribution that is long-tail in terms of task sizes.","We design one synthetic dataset and two real-world continual learning datasets to evaluate the performance of existing algorithms in such a setting.","Moreover, we study an overlooked factor in continual learning, the optimizer states, e.g. first and second moments in the Adam optimizer, and investigate how it can be used to improve continual learning performance.","We propose a method that reuses the optimizer states in Adam by maintaining a weighted average of the second moments from previous tasks.","We demonstrate that our method, compatible with most existing continual learning algorithms, effectively reduces forgetting with only a small amount of additional computational or memory costs, and provides further improvements on existing continual learning algorithms, particularly in a long-tail task sequence."],"url":"http://arxiv.org/abs/2404.02754v1"}
{"created":"2024-04-03 13:44:41","title":"Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models","abstract":"This study explores the role of cross-attention during inference in text-conditional diffusion models. We find that cross-attention outputs converge to a fixed point after few inference steps. Accordingly, the time point of convergence naturally divides the entire inference process into two stages: an initial semantics-planning stage, during which, the model relies on cross-attention to plan text-oriented visual semantics, and a subsequent fidelity-improving stage, during which the model tries to generate images from previously planned semantics. Surprisingly, ignoring text conditions in the fidelity-improving stage not only reduces computation complexity, but also maintains model performance. This yields a simple and training-free method called TGATE for efficient generation, which caches the cross-attention output once it converges and keeps it fixed during the remaining inference steps. Our empirical study on the MS-COCO validation set confirms its effectiveness. The source code of TGATE is available at https://github.com/HaozheLiu-ST/T-GATE.","sentences":["This study explores the role of cross-attention during inference in text-conditional diffusion models.","We find that cross-attention outputs converge to a fixed point after few inference steps.","Accordingly, the time point of convergence naturally divides the entire inference process into two stages: an initial semantics-planning stage, during which, the model relies on cross-attention to plan text-oriented visual semantics, and a subsequent fidelity-improving stage, during which the model tries to generate images from previously planned semantics.","Surprisingly, ignoring text conditions in the fidelity-improving stage not only reduces computation complexity, but also maintains model performance.","This yields a simple and training-free method called TGATE for efficient generation, which caches the cross-attention output once it converges and keeps it fixed during the remaining inference steps.","Our empirical study on the MS-COCO validation set confirms its effectiveness.","The source code of TGATE is available at https://github.com/HaozheLiu-ST/T-GATE."],"url":"http://arxiv.org/abs/2404.02747v1"}
{"created":"2024-04-03 13:39:59","title":"IEEE VIS Workshop on Visualization for Climate Action and Sustainability","abstract":"This first workshop on visualization for climate action and sustainability aims to explore and consolidate the role of data visualization in accelerating action towards addressing the current environmental crisis. Given the urgency and impact of the environmental crisis, we ask how our skills, research methods, and innovations can help by empowering people and organizations. We believe visualization holds an enormous power to aid understanding, decision making, communication, discussion, participation, education, and exploration of complex topics around climate action and sustainability. Hence, this workshop invites submissions and discussion around these topics with the goal of establishing a visible and actionable link between these fields and their respective stakeholders. The workshop solicits work-in-progress and research papers as well as pictorials and interactive demos from the whole range of visualization research (dashboards, interactive spaces, scientific visualization, storytelling, visual analytics, explainability etc.), within the context of environmentalism (climate science, sustainability, energy, circular economy, biodiversity, etc.) and across a range of scenarios from public awareness and understanding, visual analysis, expert decision making, science communication, personal decision making etc. After presentations of submissions, the workshop will feature dedicated discussion groups around data driven interactive experiences for the public, and tools for personal and professional decision making.","sentences":["This first workshop on visualization for climate action and sustainability aims to explore and consolidate the role of data visualization in accelerating action towards addressing the current environmental crisis.","Given the urgency and impact of the environmental crisis, we ask how our skills, research methods, and innovations can help by empowering people and organizations.","We believe visualization holds an enormous power to aid understanding, decision making, communication, discussion, participation, education, and exploration of complex topics around climate action and sustainability.","Hence, this workshop invites submissions and discussion around these topics with the goal of establishing a visible and actionable link between these fields and their respective stakeholders.","The workshop solicits work-in-progress and research papers as well as pictorials and interactive demos from the whole range of visualization research (dashboards, interactive spaces, scientific visualization, storytelling, visual analytics, explainability etc.), within the context of environmentalism (climate science, sustainability, energy, circular economy, biodiversity, etc.) and across a range of scenarios from public awareness and understanding, visual analysis, expert decision making, science communication, personal decision making etc.","After presentations of submissions, the workshop will feature dedicated discussion groups around data driven interactive experiences for the public, and tools for personal and professional decision making."],"url":"http://arxiv.org/abs/2404.02743v1"}
{"created":"2024-04-03 13:39:29","title":"LiDAR4D: Dynamic Neural Fields for Novel Space-time View LiDAR Synthesis","abstract":"Although neural radiance fields (NeRFs) have achieved triumphs in image novel view synthesis (NVS), LiDAR NVS remains largely unexplored. Previous LiDAR NVS methods employ a simple shift from image NVS methods while ignoring the dynamic nature and the large-scale reconstruction problem of LiDAR point clouds. In light of this, we propose LiDAR4D, a differentiable LiDAR-only framework for novel space-time LiDAR view synthesis. In consideration of the sparsity and large-scale characteristics, we design a 4D hybrid representation combined with multi-planar and grid features to achieve effective reconstruction in a coarse-to-fine manner. Furthermore, we introduce geometric constraints derived from point clouds to improve temporal consistency. For the realistic synthesis of LiDAR point clouds, we incorporate the global optimization of ray-drop probability to preserve cross-region patterns. Extensive experiments on KITTI-360 and NuScenes datasets demonstrate the superiority of our method in accomplishing geometry-aware and time-consistent dynamic reconstruction. Codes are available at https://github.com/ispc-lab/LiDAR4D.","sentences":["Although neural radiance fields (NeRFs) have achieved triumphs in image novel view synthesis (NVS), LiDAR NVS remains largely unexplored.","Previous LiDAR NVS methods employ a simple shift from image NVS methods while ignoring the dynamic nature and the large-scale reconstruction problem of LiDAR point clouds.","In light of this, we propose LiDAR4D, a differentiable LiDAR-only framework for novel space-time LiDAR view synthesis.","In consideration of the sparsity and large-scale characteristics, we design a 4D hybrid representation combined with multi-planar and grid features to achieve effective reconstruction in a coarse-to-fine manner.","Furthermore, we introduce geometric constraints derived from point clouds to improve temporal consistency.","For the realistic synthesis of LiDAR point clouds, we incorporate the global optimization of ray-drop probability to preserve cross-region patterns.","Extensive experiments on KITTI-360 and NuScenes datasets demonstrate the superiority of our method in accomplishing geometry-aware and time-consistent dynamic reconstruction.","Codes are available at https://github.com/ispc-lab/LiDAR4D."],"url":"http://arxiv.org/abs/2404.02742v1"}
{"created":"2024-04-03 13:38:49","title":"Mixing Individual and Collective Behaviours to Predict Out-of-Routine Mobility","abstract":"Predicting human displacements is crucial for addressing various societal challenges, including urban design, traffic congestion, epidemic management, and migration dynamics. While predictive models like deep learning and Markov models offer insights into individual mobility, they often struggle with out-of-routine behaviours. Our study introduces an approach that dynamically integrates individual and collective mobility behaviours, leveraging collective intelligence to enhance prediction accuracy. Evaluating the model on millions of privacy-preserving trajectories across three US cities, we demonstrate its superior performance in predicting out-of-routine mobility, surpassing even advanced deep learning methods. Spatial analysis highlights the model's effectiveness near urban areas with a high density of points of interest, where collective behaviours strongly influence mobility. During disruptive events like the COVID-19 pandemic, our model retains predictive capabilities, unlike individual-based models. By bridging the gap between individual and collective behaviours, our approach offers transparent and accurate predictions, crucial for addressing contemporary mobility challenges.","sentences":["Predicting human displacements is crucial for addressing various societal challenges, including urban design, traffic congestion, epidemic management, and migration dynamics.","While predictive models like deep learning and Markov models offer insights into individual mobility, they often struggle with out-of-routine behaviours.","Our study introduces an approach that dynamically integrates individual and collective mobility behaviours, leveraging collective intelligence to enhance prediction accuracy.","Evaluating the model on millions of privacy-preserving trajectories across three US cities, we demonstrate its superior performance in predicting out-of-routine mobility, surpassing even advanced deep learning methods.","Spatial analysis highlights the model's effectiveness near urban areas with a high density of points of interest, where collective behaviours strongly influence mobility.","During disruptive events like the COVID-19 pandemic, our model retains predictive capabilities, unlike individual-based models.","By bridging the gap between individual and collective behaviours, our approach offers transparent and accurate predictions, crucial for addressing contemporary mobility challenges."],"url":"http://arxiv.org/abs/2404.02740v1"}
{"created":"2024-04-03 13:35:51","title":"Adaptive Affinity-Based Generalization For MRI Imaging Segmentation Across Resource-Limited Settings","abstract":"The joint utilization of diverse data sources for medical imaging segmentation has emerged as a crucial area of research, aiming to address challenges such as data heterogeneity, domain shift, and data quality discrepancies. Integrating information from multiple data domains has shown promise in improving model generalizability and adaptability. However, this approach often demands substantial computational resources, hindering its practicality. In response, knowledge distillation (KD) has garnered attention as a solution. KD involves training light-weight models to emulate the behavior of more resource-intensive models, thereby mitigating the computational burden while maintaining performance. This paper addresses the pressing need to develop a lightweight and generalizable model for medical imaging segmentation that can effectively handle data integration challenges. Our proposed approach introduces a novel relation-based knowledge framework by seamlessly combining adaptive affinity-based and kernel-based distillation through a gram matrix that can capture the style representation across features. This methodology empowers the student model to accurately replicate the feature representations of the teacher model, facilitating robust performance even in the face of domain shift and data heterogeneity. To validate our innovative approach, we conducted experiments on publicly available multi-source prostate MRI data. The results demonstrate a significant enhancement in segmentation performance using lightweight networks. Notably, our method achieves this improvement while reducing both inference time and storage usage, rendering it a practical and efficient solution for real-time medical imaging segmentation.","sentences":["The joint utilization of diverse data sources for medical imaging segmentation has emerged as a crucial area of research, aiming to address challenges such as data heterogeneity, domain shift, and data quality discrepancies.","Integrating information from multiple data domains has shown promise in improving model generalizability and adaptability.","However, this approach often demands substantial computational resources, hindering its practicality.","In response, knowledge distillation (KD) has garnered attention as a solution.","KD involves training light-weight models to emulate the behavior of more resource-intensive models, thereby mitigating the computational burden while maintaining performance.","This paper addresses the pressing need to develop a lightweight and generalizable model for medical imaging segmentation that can effectively handle data integration challenges.","Our proposed approach introduces a novel relation-based knowledge framework by seamlessly combining adaptive affinity-based and kernel-based distillation through a gram matrix that can capture the style representation across features.","This methodology empowers the student model to accurately replicate the feature representations of the teacher model, facilitating robust performance even in the face of domain shift and data heterogeneity.","To validate our innovative approach, we conducted experiments on publicly available multi-source prostate MRI data.","The results demonstrate a significant enhancement in segmentation performance using lightweight networks.","Notably, our method achieves this improvement while reducing both inference time and storage usage, rendering it a practical and efficient solution for real-time medical imaging segmentation."],"url":"http://arxiv.org/abs/2404.02738v1"}
{"created":"2024-04-03 13:34:09","title":"InstantStyle: Free Lunch towards Style-Preserving in Text-to-Image Generation","abstract":"Tuning-free diffusion-based models have demonstrated significant potential in the realm of image personalization and customization. However, despite this notable progress, current models continue to grapple with several complex challenges in producing style-consistent image generation. Firstly, the concept of style is inherently underdetermined, encompassing a multitude of elements such as color, material, atmosphere, design, and structure, among others. Secondly, inversion-based methods are prone to style degradation, often resulting in the loss of fine-grained details. Lastly, adapter-based approaches frequently require meticulous weight tuning for each reference image to achieve a balance between style intensity and text controllability. In this paper, we commence by examining several compelling yet frequently overlooked observations. We then proceed to introduce InstantStyle, a framework designed to address these issues through the implementation of two key strategies: 1) A straightforward mechanism that decouples style and content from reference images within the feature space, predicated on the assumption that features within the same space can be either added to or subtracted from one another. 2) The injection of reference image features exclusively into style-specific blocks, thereby preventing style leaks and eschewing the need for cumbersome weight tuning, which often characterizes more parameter-heavy designs.Our work demonstrates superior visual stylization outcomes, striking an optimal balance between the intensity of style and the controllability of textual elements. Our codes will be available at https://github.com/InstantStyle/InstantStyle.","sentences":["Tuning-free diffusion-based models have demonstrated significant potential in the realm of image personalization and customization.","However, despite this notable progress, current models continue to grapple with several complex challenges in producing style-consistent image generation.","Firstly, the concept of style is inherently underdetermined, encompassing a multitude of elements such as color, material, atmosphere, design, and structure, among others.","Secondly, inversion-based methods are prone to style degradation, often resulting in the loss of fine-grained details.","Lastly, adapter-based approaches frequently require meticulous weight tuning for each reference image to achieve a balance between style intensity and text controllability.","In this paper, we commence by examining several compelling yet frequently overlooked observations.","We then proceed to introduce InstantStyle, a framework designed to address these issues through the implementation of two key strategies: 1) A straightforward mechanism that decouples style and content from reference images within the feature space, predicated on the assumption that features within the same space can be either added to or subtracted from one another.","2) The injection of reference image features exclusively into style-specific blocks, thereby preventing style leaks and eschewing the need for cumbersome weight tuning, which often characterizes more parameter-heavy designs.","Our work demonstrates superior visual stylization outcomes, striking an optimal balance between the intensity of style and the controllability of textual elements.","Our codes will be available at https://github.com/InstantStyle/InstantStyle."],"url":"http://arxiv.org/abs/2404.02733v1"}
{"created":"2024-04-03 13:32:33","title":"Usage of OpenAlex for creating meaningful global overlay maps of science on the individual and institutional levels","abstract":"Global overlay maps of science use base maps that are overlaid by specific data (from single researchers, institutions, or countries) for visualizing scientific performance such as field-specific paper output. A procedure to create global overlay maps using OpenAlex is proposed. Six different global base maps are provided. Using one of these base maps, example overlay maps for one individual (the first author of this paper) and his research institution are shown and analyzed. A method for normalizing the overlay data is proposed. Overlay maps using raw overlay data display general concepts more pronounced than their counterparts using normalized overlay data. Advantages and limitations of the proposed overlay approach are discussed.","sentences":["Global overlay maps of science use base maps that are overlaid by specific data (from single researchers, institutions, or countries) for visualizing scientific performance such as field-specific paper output.","A procedure to create global overlay maps using OpenAlex is proposed.","Six different global base maps are provided.","Using one of these base maps, example overlay maps for one individual (the first author of this paper) and his research institution are shown and analyzed.","A method for normalizing the overlay data is proposed.","Overlay maps using raw overlay data display general concepts more pronounced than their counterparts using normalized overlay data.","Advantages and limitations of the proposed overlay approach are discussed."],"url":"http://arxiv.org/abs/2404.02732v1"}
{"created":"2024-04-03 13:29:12","title":"Learning Sequence Attractors in Recurrent Networks with Hidden Neurons","abstract":"The brain is targeted for processing temporal sequence information. It remains largely unclear how the brain learns to store and retrieve sequence memories. Here, we study how recurrent networks of binary neurons learn sequence attractors to store predefined pattern sequences and retrieve them robustly. We show that to store arbitrary pattern sequences, it is necessary for the network to include hidden neurons even though their role in displaying sequence memories is indirect. We develop a local learning algorithm to learn sequence attractors in the networks with hidden neurons. The algorithm is proven to converge and lead to sequence attractors. We demonstrate that the network model can store and retrieve sequences robustly on synthetic and real-world datasets. We hope that this study provides new insights in understanding sequence memory and temporal information processing in the brain.","sentences":["The brain is targeted for processing temporal sequence information.","It remains largely unclear how the brain learns to store and retrieve sequence memories.","Here, we study how recurrent networks of binary neurons learn sequence attractors to store predefined pattern sequences and retrieve them robustly.","We show that to store arbitrary pattern sequences, it is necessary for the network to include hidden neurons even though their role in displaying sequence memories is indirect.","We develop a local learning algorithm to learn sequence attractors in the networks with hidden neurons.","The algorithm is proven to converge and lead to sequence attractors.","We demonstrate that the network model can store and retrieve sequences robustly on synthetic and real-world datasets.","We hope that this study provides new insights in understanding sequence memory and temporal information processing in the brain."],"url":"http://arxiv.org/abs/2404.02729v1"}
{"created":"2024-04-03 13:28:52","title":"Unsupervised Learning of Effective Actions in Robotics","abstract":"Learning actions that are relevant to decision-making and can be executed effectively is a key problem in autonomous robotics. Current state-of-the-art action representations in robotics lack proper effect-driven learning of the robot's actions. Although successful in solving manipulation tasks, deep learning methods also lack this ability, in addition to their high cost in terms of memory or training data. In this paper, we propose an unsupervised algorithm to discretize a continuous motion space and generate \"action prototypes\", each producing different effects in the environment. After an exploration phase, the algorithm automatically builds a representation of the effects and groups motions into action prototypes, where motions more likely to produce an effect are represented more than those that lead to negligible changes. We evaluate our method on a simulated stair-climbing reinforcement learning task, and the preliminary results show that our effect driven discretization outperforms uniformly and randomly sampled discretizations in convergence speed and maximum reward.","sentences":["Learning actions that are relevant to decision-making and can be executed effectively is a key problem in autonomous robotics.","Current state-of-the-art action representations in robotics lack proper effect-driven learning of the robot's actions.","Although successful in solving manipulation tasks, deep learning methods also lack this ability, in addition to their high cost in terms of memory or training data.","In this paper, we propose an unsupervised algorithm to discretize a continuous motion space and generate \"action prototypes\", each producing different effects in the environment.","After an exploration phase, the algorithm automatically builds a representation of the effects and groups motions into action prototypes, where motions more likely to produce an effect are represented more than those that lead to negligible changes.","We evaluate our method on a simulated stair-climbing reinforcement learning task, and the preliminary results show that our effect driven discretization outperforms uniformly and randomly sampled discretizations in convergence speed and maximum reward."],"url":"http://arxiv.org/abs/2404.02728v1"}
{"created":"2024-04-03 13:27:54","title":"Harnessing the Power of Large Vision Language Models for Synthetic Image Detection","abstract":"In recent years, the emergence of models capable of generating images from text has attracted considerable interest, offering the possibility of creating realistic images from text descriptions. Yet these advances have also raised concerns about the potential misuse of these images, including the creation of misleading content such as fake news and propaganda. This study investigates the effectiveness of using advanced vision-language models (VLMs) for synthetic image identification. Specifically, the focus is on tuning state-of-the-art image captioning models for synthetic image detection. By harnessing the robust understanding capabilities of large VLMs, the aim is to distinguish authentic images from synthetic images produced by diffusion-based models. This study contributes to the advancement of synthetic image detection by exploiting the capabilities of visual language models such as BLIP-2 and ViTGPT2. By tailoring image captioning models, we address the challenges associated with the potential misuse of synthetic images in real-world applications. Results described in this paper highlight the promising role of VLMs in the field of synthetic image detection, outperforming conventional image-based detection techniques. Code and models can be found at https://github.com/Mamadou-Keita/VLM-DETECT.","sentences":["In recent years, the emergence of models capable of generating images from text has attracted considerable interest, offering the possibility of creating realistic images from text descriptions.","Yet these advances have also raised concerns about the potential misuse of these images, including the creation of misleading content such as fake news and propaganda.","This study investigates the effectiveness of using advanced vision-language models (VLMs) for synthetic image identification.","Specifically, the focus is on tuning state-of-the-art image captioning models for synthetic image detection.","By harnessing the robust understanding capabilities of large VLMs, the aim is to distinguish authentic images from synthetic images produced by diffusion-based models.","This study contributes to the advancement of synthetic image detection by exploiting the capabilities of visual language models such as BLIP-2 and ViTGPT2.","By tailoring image captioning models, we address the challenges associated with the potential misuse of synthetic images in real-world applications.","Results described in this paper highlight the promising role of VLMs in the field of synthetic image detection, outperforming conventional image-based detection techniques.","Code and models can be found at https://github.com/Mamadou-Keita/VLM-DETECT."],"url":"http://arxiv.org/abs/2404.02726v1"}
{"created":"2024-04-03 13:23:32","title":"Deterministic Identification Codes for Fading Channels","abstract":"Many communication applications incorporate event-triggered behavior, where the conventional Shannon capacity may not effectively gauge performance. Consequently, we advocate for the concept of identification capacity as a more suitable metric for assessing these systems. We consider deterministic identification codes for the Gaussian AWGN, the slow fading, and the fast fading channels with power constraints. We prove lower bounds on capacities for the slow and the fast fading channels with side information for a wide range of fading distributions. Additionally, we present the code construction with efficient encoding which achieves the lower bound on capacity both for the slow and the fast fading channels. At last, we prove the same lower bound on the capacity of the fast fading channel without side information, i.e. the same lower bound holds even when the receiver doesn't know the fading coefficients. As a result we show that compared with Shannon's message transmission paradigm we achieved completely different capacity scaling for deterministic identification codes for all relevant fading channels.","sentences":["Many communication applications incorporate event-triggered behavior, where the conventional Shannon capacity may not effectively gauge performance.","Consequently, we advocate for the concept of identification capacity as a more suitable metric for assessing these systems.","We consider deterministic identification codes for the Gaussian AWGN, the slow fading, and the fast fading channels with power constraints.","We prove lower bounds on capacities for the slow and the fast fading channels with side information for a wide range of fading distributions.","Additionally, we present the code construction with efficient encoding which achieves the lower bound on capacity both for the slow and the fast fading channels.","At last, we prove the same lower bound on the capacity of the fast fading channel without side information, i.e. the same lower bound holds even when the receiver doesn't know the fading coefficients.","As a result we show that compared with Shannon's message transmission paradigm we achieved completely different capacity scaling for deterministic identification codes for all relevant fading channels."],"url":"http://arxiv.org/abs/2404.02723v1"}
{"created":"2024-04-03 13:22:47","title":"On-line conformalized neural networks ensembles for probabilistic forecasting of day-ahead electricity prices","abstract":"Probabilistic electricity price forecasting (PEPF) is subject of increasing interest, following the demand for proper quantification of prediction uncertainty, to support the operation in complex power markets with increasing share of renewable generation. Distributional neural networks ensembles have been recently shown to outperform state of the art PEPF benchmarks. Still, they require critical reliability enhancements, as fail to pass the coverage tests at various steps on the prediction horizon. In this work, we propose a novel approach to PEPF, extending the state of the art neural networks ensembles based methods through conformal inference based techniques, deployed within an on-line recalibration procedure. Experiments have been conducted on multiple market regions, achieving day-ahead forecasts with improved hourly coverage and stable probabilistic scores.","sentences":["Probabilistic electricity price forecasting (PEPF) is subject of increasing interest, following the demand for proper quantification of prediction uncertainty, to support the operation in complex power markets with increasing share of renewable generation.","Distributional neural networks ensembles have been recently shown to outperform state of the art PEPF benchmarks.","Still, they require critical reliability enhancements, as fail to pass the coverage tests at various steps on the prediction horizon.","In this work, we propose a novel approach to PEPF, extending the state of the art neural networks ensembles based methods through conformal inference based techniques, deployed within an on-line recalibration procedure.","Experiments have been conducted on multiple market regions, achieving day-ahead forecasts with improved hourly coverage and stable probabilistic scores."],"url":"http://arxiv.org/abs/2404.02722v1"}
{"created":"2024-04-03 13:21:58","title":"Can We Understand Plasticity Through Neural Collapse?","abstract":"This paper explores the connection between two recently identified phenomena in deep learning: plasticity loss and neural collapse. We analyze their correlation in different scenarios, revealing a significant association during the initial training phase on the first task. Additionally, we introduce a regularization approach to mitigate neural collapse, demonstrating its effectiveness in alleviating plasticity loss in this specific setting.","sentences":["This paper explores the connection between two recently identified phenomena in deep learning: plasticity loss and neural collapse.","We analyze their correlation in different scenarios, revealing a significant association during the initial training phase on the first task.","Additionally, we introduce a regularization approach to mitigate neural collapse, demonstrating its effectiveness in alleviating plasticity loss in this specific setting."],"url":"http://arxiv.org/abs/2404.02719v1"}
{"created":"2024-04-03 13:20:36","title":"Evolving Agents: Interactive Simulation of Dynamic and Diverse Human Personalities","abstract":"Human-like Agents with diverse and dynamic personality could serve as an important design probe in the process of user-centered design, thereby enabling designers to enhance the user experience of interactive application.In this article, we introduce Evolving Agents, a novel agent architecture that consists of two systems: Personality and Behavior. The Personality system includes three modules: Cognition, Emotion and Character Growth. The Behavior system comprises two modules: Planning and Action. We also build a simulation platform that enables agents to interact with the environment and other agents. Evolving Agents can simulate the human personality evolution process. Compared to its initial state, agents' personality and behavior patterns undergo believable development after several days of simulation. Agents reflect on their behavior to reason and develop new personality traits. These traits, in turn, generate new behavior patterns, forming a feedback loop-like personality evolution.In our experiment, we utilized simulation platform with 10 agents for evaluation. During the evaluation, these agents experienced believable and inspirational personality evolution. Through ablation and control experiments, we demonstrated the outstanding effectiveness of agent personality evolution and all modules of our agent architecture contribute to creating believable human-like agents with diverse and dynamic personalities. We also demonstrated through workshops how Evolving Agents could inspire designers.","sentences":["Human-like Agents with diverse and dynamic personality could serve as an important design probe in the process of user-centered design, thereby enabling designers to enhance the user experience of interactive application.","In this article, we introduce Evolving Agents, a novel agent architecture that consists of two systems: Personality and Behavior.","The Personality system includes three modules: Cognition, Emotion and Character Growth.","The Behavior system comprises two modules: Planning and Action.","We also build a simulation platform that enables agents to interact with the environment and other agents.","Evolving Agents can simulate the human personality evolution process.","Compared to its initial state, agents' personality and behavior patterns undergo believable development after several days of simulation.","Agents reflect on their behavior to reason and develop new personality traits.","These traits, in turn, generate new behavior patterns, forming a feedback loop-like personality evolution.","In our experiment, we utilized simulation platform with 10 agents for evaluation.","During the evaluation, these agents experienced believable and inspirational personality evolution.","Through ablation and control experiments, we demonstrated the outstanding effectiveness of agent personality evolution and all modules of our agent architecture contribute to creating believable human-like agents with diverse and dynamic personalities.","We also demonstrated through workshops how Evolving Agents could inspire designers."],"url":"http://arxiv.org/abs/2404.02718v1"}
{"created":"2024-04-03 13:20:24","title":"Automatic Prompt Selection for Large Language Models","abstract":"Large Language Models (LLMs) can perform various natural language processing tasks with suitable instruction prompts. However, designing effective prompts manually is challenging and time-consuming. Existing methods for automatic prompt optimization either lack flexibility or efficiency. In this paper, we propose an effective approach to automatically select the optimal prompt for a given input from a finite set of synthetic candidate prompts. Our approach consists of three steps: (1) clustering the training data and generating candidate prompts for each cluster using an LLM-based prompt generator; (2) synthesizing a dataset of input-prompt-output tuples for training a prompt evaluator to rank the prompts based on their relevance to the input; (3) using the prompt evaluator to select the best prompt for a new input at test time. Our approach balances prompt generality-specificity and eliminates the need for resource-intensive training and inference. It demonstrates competitive performance on zero-shot question-answering datasets: GSM8K, MultiArith, and AQuA.","sentences":["Large Language Models (LLMs) can perform various natural language processing tasks with suitable instruction prompts.","However, designing effective prompts manually is challenging and time-consuming.","Existing methods for automatic prompt optimization either lack flexibility or efficiency.","In this paper, we propose an effective approach to automatically select the optimal prompt for a given input from a finite set of synthetic candidate prompts.","Our approach consists of three steps: (1) clustering the training data and generating candidate prompts for each cluster using an LLM-based prompt generator; (2) synthesizing a dataset of input-prompt-output tuples for training a prompt evaluator to rank the prompts based on their relevance to the input; (3) using the prompt evaluator to select the best prompt for a new input at test time.","Our approach balances prompt generality-specificity and eliminates the need for resource-intensive training and inference.","It demonstrates competitive performance on zero-shot question-answering datasets: GSM8K, MultiArith, and AQuA."],"url":"http://arxiv.org/abs/2404.02717v1"}
{"created":"2024-04-03 13:08:26","title":"ART: The Alternating Reading Task Corpus for Speech Entrainment and Imitation","abstract":"We introduce the Alternating Reading Task (ART) Corpus, a collection of dyadic sentence reading for studying the entrainment and imitation behaviour in speech communication. The ART corpus features three experimental conditions - solo reading, alternating reading, and deliberate imitation - as well as three sub-corpora encompassing French-, Italian-, and Slovak-accented English. This design allows systematic investigation of speech entrainment in a controlled and less-spontaneous setting. Alongside detailed transcriptions, it includes English proficiency scores, demographics, and in-experiment questionnaires for probing linguistic, personal and interpersonal influences on entrainment. Our presentation covers its design, collection, annotation processes, initial analysis, and future research prospects.","sentences":["We introduce the Alternating Reading Task (ART) Corpus, a collection of dyadic sentence reading for studying the entrainment and imitation behaviour in speech communication.","The ART corpus features three experimental conditions - solo reading, alternating reading, and deliberate imitation - as well as three sub-corpora encompassing French-, Italian-, and Slovak-accented English.","This design allows systematic investigation of speech entrainment in a controlled and less-spontaneous setting.","Alongside detailed transcriptions, it includes English proficiency scores, demographics, and in-experiment questionnaires for probing linguistic, personal and interpersonal influences on entrainment.","Our presentation covers its design, collection, annotation processes, initial analysis, and future research prospects."],"url":"http://arxiv.org/abs/2404.02710v1"}
{"created":"2024-04-03 13:07:58","title":"Building test batteries based on analysing random number generator tests within the framework of algorithmic information theory","abstract":"The problem of testing random number generators is considered and it is shown that an approach based on algorithmic information theory allows us to compare the power of different tests in some cases where the available methods of mathematical statistics do not distinguish between the tests. In particular, it is shown that tests based on data compression methods using dictionaries should be included in the test batteries.","sentences":["The problem of testing random number generators is considered and it is shown that an approach based on algorithmic information theory allows us to compare the power of different tests in some cases where the available methods of mathematical statistics do not distinguish between the tests.","In particular, it is shown that tests based on data compression methods using dictionaries should be included in the test batteries."],"url":"http://arxiv.org/abs/2404.02708v1"}
{"created":"2024-04-03 13:06:21","title":"Unblind Text Inputs: Predicting Hint-text of Text Input in Mobile Apps via LLM","abstract":"Mobile apps have become indispensable for accessing and participating in various environments, especially for low-vision users. Users with visual impairments can use screen readers to read the content of each screen and understand the content that needs to be operated. Screen readers need to read the hint-text attribute in the text input component to remind visually impaired users what to fill in. Unfortunately, based on our analysis of 4,501 Android apps with text inputs, over 0.76 of them are missing hint-text. These issues are mostly caused by developers' lack of awareness when considering visually impaired individuals. To overcome these challenges, we developed an LLM-based hint-text generation model called HintDroid, which analyzes the GUI information of input components and uses in-context learning to generate the hint-text. To ensure the quality of hint-text generation, we further designed a feedback-based inspection mechanism to further adjust hint-text. The automated experiments demonstrate the high BLEU and a user study further confirms its usefulness. HintDroid can not only help visually impaired individuals, but also help ordinary people understand the requirements of input components. HintDroid demo video: https://youtu.be/FWgfcctRbfI.","sentences":["Mobile apps have become indispensable for accessing and participating in various environments, especially for low-vision users.","Users with visual impairments can use screen readers to read the content of each screen and understand the content that needs to be operated.","Screen readers need to read the hint-text attribute in the text input component to remind visually impaired users what to fill in.","Unfortunately, based on our analysis of 4,501 Android apps with text inputs, over 0.76 of them are missing hint-text.","These issues are mostly caused by developers' lack of awareness when considering visually impaired individuals.","To overcome these challenges, we developed an LLM-based hint-text generation model called HintDroid, which analyzes the GUI information of input components and uses in-context learning to generate the hint-text.","To ensure the quality of hint-text generation, we further designed a feedback-based inspection mechanism to further adjust hint-text.","The automated experiments demonstrate the high BLEU and a user study further confirms its usefulness.","HintDroid can not only help visually impaired individuals, but also help ordinary people understand the requirements of input components.","HintDroid demo video: https://youtu.be/FWgfcctRbfI."],"url":"http://arxiv.org/abs/2404.02706v1"}
{"created":"2024-04-03 13:00:08","title":"PromptCodec: High-Fidelity Neural Speech Codec using Disentangled Representation Learning based Adaptive Feature-aware Prompt Encoders","abstract":"Neural speech codec has recently gained widespread attention in generative speech modeling domains, like voice conversion, text-to-speech synthesis, etc. However, ensuring high-fidelity audio reconstruction of speech codecs under high compression rates remains an open and challenging issue. In this paper, we propose PromptCodec, a novel end-to-end neural speech codec model using disentangled representation learning based feature-aware prompt encoders. By incorporating additional feature representations from prompt encoders, PromptCodec can distribute the speech information requiring processing and enhance its capabilities. Moreover, a simple yet effective adaptive feature weighted fusion approach is introduced to integrate features of different encoders. Meanwhile, we propose a novel disentangled representation learning strategy based on cosine distance to optimize PromptCodec's encoders to ensure their efficiency, thereby further improving the performance of PromptCodec. Experiments on LibriTTS demonstrate that our proposed PromptCodec consistently outperforms state-of-the-art neural speech codec models under all different bitrate conditions while achieving impressive performance with low bitrates.","sentences":["Neural speech codec has recently gained widespread attention in generative speech modeling domains, like voice conversion, text-to-speech synthesis, etc.","However, ensuring high-fidelity audio reconstruction of speech codecs under high compression rates remains an open and challenging issue.","In this paper, we propose PromptCodec, a novel end-to-end neural speech codec model using disentangled representation learning based feature-aware prompt encoders.","By incorporating additional feature representations from prompt encoders, PromptCodec can distribute the speech information requiring processing and enhance its capabilities.","Moreover, a simple yet effective adaptive feature weighted fusion approach is introduced to integrate features of different encoders.","Meanwhile, we propose a novel disentangled representation learning strategy based on cosine distance to optimize PromptCodec's encoders to ensure their efficiency, thereby further improving the performance of PromptCodec.","Experiments on LibriTTS demonstrate that our proposed PromptCodec consistently outperforms state-of-the-art neural speech codec models under all different bitrate conditions while achieving impressive performance with low bitrates."],"url":"http://arxiv.org/abs/2404.02702v1"}
